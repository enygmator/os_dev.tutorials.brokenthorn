{
  "articles/01_Intro_to_OSDev/1_Overview.html": {
    "href": "articles/01_Intro_to_OSDev/1_Overview.html",
    "title": "Introduction to OS Development | BrokenThorn OS Dev Tutorials",
    "keywords": "Introduction to OS Development This section introduces you to the OS development world, it's basic details and how to go about developing an OS in general, before actually starting the development of an OS, which is done in the next section (which also teaches you theory on how machines/chips work at the lowest levels). In this section we have 6 pages : Programming Computers with Programming Languages : This section introduces you to the various programming languages required to develop at the OS level. The C Programming Language : This section talks about the various features of C language you need to know to code OSes effectively. About Operating Systems and their Development : Here, you get to know a little about what OSes are and how they are built at a very basic level. Getting Setup for OS Development : This section familiarizes you with the OS dev tool chain and helps you get it setup. The History of OS Development : Here, you get to see how OSes have evolved over time, acquiring the features that we see today. Basic Concepts of an Operating system : This section introduces you to all the basic concepts/features of a modern operating system. Note This series uses C and x86 Assembly Language . It is very important to have a good understanding of both of these languages before moving on. This section includes a review of both of these languages. (Yeah, they are pretty old and used at a basic level in all machines)."
  },
  "articles/01_Intro_to_OSDev/2_Programming.html": {
    "href": "articles/01_Intro_to_OSDev/2_Programming.html",
    "title": "Programming Computers with Programming Languages | BrokenThorn OS Dev Tutorials",
    "keywords": "Programming Computers with Programming Languages If you have never programmed before, we would first like to welcome you to the world of programming and computer science. Computer scientists and software engineers use programming methods to build complex software systems that do a certain job. If you have never programmed before, you will be learning a bit of all three right from the start. This tends to make learning the first programming language difficult. However, it becomes easier to learn other programming languages over time. It is more recommended to start with a simpler language, such as Python , and build on that. Then move on to Java or C++ or C# . Java or C# is easier then C++ but it shares a lot of its syntax, so if you pick up Java first, moving to C++ would be a lot easier. In addition, by learning C++ you are also learning a a large subset of C . We recommend the following sites to learn from: cprogramming.com cplusplus.com codecademy.com YouTube also has a lot of really good videos and lectures on software engineering, computer science, and programming. Introduction to Programming The Great Debate: Which Programming Language Should You Learn First? Additional links Beginner's Resources to Learn Programming Languages Title Pro's Tinkering Guide A History of computer programming languages A beginners guide to programming languages Note These tutorials and links are quite old and there may be better places to learn stuff from at this point of time, like online playgrounds where you can quickly test code without setting up an development environment. For example, GeeksForGeeks, Tutorials Point, W3C. etc. I request you to suggest some by opening an issue in github, here . Thanks! Tip I recommend you to use an IDE (Integrated development environment) for writing code and executing it as it has a lot of benefits like syntax highlighting (colors indicating keywords and guiding you through programming), linting (Checking for all kinds of errors, warning and messages) and easier debugging/execution of computer programs. Visual Studio Code is my personal favorite. You can get it here . Though it might be worth noting that we will debug a lot of stuff manually in OS development."
  },
  "articles/01_Intro_to_OSDev/3_C_lang.html": {
    "href": "articles/01_Intro_to_OSDev/3_C_lang.html",
    "title": "The C Programming Language | BrokenThorn OS Dev Tutorials",
    "keywords": "The C Programming Language It is assumed that you already know how to program in C. This is a quick overview of some of the more important parts of the language, and also how they will work for us. Using C in Bootloaders and Kernels 16 bit and 32 bit C In the beginning, while programming your system you will find out that there is nothing at all to help you. When powered on, the system is operating in 16 bit real mode which 32 bit compilers do not support. This is the first important thing: If you want to create a 16 bit real mode OS, you must use a 16 bit C compiler. If, however, you decide that you would like to create a 32 bit OS, you must use a 32 bit C compiler. 16 bit C code is not compatible with 32 bit C code. In the series, we will be creating a 32 bit operating system. Because of this, we will be using a 32 bit C compiler. C and its executable formats A problem with C is that it does not support the ability to output flat binary programs . A flat binary program can basically be defined as a program where the entry point routine (such as main() ) is always at the first byte of the program file. Wait, what? Why would we want this? This goes back to the good old days of DOS COM programming. DOS COM programs were flat binary - they had no well-defined entry point nor symbolic names at all. To execute the program, all that needed to be done was to \"jump\" to the first byte of the program. Flat binary programs have no special internal format, so there was no standard. Its just a bunch of 1's and 0's. When the PC is powered on, the system BIOS ROM takes control. When it is ready to start an OS, it has no idea how to do it. Because of this, it runs another program - the Boot Loader to load an OS. The BIOS does not at all know what internal format this program file is or what it does. Because of this, it treats the Boot Loader as a flat binary program . It loads whatever is on the Boot Sector of the Boot Disk and \"jumps\" to the first byte of that program file and begins to simple \"execute\" the 1s and 0s. Because of this, the first part of the boot loader, also called the Boot Code or Bootloader Stage 1 cannot be in C. This is because all C compilers output a program file that has a special internal format - they can be library files, object files, or executable files. There is only one language that natively supports flat binary generation - assembly language . How to use C in a boot loader While it is true that the first part of the boot loader must be in assembly language, it is possible to use C in a boot loader. There are different ways of doing this. One way is used in both Windows and our own in-house operating system, Neptune. We combine an assembly stub program and the C program in a single file. The assembly stub program sets up the system and calls our C program. Because both of these programs are combined into a single file, Stage 1 only needs to load a single file - which in turn loads both our stub program and C program. This is one method - there are others. Most real boot loaders use C, including GRUB, Neptunes boot loader, Microsoft's NTLDR and Boot Manager. Because we are using 32 bit C, there are also ways that will allow us to mix 16 bit code with our 32 bit C code. Doing this can be fairly complicated and tricky to implement. Because of this, we stick with just using assembly language in the series boot loader. We might cover an advanced tutorial later that can describe methods of using C later on however if the reader demand is great enough. Calling a C kernel When the boot loader is ready, it loads and executes our C kernel by calling its entry point routine. Because the C program follows a specific internal format, the boot loader must know how to parse the file and locate the entry point routine to call it. In the series, we cover how to do this a little later. This allows us to use C for the kernel and other libraries that we build. Pointers in C Introduction Because you are reading this, I assume that you are already good with pointers. In system software, they are used everywhere since we are constantly referring to memory locations in various parts of the system memory (RAM, hard-disk, CPU caches). Because of this, it is very important to master pointers. A pointer is simply a variable that holds the address of something. To define a pointer, we use the * operator: char* pointer; Remember that a pointer stores an \"address\". We do not set the above pointer to anything, so what \"address\" does it refer to? The above code is an example of a wild pointer. A wild pointer is a pointer that can point to anything. Remember that C does not initialize anything for you . Because of this, the above pointer can point to anything. Another variable, address 0, some other piece of data, your own code, a hardware address. The Physical Address Space (PAS) The Physical Address Space (PAS) defines all of the \"Addresses\" that you can use. These addresses can refer to anything that is inside of the PAS. This includes physical memory (RAM), hardware devices, or even nothingness. This is very different then in applications programming in a protected mode OS, like Windows, where all \"addresses\" are memory. Here is an example. In applications programming , the following would cause a segmentation fault error and crash your program: char* pointer = 0; *pointer = 0; This creates a pointer and points it to memory address 0, which you do not \"own\". Because of this, the system does not allow you to write to it. Now, if we try that same exact code again in our future C kernel ... no crash! Instead of crashing, it overwrites the first byte of the Interrupt Vector Table (IVT) which resides at that location in memory. From this, we can make a few important differences: The system will not crash if you use null pointers Pointers can point to any \"address\" in the PAS, which may or may not be memory If you attempt to read from a memory address that does not exist, you will get garbage (whatever was on the system data bus at that time). An attempt to write to a memory address that does not exist does nothing. Writing to a non existent memory address and immediately reading it back may or may not give you the same result just \"written\"...It depends if the data \"written\" is still on the data bus or not. Things get more interesting here. ROM devices are mapped into the same PAS. This means that it is possible for you to read or write certain parts of ROM devices using pointers. A good example of a ROM device is the system BIOS. Because ROM devices are read only, writing to a ROM device is the same effect as writing to a non existent memory location. You can read from ROM devices, however. Other devices may also be mapped into the PAS. This depends on your system configuration. This means reading or writing different parts of the PAS may yield different types of results. As you can tell, pointers play a much bigger role in systems programming then they did in the applications programming world. It may be easier to think of pointers not as a \"variable that points to a memory location\" but rather a \"variable that points to an address in the PAS\" as it may or may not be RAM. Dynamic Memory Allocation In the application programming world, you would normally call malloc() and free() or new and delete to allocate a block of memory from the heap. This is different in the system programming world. To allocate memory, we do this: char* pointer = (char*)0x5000; That is it. Cool, huh? Because we have control over everything, we can just point a pointer to some address in the PAS (would have to be RAM) and say \"there's our new buffer of 1024 bytes\" or something like that. The important thing here is that there is no dynamic memory allocation. Dynamic memory allocation in C and C++ are system services and require an OS to be running. But, wait! Aren't we developing our own OS? That is the problem ðŸ˜ We will need to write our own memory management services and routines in order to be able to provide a malloc() and free() or new and delete . Until then, the only way to \"allocate\" a buffer is to use some unused location in the address space. Inline Assembly (Using assembly inside a C Program) There are some things that C cannot natively do. We will be needing to use assembly language for system services and talking to hardware devices. Most compilers provide a keyword that allows inline assembly. For example, Microsoft Visual C++ uses _asm: _asm cli ; disable interrupts> We can also have blocks of assembly code: _asm { cli hlt } Standard Library and the Run Time Library (RTL) You can use external libraries - if and only if those routines do not use system services. Anything like printf() , scanf() , memory routines, or, virtually everything but the bare minimum routines can be used. About 90% of it will be needed to be rewritten for your own OS, so it is best to write your own. The RTL is the set of services and routines that your application program uses at run time. These, by their nature, require an OS to already be running and to support them. Because of this, you will need to develop your own RTL. The startup RTL code is responsible for calling C++ constructors and destructors . If you are wanting to use C++, you must develop the RTL code to support it. This uses compiler extensions. In the series, we develop both an RTL that supports C and C++ features as well as a basic standard library as needed. Fixing Errors (Debugging) Because there is no printf() or any way to use a debugger, what are you going to do if something is not working? The series uses (and explains) how to use the Bochs Debugger , which is a debugger that comes with the Bochs emulator . This can be used to run your OS as well as for aiding in fixing most of the more common errors that you may run into. The only other way is to develop your own routines that will allow you to output information. At the most this might be able to tell you how far the software gets to before crashing. This is certainly going to be an exciting, one-of-its-kind journey! Next, we will enter the waters of OS Development and setup the tool chain to develop OSes."
  },
  "articles/01_Intro_to_OSDev/4_About_OSDev.html": {
    "href": "articles/01_Intro_to_OSDev/4_About_OSDev.html",
    "title": "About Operating Systems and their Development | BrokenThorn OS Dev Tutorials",
    "keywords": "About Operating Systems and their Development Operating systems can be a very complex topic. Learning how operating systems work can be a great learning experience. The purpose of this series is to teach the black art of Operating System (OS) Development, from the ground up. Whether you want to make your own OS, or simply to learn how they work, this series is for you. About Operating Systems An Operating System provides the basic functionality, look, and feel, for a computer. The primary purpose is to create a workable Operating Environment for the user. An example of an Operating System is Windows, Linux, and Macintosh. If you have never programmed before, computer programming is designing and writing software, or programs, for the computer to load and execute. However, the Operating System needs to be designed with this functionality. An Operating System is not a single program, but a collection of software that work and communicate with each other. This is what I mean by \"Operating Environment\". Because Operating Systems are a collection of software, in order to develop an Operating System, one must know how to develop software. That is, one must know computer programming. If you have never programmed before, take a look at the Requirements section below, and look no further. This section will have links to good tutorials and articles that could help you to learn computer programming with C++ and 80x86 Assembly Language. Knowledge Requirements for developing OSes The C Programming Language Using a high level language, such as C, can make OS development much easier. The most common languages that are used in OS development are C, C++, and Perl. Do not think these are the only languages that may be used; It is possible in other languages. I have even seen one with FreeBASIC! Getting higher level languages to work properly can also make it harder to work within the long run, however. C and C++ are the most common, with C being the most used. C, as being a middle level language, provides high level constructs while still providing low level details that are closer to assembly language, and hence, the system. Because of this, using C is fairly easy in OS development. This is one of the primary reasons why it is the most commonly used: Because the C programming language was originally designed for system level and embedded software development. Here are some references to learn C Language from. The x86 Assembly Language 80x86 Assembly Language is a low level programming language. Assembly Language provides a direct one to one relation with the processor machine instructions, which make assembly language suitable for hardware programming. Assembly Language, as being low level, tend to be more complex and harder to develop in, then high level languages like C. Because of this, and to aid in simplicity, We are only going to use assembly language when required, and no more. Assembly Language is another complex language that can take a book to fill. If you do not know x86 Assembly Language, the following may help: Here is a link to AT&T syntax: AT&T syntax: https://gist.github.com/DmitrySoshnikov/c67cbde1cceb0d6a194830b41baa5c8b inline assembly: https://www.codeproject.com/articles/15971/using-inline-assembly-in-c-c Intel vs ATT syntax: https://www.nayuki.io/page/a-fundamental-introduction-to-x86-assembly-programming inline assembly: https://ibiblio.org/gferg/ldp/GCC-Inline-Assembly-HOWTO.html assembly language (Intel syntax / NASM): https://www.tutorialspoint.com/assembly_programming/ Note The above links are not from the original author. They are links from which I learnt the x86 assembly language. They are pretty good resources for any type of coding you will do in x86 asm . That is all you need to know; Everything else I'll teach along the way. Important From here on out, I will NOT be explaining C or x86 Assembly Language concepts. I will however, still explain new instructions that you may not be familiar with, such as lgdt , and the use of sti , cli , bt , cpuid and some others. Hope you like it!"
  },
  "articles/01_Intro_to_OSDev/5_OSDev_setup.html": {
    "href": "articles/01_Intro_to_OSDev/5_OSDev_setup.html",
    "title": "Getting Setup for OS Development | BrokenThorn OS Dev Tutorials",
    "keywords": "Getting Setup for OS Development In developing low level code, we will need specialized low level software to help us out. Some of these tools are not needed, however, they are highly recommended as they can significantly aid in development. NASM - The Assembler The Netwide Assembler (NASM) can generate flat binary 16bit programs, while most other assemblers (Turbo Assembler (TASM), Microsoft's Macro Assembler (MASM)) cannot. During the development of the OS, some programs must be pure binary executables. Because of this, NASM is a great choice to use. You can download NASM from here . Microsoft Visual C++ Because portability is a concern, most of the code for our operating system will be developed in C. During OS Development, there are some things that we must have control over that not all compilers may support, however. For example, say good bye to all runtime compiler support (templates, exceptions) and the good old standard library! Depending on the design of your system, you may also need to support or change more detailed properties: Such as loading at a specific address, adding your own internal sections in your programs' binary, etc. The basic idea is that not all compilers out there are capable of generating operating system machine/binary code. I will be using Microsoft Visual C++ for developing the system. However, it is also possible to develop in other compilers such as DJGPP, GCC or even Cygwin. Cygwin is a command shell program that is designed to emulate Linux command shell. There is a GCC port for Cygwin. You can download Visual Studio here and then select Desktop development with C++ workload during it's installation. Tool for Copying the Boot Loader The bootloader is a pure binary program that is stored in a single 512 byte sector. It is a very important program as it is impossible to create an OS without it. It is the very first program of your OS that is loaded directly by the BIOS, and executed directly by the processor. We can use NASM to assemble the program, but how do we get it on a floppy disk? We cannot just copy the file. Instead, we have to overwrite the boot record that Windows places (after formatting the virtual/real disk) with our bootloader. Why do we need to do this? Remember that the BIOS only looks at the bootsector when finding a bootable disk. The bootsector, and the \"boot record\" are both in the same sector! Hence, we have to overwrite it. There are a lot of ways we can do this. Here, I will present two. If you are unable to get one method working on your system, our readers may try the other method. Warning Do Not attempt to play with the following software until I explain how to use it. Using this software incorrectly can corrupt the data on your disk or make your PC unbootable. PartCopy - Low Level Disk Copier PartCopy allows the copying of sectors from one drive to another. PartCopy stands for \"Partial copy\". Its function is to copy a certain number of sectors from one location to another, to and from a specific address. You can download it from here . Windows DEBUG Command Windows provides a small command line debugger that may be used through the command line. There are quite a bit of different things that we can do with this software, but all we need it to do is copy our boot loader to the first 512 bytes on disk. Go to the command prompt, and type debug . You will be greeted by a little prompt (-): C:\\Documents and Settings\\Michael>debug - Here is where you enter your commands. h is the help command, q is the quit command. The w (write) command is the most important for us. You can have debug load a file into memory such as, say, our boot loader: C:\\Documents and Settings\\Michael>debug boot_loader.bin - This allows us to perform operations on it. (We can also use debugs L (Load) command to load the file is we wanted to). In the above example, boot_loader.bin will be loaded at address 0x100. To write the file to the first sector of our disk, we need to use the W (Write) command which takes the following form: W [address] [drive] [firstsector] [number] Okay... so let's see: The file is at address 0x100. We want the floppy drive (Drive 0). The first sector is the first sector on the disk (sector 0) and the number of sectors is ehm... 1. Putting this together, this is our command to write boot_loader.bin to the boot sector of a floppy: C:\\Documents and Settings\\Michael>debug boot_loader.bin -w 100 0 0 1 -q VFD - Virtual Floppy Drive Weather you have a floppy drive or not, this program is very useful. It can simulate a real floppy drive from a stored floppy image, or even in RAM. This program creates a virtual floppy image, allows formatting, and copying files (Such as, your kernel perhaps?) directly using Windows Explorer. You can download it from here . Bochs Emulator - PC Emulator and Debugger You pop in a floppy disk into a computer, hoping that it works. You boot your computer and look in awe at your greatest creation! ...Until your floppy motor dies out because you forgot to send the command to the controller in your bootloader. When working with low level code, it is possible to destroy hardware if you are not careful. Also, to test your OS, you will need to reboot your computers hundreds of times during development. Also, what do you do if the computer just reboots? What do you do if your Kernel crashes? Because there is no debugger for your OS, it is virtually impossible to debug. The solution? A PC Emulator. There are plenty available, two of them being VMWare and Bochs Emulator. I will be using Bochs and Microsoft Virtual PC for testing. You can download Bochs from here . Note You do not need to know how to use the software I listed. I will explain how to use them as we start using them. Tip If you would like to run your system on a real computer that does not have a floppy drive, it is still possible to boot from CD even though it is a floppy image. This is done through Floppy Emulation that which most of BIOSs support. Simply get a CD burning software (I personally use MagicISO) that can create a bootable ISO from a floppy image. Then, simply burn the ISO image to a CD and it should work. The Build Process There are a lot of tools listed above. To better understand how they can be useful, we should take a look at the entire build process of the OS: Setting everything up Use VFD to create and format a virtual floppy image to use. Set up Bochs Emulator to boot from the floppy image. The bootloader Assemble the bootloader with NASM to create a flat binary program. Use PartCopy or the DEBUG command to copy the bootloader to the bootsector of the virtual floppy image. The Kernel (And basically all other programs) Assembly and/or compile all sources into an object format (Such as ELF or PE) that can be loaded and executed by the boot loader. Copy kernel into floppy disk using Windows Explorer. Test it! Using Bochs emulator and debugger, using a real floppy disk, or by using MagicISO to create a bootable CD. Some of the terms and concepts listed here may be new to you. Do not worry!ðŸ˜€ everything will be explained in the upcoming sections. The purpose of this section is to create a stepping stone for the rest of the series. This page provides a basic introduction, and a listing of the tools we will be using. I will explain how to use these programs as we need to, so you do not need a tutorial on anything listed here besides what has been listed in the Requirements page. We also have taken a look at the building process for developing an operating system. For the most part, its fairly simple, however it provides a way to see when the programs listed will be used. In the next page we are going to go back in time from the first Disk Operating System (DOS) and take a little tour through history. We will also look at some basic OS concepts."
  },
  "articles/01_Intro_to_OSDev/6_OSDev_History.html": {
    "href": "articles/01_Intro_to_OSDev/6_OSDev_History.html",
    "title": "The History of OS Development | BrokenThorn OS Dev Tutorials",
    "keywords": "The History of OS Development In this page, we are going to look at operating systems in a different way. We will go back in time to look at the history of operating systems. You will find there are many similarities between these vintage operating systems. These similarities will then be classified into the basic features operating systems have in common; which will also be a part of you own OS. Most of todays operating systems are graphical. These graphical user interfaces (GUI), however, provide a large abstraction layer to what is really going on in an OS. Many operating systems concepts date back to when programs were written on tape. A lot of these concepts are still in play today. Prehistory - The Need for Operating Systems Prior to the 1950s, all programs were on punch cards. These punch cards represented a form of instructions, which would control every faucet of the computer hardware. Each piece of software would have full control of the system. Most of the time, the software would be completely different with each other. Even the versions of a program. The problem was that each program was completely different. They had to always be rewritten from scratch. There was no common support for the software, so the software had to communicate directly with the hardware. This also made portability and compatibility impossible. During the realm of Mainframe computers, creating code libraries became more feasible. While it did fix some problems, such as two versions of software being completely different, each software still had full control of hardware. If new hardware came out, the software will not work. If the software crashed, it would need to be debugged using light switches from a control panel. The idea of an interface between hardware and programs came during the Mainframe era. By having an abstraction layer to the hardware, programs will no longer need to have full control, but instead they all would use a single common interface to the hardware. What is this ultra cool interface? Why, its that sweet cuddly (sometimes nasty) thing we call an Operating System! ðŸ˜€ 1950s The first real operating system recorded, according to Wikipedia, is the GM-NAA I/O. The SHARE Operating System was a successor of the GM-NAA I/O. SHARE provided sharing programs, managed buffers, and was the first OS to allow the execution of programs written in Assembly Language. SHARE became the standard OS for IBM computers in the late 1950s. The SHARE Operating System (SOS) was the first OS to manage buffers, provide program sharing, and allow execution of assembly language programs. \"Managing Buffers\" relate to a form of \"Managing Memory\". \"Program Sharing\" relates to using libraries from different programs. The two important things to note here are that, since the beginning of time (Not really ðŸ˜‚), Operating Systems have been responsible for Memory Management and Program Execution/Management Because this isn't the history of the world (nor that of computers) that I am narrating, lets jump ahead to the good old DOS. 1964 - DOS/360 and OS/360 DOS/360 (or just \"DOS\") was a Disk Operating System was originally announced by IBM to be released on the last day of 1964. Do to some problems, IBM was forced to ship DOS/360 with 3 versions, each released June 1966. The versions were: BOS/360 - 8KB Configuration. DOS/360 - 16KB Configuration with disk. TOS/360 - 16KB Configuration with tape. A couple of important things to note is that DOS/360 offered no Multitasking , and no Memory Protection . The OS/360 was being developed about the same time by IBM. The OS/360 used \"OS/MFT\" (Multiple Fixed Transactions) to support multiple programs, with a Fixed Base Address . With OS/MVT (Multiple Variable Transaction), it can support varies program sizes. Now we have a few more interesting words - Multitasking, Memory Protection, and Fixed Base Address . Adding to before, we also have Program execution and Memory Management . 1969 - Unix comes along The Unix Operating System was originally written in C. Both C and Unix were originally created by AT&T. Unix and C were freely distributed to government and academic institutions, causing it to be ported to a wider variety of machine families then any other OS. Unix is a multiuser , Multitasking Operating System. Unix includes a Kernel , File System and a Command Shell . There are a lot of Graphical User Interfaces (GUI) that uses the Command Shell to interact with the OS, and provide a much friendlier and nicer look. 1982 - Commodore DOS Commodore DOS (CBM DOS) was used with Commodore's 8 bit computers. Unlike the other computers before or since-which booted from disk into the systems memory at startup, CBM DOS executed internally within the drive-internal ROM chips, and was executed by an MOS 6502 CPU. 1985 - Microsoft Windows 1.0 The first Windows was a DOS application. Its \"MSDOS Executive\" program allows the running of a program. None of the \"Windows\" could overlap, however, so each \"window\" was displayed side to side. It was not very popular. 1987 - Microsoft Windows 2.0 The second version of Windows was still a DOS Graphical Shell , but supported overlapping windows, and more colors. However, do to the limitation of DOS, it was not widely used. Note DOS is a 16 bit operating system. During this time frame, DOS had to reference memory through Linear Addressing, and disks through LBA (Linear Block Addressing). Because the x86 platform is backward compatible, When the PC boots it is in 16 bit mode (Real Mode), and still has LBA. More on this later. Due to 16 bit mode limitations, DOS could not access more then 1 MB of memory. This is solved, today, by enabling the 20th address line through the Keyboard Controller. We will go over this later. Because of this 1 MB limitation, Windows was far to slow, which was one primary reason of it being unpopular. 1987 - Microsoft Windows 3.0 Windows 2.0 was completely redesigned. Windows 3.0 was still a DOS Graphical Shell, however it included A \"DOS Extender\" to allow access to 16 MB of memory, over the 1 MB limit of DOS. It is supports multitasking with DOS programs. This is the Windows that made Microsoft big. It supports resizable windows, and movable windows. Windows in relation to OS Developers I have seen quite a few beginning OS developers want to develop the next Windows. While it is possible, it is extremely difficult, and is impossible with a one person team. Take a look at the above picture again. Remember that it is a graphical shell over a command shell , being executed by a Kernel . Also, remember that even Windows had to start here. The Command Shell was DOS. the Graphical Shell was \"Windows\". In the next page, we will consolidate all the features these OSes share to help define what an OS consists of."
  },
  "articles/01_Intro_to_OSDev/7_Basic_OS_Concepts.html": {
    "href": "articles/01_Intro_to_OSDev/7_Basic_OS_Concepts.html",
    "title": "Basic Concepts of an Operating system | BrokenThorn OS Dev Tutorials",
    "keywords": "Basic Concepts of an Operating system Looking back though our small trip to memory lane brings some important new terms with it. So far, we only gave \"operating system\" a small definition. The previous page should help us in defining a better, more descriptive definition of what an operating system is. Since we now know what features most OSes have in common, to help define them better, lets put the above bolded terms into a list: Memory Management Program Management Multitasking Memory Protection Fixed Base Address Multi-user presence Kernel File System Command Shell Graphical User Interface (GUI) Graphical Shell Linear Block Addressing (LBA) Bootloader (From the previous tutorial) Memory Management Memory Management refers to: Dynamically giving and using memory to and from programs that request it. Implementing a form of Paging , or even Virtual Memory . Insuring the OS Kernel does not read or write to unknown or invalid memory. Watching and handling Memory Fragmentation . Program Management This relates closely with Memory Management. Program Management is responsible for: Insuring the program doesn't write over another program. Insuring the program does not corrupt system data. Handle requests from the program to complete a task (such as allocate or deallocate memory). Multitasking Multitasking refers to: Switching and giving multiple programs a certain timeframe to execute. Providing a Task Manager to allow switching (Such as Windows Task Manager). TSS (Task State Segment) switching. Another new term! Executing multiple programs simultaneously. Memory Protection This refers to: Accessing an invalid descriptor in protected mode (Or an invalid segment address) Overwriting the program itself. Overwriting a part or parts of another file in memory. Fixed Base Address A \"Base Address\" is the location where a program is loaded in memory. In normal applications programming, you wouldn't normally need this. In OS Development, however, you do. A \"Fixed\" Base Address simply means that the program will always have the same base address each time it is loaded in memory. Two example programs are the BIOS and the Bootloader. Multiuser This refers to: Login and Security Protection. Ability of multiple users to work on the computer. Switching between users without loss or corruption of data. Kernel The Kernel is the heart of the Operating System. It provides the basic foundation, memory management, file systems, program execution, etc. We will take a closer look at the kernel very soon, don't worry ðŸ˜€ File System In OS Development, there is no such thing as a \"file\". Everything could be pure binary code (from the bootsector); from the start. A File System is simply a specification that describes information regarding files. In most cases, this refers to Clusters, Segments, segment address, root directories, etc. the OS has to find the exact starting address of the file in order to load it. File Systems also describe file names. There are external and internal file names. For example, the FAT12 specification states a filename can only be 11 characters. No more, no less. Seriously. This means the filename \"KRNL.sys\", for example, will have the internal file name \"KRNL SYS\" . We will be using FAT12 and be discussing it in detail later. Command Shell A Command Shell sits on top the Kernel as a separate program. The Command Shell provides basic input and output through the use of typing commands. The Command Shell uses the Kernel to help with this, and complete low level tasks. Graphical User Interface (GUI) The Graphical User Interface (GUI) simply refers to the graphical interface and interactions between the Graphical Shell and the user. Graphical Shell The Graphical Shell provides video routines and low level graphical abilities. It normally will be executed by the Command Shell. (As in Windows 1.0,2.0, and 3.0). Usually this is automatic these days, however. Linear Block Addressing (LBA) Operating Systems have control over every single little byte in memory . Linear Addressing refers to directly accessing linear memory. For example: mov ax, [0x09000] ; There is no such thing as Access Violations in OS Development This is a good thing, but is also a very bad thing. For example: mov bx, [0x7bff] ; or some other address less then 7c00h mov cx, 10 .loop1: mov [bx], 0x0 ; clear bx inc bx ; go to next address loop .loop1 ; loop until cx=0 The above code seems harmless. However, if the above code was found in a bootloader, the above code will overwrite itself by 10 bytes. Ouch. The reason is that bootloaders are loaded with a Fixed address of 0x7c00:0, and the above code starts writing from 07bffh: One byte before 07c00h. Bootloader From the previous page, we know that the bootloader is loaded by the BIOS, and is the very first program to execute on power on. The bootloader is loaded by the BIOS at absolute address 0x7c00:0 . After loading, the CS:IP (which you will learn about soon) is set to your bootloader, and the bootloader takes full control. Important A Floppy Sector is only 512 bytes in size. Remember that the bootloader has to fit in a single bootsector. What does this mean? The bootloader is very limited in size, and cannot exceed 512 bytes. Most of the time, the bootloader will either just load and execute the kernel, or a Second Stage Bootloader . Conclusion In the next section we will explore the creation of a stage 1 bootloader by delving into the theory and code behind the process of booting up a machine and executing the bootloader."
  },
  "articles/02_Bootloader_Stage_1/1_Overview.html": {
    "href": "articles/02_Bootloader_Stage_1/1_Overview.html",
    "title": "this is overview | BrokenThorn OS Dev Tutorials",
    "keywords": "this is overview"
  },
  "articles/02_Bootloader_Stage_1/2_Booting_Process.html": {
    "href": "articles/02_Bootloader_Stage_1/2_Booting_Process.html",
    "title": "Booting Process | BrokenThorn OS Dev Tutorials",
    "keywords": "Booting Process"
  },
  "articles/03_Bootloader_Stage_2/1_Overview.html": {
    "href": "articles/03_Bootloader_Stage_2/1_Overview.html",
    "title": "this is overview | BrokenThorn OS Dev Tutorials",
    "keywords": "this is overview"
  },
  "articles/51_Using_the_Toolchain/1_Overview.html": {
    "href": "articles/51_Using_the_Toolchain/1_Overview.html",
    "title": "this is overview | BrokenThorn OS Dev Tutorials",
    "keywords": "this is overview"
  },
  "articles/61_unorganised_tutorial/1_Overview.html": {
    "href": "articles/61_unorganised_tutorial/1_Overview.html",
    "title": "Unorganized Tutorial: Overview | BrokenThorn OS Dev Tutorials",
    "keywords": "Unorganized Tutorial: Overview This project/website is still in its making and will be completed within the next few weeks, so hang tight! You can meanwhile visit the official site for all the original articles. All the articles in this section are those which have been ported over from the original website, but haven't yet been checked for errors or properly organized and have been put here for the purpose of immediate usage of search indexing and easier access of all articles at one point regardless of their readiness. This is only until all these articles are properly classified and put up at their respective endpoints in this website."
  },
  "articles/61_unorganised_tutorial/T10.html": {
    "href": "articles/61_unorganised_tutorial/T10.html",
    "title": "Prepare for the Kernel part 1 | BrokenThorn OS Dev Tutorials",
    "keywords": "Prepare for the Kernel part 1 This is our first two-part tutorial. The first part will describe all of the new code in detail. We will cover basic 32 bit graphics programming in assembly. This includes: Basic VGA Programming concepts, accessing video display, printing strings, clearing the screen, and updating the hardware cursor. There is a little math involved, but not too much ðŸ˜€ The demo itself is completed. It will be shown in the second part of this tutorial, along with an overview of the completed Stage 2 source code, including its new little FAT12 driver, Floppy driver. These are not \"real\" drivers by definition that we will add. However, they will help demonstrate the functionality of drivers, and why they are useful. All of the code is a heavily modified version of our FAT12 loading code from the bootloader, so I will not be describing FAT12 again in detail. With that, Part two--as being the last tutorial for Stage 2--will go over the loading and executing of a basic (pure binary) Kernel image at 1 MB. This two part tutorial is the last tutorial for Stage 2! When we start the Kernel, we will need to cover different executable format files. We will need to insure Stage 2 executes the object files correctly. Because of this, when we start the Kernel, we will add the loader to our current Stage 2 bootloader to insure it loads our Kernel correctly. This is later, though ðŸ˜€ With all of that in mind, Part 1 of this tutorial covers : Basic VGA Programming Concepts Accessing the Display Printing characters Printing strings CRT Microcontroller theory and updating the hardware cursor Clearing the screen This tutorial references [The infamous Tutorial 7] (fix link) a lot. That is, the Real Mode Addressing Map and Default I/O Port Addresses . It may be helpful to have that tutorial up when we talk about video address space and VGA port access. Ready? The Display VGA - Theory The Video Graphics Array (VGA) is an analog computer display standard marketed in 1987 by IBM. It is called an \"Array\" because it was originally developed as a single chip, replacing dozens of logic chips in a Industry Standard Architecture (ISA) board that the MDA , CGA , and EGA used. Because this was all on a single ISA board, it was very easy to connect it to the motherboard. The VGA consists of the video buffer, video DAC, CRT Controller, Sequencer unit, Graphics Controller, and an Attribute Controller . Please note that, we will not cover everything in detail yet until we start talking about video drivers. This is primarily to preserve space, and to make things more easier as programming the VGA can get quite complex. Video Buffer The Video Buffer is a segment of memory mapped as Video Memory. We can change what region of memory is mapped to video memory. At startup, the BIOS maps it to 0xA0000. , which means that video memory is mapped to 0xA0000. (Remember the Real Mode Address Map from Tutorial 7?) This is important! Video DAC The Video Digital to Analog Converter (DAC) contains the color palette that is used to convert the video data into an analog video signal that is sent to the display. This signal indicates the red, green, and blue intensities in analog form. We will go into more detail later, so don't worry if you do not understand this yet. CRT Controller This controller generates horizontal and vertical synchronization signal timings, addressing for the video buffer, cursor and underline timings. We will go into more detail later in this tutorial, as we need to go through the CRT Controller when updating the cursor. Sequencer The Sequencer generates basic memory timings for video memory and the character clock for controlling regenerative buffer fetches. It allows the system to access memory during active display intervals. Once more, we will not cover this in detail yet. We will cover everything in great detail later when looking at Video Drivers, don't worry ðŸ˜€ Graphics Controller This is the interface between video memory and the attribute controller, and between video memory and the CPU. During active display times, memory data is sent from the video buffer (Video Memory) and sent to the Attribute Controller. In Graphics Modes, this data is converted from parallel to a serial bit plane data before being sent. In text modes, Just the parallel data is sent. Don't worry if you do not understand these yet. I do not plan on going into much detail here. We will cover everything in detail later when we talk about developing a video driver. For now, just remember that: The Graphics Controller refreshes the display from the parallel data from video memory. This is automatic based on the active display times. This simply means, that By writing to video memory (Default mapped to 0xA0000) we effectively write to video display, depending on the current mode. This is important when printing characters. Remember that it is possible to change the address range used by the Graphics Controller. When initializing, the BIOS does just this to map video memory to 0xA0000. Video Modes A \"Video Mode\" is a specification of display. That is, it describes how Video Memory is referenced, and how this data is displayed by the video adapter. The VGA supports two types of modes: APA Graphics , and Text . APA Graphics All Points Addressable (APA) is a display mode, that, on a video monitor, dot matrix, or any device that consists of a pixel array, where every cell can be referenced individually. In the case of video display, where every cell represents a \"pixel\", where every pixel can be manipulated directly. Because of this, almost all graphic modes use this method. By modifying this pixel buffer, we effectively modify individual pixels on screen. Pixel : A \"Pixel\" is the smallest unit that can be represented on a display. On a display, it represents the smallest unit of color. That is, basically, a single dot. The size of each pixel depends heavily on the current resolution and video mode. Text Modes A Text Mode is a display mode where the content on the screen is internally represented in terms of characters rather then pixels, as with APA. A Video Controller implementing text mode uses two buffers: A character map representing the pixels for each individual character to be displayed, and a buffer that represents what characters are in each cell. By changing the character map buffer, we effectively change the characters themselves, allowing us to create a new character set. By changing the Screen Buffer , which represents what characters are in each cell, we effectively change what characters are displayed on screen. Some text modes also allow attributes, which may provide a character color, or even blinking, underlined, inversed, brightened, etc. MDA, CGA, EGA Remember that VGA is based off of MDA, CGA, and EGA. VGA also supports a lot of the modes these adapters do. Understanding these modes will help in better understanding VGA. MDA - Theory Back before I was born (Seriously ðŸ˜€ ) in 1981, IBM developed a standard video display card for the PC. They were the Monochrome Display Adapter (MDA), and Monochrome Display and Printer Adapter (MDPA) . The MDA did not have any graphics mode of any kind. It only had a single text mode, (Mode 7) which could display 80 columns by 25 lines of high resolution text characters. This display adapter was a common standard used in older PC's. CGA - Theory In 1981, IBM also developed the Color Graphics Adapter (CGA) , considered the first color display standard for PC's. The CGA only supported a Color Palette of 16 colors, because it was limited to 4 bytes per pixel. CGA supported two text modes and two graphics modes, including: 40x25 characters (16 color) text mode 18x25 characters (16 color) text mode 320x200 pixels (4 colors) graphics modes 640x200 pixels (Monochrome) graphics mode It is possible to trick the display adapter in creating and discovering new, \"undocumented\" video modes. More on this later. EGA - Theory Introduced in 1984 by IBM, The Enhanced Graphics Adapter (EGA) produced a display of 16 colors at a resolution up to 640x350 pixels. Remember that the VGA adapters are backward compatible, similar to the 80x86 microprocessor family. Because of this, and to insure backward compatibility, the BIOS starts up in Mode 7 (Originally from the MDA), which supports 80 columns, by 25 lines. This is important to us, because this is the mode we are in! VGA Memory Addressing Video memory used by the VGA Controller is mapped to the PC's memory from 0xA0000 to 0xBFFFF. Remember the Real Mode Memory Map from [Tutorial 7] (fix link) ! Typically, the Video Memory is mapped as the following: 0xA0000 - 0xBFFFF Video Memory used for graphics modes 0xB0000 - 0xB7777 Monochrome Text mode 0xB8000 - 0xBFFFF Color text mode and CGA compatible graphics modes Do to the different addresses used in the memory mapping, it is possible to have both ECG, CGA, and VGA display adapters installed on the same machine. It is possible to change the memory mappings used by the video adapter cards through the CRT Microcontroller. Normally this is done through Video Drivers. More on this later, though. One can also modify how the Video Controller uses this memory. In doing so, we can create \"new\", or rather, \"undocumented\" modes. One common mode is the infamous \"Mode X\". Remember that modifying the display buffer and text buffers effectively change what is displayed on screen? This is do to the video controller refreshing the display based on the current refresh rate. The Video Controller sends commands to the CRT Controller inside the Monitor through the VGA Port. This generates a Vertical and Horizontal Retrace of the CRT to refresh the monitors' display. And, because the text and display adapter is mapped to the above PC memory addresses, Writing to this region of memory changes what is displayed on screen For an example, remember that we are in Mode 7? Mode 7 is a color text mode, hence uses memory that begins at 0xB8000. Because this is the text buffer used by the Video Controller to determine what to display, Writing to 0xB8000 effectively displays text on screen. %define VIDMEM 0xB8000 ; video memory mov edi, VIDMEM ; get pointer to video memory mov [edi], 'A' ; print character 'A' mov [edi+1], 0x7 ; character attribute The above will display the character \"A\", in white, black background (The attribute), in the top left corner of the display. Too cool for school ðŸ˜€ Printing characters Okay, so how do we print a character at any x/y location on screen? A special property about memory is how it is linear. If we reach the end of a line being displayed, the next byte is on the line right below it. Because of linear addressing, we have to be able to convert an x/y location to a linear address to render it to screen. And, a special formula to do that is: x + y * screen width . Here is an example. Lets say, we want to print a character, 'A', into location x/y (5,5). Knowing that video memory begins at 0xb8000, and is linear, we can use the formula to convert this x/y location to an absolute address: address = x + (y * screen width) address = 5 + (5 * 80) address = 5 + 400 address = 405 This means, from the start of video memory, location 5,5 is 405 bytes away. So, add this to the base address of video memory: 0xB8000 + 405 = 0xB8195 So... by writing character 'A' to 0xB8195, we effectively write to x/y location (5,5). Cool, huh? Knowing this, lets first provide a way to store the current location at where we are on screen. This is so that we can act like the BIOS, so that the rest of the program does not need to: _CurX db 0 ; current x/y location _CurY db 0 %define VIDMEM 0xB8000 ; video memory %define COLS 80 ; width and height of screen %define LINES 25 %define CHAR_ATTRIB 14 ; character attribute (White text on black background) Remember that we are in Mode 7. This mode has 80 columns of characters per row, and 25 lines. And, of course, video memory begins at 0xB8000. But wait! What is the character attribute? Text Mode 7 actually uses two bytes per character, not one. Remember this! The first byte represents the actual character, and the second byte is a ...wait for it... attribute byte! Because of this, when writing a character to screen in Mode 7, you will need to write two bytes, not one. The attribute byte provides a way of supplying color, as well as certain attributes, such as blinking. The values can be... 0 - Black 1 - Blue 2 - Green 3 - Cyan 4 - Red 5 - Magenta 6 - Brown 7 - Light Gray 8 - Dark Gray 9 - Light Blue 10 - Light Green 11 - Light Cyan 12 - Light Red 13 - Light Magenta 14 - Light Brown 15 - White The attribute byte is a byte that defines certain attributes, and defining both foreground and background colors. The byte follows the format: Bits 0 - 2: Foreground color Bit 0: Red Bit 1: Green Bit 2: Blue Bit 3: Foreground Intensity Bits 4 - 6: Background color Bit 4: Red Bit 5: Green Bit 6: Blue Bit 7: Blinking or background intensity Okay, now that we have everything set up, lets print a character! Setting up Printing characters is a little complex because we have to track where we are, both in current x/y location and when writing to video memory. We also need to track certain characters, such as the newline character, and to watch for the end of line. And yet, we still need to update the hardware cursor to this position as well. Putch32 is the PMode routine that will display a character in stage 2. Don't worry, we will rewrite these routines for the Kernel using C. By showing how it's done in assembly, we can compare assembly language relationships with C. More on this later. Anyways, here's the startup code: bits 32 %define VIDMEM 0xB8000 ; video memory %define COLS 80 ; width and height of screen %define LINES 25 %define CHAR_ATTRIB 14 ; character attribute (White text on black background) _CurX db 0 ; current x/y location _CurY db 0 ;**************************************************; ; Putch32 () ; - Prints a character to screen ; BL => Character to print ;**************************************************; Putch32: pusha ; save registers mov edi, VIDMEM ; get pointer to video memory Okay, we have some basic definitions. _CurX and _CurY will contain the current x/y location to write the character to. By incrementing _CurX, we effectively go to the next character in the line. Also note that EDI contains the base address of video memory. Now, by writing to video memory [EDI], we an display characters on screen do to the current video memory map. Before displaying characters, we have to find out where to display it. To do this, just write it to the current x/y location (_CurX and _CurY). This is not quite simple though. As you remember, video memory is linear, so we have to convert the x/y location into linear memory. Remember our formula x + y * screen width . This can be easily computed. However, remember that every character is two bytes in size. Remember that _CurX, _CurY, COLS, LINES, are based off characters, not bytes. i.e., COLS=80 characters. Because there are two bytes per character, we have to compare with 80*2. Simple, huh? This makes things a little more complex, but not that hard: ;-------------------------------; ; Get current position ; ;-------------------------------; xor eax, eax ; clear eax ;-------------------------------- ; Remember: currentPos = x + y * COLS! x and y are in _CurX and _CurY. ; Because there are two bytes per character, COLS=number of characters in a line. ; We have to multiply this by 2 to get number of bytes per line. This is the screen width, ; so multiply screen with * _CurY to get current line ;-------------------------------- mov ecx, COLS*2 ; Mode 7 has 2 bytes per char, so its COLS*2 bytes per line mov al, byte [_CurY] ; get y pos mul ecx ; multiply y*COLS push eax ; save eax--the multiplication This is the first part of the formula: y * screen width (in bytes) , or _CurY * (COLS*bytes per character) . We store it on the stack so that we could finish the formula. ;-------------------------------- ; Now y * screen width is in eax. Now, just add _CurX. But, again remember that _CurX is relative ; to the current character count, not byte count. Because there are two bytes per character, we ; have to multiply _CurX by 2 first, then add it to our screen width * y. ;-------------------------------- mov al, byte [_CurX] ; multiply _CurX by 2 because it is 2 bytes per char mov cl, 2 mul cl pop ecx ; pop y*COLS result add eax, ecx Okay then! Notice that we multiply _CurX by 2 to get the current byte location. Then, we pop the result of y * COLS and add it to the x position--completing our x+y*COLS formula. Yay! Okay, now EAX contains the offset byte to print our character to, so lets add it to EDI--which holds the base address of video memory: ;------------------------------- ; Now eax contains the offset address to draw the character at, so just add it to the base address ; of video memory (Stored in edi) ;------------------------------- xor ecx, ecx add edi, eax ; add it to the base address Okay, now EDI contains the exact byte to write to. BL contains the character to write. If the character is a newline character, we will want to move to the next row. Else, just print the character: ;-------------------------------; ; Watch for new line ; ;-------------------------------; cmp bl, 0x0A ; is it a newline character? je .Row ; yep--go to next row ;-------------------------------; ; Print a character ; ;-------------------------------; mov dl, bl ; Get character mov dh, CHAR_ATTRIB ; the character attribute mov word [edi], dx ; write to video display ;-------------------------------; ; Update next position ; ;-------------------------------; inc byte [_CurX] ; go to next character cmp [_CurX], COLS ; are we at the end of the line? je .Row ; yep-go to next row jmp .done ; nope, bail out Okay then! Pretty easy, huh? Oh right..to go to the next row is easy: ;-------------------------------; ; Go to next row ; ;-------------------------------; .Row: mov byte [_CurX], 0 ; go back to col 0 inc byte [_CurY] ; go to next row ;-------------------------------; ; Restore registers & return ; ;-------------------------------; .done: popa ; restore registers and return ret Working with strings Okay, so we can print a character. Yippee. I am very excited to see a single character. Yeah, I don't think so ðŸ˜€ To print actual information, we will need a way to print full strings. Because we already have a routine that tracks current position (and updates it), and prints the characters, all we need to do to print a string is a simple loop. Puts32: ;-------------------------------; ; Store registers ; ;-------------------------------; pusha ; save registers push ebx ; copy the string address pop edi Okay, here's our Puts32() function. It takes one parameter: EBX, which contains the address of a null terminated string to print. Because out Putch32() function requires that BL store the character to print, we need to save a copy of EBX, so we do it here. Now, we loop: .loop: ;-------------------------------; ; Get character ; ;-------------------------------; mov bl, byte [edi] ; get next character cmp bl, 0 ; is it 0 (Null terminator)? je .done ; yep-bail out We use EDI to dereference the string to get the current character to display. Note the test for the null terminator. If found, we bail out. Now, to display the character... The most complex code you will ever see: ;-------------------------------; ; Print the character ; ;-------------------------------; call Putch32 ; Nope-print it out ...Or not ðŸ˜€ All we need to do now is to go to the next character, and loop: ;-------------------------------; ; Go to next character ; ;-------------------------------; .Next: inc edi ; go to next character jmp .loop .done: ;-------------------------------; ; Update hardware cursor ; ;-------------------------------; ; Its more efficiant to update the cursor after displaying ; the complete string because direct VGA is slow mov bh, byte [_CurY] ; get current position mov bl, byte [_CurX] call MovCur ; update cursor popa ; restore registers, and return ret Voila! We got ourselves a way to print strings in 32 bit protected mode. Not to hard, is it? Oh wait.. What is MovCur for? We will look at that next. Updating the hardware cursor Okay, so we can print characters and strings out now. You might notice something though: the cursor does not move! Because of this, it just stays no matter what we do. This cursor is a simple underline that the BIOS uses to indicate the current position when printing text. This cursor is handled by the hardware. The CRT Microcontroller , in fact. So, we have to know some basic vga programming in order to move this cursor. CRT Microcontroller Warning for CRT users While I encourage practicing and trying new things, please remember that, in an OS environment, you are working directly with the hardware, and have direct control over everything. CRT Monitor failures are violent in nature, and can explode and produce sharp glass fragments to fly at high speeds. It is possible to change frequency settings greater then the devices can handle. This may increase the chances of a device or microchip to malfunction, producing unpredictable or disastrous results. Because of this, if you, the reader, like experimenting with the code, I recommend testing all experimental code in an emulator to its fullest first, before attempting real hardware. I will not explain everything regarding video programming yet until we talk about Video Drivers. We will look at everything in detail then, cool? Anyhow...On to the CRT Controller! Port Mapping The CRT Controller uses a single Data Register which is mapped to port 0x3D5 . Remember the Port table from Tutorial 7? The CRT Controller uses a special register - an Index Register , to determine the type of data in the Data Register is. So, in order to give data to the CRT Controller, we have too write two values. One to the Index Register (Containing the type of data we are writing), and one to the Data Register (Containing the data). Not too hard ðŸ˜€ The Index Register is mapped to ports 0x3D5 or 0x3B5. The Data Register is mapped to ports 0x3D4 or 0x3B4. There are more registers then these two (Such as the Misc. Output Register), but we will focus on these two for now. Index Register Mapping By default, the indices for the Index Register are mapped to the following: CRT Microcontroller - Index Register table Index Offset CRT Controller Register 0x0 Horizontal Total 0x1 Horizontal Display Enable End 0x2 Start Horizontal Blanking 0x3 End Horizontal Blanking 0x4 Start Horizontal Retrace Pulse 0x5 End Horizontal Retrace 0x6 Vertical Total 0x7 Overflow 0x8 Preset Row Scan 0x9 Maximum Scan Line 0xA Cursor Start 0xB Cursor End 0xC Start Address High 0xD Start Address Low 0xE Cursor Location High 0xF Cursor Location Low 0x10 Vertical Retrace Start 0x11 Vertical Retrace End 0x12 Vertical Display Enable End 0x13 Offset 0x14 Underline Location 0x15 Start Vertical Blanking 0x16 End Vertical Blanking 0x17 CRT Mode Control 0x18 Line Compare By writing an index offset value into the index Register, it indicates what register the Data Register points to (That is, what it references.) Most of what is in the above table we don't need to worry about right now. However, look at indices 0xE and 0xF for a moment: 0x0E: Cursor Location High Byte 0x0F: Cursor Location Low Byte Yippee! These indices refer to the current offset location of the hardware cursor. This offset is just an x/y location (as a linear location - remember the formula x + y * screen width! ), split into its high and low bytes. Moving the hardware cursor Okay, first remember that the indices for the cursor are 0x0E and 0x0F, which we have to first put into the Index Register at port 0x3D4: mov al, 0x0f mov dx, 0x03D4 out dx, al This puts index 0x0F (the cursor low byte address) into the index register. Now, this means the value put into the Data Register (Port 0x3d5) indicates the low byte of the cursor location: mov al, bl ; al contains the low byte address mov dx, 0x03D5 out dx, al ; low byte This sets the new low byte location for the cursor! Cool, huh? Setting the high byte is exactly the same, except we have to set the index to 0x0E, which is, again, the high byte index. Here is the complete routine: ;**************************************************; ; MoveCur () ; - Update hardware cursor ; parm/ bh = Y pos ; parm/ bl = x pos ;**************************************************; bits 32 MovCur: pusha ; save registers (aren't you getting tired of this comment?) ;-------------------------------; ; Get current position ; ;-------------------------------; ; Here, _CurX and _CurY are relative to the current position on screen, not in memory. ; That is, we don't need to worry about the byte alignment we do when displaying characters, ; so just follow the formula: location = _CurX + _CurY * COLS xor eax, eax mov ecx, COLS mov al, bh ; get y pos mul ecx ; multiply y*COLS add al, bl ; Now add x mov ebx, eax ;--------------------------------------; ; Set low byte index to VGA register ; ;--------------------------------------; mov al, 0x0f ; Cursor location low byte index mov dx, 0x03D4 ; Write it to the CRT index register out dx, al mov al, bl ; The current location is in EBX. BL contains the low byte, BH high byte mov dx, 0x03D5 ; Write it to the data register out dx, al ; low byte ;---------------------------------------; ; Set high byte index to VGA register ; ;---------------------------------------; xor eax, eax mov al, 0x0e ; Cursor location high byte index mov dx, 0x03D4 ; Write to the CRT index register out dx, al mov al, bh ; the current location is in EBX. BL contains low byte, BH high byte mov dx, 0x03D5 ; Write it to the data register out dx, al ; high byte popa ret That was easy, huh? Next up: Clearing the screen! Clearing the screen Because we already have a way to display text, just loop, and reset the current position to 0! This is surprisingly simple... ;**************************************************; ; ClrScr32 () ; - Clears screen ;**************************************************; bits 32 ClrScr32: pusha cld mov edi, VIDMEM mov cx, 2000 mov ah, CHAR_ATTRIB mov al, ' ' rep stosw mov byte [_CurX], 0 mov byte [_CurY], 0 popa ret Easy, huh? Okay, so we have a way to print text, which also updates the hardware cursor, and clear the screen. If we wanted to, we can expand this stage 2 loader to include a small menu and advanced options when giving control to the Kernel. More on this later... Demo I decided to create a little demo to demonstrate everything in this tutorial. The next tutorial builds directly on this code. This tutorial uses everything we talked about in this tutorial. It sets the foreground and background colors based on the character attribute byte. And, because of our ClrScr32() routine, effectively clears the screen to that background color. Cool, huh? You can download the demo Here . Conclusion I was pretty stumped on how to go about these next tutorials. I believe (Hope!) splitting it in two parts was a good solution. We have went over a lot of stuff here, more specifically graphics concepts. We talked about basic VGA concepts, printing characters, strings, clearing the screen, and updating the hardware cursor. By changing the attribute byte of the text we print out, we could easily print characters out in all shorts of colors! You can even get a new background by changing the color in the attribute byte, and calling our ClrScr32 () function! Cool, don't you think? It certainly beets the boring black and white... ðŸ˜€ The next tutorial finishes Stage 2, and loads and executes a basic pure binary 32 bit Kernel image at 1 MB. Don't worry--When we get into the Kernel section of this series, we will change the way the Kernel is built, and modify how it is loaded. This will allow us to load the Kernel as an object format--allowing it to import or export symbols, and mix it in with C. I cannot wait! The next tutorial is not a tutorial in a sense of learning new things. Instead, it covers all of the code that has already been explained. This code, however, is modified for better code layout, and provide the interface (and separation) between a basic Filesystem (FAT12) Driver and a Floppy Driver. Nonetheless, it is the closing tutorial for Stage 2. We will go back to Stage 2 a bit later, as Stage 2 can be modified to provide more options, or even to support Multibooting , and Boot Options . We shall see... ðŸ˜‰"
  },
  "articles/61_unorganised_tutorial/T11.html": {
    "href": "articles/61_unorganised_tutorial/T11.html",
    "title": "Prepare for the Kernel part 2 | BrokenThorn OS Dev Tutorials",
    "keywords": "Prepare for the Kernel part 2 This is the tutorial you have been waiting for. It builds directly on the all of the previous code, and loads our Kernel at the 1 MB mark, and executes our Kernel. The Kernel is the most important part of our OS. The Kernel...We have talked a little about this mysterious foe before, haven't we? We will talk about the Kernel a lot more in the next few tutorials, including design, structure, and development. Right now, we already have everything set up... It's time to load the Kernel and say good bye to Stage 2! Note: This tutorial requires a basic understanding of the Bootloaders 3 and 4 tutorials. We cover everything in detail here, but all of the concepts are explained in depth in the Bootloaders 3 and 4 Tutorials. If you have not read those tutorials, Please look at those tutorials first. [OS Development Series Tutorial 5: Bootloaders 3] (fix link) [OS Development Series Tutorial 6: Bootloaders 4] (fix link) If you have read them, this tutorial should not be that hard. Ready? A Basic Kernel Stub This is the Kernel we will load: ; We are still pure binary. We will fix this in the next few tutorials ðŸ˜€ org 0x10000 ; Kernel starts at 1 MB bits 32 ; 32 bit code jmp Stage3 ; jump to stage 3 %include \"stdio.inc\" ; Our stdio.inc file we developed from the previous tutorial msg db 0x0A, 0x0A, \"Welcome to Kernel Land!!\", 0x0A, 0 Stage3: ;-------------------------------; ; Set registers ; ;-------------------------------; mov ax, 0x10 ; set data segments to data selector (0x10) mov ds, ax mov ss, ax mov es, ax mov esp, 90000h ; stack begins from 90000h ;---------------------------------------; ; Clear screen and print success ; ;---------------------------------------; call ClrScr32 mov ebx, msg call Puts32 ;---------------------------------------; ; Stop execution ; ;---------------------------------------; cli hlt Okay, there is nothing much here. We will build on this program heavily in the next section. Notice that it is all 32 bit. Sweet, huh? We are going to be out of the 16 bit world completely here. For now, we just halt the system when we get to the Kernel. Please note that we will not be using this file probably at all in the rest of the series. Rather, we will be using a 32 bit C++ compiler. After we load the kernel image in memory, we can parse the file in memory for the kernel entry routine and call the C main() routine directly from our 2nd stage boot loader. Cool, huh? In other words, we will go from our 2nd stage boot loader directly into the C++ world without any stub file or program. However, we need a starting point. Because of this, we will use a basic stub file in this tutorial to help test and demonstrate it working. In the next few tutorials we will be getting our compilers up and working and use that instead. But now we are getting ahead of ourselves here ðŸ˜‰ The floppy interface Yay! Its time to finish off stage 2! In order to load the Kernel we need to traverse FAT12 again. But before that, we have to get sectors off disk. This code is EXACTALLY the same from our bootloader, and uses the BIOS INT 0x13 to load sectors off disk. Because this tutorial is also a complete review, lets break each routine into sections and describe exactly what is going on. Reading a sector - BIOS INT 0x13 We talked about everything regarding loading sectors in our Bootloaders 3 . Looking back at the tutorial, remember that we can use the BIOS Interrupt 0x13 function 2 to read a sector. Okay, then. The problem here is that We have to load sectors before going into protected mode. If we attempt to call a BIOS interrupt from protected mode, the processor will triple fault, remember? Anyways, what was the interrupt? Right.... INT 0x13/AH=0x02 - DISK : READ SECTOR(S) INTO MEMORY AH = 0x02 AL = Number of sectors to read CH = Low eight bits of cylinder number CL = Sector Number (Bits 0-5). Bits 6-7 are for hard disks only DH = Head Number DL = Drive Number (Bit 7 set for hard disks) ES:BX = Buffer to read sectors to Returns: AH = Status Code AL = Number of sectors read CF = set if failure, cleared is successful This is not THAT hard. Remember from the Bootloaders tutorial though. That is, we need to keep track of the sector, track, and head number, and insure we don't load attempt to load a sector beyond the track. That is, Remember that there are 18 sectors per track? Setting the sector number greater then 18 will cause the controller to fail, and processor to triple fault. Okay...18 sectors per track. Remember that each sector if 512 bytes. Also, remember that there are 80 tracks per side. Okay then! All of this information... Sectors per track, the number of tracks, number of heads, the size of a sector, completely depend on the disk itself. Remember that a sector does not NEED to be 512 bytes? We describe everything in the OEM Parameter Block: bpbOEM db \"My OS \" bpbBytesPerSector: DW 512 bpbSectorsPerCluster: DB 1 bpbReservedSectors: DW 1 bpbNumberOfFATs: DB 2 bpbRootEntries: DW 224 bpbTotalSectors: DW 2880 bpbMedia: DB 0xf0 ;; 0xF1 bpbSectorsPerFAT: DW 9 bpbSectorsPerTrack: DW 18 bpbHeadsPerCylinder: DW 2 bpbHiddenSectors: DD 0 bpbTotalSectorsBig: DD 0 bsDriveNumber: DB 0 bsUnused: DB 0 bsExtBootSignature: DB 0x29 bsSerialNumber: DD 0xa0a1a2a3 bsVolumeLabel: DB \"MOS FLOPPY \" bsFileSystem: DB \"FAT12 \" This should look familiar! Each member has been described in Tutorial 5--Please see that tutorial for a full detailed explanation of everything here. Now, all we need to have is a method so that we can load any number of sectors from disk to some location in memory. We immediately run into a problem though. Okay-- We know what sector we want to load . However, BIOS INT 0x13 does not work with sectors. Okay, it does--but it also works with cylinders (Remember that a cylinder is just a head?) and tracks. So what does this have to do with anything? Imagine if we want to load sector 20. We cannot directly use this number, because there are only 18 sectors per track . Attempting to read from the 20th sector on the current track will cause the floppy controller to fail, and processor to triple fault, as that sector does not exist. In order to read the 20'th sector, we have to read Track 2 Sector 2, Head 0 We will verify this later. What this means as that, if we want to specify a sector to load, we need to convert our linear sector number into the exact cylinder, track, and sector location on disk. Wait for it...Aha! Remember our CHS to LBA conversion routines? Converting LBA to CHS This should sound familiar, doesn't it? Linear Block Addressing (LBA) simply represents an indexed location on disk. The first block being 0, the second block being 1. In other words, LBA simply represents the sector number, beginning with 0, where each \"block\" is a single \"sector\". Anyhow...We have to find a way to convert this sector number (LBA) to the exact cylinder/head/sector location on disk. Remember this from Bootloaders 4 tutorial? Some of our readers exclaimed this code was fairly tricky--and I am to admit it is. So, I am going to explain it in detail here. First, lets look at the forumlae again: absolute sector = (logical sector / sectors per track) + 1 absolute head = (logical sector / sectors per track) MOD number of heads absolute track = logical sector / (sectors per track * number of heads) Okay! This is pretty easy, huh? The \"logical sector\" is the actual sector number we want. Note that the logical sector / sectors per track is inside of all of the above equations. Because this division is inside of all of these equations, we can store it's result and use it for the other two expressions. Lets put this into an example. We already said the 20th sector should be Track 2, Sector 2, remember? Lets try to put this formula to the test then: absolute sector = (logical sector / sectors per track) + 1 2.111111111111111111111111111111 = 20 / 18 (sectors per track) + 1 We only keep the absolute number (2)--Aha! Sector 2! Note that we need to add 1 here because LBA addressing begins from 0. Remember that the basic formula \"logical sector / sectors per track\" is in ALL of these formulas. It is simply 1.1111111111111111111111111111111 in this example (Note in the above formula, we added 1 more). Because we are working with whole numbers, this is simply 1. absolute head = (logical sector / sectors per track) MOD number of heads (1) MOD Number of heads (2) = Head 1 Remember from the OEM Block that we specified 2 heads per cylinder. So far, this indicates sector 2 on Head 1. Great--but what track are we on? absolute track = logical sector / (sectors per track * number of heads) (1) * Number of heads (2) = Track 2 Notice that this is the exact same formula as above. The ONLY difference is that simple operation. Anyhow... following the formula we have: Logical Sector 20 is on Sector 2 Track 2 Head 0 . Compare this with what we originally said in the previous section, and notice how this formula works ðŸ˜‰ Okay, so now lets try to apply these formulas in the code: LBACHS Explanation: Detail Okay, this routine takes one parameter: AX, which contains the logical sector to convert into CHS. Note the formula (logical sector / sectors per track) is part of all three formulas. Rather then recalculating this over and over, it is more efficient to just calculate it once , and use that result in all of the other calculations... This is how this routine works. LBACHS: xor dx, dx ; prepare dx:ax for operation div WORD [bpbSectorsPerTrack] ; calculate Now AX contains the logical sector / sectors per track operation. Begin with sector 1 (Remember the + 1 in logical sector / sectors per track ?) inc dl ; adjust for sector 0 mov BYTE [absoluteSector], dl Clear DX. AX still contains the result of logical sector / sectors per track xor dx, dx ; prepare dx:ax for operation Now for the formulas... absolute head = (logical sector / sectors per track) MOD number of heads absolute track = logical sector / (sectors per track * number of heads) The multiplication results into a division by the number of heads. So the only difference between these two is the operation--one is division, and one is the remainder of that division (The Modulus). Okay, lessee...What instruction can we use that could return both the remainder (MOD) and division result? DIV! Remember that (logical sector / sectors per track) is still in AX, so all we need to do is divide by number of heads per cylinder... div WORD [bpbHeadsPerCylinder] ; calculate The equations for absolute head and absolute track are very similar. The only actual difference is the operation. This simple DIV instruction sets both DX and AX. AX Now stores the DIVISION of HeadsPerCylinder; DX now contains the REMAINDER (Modulus) of the same operation mov BYTE [absoluteHead], dl mov BYTE [absoluteTrack], al ret I hope this clears things up a bit. If not, please let me know ðŸ˜‰ Converting CHS to LBA This is a lot more simpler: ClusterLBA: ; LBA = (cluster - 2 ) * sectors per cluster sub ax, 0x0002 ; subtract 2 from cluster number xor cx, cx mov cl, BYTE [bpbSectorsPerCluster] ; get sectors per cluster mul cx ; multiply Reading in sectors Okay, so now we have everything to read in sectors. This code is also exactly the same from the bootloader. ;************************************************; ; Reads a series of sectors ; CX=>Number of sectors to read ; AX=>Starting sector ; ES:BX=>Buffer to read to ;************************************************; ReadSectors: .MAIN mov di, 0x0005 ; five retries for error Okay, here we attempt to read the sectors 5 times. .SECTORLOOP push ax push bx push cx call LBACHS ; convert starting sector to CHS We store the registers on the stack. The starting sector is a linear sector number (Stored in AX). Because we are using BIOS INT 0x13, We need to convert this to CHS before reading from the disk. So, we use our LBA to CHS coversition routine. Now, absoluteTrack contains the track number, absoluteSector contains the sector within the track, and absoluteHead contains the head number. All of this was set by our LBA to CHA conversion routine, remember? mov ah, 0x02 ; BIOS read sector mov al, 0x01 ; read one sector mov ch, BYTE [absoluteTrack] ; track mov cl, BYTE [absoluteSector] ; sector mov dh, BYTE [absoluteHead] ; head mov dl, BYTE [bsDriveNumber] ; drive int 0x13 ; invoke BIOS Now we set up to read a sector, and invoke the BIOS to read it. For simplicity, lets take another look at the BIOS INT 0x13 routine that we are executing: INT 0x13/AH=0x02 - DISK : READ SECTOR(S) INTO MEMORY AH = 0x02 AL = Number of sectors to read CH = Low eight bits of cylinder number CL = Sector Number (Bits 0-5). Bits 6-7 are for hard disks only DH = Head Number DL = Drive Number (Bit 7 set for hard disks) ES:BX = Buffer to read sectors to Compare this with how we execute the code above--fairly simple, huh? Remember that the buffer to write to is in ES:BX, which INT 0x13 references as the buffer. We passed ES:BX into this routine, so that is the location to load the sectors to. jnc .SUCCESS ; test for read error xor ax, ax ; BIOS reset disk int 0x13 ; invoke BIOS dec di ; decrement error counter pop cx pop bx pop ax jnz .SECTORLOOP ; attempt to read again The BIOS INT 0x13 function 2 sets the Carry Flag (CF) is there is an error. If there is an error, decrement the counter (Remember we set up the loop to try 5 times?), and then try again! If all 5 attempts failed (CX=0, Zero flag set), then we fall down to the INT 0x18 instruction: int 0x18 ...Which reboots the computer. If the Carry Flag was NOT set (CF=0), then the jnz instruction jumps here, as it indicates that there was no error. The sector was read successfully. .SUCCESS pop cx pop bx pop ax add bx, WORD [bpbBytesPerSector] ; queue next buffer inc ax ; queue next sector loop .MAIN ; read next sector ret Now, just restore the registers, and go to the next sector. Not to hard ðŸ˜€ Note that, because ES:BX contains the address to load the sectors to, we need to increment BX by the bytes per sector to go to the next sector. AX contained the starting sector to read from, so we need to increment that too. I guess that's all for now. Please reference Bootloaders 4 for a full explanation of this routine. Floppy16.inc In the example demo, all of the floppy access routines are inside of Floppy16.inc . FAT12 Interface Yay--We can load sectors. Woohoo... :( As you know, we cannot really do much with that. What we need to do next is create a basic definition of a \"file\" and what a \"file\" is. We do this by means of a Filesystem . Filesystems can get quite complex. Please reference Bootloaders 4 while I explain this code to fully understand how this code works. Constants During parsing Fat12, we will be needing a location to load the root directory table and the FAT table. To make things somewhat easier, lets hide these locations behind constants: %define ROOT_OFFSET 0x2e00 %define FAT_SEG 0x2c0 %define ROOT_SEG 0x2e0 We will be loading our root directory table to 0x2e00 and our FAT to 0x2c00. FAT_SEG and ROOT_SEG are used for loading into segment registers. Traversing FAT12 As you know, some OS code can simply get ugly. Filesystem code, in my opinion, is one of them. This is one of the reasons why I decided to go over this code in this review-like tutorial. The FAT12 code is basically the same as the bootloaders, but I decided to modify it to decrease dependencies with the main program. Because of this, I decided to describe it in detail here. Please note, I will not be going over FAT12 in detail here. Please see the Bootloaders 4 tutorial for complete details. Anyhow, as you know, in order to traverse FAT12 the first thing we need to load is the Root Directory Table , so lets look at that first. Loading the Root Directory Table Disk structure FAT12 FS Sectors Boot Sector Extra Reserved Sectors File Allocation Table 1 File Allocation Table 2 Root Directory (FAT12/FAT16 Only) Data Region containing files and directories Remember that the Root Directory Table is located right after the FAT's and Reserved sectors? In loading the root directory table, we need to find a location in memory that we do not currently need and copy it there. For now, I chose 0x7E00 (Real mode: 0x7E0:0). This is right above our bootloader, which is still in memory because we have never overwritten it. There is an important concept here. Notice that we have to load everything at absolute memory locations. This is very bad, as we have to physically keep track of where things are located. This is where a Low level memory manager comes into play. More later... ;******************************************* ; LoadRoot () ; - Load Root Directory Table ;******************************************* LoadRoot: pusha ; store registers push es We first store the current state of the registers. Not doing so will effect the rest of the program that uses it, which is very bad. Now we get the size of the root directory table, so that we know the number of sectors to load. Remember from Bootloaders 4 : Each entry is 32 bytes in size. When we add a new file in a FAT12 formatted disk, Windows automatically appends to the root directory for us, and adds to the bpbRootEntries byte offset variable of the OEM Parameter Block See...Windows is nice ðŸ˜€ So...lessee, knowing each entry is 32 bytes in size, multiplying 32 bytes by the number of root directories will tell us how many bytes there are in the Root Directory Table . Simple enough, but we need the number of sectors --so we need to divide this result by the number of sectors: ; compute size of root directory and store in \"cx\" xor cx, cx ; clear registers xor dx, dx mov ax, 32 ; 32 byte directory entry mul WORD [bpbRootEntries] ; total size of directory div WORD [bpbBytesPerSector] ; sectors used by directory xchg ax, cx ; move into AX OKAY, so now AX=number of sectors the root directory takes. Now, we have to find the starting location. Remember from Bootloaders 4: The Root Directory table is Right after both FAT's and reserved sectors on the disk. Please look at the above disk structure table to see where the root directory table is located. So...All we need to do is get the amount of sectors for the FAT's, and add that to the reserved sectors to get the exact location on disk: ; compute location of root directory and store in \"ax\" mov al, byte [bpbNumberOfFATs] ; number of FATs mul word [bpbSectorsPerFAT] ; sectors used by FATs add ax, word [bpbReservedSectors] ; adjust for bootsector mov word [datasector], ax ; base of root directory add word [datasector], cx Now that we have the number of sectors to read in, and the exact starting sector, lets read it in! ; read root directory push word ROOT_SEG pop es mov bx, 0x0 ; copy root dir call ReadSectors ; read in directory table pop es popa ; restore registers and return ret Notice that we set the seg:offset location to read into ROOT_SEG:0. Next up, loading the FAT! Loading the FAT Okay...Remember from Bootloaders 4 , we talked about the disk structure of a FAT12 formatted disk. Going Back in Time(tm), lets take another look: Disk structure (take another look) FAT12 FS Sectors Boot Sector Extra Reserved Sectors File Allocation Table 1 File Allocation Table 2 Root Directory (FAT12/FAT16 Only) Data Region containing files and directories Remember that there are either one or two FATs? Also notice that they are right after the reserved sectors on disk. This should look familiar! ;******************************************* ; LoadFAT () ; - Loads FAT table ; ; Parm/ ES:DI =Root Directory Table ;******************************************* LoadFAT: pusha ; store registers push es First we need to know how many sectors to load. Look back at the disk structure again. We store the number of FATs (and the sectors per FAT) in the OEM Parameter Block. So to get the total sectors, just multiply them: ; compute size of FAT and store in \"cx\" xor ax, ax mov al, BYTE [bpbNumberOfFATs] ; number of FATs mul word [bpbSectorsPerFAT] ; sectors used by FATs mov cx, ax Now, we need to take the reserved sectors into consideration, as they are before the FAT... ; compute location of FAT and store in \"ax\" mov ax, word [bpbReservedSectors] Yippee! Now, CX contains the number of sectors to load, so call our routine to load the sectors! ; read FAT into memory (Overwrite our bootloader at 0x7c00) push word FAT_SEG pop es xor bx, bx call ReadSectors pop es popa ; restore registers and return ret That's all there is to it ðŸ˜‰ Searching for a file In searching for a file, we need the filename to search with. Remember that DOS uses 11 byte file names following the common 8.3 naming convention (8 byte file name, 3 character extension.) Because of the way the entries in the Root directory is structured, This MUST be 11 bytes--no exceptions . Remember the format of the Root Directory Table: The filename is stored within the first 11 bytes of an entry. Lets take another look at the format of each directory entry: Bytes 0-7 : DOS File name (Padded with spaces) Bytes 8-10 : DOS File extension (Padded with spaces) Bytes 11 : File attributes. This is a bit pattern: Bit 0 : Read Only Bit 1 : Hidden Bit 2 : System Bit 3 : Volume Label Bit 4 : This is a subdirectory Bit 5 : Archive Bit 6 : Device (Internal use) Bit 6 : Unused Bytes 12 : Unused Bytes 13 : Create time in ms Bytes 14-15 : Created time, using the following format: Bit 0-4 : Seconds (0-29) Bit 5-10 : Minutes (0-59) Bit 11-15 : Hours (0-23) Bytes 16-17 : Created year in the following format: Bit 0-4 : Year (0=1980; 127=2107 Bit 5-8 : Month (1=January; 12=December) Bit 9-15 : Hours (0-23) Bytes 18-19 : Last access date (Uses same format as above) Bytes 20-21 : EA Index (Used in OS/2 and NT, don't worry about it) Bytes 22-23 : Last Modified time (See byte 14-15 for format) Bytes 24-25 : Last modified date (See bytes 16-17 for format) Bytes 26-27 : First Cluster Bytes 28-32 : File Size All Bolded entries are the important ones. We must compare the first 11 bytes of each entry, as they contain the filename. Once we find a match, We need to reference byte 26 of the entry to get it's current cluster . All of this should sound familiar. Now...On to the code! ;******************************************* ; FindFile () ; - Search for filename in root table ; ; parm/ DS:SI =File name ; ret/ AX =File index number in directory table. -1 if error ;******************************************* FindFile: push cx ; store registers push dx push bx mov bx, si ; copy filename for later We first store the current register states. We need to use SI, so we need to save the current filename somewhere...BX, perhaps? Remember that we need to parse the Root Directory table to find the image name. To do this, we need to check the first 11 bytes of each entry in the directory table to see if we found a match. Sounds simple, huh? To do this, we need to know how many entries there are... ; browse root directory for binary image mov cx, word [bpbRootEntries] ; load loop counter mov di, ROOT_OFFSET ; locate first root entry cld ; clear direction flag Okay, so CX now contains the number of entries to look in. All we need to do now is loop and compare the 11 byte character filename. Because we are using string instructions, we want to first insure the direction flag is cleared, which is what cld does. DI is set to the current offset into the directory table. This is the location of the table. i.e., ES:DI points to the starting location of the table, so lets parse it! .LOOP: push cx mov cx, 11 ; eleven character name. Image name is in SI mov si, bx ; image name is in BX push di rep cmpsb ; test for entry match If the 11 bytes match, the file was found. Because DI contains the location of the entry within the table, we immediately jump to .Found. If it does not match, we need to try the next entry in the table. We add 32 bytes onto DI. ( Remember that each entry is 32 bytes? ) pop di je .Found pop cx add di, 32 ; queue next directory entry loop .LOOP If the file was not found, restore only the registers that are still on the stack, and return -1 (error) .NotFound: pop bx ; restore registers and return pop dx pop cx mov ax, -1 ; set error code ret If the file was found, restore all of the registers. AX contains the entry location within the Root Directory Table so that it can be loaded. .Found: pop ax ; return value into AX contains entry of file pop bx ; restore registers and return pop dx pop cx ret Yay! Now that we can find the file (and get it's location within the Root Directory Table), lets load it! Loading a file Now that everything is finally set up, it is finally time to load the file! Most of this is pretty easy, as it calls our other routines. It is here that we loop, and insure that all of the file's clusters are loaded into memory. ;******************************************* ; LoadFile () ; - Load file ; parm/ ES:SI => File to load ; parm/ BX:BP => Buffer to load file to ; ret/ AX => -1 on error, 0 on success ; ret/ CX => Number of sectors loaded ;******************************************* LoadFile: xor ecx, ecx push ecx Here we just save the registers. We need to keep a copy of the buffer to write to somewhere, so we keep that on the stack as well. CX is used to keep track of how many sectors we have loaded. We store this on the stack for later. In loading the file, we will need to first find it (Kind of obvious, don't you think? ^^) We can easily use our FindFile routine here. FindFile sets AX to -1 on error, or the starting entry location within the Root Directory Table upon success . We can use this index to get anything we ever wanted to know about the file. .FIND_FILE: push bx ; BX=>BP points to buffer to write to; store it for later push bp call FindFile ; find our file. ES:SI contains our filename cmp ax, -1 ; check for error jne .LOAD_IMAGE_PRE ; No error ðŸ˜€ Load the FAT pop bp ; Nope :( Restore registers, set error code and return pop bx pop ecx mov ax, -1 ret Okay, so if we get here, the file was found. ES:DI contains the location of the first root entry, which was set by FindFile(), so by referencing ES:DI we effectively get the file's entry. Look back at the entry description table above in the previous section. Notice that we can offset 0x1A bytes to get to byte 26 (The starting cluster number), so store it... .LOAD_IMAGE_PRE: sub edi, ROOT_OFFSET sub eax, ROOT_OFFSET ; get starting cluster push word ROOT_SEG pop es mov dx, word [es:di + 0x001A] ; ES:DI points to file entry in root directory table. mov word [cluster], dx ; Reference the table for file's first cluster pop bx ; get location to write to so we don't screw up the stack pop es push bx ; store location for later again push es The above is messy, I know. Remember that AX was set to the entry number by the call to FindFile? We need to store that here, but need to keep the buffer to write to on the top of the stack still. This is why I played with the stack a little here ðŸ˜€ Anyways, next we load the FAT. This is incredibly easy... call LoadFAT ; Load the FAT to 0x7c00 OKAY then! Now that the FAT is loaded, and that we have the starting file cluster, it is time to actually read in the file's sectors. .LOAD_IMAGE: mov ax, WORD [cluster] ; cluster to read pop es pop bx call ClusterLBA ; convert cluster to LBA xor cx, cx mov cl, BYTE [bpbSectorsPerCluster] ; sectors to read call ReadSectors ; Read in cluster pop ecx ; increment sector count inc ecx push ecx push bx ; save registers for next iteration push es mov ax, FAT_SEG mov es, ax xor bx, bx This code is not that bad. Remember that, for FAT12, each cluster is just 512 bytes ? i.e., each cluster simply represents a \"sector\". We first get the starting cluster/sector number. We cannot do much with just a cluster number though, as it is a linear number. That is, it is the sector number in CHS Not LBA format--It assumes we have the track and head information. Because our ReadSectors() requires an LBA linear sector number, We convert this CHS to an LBA address . Then, get the sectors per cluster, and read it in! Note that we pop ES and BX--They were pushed on the stack from the beginning. ES:BX points to the ES:BP buffer that was passed to this routine--It contains the buffer to load the sectors into. OKAY, so now that a cluster was loaded, we have to check with the FAT to determine if the end of file is reached. However, Remember that each FAT entry is 12 bytes? We found out from Bootloaders 4 that there is a pattern when reading the FAT: For every even cluster, take the low twelve bits; for every high cluster take the high twelve bits Please see Bootloaders 4 to see this in detail. To determine if it is even or odd, just divide by 2: ; compute next cluster mov ax, WORD [cluster] ; identify current cluster mov cx, ax ; copy current cluster mov dx, ax ; copy current cluster shr dx, 0x0001 ; divide by two add cx, dx ; sum for (3/2) mov bx, 0 ; location of FAT in memory add bx, cx ; index into FAT mov dx, WORD [es:bx] ; read two bytes from FAT test ax, 0x0001 jnz .ODD_CLUSTER .EVEN_CLUSTER: and dx, 0000111111111111b ; take low twelve bits jmp .DONE .ODD_CLUSTER: shr dx, 0x0004 ; take high twelve bits .DONE: mov WORD [cluster], dx ; store new cluster cmp dx, 0x0FF0 ; test for end of file marker (0xFF) jb LOAD_IMAGE ; No? Go on to next cluster then DONE: pop es ; restore all registers pop bx pop ecx xor ax, ax ; return success code ret That's all there is too it! Granted a little complex, but not to hard, I hope ðŸ˜‰ Fat12.inc Great! All of the FAT12 code is in Fat12.inc . Finishing Stage 2 Back to Stage 2 - Loading and Executing the Kernel Now that the messy code is over, all we need to do is load our Kernel image into memory from Stage 2, and execute our kernel. The problem is: Where? While we do want to load it to 1MB, we cannot do this directly yet. The reason is that we are still in real mode. Because of this, we will first need to load the image to a lower address first. After we switch into protected mode, we can copy our kernel to a new location. This can be 1MB, or even 3GB if paging is enabled. call LoadRoot ; Load root directory table mov ebx, 0 ; BX:BP points to buffer to load to mov ebp, IMAGE_RMODE_BASE mov Esi, ImageName ; our file to load call LoadFile ; load our file MOV dword [ImageSize], ecx ; size of kernel cmp ax, 0 ; Test for success je EnterStage3 ; yep--onto Stage 3! mov si, msgFailure ; Nope--print error call Puts16 mov ah, 0 int 0x16 ; await keypress int 0x19 ; warm boot computer cli ; If we get here, something really went wong hlt Now our kernel is loaded to IMAGE_RMODE_BASE:0. ImageSize contains the number of sectors loaded (The size of the kernel). To execute inside of protected mode, all we need to do is jump or call it. Because we want our kernel at 1MB, we first need to copy it before we execute it: bits 32 Stage3: mov ax, DATA_DESC ; set data segments to data selector (0x10) mov ds, ax mov ss, ax mov es, ax mov esp, 90000h ; stack begins from 90000h ; Copy kernel to 1MB (0x10000) CopyImage: mov eax, dword [ImageSize] movzx ebx, word [bpbBytesPerSector] mul ebx mov ebx, 4 div ebx cld mov esi, IMAGE_RMODE_BASE mov edi, IMAGE_PMODE_BASE mov ecx, eax rep movsd ; copy image to its protected mode address call CODE_DESC:IMAGE_PMODE_BASE; execute our kernel! There is a little problem here, though. This assumes the Kernel is a pure binary file . We cannot have this, because C does not support this. We need the Kernel to be a binary format that C supports, and we will need to parse it in order to load the Kernel using C. For now, we will keep this pure binary, but will fix this within the next few tutorials. Sound cool? Demo Our pure uber-1337 32 bit Kernel executing. DOWNLOAD DEMO HERE Conclusion In this tutorial, we covered these concepts in a new perspective, however. This may help understanding these topics a little bit more, and to see them being implemented into separate routines. We have developed code to load sectors off disk, and parse FAT12 to load our Kernel at whatever location we want. Cool, huh? In this Series, we are loading the Kernel at 1 MB. With a basic full 32 bit Kernel finally loaded and executing, we can finally start focusing our attention to the most important part of any operating system -- The Kernel. In the next few tutorials, we will cover Kernel Theory, Revolutions, and Designs. We will then start covering Low Level C Programming , and Low level programming with high level language concepts and theory. There are a lot of freedom when programming C at Kernel Level, that most other programming fields do not allow. For example, There still is no such thing as an \"Access Violation\", so you still have direct control over every byte in memory. The bad news: There is also no such thing as a \"standard library\" either. To add more bad news, you still have to remember that you are programming a low level environment , just with another abstraction layer that is C."
  },
  "articles/61_unorganised_tutorial/T12.html": {
    "href": "articles/61_unorganised_tutorial/T12.html",
    "title": "Kernel: Basic Concepts Part 1 | BrokenThorn OS Dev Tutorials",
    "keywords": "Kernel: Basic Concepts Part 1 The Kernel is the Core of all operating systems. Understanding what it is and how it effects the operating system is important. In this tutorial, We will look at what goes behind Kernels, what they are, and what they are responsible for. Understanding these concepts is essential in coming up with a good design. Kernel: Basic Definition In order to understand what an OS Kernel is, we need to first understand what a \"kernel\" is at it's basic definitions. Dictionaries define \"kernel\" as \"core\", \"essential part\", or even \"The body of something\". When applying this definition to an Operating System environment, we can easily state that: The Kernel is the core component of an operating system. Okay, but what does this mean for us? What exactly is an OS Kernel, and why should we care for it? There is no rule that states a kernel is mandatory. We can easily just load and execute programs at specific addresses without any \"kernel\". In fact, all of the early computer systems started this way. Some modern systems also use this. A notable example of this are the early console video game systems, which required rebooting the system in order to execute one of the games designed for that console. So, what is the point of a Kernel? In a computing environment, it is impractical to restart every time to execute a program. This will means that each program itself would need its own bootloaders and direct hardware controlling. After all, if the programs need to be executed at bootup, there would be no such thing as an operating system. What we need is an abstraction layer to provide the capability of executing multiple programs, and manage their memory allocations. It also can provide an abstraction to the hardware, which will not be possible if each program had to start on bootup without an OS. After all, the software will be running on raw hardware. The keyword here is Abstraction . Lets look closer... The need for Kernels The Kernel provides the primary abstraction layer to the hardware itself. The Kernel is usually at Ring 0 because of this very reason: It has direct control over every little thing . Because we are still at Ring 0, we already experienced this. This is good--but what about other software? Remember that we are developing an operating environment ? Our primary goal is providing a safe, and effective environment for applications and other software to execute. If we let all software to run at Ring 0, alongside the Kernel, there would be no need for a kernel, would there be? If there was, The ring 0 software may conflict with the ring 0 Kernel , causing unpredictable results. After all, they all have complete control over every byte in the system. Any software can overwrite the kernel, or any other software without any problems. Ouch. Yet, that is only the beginning of the problems. It is impossible to have multitasking, or multiprocessing as there is no common ground to switch between programs and processes. Only one program can execute at a time. The basic idea is that a Kernel is a necessity. Not only do we want to prevent other software direct control over everything, but we want to create an abstraction layer for it. Understanding where and how the Kernel fits in with the rest of the system is very important. Abstraction Layers of Software Software has a lot of abstractions. All of these abstractions is meant to provide a core and basic interfaces to not only hide implementation detail, but to shield you from it. Having direct control over everything might seem cool--but imagine how much problems would be caused by doing this. You might be curious as of what problems I am referring to. Remember that, it its core, electronics does only what we tell it. We can control the software down to the hardware level, and in some cases, electronics level. Making a mistake at these levels can physically cause damage to those devices. Lets take a look at each abstraction layer to understand what I mean, and to see where our Kernel fits in. Relationship with PMode Protection Ring Levels In Bootloaders 3 Tutorial , we have took a detailed look at the Rings of Assembly Language. We also looked at how this related to protected mode . Remember that Ring 0 software has the lowest protection level. This means that we have direct control over everything, and are expected to never crash. If any Ring 0 program was to crash, it will take the system down with it (Triple Fault). Because of this, not only do we want to shield everything else from direct control, but we want to only give software the protection level needed to run it. Because of this, normally: Kernels work in Ring 0 (\"Supervisor Mode\") Device Drivers work in Rings 1 and 2, as they require direct access to hardware devices Normal application software work in Ring 3 (\"User Mode\") Okay... how does this all fit together? Lets take a closer look... Level 1: Hardware Level This is the actual physical component. The actual microcontroller chips on the motherboard. They send low level commands to other microcontrollers on other devices that physically control this device. How? We will look at that in Level 2. Examples of hardware are the microcontroller chipset (The \"Motherboard Chipset'), disk drives, SATA, IDE, hard drives, memory, the processor (Which is also a controller--Please see Level 2 more more information). This is the lowest level, and the most detailed as it is pure electronics. Level 2: Firmware Level The Firmware sets on top of the electronics level. It contains the software needed by each hardware device and microcontroller. One example of firmware is the BIOS POST. Remember the processor itself is nothing more then a controller--and just like other controllers, rely on its firmware. The Instruction Decoder within the processor dissects a single machine instruction into either Macrocode , or directly to Microcode . Please see the Tutorial 7: System Architecture Tutorial for more information. Microcode Firmware is usually developed using microcode, and either assembled (With a microassembler) and uploaded into a storage area (Such as the BIOS POST), or hardwired into the logic circuits of the device through various of means. Microcode is usually stored within a ROM chip, such as EEPROM. Microcode is very hardware specific. Whenever there is a new change or revision, a new Microcode instruction set and Micro assembler needs to be developed. On some systems, Microcode has been used to control individual electronic gates and switches within the circuit. Yes, It is that low level. Macrocode Microcode is very low level, and can be very hard to develop with, especially in complex systems, such as a microprocessor or CPU. It also must be reimplemented whenever a change happens--Not only the code, but the Microprograms as well. Because of this, some systems have implemented a more higher level language called Macrocode on top of Microcode. Because of this abstraction layer, Macrocode changes less frequently then that of Microcode, and is more portable. Also, do to its abstraction layer, is more easier to work with. It is still, however, very low level. It is used as the internal logic instruction set to convert higher level machine language into Microcode--which is translated by the Instruction Decoder. Level 3: Ring 0 - Kernel Level This is where we are at. The Stage 2 Bootloaders only focus was to set everything up so that our Kernel has an environment to run in. Our Kernel provides the abstraction between Device Drivers and Applications software, and the firmware that the hardware uses. Level 4: Rings 1 and 2 - Device Drivers Device Drivers go through the Kernel to access the hardware. Device Drivers need a lot of freedom and control because they require direct control over specific microcontrollers. Having to much control, however, can crash the system. For example, what would happen if a driver modified the GDT, or set up its own? Doing so will immediately crash the kernel. Because of this, we will want to insure these drivers cannot use LGDT to load its own GDT. This is why we want these drivers to operate at either Ring 1 or Ring 2--Not ring 0 . For an example, a Keyboard Device Driver will need to provide the interface between Applications software and the Keyboard Microcontroller . The driver may be loaded by the Kernel as a library providing the routines to indirectly access the controller. As long as there is a standard interface used, we can provide a very portable Kernel as long as we hide all hardware dependencies. Level 5: Ring 3 - Applications Level This is where the software are at. They use the interfaces provided by the System API and Device Driver interfaces. Normally they do not access the Kernel directly. Conclusion (Abstraction Layers of Software) This Series will be developing the drivers during the development of the Kernel. This will allow us to keep things object oriented, and provide abstraction layer for the Kernel. With that in mind, notice where we are at-- Level 0 . All other programs rely on the Kernel. Why? Lets look at the Kernel... The Kernel Because the Kernel is the Core component, it needs to provide the management for everything that relies on it. The primary purpose of the Kernel is to manage system resources, and provide an interface so other programs can access these resources. In a lot of cases, the Kernel itself is unable to use the interface it provides to other resources. It has been stated that the Kernel is the most complex and difficult tasks in programming. This implies that designing and implementing a good Kernel is very difficult. In Tutorial 2 we took a brief look at different past operating systems. We have bolded a lot of new terms inside that tutorial--and have compiled a list of those terms at the end of the tutorial. This is where that list starts getting implemented. Lets first look at that list again, and look at how it related to the Kernel. Everything Bolded is handled by the Kernel: Memory Management Program Management Multitasking Memory Protection Fixed Base Address - This was covered in Tutorial 2 Multiuser - This is usually implemented by a shell Kernel - Of course File System Command Shell Graphical User Interface (GUI) Graphical Shell Linear Block Addressing (LBA) - This was covered in Tutorial 2 Bootloader -Completed Some of the above can be implemented as separate drivers, used by the Kernel. For example, Windows uses ntfs.sys as an NTFS Filesystem Driver. This list should look familiar from Tutorial 2 . We have also covered some of these terms. Lets look at the bolded terms, and see how they relate to the Kernel. We will also look at some new concepts. Memory Management This is quite possibly the most important part of any Kernel. And rightfully so--all programs and data require it. As you know, in the Kernel, because we are still in Supervisor Mode (Ring 0), We have direct access to every byte in memory . This is very powerful, but also produces problems, especially in a multitasking environment, where multiple programs and data require memory. One of the primary problems we have to solve is: What do we do when we run out of memory? Another problem is fragmentation . It is not always possible to load a file or program into a sequential area of memory . For an example, lets say we have 2 programs loaded. One at 0x0, the other at 0x900. Both of these programs requested to load files, so we load the data files: Notice what is happening here. There is a lot of unused memory between all of these programs and files. Okay...What happens if we add a bigger file that is unable to fit in the above? This is when big problems arise with the current scheme. We cannot directly manipulate memory in any specific way, as it will corrupt the currently executing programs and loaded files. Then there is the problems of where each program is loaded at. Each program will be required to be Position Independent or provide relocation Tables . Without this, we will not know what base address the program is supposed to be loaded at. Lets look at these deeper. Remember the ORG directive? This directive sets the location where your program is expected to load from. By loading the program at a different location, the program will reference incorrect addresses, and will crash. We can easily test this theory. Right now, Stage2 expects to be loaded at 0x500. However, if we load it at 0x400 within Stage1 (While keeping the ORG 0x500 within Stage2), a triple fault will occur. This adds on two new problems. How do we know where to load a program at? Considering all we have is a binary image, we cannot know. However, if we make it standard that all programs begin at the same address--lets say, 0x0, then we can know. This would work--but is impossible to implement if we plan to support multitasking. However, if we give each program there own memory space, that virtually begins at 0x0, this will work. After all, from each programs' perspective, they are all loaded at the same base address--even if they are different in the real (physical) memory. What we need is some way to abstract the physical memory. Lets look closer. Virtual Address Space (VAS) A Virtual Address Space is a Program's Address Space . One needs to take note that this does not have to do with System Memory . The idea is so that each program has their own independent address space. This insures one program cannot access another program, because they are using a different address space. Because VAS is Virtual and not directly used with the physical memory, it allows the use of other sources, such as disk drives, as if it was memory. That is, It allows us to use more memory then what is physically installed in the system. This fixes the \"Not enough memory\" problem. Also, as each program uses its own VAS , we can have each program always begin at base 0x0000:0000. This solves the relocation problems discussed earlier, as well as memory fragmentation--as we no longer need to worry about allocating continuous physical blocks of memory for each program. Virtual Addresses are mapped by the Kernel trough the MMU. More on this a little later. Virtual Memory: Abstract Virtual Memory is a special Memory Addressing Scheme implemented by both the hardware and software. It allows non contiguous memory to act as if it was contiguous memory. Virtual Memory is based off the Virtual Address Space concepts. It provides every program its own Virtual Address Space, allowing memory protection, and decreasing memory fragmentation. Virtual Memory also provides a way to indirectly use more memory then we actually have within the system. One common way of approaching this is by using Page files , stored on a hard drive . Virtual Memory needs to be mapped through a hardware device controller in order to work, as it is handled at the hardware level. This is normally done through the MMU , which we will look at later. For an example of seeing virtual memory in use, lets look at it in action: Notice what is going on here. Each memory block within the Virtual Addresses are linear. Each Memory Block is mapped to either it's location within the real physical RAM, or another device, such as a hard disk. The blocks are swapped between these devices as an as needed bases. This might seem slow, but it is very fast thanks to the MMU. Remember: Each program will have its own Virtual Address Space--shown above. Because each address space is linear, and begins from 0x0000:00000, this immediately fixes a lot of the problems relating to memory fragmentation and program relocation issues. Also, because Virtual Memory uses different devices in using memory blocks, it can easily manage more then the amount of memory within the system. i.e., If there is no more system memory, we can allocate blocks on the hard drive instead. If we run out of memory, we can either increase this page file on an as needed bases, or display a warning/error message, Each memory \"Block\" is known as a Page , which is usually 4096 bytes in size. Once again, we will cover everything in much detail later. Memory Management Unit (MMU): Abstract My, oh my, where have we heard this term before? o.0 ðŸ˜€ The MMU, Also known as Paged Memory Management Unit (PMMU) is a component inside the microprocessor responsible for the management of the memory requested by the CPU. It has a number of responsibilities, including Translating Virtual Addresses to Physical Addresses, Memory Protection, Cache Control, and more. Segmentation: Abstract Segmentation is a method of Memory Protection . In Segmentation, we only allocate a certain address space from the currently running program. This is done through the hardware registers . Segmentation is one of the most widely used memory protection scheme. On the x86, it is usually handled by the segment registers : CS, SS, DS, and ES. We have seen the use of this through Real Mode. Paging: Abstract THIS will be important to us. Paging is the process of managing program access to the virtual memory pages that are not in RAM. We will cover this a lot more later. Program Management THIS is where the ring levels start getting important. As you know, Our Kernel is at Ring 0, while the applications are at Ring 3. This is good, as it prevents the applications direct access to certain system resources. This is also bad, as a lot of these resources are needed by the applications. You might be curious on how the processor knows what ring level it is in, and how we can switch ring levels. The processor simply uses an internal flag to store the current ring level. Okay, but how does the processor know what ring to execute the code in? This is where the GDT and LDT become important. As you know, in Real Mode, there is no protection levels. Because of this, everything is \"Ring 0\". Remember that we have to set up a GDT prior to going into protected mode? Also, remember that we needed to execute a far jump to enter the 32 bit mode. Lets go over this in more detail here, as they will play very important roles here. Supervisor Mode Ring 0 is known as supervisor mode . It has access to every instruction, register, table, and other, more privileged resources that no other applications with higher ring levels can access. Ring 0 is also known as Kernel level , and is expected never to fail. If a ring 0 program crashes, it will take the system down with it. Remember that: \"With great power comes great responsibility\" . This is the primary reason for protected mode. ðŸ˜‰ Supervisor Mode utilizes a hardware flag that can be changed by system level software. System level software (Ring 0) will have this flag set, while application level software (Ring 3) will not. There are a lot of things that only Ring 0 code can do, that Ring 3 code cannot. Remember the flags register from Tutorial 7 ? The IOPL Flag of the RFLAGS register determines what level is required to execute certain instructions, such as IN and OUT instructions. Because the IOPL is usually 0, this means that Only Ring 0 programs have direct access to hardware via software ports. Because of this, we will need to switch back to Ring 0 often. Kernel Space Kernel Space refers to a special region of memory that is reserved for the Kernel, and Ring 0 device drivers. In most cases, Kernel Space should never be swapped out to disk, like virtual memory . If an operating software runs in User Space , it is often known as \"Userland\" . User Space This is normally the Ring 3 application programs . Each application usually executes in its own Virtual Address Space (VAS) and can be swapped from different disk devices. Because each application is within their own virtual memory, they are unable to access another programs memory directly. Because of this, they will be required to go through a Ring 0 program to do this. This is necessary for Debuggers . Applications are normally the least privileged. Because of this, they usually need to request support from a ring 0 Kernel level software to access system resources. Switching Protection Levels What we need is a way so that these applications can query the system for these resources. However, to do this, we need to be in Ring 0, Not Ring 3. Because of this, we need a way to switch the processor state from Ring 3 to Ring 0, and allow applications to query our system. Remember back in Tutorial 5 we covered the rings of assembly language. Remember that the processor will change the current ring level under these conditions: A directed instruction, such as a far jump, far call, fat ret etc. A trap instruction, such as INT, SYSCALL, SYSEXIT, SYSENTER, SYSRETURN etc. Exceptions So...In order for an application to execute a system routine (while switching to Ring 0), the application must either far jump , execute an Interrupt , or use a special instruction, such as SYSENTER . This is great--but how does the processor know what ring level to switch into? This is where the GDT comes into play. Remember that, in each descriptor of the GDT, we had to set up the Ring Level for each descriptor? In our current GDT, We have 2 descriptors: Each for Kernel Mode Ring 0. This is our Kernel Space . All we need to do is to add 2 mode descriptors to our current GDT, but set for Ring 3 access . This is our User Space . Lets take a closer look. Remember from tutorial 8 that the important byte here is the access byte! . Because of this, here is the byte pattern again: Bit 0 (Bit 40 in GDT): Access bit (Used with Virtual Memory). Because we don't use virtual memory (Yet, anyway), we will ignore it. Hence, it is 0 Bit 1 (Bit 41 in GDT): is the readable/writable bit. Its set (for code selector), so we can read and execute data in the segment (From 0x0 through 0xFFFF) as code Bit 2 (Bit 42 in GDT): is the \"expansion direction\" bit. We will look more at this later. For now, ignore it. Bit 3 (Bit 43 in GDT): tells the processor this is a code or data descriptor. (It is set, so we have a code descriptor) Bit 4 (Bit 44 in GDT): Represents this as a \"system\" or \"code/data\" descriptor. This is a code selector, so the bit is set to 1. Bits 5-6 (Bits 45-46 in GDT): is the privilege level (i.e., Ring 0 or Ring 3). We are in ring 0, so both bits are 0. Bit 7 (Bit 47 in GDT): Used to indicate the segment is in memory (Used with virtual memory). Set to zero for now, since we are not using virtual memory yet ;******************************************* ; Global Descriptor Table (GDT) ;******************************************* gdt_data: ; Null descriptor (Offset: 0x0)--Remember each descriptor is 8 bytes! dd 0 ; null descriptor dd 0 ; Kernel Space code (Offset: 0x8 bytes) dw 0FFFFh ; limit low dw 0 ; base low db 0 ; base middle db 10011010b ; access - Notice that bits 5 and 6 (privilege level) are 0 for Ring 0 db 11001111b ; granularity db 0 ; base high ; Kernel Space data (Offset: 16 (0x10) bytes dw 0FFFFh ; limit low (Same as code)10:56 AM 7/8/2007 dw 0 ; base low db 0 ; base middle db 10010010b ; access - Notice that bits 5 and 6 (privilege level) are 0 for Ring 0 db 11001111b ; granularity db 0 ; base high ; User Space code (Offset: 24 (0x18) bytes) dw 0FFFFh ; limit low dw 0 ; base low db 0 ; base middle db 11111010b ; access - Notice that bits 5 and 6 (privilege level) are 11b for Ring 3 db 11001111b ; granularity db 0 ; base high ; User Space data (Offset: 32 (0x20) bytes dw 0FFFFh ; limit low (Same as code)10:56 AM 7/8/2007 dw 0 ; base low db 0 ; base middle db 11110010b ; access - Notice that bits 5 and 6 (privilege level) are 11b for Ring 3 db 11001111b ; granularity db 0 ; base high Notice what is happening here. All code and data have the same range values--the only difference is that of the Ring levels. As you know, protected mode uses CS to store the Current Privilege Level (CPL) . When entering protected mode for the first time, We needed to switch to Ring 0 . Because the value of CS was invalid (From real mode), we need to choose the correct descriptor from the GDT into CS. Please see Tutorial 8 for more information . This required a far jump, as we needed to upload a new value into CS. By far jumping to a Ring 3 descriptor, we can effectively enter a Ring 3 state. As, as you know, we can use a INT, SYSCALL/SYSEXIT/SYSENTER/SYSRET, far call, or an exception to have the processor switch back to Ring 0. Lets take a look closer at these methods... System API: Abstract The program relies on the System API to access system resources. Most applications reference the System API directly, or through their language API--Such as the C runtime library . The System API provides the Interface between applications and system resources through System Calls . Interrupts A Software Interrupt is a special type of interrupt implemented in software. Interrupts are used quite often, and rely on the use of a special table--the Interrupt Descriptor Table (IDT) . We will look at Interrupts a lot more closer later, as it is the first thing we will implement in our Kernel. Linux uses INT 0x80 for all system calls. Interrupts are the most portable way to implement system calls. Because of this, we will be using interrupts as the first way of invoking a system routine. Call Gates Call Gates provide a way for Ring 3 applications to execute more privileged (Ring 0,1,2) code. The Call gate interfaces between the Ring 0 routines and the Ring 3 applications, and is normally set up by the Kernel. Call Gates provide a single gate (Entry point) to FAR CALL. This entry point is defined within the GDT or LDT. It is much easier to understand a call gate with an example. ;******************************************* ; Global Descriptor Table (GDT) ;******************************************* gdt_data: ; Null descriptor (Offset: 0x0)--Remember each descriptor is 8 bytes! dd 0 ; null descriptor dd 0 ; Kernel Space code (Offset: 0x8 bytes) dw 0FFFFh ; limit low dw 0 ; base low db 0 ; base middle db 10011010b ; access - Notice that bits 5 and 6 (privilege level) are 0 for Ring 0 db 11001111b ; granularity db 0 ; base high ; Kernel Space data (Offset: 16 (0x10) bytes dw 0FFFFh ; limit low (Same as code)10:56 AM 7/8/2007 dw 0 ; base low db 0 ; base middle db 10010010b ; access - Notice that bits 5 and 6 (privilege level) are 0 for Ring 0 db 11001111b ; granularity db 0 ; base high ; Call gate (Offset: 24 (0x18) bytes CallGate1: dw (Gate1 & 0xFFFF) ; limit low address of gate routine dw 0x8 ; code segment selector db 0 ; base middle db 11101100b ; access - Notice that bits 5 and 6 (privilege level) are 11 for Ring 3 db 0 ; granularity db (Gate1 >> 16) ; base high of gate routine ; End of the GDT. Define the routine wherever ; The call gate routine Gate1: ; do something special here at Ring 3 retf ; far return back to calling routine The above is an example of a call gate. To execute the call gate, we offset from the descriptor code within the GDT. Notice how similar this is from our jmp 0x8:Stage2 instruction: ; execute the call gate call far 0x18:0 ; far call--calls our Gate1 routine Call Gates are not used too often in modern operating systems. One of the reasons is that most architectures do not support Call Gates. They are also quite slow as they require a FAR CALL and FAR RET instructions. On systems where the GDT is not in protected memory, it is also possible for other programs to create their own Call Gates to raise its protection level (and get Ring 0 access.) They have also been known to have security issues. One notable worm, for example, is Gurong , which installs its own call gate in the Windows Operating System. SYSENTER / SYSEXIT Instructions These instructions were introduced from the Pentium II and later CPUs. Some recent AMD processors also support these instructions. SYSENTER can be executed by any application. SYSRET can only be executed by Ring 0 programs. These instructions are used as a fast way to transfer control from a User Mode (Ring 3) to a Privilege Mode (Ring 0), and back quickly. This allows a fast and safe way to execute system routines from user mode. These instructions directly rely on the Model Specific Registers (MSR's). Please see Tutorial 7 for an explanation of MSRs, and the RDMSR and WRMSR instructions. SYSENTER The SYSENTER instruction automatically sets the following registers to their locations defined within the MSR: CS = IA32_SYSENTER_CS MSR + the value 8 ESP = IA32_SYSENTER_ESP MSR EIP = IA32_SYSENTER_IP MSR SS = IA32_SYSENTER_SS MSR This instruction is only used to transfer control from a Ring 3 code to Ring 0. At startup, we will need to set these MSR's to point to a Starting location which will be our Syscall Entry Point for all system calls. Lets take a look at SYSEXIT. SYSEXIT The SYSEXIT instruction automatically sets the following registers to their locations defined within the MSR: CS = IA32_SYSENTER_CS MSR + the value 16 ESP = ECX Register EIP = EDX Register SS = IA32_SYSENTER_CS MSR MSR + 24 Using SYSENTER/SYSEXIT Okay, using these instructions might seem complicated, but they are not too hard ðŸ˜‰ Because SYSENTER and SYSEXIT require that the MSR's are set up prior to calling them, we first need to initialize those MSRs. Remember that IA32_SYSENTER_CS is index 0x174, IA32_SYSENTER_ESP is 0x175, and IA32_SYSENTER_IP is 0x176 within the MSR. Remember from tutorial 7? Knowing this, lets set them up for SYSENTER: %define IA32_SYSENTER_CS 0x174 %define IA32_SYSENTER_ESP 0x175 %define IA32_SYSENTER_EIP 0x176 mov eax, 0x8 ; kernel code descriptor mov edx, 0 mov ecx, IA32_SYSENTER_CS wrmsr mov eax, esp mov edx, 0 mov ecx, IA32_SYSENTER_ESP wrmsr mov eax, Sysenter_Entry mov edx, 0 mov ecx, IA32_SYSENTER_EIP wrmsr ; Now, we can use sysenter to execute Sysenter_Entry at ring 0 from either a Ring 0 program or Ring 3: sysenter Sysenter_Entry: ; sysenter jumps here, is is executing this code at privilege level 0\\. Similar to Call Gates, normally we will ; provide a single entry point for all system calls. If the code that executes sysenter is at Ring 3, and Sysenter_Entry is at protection level 0, the processor will switch modes within the SYSENTER instruction. in the above code, both are at Protection Level 0, so the processor will just call the routine without changing modes. As you can see, there is a bit of work that must be done prior to calling SYSENTER.\\ and SYSEXIT. SYSENTER and SYSEEXIT are not portable. Because of this, it is wise to implement another, more portable, method alongside SYSENTER/SYSEXIT. SYSCALL / SYSRET Instructions [I plan on adding a section for SYSCALL and SYSRET here soon] Error Handling What do we do if a program causes a problem? How will we know what that problem is and how to handle it? Normally this is done by means of Exception Handling . Whenever the processor enters an invalid state caused by an invalid instruction, divide by 0, etc; the processor triggers an Interrupt Service Routine (ISR) . If you have mapped our own ISR's, it will call our routines. The ISR called depends on what the problem was. This is great, as we know what the problem is, and can try finding the program that originally caused the problem. One way of doing this is simply getting the last program that you have given processor time to. That is guaranteed to be the one that has generated the ISR. Once you have the programs information, then one can either output an error or attempt to shutdown the program. IRQs are mapped by the internal Programmable Interrupt Controller (PIC) inside the processor. They are mapped to interrupt entries within the Interrupt Descriptor Table (IDT). This is the first thing we will work on inside the Kernel, so we will cover everything later. Conclusion We looked at a lot of different concepts in this tutorial, ranging from Kernel theory, memory management concepts, Virtual Memory Addressing (VMA), and program management, including separating Ring 0 from Ring 3, and providing the interface between applications and system software. Whew! That's a lot, don't you think? a lot of the concepts in this tutorial may be new to you--don't worry. This is more of a \"Get your feet wet\" tutorial, where we cover all of the basic concepts related to Kernels. This tutorial has barely scratched the surface of what a Kernel must do. That is a start, though. ðŸ˜‰ In the next tutorial, we are going to look at Kernels from another perspective. We will cover some new concepts yet again, and talk about Kernel designs and implementations. Afterwards, we will start building our compilers and toolchains to work with C and C++. Sound fun? I am currently using MSVC++ 2005 for my Kernel. We will also finish off other concepts that we have not looked at here, including multitasking, TSS, Filesystems , and more. Its going to be fun ðŸ˜‰"
  },
  "articles/61_unorganised_tutorial/T12-13.html": {
    "href": "articles/61_unorganised_tutorial/T12-13.html",
    "title": "The Kernel: Setting up | BrokenThorn OS Dev Tutorials",
    "keywords": "The Kernel: Setting up"
  },
  "articles/61_unorganised_tutorial/T13.html": {
    "href": "articles/61_unorganised_tutorial/T13.html",
    "title": "Kernel: Basic Concepts Part 2 | BrokenThorn OS Dev Tutorials",
    "keywords": "Kernel: Basic Concepts Part 2 Here's what's on the menu for today: Hardware Abstraction Kernel: A new perspective Kernel designs: Abstract: Primary Design Models Kernel designs: Abstract: Secondary Design Models This tutorial will cover the glue between the bootloader and beginning kernel design. This will be the glue that brings everything together for us to see what kernels really are, and to understand what we need to do. All the concepts listed here will be very important in the next few tutorials, as we will start designing and developing our Hardware Abstraction Layer (HAL) and our uber-1337 kernel. err ... wait, that's actually the next tutorial!! So, lets both lay back in our comfortable seats and take a look at another fun happy tutorial! Oh right, and this tutorial is not that big either, which is nice ðŸ˜€ Note: This tutorial recommends that our readers have read through [Tutorial 2] (Fix link) before proceeding. I plan on adding a section describing exokernels. They are a relatively new kernel design concept. I do not plan on implementing this design within this series, but feel our readers might be interested in the kernel design. Perhaps use the design in their own OS? Hardware Abstraction Hardware Abstraction is very important. By now, you may know how complex hardware programming can be, and how very hardware dependent it is. This is where a Hardware Abstraction Layer (HAL) comes in. A HAL is a software abstraction layer used to provide an interface to the physical hardware. It is an abstraction layer. These abstractions provide a way to interact with devices, while not needing to know the details of a particular device or controller. Normally in modern OSs, the HAL is a basic Motherboard chipset driver . It provides a basic interface between the kernel and the hardware of the machine, including the processor. This is great, as the Kernel can interact with the HAL whenever it needs access to the hardware. This also means that the kernel can be completely hardware independent. This also allows us to think in terms of the device itself, rather then specific controllers or mappings. This helps make the kernel itself cleaner as well. Another great benefit comes from abstraction itself. If we decide to port our OS to a system with different hardware, all we need to do is develop a new HAL for it. This assumes that the HAL is designed very well to allow this. Most modern operating systems use a HAL in some way. We will also be developing a HAL to act as a motherboard chipset driver between the chipset hardware and the kernel. We will start developing on our HAL within the next tutorial, when we abstract the processor itself behind the HAL. Kernel: A new perspective A \"Kernel\" is the central component of a system. This system can be anything. The Kernel is the core of the system; it provides the very basic facilities for the management of efficient execution of the system. In an operating system, this all-so-powerful Kernel provides the most basic interface to the system hardware and resources. It also provides the most basic management facilities, such as processor management, I/O management, memory management, and process management. The Kernel can contain more, depending on the complexity of the system being developed. Okay...The previous list might sound familiar... hmm ..Where have we seen that before? We actually looked at each inside of [Tutorial 2] (fix link). Lets look at this closer for better understanding. Kernel: Putting everything together Memory Management Okay, then! Remember again from [Tutorial 2] (fix link). We have created a basic list of items regarding memory management and protection. Lets take another look at that again: Memory Management refers to: Dynamically giving and using memory to and from programs that request it. Implementing a form of Paging, or even Virtual Memory. Insuring the OS Kernel does not read or write to unknown or invalid memory. Watching and handling Memory Fragmentation. Memory Protection refers to: Accessing an invalid descriptor in protected mode (Or an invalid segment address) Overwriting the program itself. Overwriting a part or parts of another file in memory. Right about now, you should have a better understanding of everything within [Tutorial 2] (fix link). Remember that the Kernel, as it is running in ring 0, has direct control over every single byte in memory...Even if there is none. Also, remember that this is all running directly on physical memory. What happens if we run out of memory? What would happen if we write to nonexistent memory? What about memory locations used by hardware devices? This also does not touch the \"gaps\" that may be found throughout memory as well. Warning: Writing random locations in physical memory may (Depending on where you write to) can cause malfunctions (Depending if a hardware device uses that area of memory), or completely make the system unbootable, and completely useless. (Depending if you write over the BIOS data area.) Never directly probe memory! With all of this in mind, you should begin to see how important it is to properly manage physical memory. A Kernel that properly manages the physical memory can create a virtual interface between applications and memory. This can be done through separating User Space and Kernel Space code and data, and through Virtual Addressing. Because of the many problems with directly running in physical memory, we can emulate a better method of memory. This memory emulation (Virtual Memory) can emulate a system with a lot more memory then physical RAM, where each application uses its own virtual memory address space. Processor Management This is a new one. As you know, the BIOS ROM initializes and starts up the primary processor. It only starts a single core. If you are running your OS on a system with a multicore processor, or a system with multiple processors, you will need to start up the other processors and cores manually. Letting applications play with the different processors at any time can cause fatal system problems. Because of this, we should never allow applications the ability to do this. I/O Device Management Similar to physical memory, allowing applications direct access to controller ports and registers can cause the controller to malfunction, or system to crash. With this, depending on the complexity of the device, some devices can get surprisingly complex to program, and uses several different controllers. Because of this, providing a more abstract interface to manage the device is important. This interface is normally done by a Device Driver or Hardware Abstraction Layer . This allows us to think in terms of the device, rather then its details. Frequently, applications will require access to these devices. The Kernel must maintain the list of these devices by querying the system for them in some way. This can be done through the BIOS, or through one of the various system buses (Such as PCI/PCIE, or USB.) When an application requests an operation on a device (Such as, displaying a character), the kernel needs to send this request to the current active video driver. The video driver, in turn, needs to carry out this request. This is an example of Inter Process Communication (IPC). Process Management This is the most important task of the Kernel, and any computer for that matter. The Kernel needs a way of allocating execution time, and executing and management of different applications and processes. This is where Program Management, and Multitasking comes in. These terms should sound familiar from Tutorial 2 . Lets take another look at that from tutorial 2: Program Management is responsible for: Insuring the program doesn't write over another program. Insuring the program does not corrupt system data. Handle requests from the program to complete a task (such as allocate or deallocate memory). Multitasking refers to: Switching and giving multiple programs a certain timeframe to execute. Providing a Task Manager to allow switching (Such as Windows Task Manager). TSS (Task State Segment) switching. Another new term! Executing multiple programs simultaneously. To execute an application, the Kernel must set up the applications own Virtual Address Space (VAS) , and load the file into the VAS. the Kernel then sets up the applications stack, and jumps to it to begin execution. Through Virtual Addressing, we can insure the application does not run into system memory problems. In a multitasking system, the Task Manager will allocate a certain amount of time to each process, and only execute them within that time frame. It will then switch between running applications. Because the time allocated is small, the Task Manager can switch between running process quickly, giving the illusion of multiple processes running simultaneously. This can either be done through hardware or software. The processor supports hardware task switching through the use of its Task State Segment (TSS) register. The System API By now, you should start being able to understand how everything fits together, and where a lot of the concepts from [Tutorial 2] (fix link OSDev2.html) starts to come in. Yet, there is one little detail that we have not covered yet. How does the application ask the Kernel for request to a device or system resource? We have seen methods on how the OS manages and control the application, but how does the application control the system? This is where the system Application Programming Interface (API) comes in. The System API is an API that applications may use to interact with the Kernel and other system software. There are a lot of methods for creating the System API. Most systems support System API routines through interrupts. For an example, The Linux Kernel System API primarily uses interrupt number 0x80 for system routines. Wow, that is a lot of stuff, huh? Don't worry if you don't understand this yet. Everything will be clear soon enough ðŸ˜€ Kernel Designs - Abstract: Primary Design Models By now, you may start realizing how important Kernels are, and where they fit in. There has been a lot of operating systems that have been developed using a lot of different designs and setups. A lot of these designs have some similar basic concepts. There are a lot of different ways to construct kernels. We will look some of the more used designs here. Monolithic kernel Design In a Monolithic Kernel, all system process run as part of the Kernel at Ring 0 Lets first look at the term \"Monolithic\". The first part--\"Mono\" means \"one\". The second part--\"lithic\" means \"it is of or like stone\". In a Monolithic kernel, the entire Kernel executes in Kernel space at Ring 0. It provides a higher level interface over computer resources and hardware. It also provides a basic set of system calls via the System API. In a monolithic kernel, most (if not all) Kernel services are part of the kernel, itself. This does not mean that the services cannot be independent of each other. However, the software is very tightly integrated to the rest of the kernel. This makes monolithic kernels very fast and efficient, compared to other designs. Because all OS services run in kernel space as part of the kernel (or as an extension to the kernel), if there is a problem with a device driver or a system service program, it can cause the entire system to crash. When an application requests a system service, it executes a system call through the System API. Examples of Monolithic kernels Several large scale operating systems use a hybrid kernel, including but not limited to: Unix-like kernels Linux Syllable Unix kernels BSD FreeBSD NetBSD Solaris AI DOS DR-DOS MS-DOS Microsoft Windows 9x series (95, 98, Windows 98SE, Me) Mac OS kernel, up to Mac OS 8.6 OpenVMS XTS-400 Microkernel Design In a Microkernel design, the Kernel only provides basic functionality needed for user mode system services. A Microkernel is a kernel design that provides no OS services at all, only the mechanisms needed to implement those services. Because of this, the Kernel itself is usually quite small compared to Monolithic kernels. For example, a microkernel may implement low level memory management and thread management, and Inter Process Communication (IPC). The above image displays a microkernel. Notice the kernel only implements the very basics of basics. In this case, it implements basic process management and scheduling, Inter Process Communication (IPC), and basic virtual memory management. The Kernel would use external user mode services, such as Device Drivers and Filesystems, rather then everything implemented as part of the kernel (As with Monolithic kernels.) Because of this, if an external service crashes, the system may still be functional, and the system will not crash. Inter Process Communication (IPC) and understanding Servers and Device Drivers is important in understanding how Microkernels work. Microkernel Servers Microkernel \"Servers\" are external programs that is granted special privileges by the kernel that normal programs do not have. These \"privileges\" may be direct access to hardware, or even physical memory. This allows server programs to interact directly with the hardware devices they are controlling. Wait...It sounds like a device driver, doesn't it? Yep ðŸ˜€ That's basically what they are. Remember that microkernels are very minimal. They rely on external programs - servers - to help out. Servers needed by the kernel itself is normally loaded into memory before the kernel is executed. An example that will be needed is a file system server, that will contain the code for parsing the filesystem. Because the Kernel has no filesystem code, it has no way of loading the filesystem server! Because of this, it needs to be loaded before the kernel is executed. How can we do this? There are several ways. One method is loading a complete RAM image containing both the kernel and supported severs in it. Another method is simply loading the necessary servers at startup within the bootloader, and in someway giving the server information to the kernel upon executing. In both cases, the bootloader can determine what filesystem loading code to use, however the code can interact with the filesystem server without ever needing to load it in the first place! Cool, huh? Note: A \"server\" may also be called a \"daemon\". Inter Process Communication (IPC) IPC is very important in microkernels. It allows separate processes to communicate with each other, usually by sending messages, but it can also be invoked by using shared memory. There are a lot of ways a process can \"signal\" another process. With regards to microkernel severs, the most commonly used is also one of the easiest to understand - message passing. IPC allows the servers and kernel to interact with each other. Synchronous IPC : In Synchronous IPC , The process sending the message is suspended until the other process responds. If the other process is busy, the message is stored in a queue for that process to act upon when ready. Asynchronous IPC : Similar to Synchronous IPC , however both processes continue executing. That is, the process is not suspended. Kernel Designs - Abstract: Secondary Design Models Remember that there are countless of ways that kernels may be designed. The following are common design models that are based off of the primary design models (Monolithic and Microkernels). Hybrid kernels Hybrid kernels are Microkernels with aspects from Monolithic kernels A Hybrid kernel is a kernel combining aspects from both Monolithic and Microkernel designs. Hybrid kernels usually has a structure similar to microkernels, but implemented as a monolithic kernel. Lets look at this another way for better understanding. Hybrid Kernels, similar to microkernels, use separate sever programs for filesystems, device drivers, etc. However, like Monolithic Kernels, these severs execute as part of the Kernel, instead of user space. There are some controversy on what the term \"Hybrid Kernel\" applies to. It may be called a \"Microkernel\", \"Macrokernel\", or \"modified microkernel or modified macrokernel\". Hybrid kernels are not in their own design; they are just modified Microkernels with some aspects from monolithic kernels. Do to this, there are some controversy on what to consider hybrid kernels. Microsoft's NT Architecture uses a hybrid approach to their kernel design model. Microsoft describes their kernel as a \"Modified microkernel\". Examples of Hybrid kernels Several large scale operating systems use a hybrid kernel, including but not limited to: BeOS Kernel Haiku Kernel BSD DragonFly BSD Kernel XNU Kernel NetWare Kernel Plan 9 Kernel Inferno Kernel Windows (NT,2000,2003,XP,Vista) NT Kernel ReactOS Kernel Nanokernel Nanokernels, also known as Picokernels , are a very small kernel. Normally, this would be a minimal microkernel structure. As the kernel itself is very small, it must rely on other software and drivers for the basic resources within the system. Conclusion We will be developing a modified microkernel in this series. This will allow our readers to gain some experience and understanding in both monolithic and microkernel designs, as well as mixing the approaches into a Hybrid Microkernel. In fact, our kernel will look similar to that is displayed in this tutorial. We will touch upon the full design of our kernel within the next tutorial, along with developing the basic building blocks for our HAL to abstract processor dependencies using C++."
  },
  "articles/61_unorganised_tutorial/T13_1.html": {
    "href": "articles/61_unorganised_tutorial/T13_1.html",
    "title": "MSVC++ 2005, 2008, 2010 | BrokenThorn OS Dev Tutorials",
    "keywords": "MSVC++ 2005, 2008, 2010 Welcome! ðŸ˜€ This tutorial covers setting up Microsoft Visual C++ 2005 to work in Kernel Land. This will allow us to use, and completely work in, the nice MSVC++ 2005 IDE. We will be using the Express Edition. If you have the professional edition, some of the screen shots will be different. Do not worry as most of the options are still the same. This tutorial will also work fine if you have Visual C++ 2008 or Visual C++ 2010 (with some slight modifications in what options to set). Getting a high level language to work can be tricky to work and set up with. Getting the build envirement to work itself adds on even more complexity. The first problem, for example, is that MSVC++ only outputs Win32-compilent PE executables and DLL's. And, at our current stage, we only have a flat, pure binary program loaded at absolute address 1 MB. How do we execute a full blown C++ program, from our flat pure-assembler program? And yet, that is the beginning of the problems. C++ itself relies on the C++ runtime library. So? The C++ runtime library relies on the operating system. Because we are developing the operating system, C++ has no standard library to work with within our operating system . This means, that we have to work without any standard runtime. But wait! Remember that, in application software, the runtime needs to initialize everything for our C++ envirement (Such as executing global constructors, providing basic C++ operation support, and executing our main())? Because we have no runtime, we have to do everything ourselves. This produces an interesting chicken and egg scenario: How can we develop a runtime envirement without a runtime for it to work in? As you can probably see, it can be quite tricky to get C++ to even work properly. In this tutorial, we are going to set up MSVC++ 2005 for kernel development, and set up the language to work for us. We will also be watching for runtime integrations (i.e, watching where basic C++ relies on the runtime, so we can build our own). Please note, however, that some C++ features rely on details that we have yet to impliment. These details are fairly advanced. For example, the C++ new and delete operaters require that we have a working memory manager already. As such, this section cannot cover everything just yet. Nontheless, we will set as much things up as possible here. Ready? Setting up a new Project Just like almost any other project, creating a project is fairly straightfoward. Within the IDE, Select File->New->Project . You should see a nice dialog: Notice that the Empty Project setting is selected under Installed Templates . Now, type in the name of the project, and choose the project location. When you are done, select the \"OK\" button, which should be highlighted. Your new project should now be created. The Build Envirement - Project Properties This is great! The problem, however, is that the compilier assumes we are building a basic Win32 application. As such, it sets all of the project properties to it's default configuation, and links the Standard C++ Runtime libraries--which will not work for us. Because of this, we need to change the configuation settings. To access Project Properties , Right Click the project name, and select Properties . You should recieve a dialog, simular to the following: All of the configuation settings are discussed in the same format listed in the above picture (Please look at the left plane). Project Wide Settings Most configuation settings depend entirely on the envirement that is being built on. Remember that we are still in a very low level envirement. A Single wrong instruction produced by the compilier can make our code triple fault. Also, remember that We are still at Ring 0 . As such, we still have control over every little thing. This is important, because if the code the compilier produces does not work with our current operating system setup, the code will triple fault. This is a problem. Alot of the configuation settings effect the output code. Weather these changes cause a triple fault, or work completely depends on the layout of your operating system, and its configuations. Alot of these changes do not need to be changed. However, because certain configuations may cause a triple fault, this indicates to be extra careful when trying to produce \"The fastest and greatest code\" from your C++ compilier. There are, however, some options that REQUIRE changing. These are the options that I will look at here. I will also cover some other options that one may find helpful. I will explain these specific options in depth. At the end of this section, I will post my current configuation, cool? This way, you can compare your configuations, and learn about setting up MSVC++ 2005. Configuation Type We are going to be building the kernel as an executable, so keep this as Application (.exe) . This setting is located under General (Please see the image shown in the above section to locate Configuation Type ). C++ Configuation Settings Looking at the above image again, you will see the C/C++ and Linker properties expanded. the C/C++ properties include General, Optomization, Preprocessor, Code Generation, etc. We will cover these properties here. C/C++ > General None of these options we are not required to change. There are a couple of options I want to look at here, however. Additional Include Directories : This option allows us to provide our own path for INCLUDE files. This will allow us to use the format when including our own files: #include <myheader.h> This can be usefull when seperating the inlcusion of files within the same directory ( #include \"myheader.h\" ) and including files within a standard Kernel include directory ( #include <myheader.h> ) Debug Information Format : Although we are using MSVC++, we Cannot use it's debugging features. Debuggers require a runtime envirement to run in (and to hook) with an application. Because we do not have a runtime envirement, you should Disable this. Normally, Adding debuggng information will not cause any problems. However, because we are unable to use the debugger right now, there is no reason to generate debug info. Warning Level : Operating System code can get very complex. It is important that we can track even the slightest of potential problems. Because of this, I recommend to Set this to the highest level . C/C++ > Optomization Optimization : This can be set to any option. If a specific setting causes the code to crash, disassemble the code and try to find out why. All source code in this series have been tested with all optomization levels to work. Omit Frame Pointers : This is not required; but setting this option frees up ESP so we may use it. C/C++ > Preprocessor Preprocessor Definitions : Throughout the source code, I will be hiding all x86 architecture dependencies behind a special preprocessor constant. This makes it easier to port non-portable code to other architectures. This constant is ARCH_X86 . This can be #define'd, but putting ARCH_X86 here is easier ðŸ˜‰ Ignore Standard Include Path : Remember we do not have a standard library anymore? ðŸ˜€ C/C++ > Code Generation There are a few options that I want to go over. Enable C++ Exceptions : This requires runtime support, which we do not have. I plan on implimenting exception handling soon, though. Until then, this should be set to No . Struct Member Alignment : While writing the Kernel, we will be using alot of classes and structures. Most of these must be byte aligned. Most compiliers add extra padding (for speed) to these structures, which will throw off the alignment that we need. Because of this, set this to 1 Byte (/Zp1) Buffer Security Check : When enabled, MSVC++ adds extra code to test for possible buffer under and overruns. This relies on the MSVC++ runtime, which we cannot use. Because of this, we cannot use this. Set this to No (/GS-) C/C++ > Language Enable Run-Time Type Info : Run Time Type Info (RTTI) requires runtime support. Because we are disabling the runtime, we cannot use this. Set to No (/GR-) C/C++ > Advanced No changes needed here. I do personally recommend using __cdecl over __stdcall , as __cdecl seems to have a cleaner symbol names. It does not really matter though. C/C++ > Command Line Here is the command line that I am using. If you are having difficulty, feel free to use this as a refrence. You can also see all of these options set in the demo at the end of this chapter. /O2 /Oy /I \"..\\Include\\\\\" /D \"ARCH_X86\" /X /FD /MT /Zp1 /GS- /GR- /FAs /Fa\"Debug\\\\\" /Fo\"Debug\\\\\" /Fd\"Debug\\vc80.pdb\" /W4 /nologo /c /Gd /TP /errorReport:prompt Compare this command line with the one you currently have. You may have additional options, depending on weather you decided to add more options. Linker Configuation Settings The linker is very important to us for a number of reasons. It is responsible for creating the final symbolic names the compilier produces. These symbolic names represent numerical addresses for varables, routines, and constants. For example, the routine \"main()\" might be compilied into the symbolic name \"_main\". In assembly language, we refrence varables and routines by their symbolic names. Because of this, to call a C++ main() routine, we will normally do this: call _main ; call C++ main() routine The linker produces a linker map with all of these symbolic names. This will be very important with debugging and testing. With this, there are some linker settings that are required, while others are optional. The optional settings may or may not work depending on your envirement settings and configuations. Linker > General There are no options that require changing here. If you are using a real (or virtual) floppy drive, I personally recommend setting the Output File to point to the floppy drive. This way, the final binary will be placed into the floppy disk, allowing us to immediately test the Kernel in the emulator. Linker > Input Additional Dependencies : By default, MSVC++ automatically links in a number of its libraries, including kernel32.lib, user32.lib, gdi32.lib, winspool.lib and more. Because we never use them, they will not cause any problems. They will add extra uneeded bloat to your kernel, though. Setting this to $(NOINHERIT) will fix this so they will not be linked. Ignore Default Libraries : There is no standard library, so set this to Yes (/NODEFAULTLIB) Linker > Debugging Remember that the linker can generate a mapfile? This allows us to see the relitive address locations of all global symbolic names. This will be very important to us, coinsidering we are still at the binary image level. To do this: Set Generate Map File to Yes (/MAP) Set Map File Name to the name of the mapfile to generate. Hit Apply Linker > System SubSystem : This value is stored within the program file. It tells the operating system how to run the application. Because this is a driver application, set this to Native (/SUBSYSTEM:NATIVE) . Driver : This option insures to build this program as a kernel-level driver. This automatically envokes the /FIXED:NO option (instead of the standard /FIXED option), which generates a relocation section, instead of a fixed base address. Because we are developing a driver application, set this option to Driver (/DRIVER) . Linker > Optimization Setting Refrences to Eleminate unrefrenced data removes all unrefrenced symbols (such as varables and functions that are never used.) I recommend setting this option to reduce the number of symbols from the linker map, and to reduce kernel size. Setting Enable COMDAT folding to Remove redundent COMDATS will also reduce the size of the Kernel, and the number of redundent COMDATS. Linker > Advanced Entry Point : This should be set to the entry point of your kernel. In our system, this will be kernel_entry . Base Address : This is the base address that the image will be loaded to. Remember that the kernel is loaded to 1MB? Because of this, this should be set to 0x100000. Fixed Base Address : This will be automatically envoked by the linker. Set this to Generate a relocation section (/FIXED:NO) . Linker > Command Line Additional options : Add /ALIGN:512 to the Additional options text box. This is required to insure proper section alignment. Not doing so will cause problems executing the kernel or triple faults . The command line : Thats all! Compare your command line with the following. You may have additional options depending on your envirement setup. /OUT:\"A:\\KRNL32.EXE\" /INCREMENTAL:NO /NOLOGO /LIBPATH:\"..\\Lib\\\\\" /MANIFEST:NO /NODEFAULTLIB /MAP:\"Kernel.map\" /SUBSYSTEM:NATIVE /DRIVER /OPT:REF /OPT:ICF /ENTRY:\"kernel_entry\" /BASE:\"0x100000\" /FIXED:No /ERRORREPORT:PROMPT Executing the PE Kernel I do not plan on going over the entire format of executable files here. Not until we cover program and task managers, anyways. The problem, however, is that MSVC++ can only output COFF and PE file formats. Because of this, we have to find a way of parsing it from within our Stage 2 bootloader. Because I do not plan on describing the PE format in detail yet, I will first describe its basic format, and how the code works. Lets take a look! File Format Once we have loaded a file image into memory, it is simply a direct copy of the image file on disk. Because of this, in order to parse the file, all we need to do is read it from where we loaded it from memory. Understanding how to parse file formats are very important. Remember that the FIRST byte within the FIRST structure actually represents the FIRST byte from where it is loaded at in memory. _IMAGE_DOS_HEADER This structure is the very first structure within the PE file. typedef struct _IMAGE_DOS_HEADER { // DOS .EXE header USHORT e_magic; // Magic number (Should be MZ) USHORT e_cblp; // Bytes on last page of file USHORT e_cp; // Pages in file USHORT e_crlc; // Relocations USHORT e_cparhdr; // Size of header in paragraphs USHORT e_minalloc; // Minimum extra paragraphs needed USHORT e_maxalloc; // Maximum extra paragraphs needed USHORT e_ss; // Initial (relative) SS value USHORT e_sp; // Initial SP value USHORT e_csum; // Checksum USHORT e_ip; // Initial IP value USHORT e_cs; // Initial (relative) CS value USHORT e_lfarlc; // File address of relocation table USHORT e_ovno; // Overlay number USHORT e_res[4]; // Reserved words USHORT e_oemid; // OEM identifier (for e_oeminfo) USHORT e_oeminfo; // OEM information; e_oemid specific USHORT e_res2[10]; // Reserved words LONG e_lfanew; // File address of new exe header } IMAGE_DOS_HEADER, *PIMAGE_DOS_HEADER; We do not need to fully understand this yet, until we create a full PE loader. For now, because we are only looking for the entry routine address, we need to find the entry routine address from the _IMAGE_FILE_HEADER structure, which contains the start of the PE header. The address of the _IMAGE_FILE_HEADER structure is inside of the e_lfanew member of the _IMAGE_DOS_HEADER. So, in order to access this member, we refrence the byte offset from where it is loaded in memory: mov ebx, [IMAGE_PMODE_BASE+60] ; e_lfanew is a 4 byte offset address of the PE header; it is 60th byte. Get it add ebx, IMAGE_PMODE_BASE ; add base Yey! Noe EBX contains the starting address of the _IMAGE_FILE_HEADER structure. This assumes our PE kernel image was loaded at IMAGE_PMODE_BASE . Real Mode DOS Stub Program Okay then! Lets look back up at the PE file image structure again (The above picture.) Notice how a DOS stub program is right after the _IMAGE_DOS_HEADER. This is a useful program, actually. This is the program that displays \"This program cannot be run in DOS Mode\", if you try to execute a Windows program from within DOS. It is possible to change the program that is executed. This allows us to embed our own program to execute, instead of the dull default one. We do this is MSVC++ using the STUB command line option. For example: /STUB=myprog.exe As long as myprog.exe is a 32 bit application, MSVC++ will embed that program as the DOS stub program, insead of the dull default one. Cool? This can be usefull for a verity of reasons. Who knows--Perhaps provide a specialized DOS version of your program? Because our kernel is an EXE file, it is possible for users to double-click and attempt to run it from Windows. Instead, this DOS stub program will run instead. Cool, huh? Anywhoo...Because the size of this program is not constant, we need to jump over it to the next section--the _IMAGE_FILE_HEADER. This is why we needed to get the location of _IMAGE_FILE_HEADER from the _IMAGE_DOS_HEADER struct. _IMAGE_FILE_HEADER typedef struct _IMAGE_FILE_HEADER { USHORT Machine; USHORT NumberOfSections; ULONG TimeDateStamp; ULONG PointerToSymbolTable; ULONG NumberOfSymbols; USHORT SizeOfOptionalHeader; USHORT Characteristics; } IMAGE_FILE_HEADER, *PIMAGE_FILE_HEADER; Okay...Remember that EBX now contains the starting address of this structure. This structure is useful, but not for what we need. We need a way of executing the entry point routine, remember? Knowing that this struct is 24 bytes in size, and the _IMAGE_OPTIONAL_HEADER structure is right after it, we can just skip this structure for now: mov ebx, [IMAGE_PMODE_BASE+60] ; e_lfanew is a 4 byte offset address of the PE header; it is 60th byte. Get it add ebx, IMAGE_PMODE_BASE ; add base ; EBX now points to beginning of _IMAGE_FILE_HEADER. Jump over it to the next section (_IMAGE_OPTIONAL_HEADER) add ebx, 24 _IMAGE_OPTIONAL_HEADER struct _IMAGE_OPTIONAL_HEADER { // // Standard fields. // USHORT Magic; UCHAR MajorLinkerVersion; UCHAR MinorLinkerVersion; ULONG SizeOfCode; ULONG SizeOfInitializedData; ULONG SizeOfUninitializedData; ULONG AddressOfEntryPoint; << IMPORTANT! ULONG BaseOfCode; ULONG BaseOfData; // // NT additional fields. // ULONG ImageBase; ULONG SectionAlignment; ULONG FileAlignment; USHORT MajorOperatingSystemVersion; USHORT MinorOperatingSystemVersion; USHORT MajorImageVersion; USHORT MinorImageVersion; USHORT MajorSubsystemVersion; USHORT MinorSubsystemVersion; ULONG Reserved1; ULONG SizeOfImage; ULONG SizeOfHeaders; ULONG CheckSum; USHORT Subsystem; USHORT DllCharacteristics; ULONG SizeOfStackReserve; ULONG SizeOfStackCommit; ULONG SizeOfHeapReserve; ULONG SizeOfHeapCommit; ULONG LoaderFlags; ULONG NumberOfRvaAndSizes; IMAGE_DATA_DIRECTORY DataDirectory[IMAGE_NUMBEROF_DIRECTORY_ENTRIES]; } IMAGE_OPTIONAL_HEADER, *PIMAGE_OPTIONAL_HEADER; THIS is an important structure. While its name states that it is \"optional\"--It is not, so do not worry about that. It is a required structure for all PE programs. The important member here is AddressOfEntryPoint which contains...erm... The address of the entry point routine. For example...main(), mainCRTStartup(), whatever suits your needs. Knowing that EBX points to the beginning of this structure, all we now need to do is refrence EBX+AddressOfEntryPoint. Read from that location, and we have the beginning address of the starting routine to call. After we get this address, all we need to do is far jump to that location, and we effectivly call our C++ entry point! Putting it together Now that everything is set up, lets try to put this all together. Remember that the image is loaded at IMAGE_PMODE_BASE: mov ebx, [IMAGE_PMODE_BASE+60] ; e_lfanew is 60th byte. Get it add ebx, IMAGE_PMODE_BASE ; Add base address. EBX now points to file sig (PE00) Because the image is loaded at PMODE_IMAGE_BASE, that is where the first byte of the first structure--_IMAGE_DOS_HEADER, is located. Remember that the e_lfanew member of the _DOS_IMAGE_FILE structure contains the address of the _IMAGE_FILE_HEADER. Because this is an offset address (Assuming base 0), we have to add the base address to where we loaded it in memory. ; jump over to optional header (Although it isnt optional o.0 ) add ebx, 24 mov eax, [ebx] ; _IMAGE_FILE_HEADER is 20 bytes + size of sig (4 bytes) add ebx, 16 ; address of entry point is now in ebx Now EBX points to the beginning of _IMAGE_FILE_HEADER. The first lines jumps over this section (As we do not need it now). So, after the first instruction here, EBX now points to the beginning of the _IMAGE_OPTONAL_HEADER structure , where we can begin looking for the AddressOfEntryPoint member. This member is 16 bytes from the start, so we add 16 to EBX. Now, EBX contains the address of the entry point routine. Before calling it, however, we need to add the image base address to the entry point address. That is, the entry point address is just an offset. Looking back at the _IMAGE_OPTIONAL_HEADER structure, we can see the ImageBase member. This is 12 bytes (A ULONG is 4 bytes) from AddressOfEntryPoint . Knowing EBX already points to AddressOfEntryPoint , this is very easy: mov ebp, dword [ebx] ; store entry point address add ebx, 12 ; ImageBase member is 12 bytes from AddressOfEntryPoint member mov eax, dword [ebx] ; gets image base add ebp, eax ; add image base to entry point address Now that ebp contains the entry point address, call it: call ebp ; Execute Kernel Not to hard, huh? Notice that we do not need to specify the code selector (0x8) here. The reason is that CS already contains 0x8. Developing a C++ Runtime Envirement for MSVC++ As you know, we cannot use the runtime that was provided with Windows. The reason is fairly simple. The C++ Windows runtime relies heavily on an existing Windows Operating system. Because we are developing a new operating system, this runtime is nonexistant. Because of this, We have to create our own C++ runtime code. This can get tricky. Alot of C++ features requires the use of a runtime. However, because we have disabled the runtime, the compilier will generate interesting errors when using these features. Other times are simply unpredictable, and may cause a triple fault. Lets look at this, for a moment. In applications, what calls main()? The runtime library. What calls and initialzes all global objects? The runtime library. What provides certain keyword supports that which tie with the system (such as new and delete)? The runtime library. What sets up the initil stack information? Again: The runtime library. Not defining a runtime library can cause unpredictable results. For one, global and static objects will never be initialized. Another problem is that the use of certain keywords are unpredictable. Global and static objects will never be deallocated. Also, the compilier relies on certain routines--useually defined by the standard runtime. Defining and calling virtual functions may become unpredictable. The calling of pure virtual routines will immediately crash. And, say goodby to new, delete, typeid, and exceptions . To make a story short: Creating a small C++ runtime is essental to get C++, the language itself, to even work properly for us. Global Operators You will need to define the global new and delete operators. The problem, however, is that we have no memory manager to work around with. Because of this, for now, don't do anything: void* __cdecl ::operator new (unsigned int size) { return 0; } void* __cdecl operator new[] (unsigned int size) { return 0; } void __cdecl ::operator delete (void * p) {} void __cdecl operator delete[] (void * p) { } Now we can use the new and delete keywords without error--although they do absolutly nothing...yet, anyways. Pure virtual function call handler Pure virtual functions are functions declared in the class, but contain no definition. Their primary purpose is to force derived classes to overload that function. It is not possible to call a pure virtual function directly through normal means. Calling a pure virtual function will result into undefined behavior, because that function does not actually exist--It was never defined. If a pure virtual function has some how been called, the compilier attempts to use _purecall() as the call handler. If this does not exist, the result is unpredictable--That is, a triple fault. Because of this, our C++ runtime will need to define it: int __cdecl ::_purecall() { for (;ðŸ˜‰; return 0; } Normally you would want to assert () when this happens as it should never happen. Floating Point Support Everything is working great with our new MSVC++ kernel. That is, until we try to compile float i=2/2; and BAM! We get hit by errors. More specifically, unresolved external errors...Our favoriate ðŸ˜‰ There is nothing wrong with this...Just like with using the new and delete operators without them being defined. Simulariy, MSVC++ needs some routines defined for working with floating point math. _fltused This is used by MSVC++ to determin if floating point is currently in use. This should be set to 1 and must be given C linkage if building for C++: extern \"C\" int _fltused = 1; _ftol2_sse() Depending on your optomization level, MSVC++ may embed calls to _ftol2_sse() to convert a float to a long. I wont be using SSE here, so I will just write my implimentation using the FPU: extern \"C\" long __declspec (naked) _ftol2_sse() { int a; #ifdef ARCH_X86 _asm fistp [a] _asm mov ebx, a _asm ret #endif } Other routines I have defined other routines, which are _CIcos(), _CIsqrt(), and _CIsin(). Until we can verify these routines are needed, I will keep them inside of our runtime library. Initializing globals and static data Everything is good so far, except what about globals? Remember that the runtime is responsible for executing all global executed routines and initializing all global and static objects? Because we have disabled the runtime, we have to do it. To do this, we have to watch exactally how MSVC++ handles the constructors (ctors). MSVC++ uses a special section (Simular to .data, .bss, .text, etc.) within the final binary image for ctors. When the MSVC++ compilier finds an object that must be executed by the startup code, it places a Dynamic initializer inside of this section. This means that -- for every dynamic initializer that needs to be executed at startup, they can all be found by looking inside of this special section. This section is the .CRT section. These dynamic initializers are a an array of 4 byte function pointers, which are stored within .CRT So, if we can find a way of parsing this section, we can call each function pointer that MSVC++ set for us to call each routine that needs to be called at startup. We cannot do this with C++ alone, however, as these section names are very MSVC++ specific. Also, as we are building without any runtime, the .CRT section is currently nonexistant. We have to add this section ourselves. The only way of doing this is using the preprocessor. Naming Conventions Alright...This section can be a little confusing. The section names used in MSVC++ are very strange. Serously-- .CRT$XCU ? What were they thinking!? Actually, these section names do have a purpose. the section names are composed of two parts, seperated by the dollar sign \"$\". The first part is used as the base section name . The second part indicates where it is located at in the final image. That is, we can think of a section name having this format: .section_name$location_name The section name can be .code, .data, .bss, .CRT, or any other section name. The location_name is an alpabitic name that represents where we are in the section. For an example, in .CRT$XCA , .CRT is the section name, XCA is its location in that section. It does not matter what this location name is; the important thing to remember is that it is in alphabitical order . Here is an example: .CRT$XCA .CRT$XCU .CRT$XCZ Notice the sections are arranged in the letters of the alphabit. The arrangement of the second part determins their location, at which they are stored within the final image. In the above, .CRT$XCA will be first, .CRT$XCU is second, .CRT$XCZ is the last one. Lets look at this anoher way, by mixing these up... .CRT$XCZ .CRT$XCA .CRT$XCU The same thing applies here. .CRT$XCA is the first section, again. This example illustrates that: The order of these sections depends on their alphavalue--a comes before z, so .CRT$XCA comes before .CRT$XCZ. Notice the last character. Not too hard, I hope ðŸ˜€ We will be able to see these sections inside of the linker map, when we set them up. Creating new segment names In order to create a new section, we need to use the #pragma data_seg() directive. This directive insures that all data allocated after it is placed within this new section. This directive takes the form: #pragma data_seg( [\"section-name\"[, \"section-class\"] ] ) \"section_class\" is retained for compatibility purposes only, and is now ignored by MSVC++. The important part, thus, is the first parameter--\"section-name\", which gives the new section name a...er...name: #pragma data_seg(\".CRT$XCA\") // All varables allocated here are now placed within the .CRT$XCA section, rather then .data section To go back to the default (.data) section, use this pragma without parameters: //! Select the default data segment again (.data) for the rest of the unit #pragma data_seg() Merging Sections By default, we are unable to read or write to the .CRT section. However, we can read and wite to the .data section just fine. What we want is the same permissions for both section names. We can fix this by combining the two sections together, which will insure both sections have read and write abilities: //! Now, move the CRT data into .data section so we can read/write to it #pragma comment(linker, \"/merge:.CRT=.data\") Okay... So lets see... All global initializer routines are stored as function pointers within the .CRT$XCU section of the binary image. We can declare a section right before and after this section, and insure they are right after each other, thanks to the naming convention, and the linker. Because they are right next to each other, we can effectivly declare a varable to point to these sections--effectivly pointing to the first and last function pointer in the initializer array. Lets look at this next... Initializing globals - Setup Lets look at actual code, and break it down: //! Function pointer typedef for less typing typedef void (__cdecl *_PVFV)(void); We first typedef a function pointer to improve readability. This function pointer is used to point to each global initializer. /** * MSVC++ creates dynamic initializers and deallocaters, which help us in calling the routines. * The compilier and linker bind all dynamic initializers into a function pointer table inside a * section called .CRT$XCU. */ // Standard C++ Runtime (STD CRT) __xc_a points to beginning of initializer table #pragma data_seg(\".CRT$XCA\") _PVFV __xc_a[] = { NULL }; The above code creates the .CRT$XCA section. By declaring this with an \"A\", we insure this will be right before the next .CRT section defined, so it is guaranteed to be right before our .CRT$XCU section. __xc_a is a standard MSVC++ CRT name used as a pointer to the beginning of the initializer list, stored in .CRT$XCU //! .CRT$XCU is located here. Our .CRT$XCU is giaranteed to be located before .CRT$XCZ and after .CRT$XCA because of the naming convention used. //! Standard C++ Runtime (STD CRT) __xc_z points to end of initializer table #pragma data_seg(\".CRT$XCZ\") _PVFV __xc_z[] = { NULL }; This is the .CRT$XCZ section. Again, because of naming conventions, it is guaranteed to be right after the initialzer list within .CRT$XCU. By defining a function pointer here, It is guaranteed to point to the last initializer routine - 1, within the initializer array within .CRT$XCU. __xc_z is the standard name used by the MSVC++ CRT. //! Select the default data segment again (.data) for the rest of the unit #pragma data_seg() For all other data, we want to use .data section, so switch back to that section... //! Now, move the CRT data into .data section so we can read/write to it #pragma comment(linker, \"/merge:.CRT=.data\") ...And merge the .CRT section with our .data section. This insures we can access the .CRT section from the .data section. To initialize each routine, just loop through each function pointer and call it. Warning: Beware of null function pointers. Calling a null function pointer will result into an invalid jump to some random location in memory, which will result in triple fault. void __cdecl _initterm ( _PVFV * pfbegin, _PVFV * pfend ) { // Go through each initializer while ( pfbegin < pfend ) { // Execute the global initializer if ( *pfbegin != NULL ) (**pfbegin) (); // Go to next initializer inside the initializer table ++pfbegin; } } // This initializes all global initializer routines: _initterm(__xc_a, __xc_z); Cleaning up the envirement Yippee! We now have all global initializer routines being executed. Whats next? Cleaning up after ourselves, of course. The good news is that this is much easier to work with then the initializer routines. All we need to define a location to store an array of global deinitializer function pointers at some location in memory: //! function pointer table to global deinitializer table static _PVFV * pf_atexitlist = 0; //! Maximum entries allowed in table static unsigned max_atexitlist_entries = 32; //! Current amount of entries in table static unsigned cur_atexitlist_entries = 0; These are our function pointers that we use to keep track of where we are at in the global deinitializer array. We define where these arrays is located. MSVC++ adds deintializer code for each global object, that adds a function pointer to the global deinitializer array. It does this by calling a specially defined routine, atexit () . Note: MSVC++ requires this routine. Not defining this routine will result in errors when defining a dtor of any kind. The actual routine is simple. Remember that, for each global object, MSVC++ embeds code that will call this routine. The dtor as an object is passed into this routine as a paramater. Because of this, all we need to do is to add it to the end of our dtor array: //! For every global object created, MSVC++ calls this routine with a function ptr to each dtor int __cdecl atexit(_PVFV fn) { //! Insure we have enough free space if (cur_atexitlist_entries>=max_atexitlist_entries) return 1; else { // Add the exit routine *(pf_atexitlist++) = fn; cur_atexitlist_entries++; } return 0; } So...Now that we have a way of adding dtors to the list (Remember that MSVC++ automaticlly does this through our function), All we need to do is initialize the original function pointer array: void __cdecl _atexit_init(void) { max_atexitlist_entries = 32; // Warning: Normally, the STDC will dynamically allocate this. Because we have no memory manager, just choose // a base address that you will never use for now pf_atexitlist = (_PVFV *)0x500000; } Not too hard, I hope ðŸ˜€ There are alot of possibly new concepts for our readers, however, so all of this may be better in an example demo. The Entry Point Okay, so lets see...We have covered getting the entry address from the PE image. The entry point routine is immediately executed by the 2nd stage loader. We have set up our entry point to be kernel_entry so lets define it: void _cdecl kernel_entry () { We need to insure the registers and stack are setup before any code is executed. This is very important to insure we refrence the correct descriptors in the bootloaders' GDT. We also need to setup the stack, as C++ uses the stack reguarly. #ifdef ARCH_X86 _asm { cli // clear interrupts--Do not enable them yet mov ax, 10h // offset 0x10 in gdt for data selector, remember? mov ds, ax mov es, ax mov fs, ax mov gs, ax mov ss, ax // Set up base stack mov esp, 0x90000 Next, we store the current stack frame pointer. This will insure that any routines we call has a place to return to. mov ebp, esp push ebp } #endif Now, we call our main() routine! After calling main(), just halt the system, to insure we don't return (As there is nowhere to return to.) //! Execute global constructors InitializeConstructors(); //! Call kernel entry point main (); //! Cleanup all dynamic dtors Exit (); #ifdef ARCH_X86 _asm cli #endif for (;ðŸ˜‰; } Thats all thats needed! As long as the entry poin is set to kernel_entry , This routine will be placed at the starting base address--Which should be set to 1 MB Demo Demo Download (MSVC++) This demo loads and executes a 32 bit Kernel written in MSVC++ 2005. It also includes all of the source code in this tutorial, as well. Conclusion Yey! Alot of concepts in this tutorial is farily simple, isn't it? We covered setting up MSVC++ 2005 so that we can use the compilier for use in operating system Kernels. We also looked at creating a basic C++ runtime envirement, ctor and dtor calling, virtual function handling, and global operators. In the next few tutorials, we are looking at creating envirements for different compiliers. This tutorial has covered setting up MSVC++ 2005. This tutorial was hard to write--and I am yet to finish it. There are simply so many options that MSVC++ has, and describing these options in detail will take a long time. I wanted to find a way of combining context, not just a \"do this do that\" option setting list. I am still deciding on a format style for that. I hope I did Okay ðŸ˜€"
  },
  "articles/61_unorganised_tutorial/T14.html": {
    "href": "articles/61_unorganised_tutorial/T14.html",
    "title": "Basic CRT and Code Design | BrokenThorn OS Dev Tutorials",
    "keywords": "Basic CRT and Code Design We have also decided that we will be developing a hybrid kernel design for our operating system, as it uses some concepts derived from Microkernels and Monolithic kernel designs. To keep compatibility with C compilers, we will be using C instead of C++. However, I might be developing C++ versions of the source as I personally prefer C++ over C ðŸ˜€ So, here's what is on the list: Promoting Good Coding Practices Code Design and Layout Abstracting data types and basic declarations CRT: _null.h CRT: size_t.h CRT: ctype.h and cctype CRT: va_list.h and stdarg.h/csdtarg Demo: Writing Debug Printf (Will be uploaded soon) ...That's it! This tutorial only covers the basic setup of the HAL and Kernel. Lets start! Before we Begin This is our first step away from the bootloader world. Within our bootloader, we did not need to worry much about portability nor system dependency. After all, the bootloader - by its very nature - is very system dependent. This is the beginning of our own runtime library, and Hardware Abstraction Layer (HAL). Operating Systems can get very large in size. Because we do not know how large this system will be, we need to stress good coding practices from the start. Many development projects fail. It is not because it is to complex, however. Any project can be made with less complexity if designed right. This is what I want to look at next... Pandora's Boxes The truth is, simply put, code is evil. Code can get very disorderly and ugly. It is this that adds on more complexity do to the chaotic and recursive nature of code and design. don't get me wrong, we will still need to rewrite a lot of code. The reason for this is because there is no right design. How do we stop this from happening? As long as the code is contained within a nice little box, it does not matter how disorderly or ugly the code gets on the inside. That is, Encapsulation , and the bases for nearly all of software engineering. Encapsulation is a very important concept in software engineering. Even if you are not an Object Oriented Programmer, the concept of encapsulation is still there. Interface and implementation The interface (\"public\") part of the box is the connection from that box to the outside world. It is what connects our box to other boxes within this subsystem. The interface itself contains all of the function prototypes, structures, classes, and other definitions that the box exposes to the outside world so the outside world can use and interact with the box. This is the Interface . All of the evil code that dwells within this box that define the module, all of its functions, class routines, etc. is the modules implementation . In C, we can insure routines stay as part of the implementation by using the static keyword. Interfaces can be made by using the extern keyword. Within C++, It is encouraged to use classes, with the private, public, and protected keywords. Get Ready We will be using the above concepts with developing our system to promote good programming practices with large scale software. Because portability between compilers is a concern, we will be developing the system using the C programming language. Please keep in mind, however, that you may use C++ if you prefer. Our primary focus is that of expandability and portability. Because of this, we will be hiding all hardware dependent implementations behind its own little box - The Hardware Abstraction Layer (HAL). Because the C++ startup runtime code it compiler dependent, we will put that in its own little box - The CRT (C++ Runtime) Library . All of this will be completely independent of the rest of the system. With all of this in mind, lets take the first step into our system... Code Layout and Design This tutorial contains our most complex demo so far. Because of this, I would like our readers to open up the demo source, and follow along with the tutorial for better understanding of everything. Code Design It is very important to understand why we have chosen this structure for this series. The primary reason is that of encapsulation , where each directory contains a separate library module . That is, Each of these modules is a Pandora's box . It is extremely important to keep these modules as separate as possible in order to maintain code stability, structure, and portability. In order to do this, I have decided to treat each module as independent library modules. SysBoot\\ Stage1\\ - Stage1 bootstrap loader Stage2\\ - Stage2 KRNLDR bootloader Our System Core ======================================= SysCore\\ Debug\\ - Pre-Release complete builds Release\\ - Release builds Include\\ - Standard Library Include directory Lib\\ - Standard Library Runtime. Outputs Crtlib.lib or Crtlib.dll. Hal\\ - Hardware Abstraction Layer. Outputs Hal.lib or Hal.dll. Kernel\\ - Kernel Program. Outputs Krnl32.lib or KRNL32.EXE The only thing that does not need to be built as a library module are the files within the Include/ Directory. As they are only header files, they should never have the need to contain implementations. Because of this, there is no box to open. As with applications, I have decided to make the C++ runtime code the first code to be executed. In other words, the bootloader does NOT execute the kernel. Instead, it executes the runtime code (CRTLIB), which sets up the environment for the kernel, and then executes the kernel. _null.h Its time to start getting down to the nitty gritty of the tutorial! About C++ includes If you are using C++, you might be interested about the library header files. That is, in C++, the appended *.h is dropped, and a c is prepended to all C headers. So, instead of #include <stdlib.h> , C++ uses #include <cstdlib> We would like to encourage creating an interface compatible with both languages. However, you might be wondering how do we do that? Its very simple, actually. In all compilers standard include/ directory, you will see different variants of the same file. i.e., you will see stdlib.h and cstdlib . cstdlib is simply a header file that #includes stdlib.h and no more. We will be doing the same with our library. This will allow the developers using C to use stdlib.h , while our C++ developers can still use cstdlib . This way we can both encourage good habits. Back on topic The first abstraction I would like to look at is NULL. There really is not that much to say here. However, there is one small detail: The way NULL is defined depends on whether you are using C or C++. Within standard C, NULL is defined as (void )0. Within C++, it is simply 0. * We can determine this by using the fairly standard __cplusplus predefined constant: // Undefines NULL #ifdef NULL # undef NULL #endif #ifdef __cplusplus extern \"C\" { #endif /* standard NULL declaration */ #define NULL 0 #ifdef __cplusplus } #else /* standard NULL declaration */ #define NULL (void*)0 #endif There is more in this header do to the template, but this is the important part. Everything else is quite easy. size_t.h About Data Hiding Remember the Pandora's Box theory. The data types within a box are on implementation detail . Some data types are okay, however some or better kept within the implementation. size_t is one of them. By keeping the implementation details, we can modify anything we like about the data type, without effecting anything that uses that type, so long as we remain backward compatible. Back onto topic There isn't much to say about this one... #ifdef __cplusplus extern \"C\" { #endif /* standard size_t type */ typedef unsigned size_t; #ifdef __cplusplus } #endif Data Type Hiding - stdint.h and cstdint Within the previous section, we were encouraging the importance of data hiding within an interface, However, we did not stress the importance of it with relation to portability. Each data type has a specified size to them. However, the size of each data type completely depends on the compiler and system this is being built for. Because of this, it is important to hide the data types behind a standard interface, specifically because we are working in an environment where Size Does Matter(tm). stdint.h This is a fairly big file at about 150 lines. None of it is very hard, however. It defines different integral data types that are guaranteed to be a certain size. Lets look at the fundamental types, as we will be using them throughout the system: typedef signed char int8_t; typedef unsigned char uint8_t; typedef short int16_t; typedef unsigned short uint16_t; typedef int int32_t; typedef unsigned uint32_t; typedef long long int64_t; typedef unsigned long long uint64_t; When compiling for a 32bit system, the above data types are guaranteed to be the same. That is, uint8_t is guaranteed to be 8 bits. uint16_t is guaranteed to be the size of a WORD (2 bytes), and so on. The size of the data type is encoded in its name, so we will always know its size. There is a lot more code in this file, but most of it is fairly easy. The file cstdint simply #includes stdint.h. This allows us to include these declarations in two ways: #include <stdint.h// C #include <cstdint // C++ only Please see About C++ includes... section for more information of why we have done this. ctype.h and cctype ctype.h is a set of macros that help determine what type of character in a string is. It does this by following the different properties of the standard ASCII Character Set . You can get it from asciitable.com This header file includes several macros and constants: extern char _ctype[]; #define CT_UP 0x01 /* upper case */ #define CT_LOW 0x02 /* lower case */ #define CT_DIG 0x04 /* digit */ #define CT_CTL 0x08 /* control */ #define CT_PUN 0x10 /* punctuation */ #define CT_WHT 0x20 /* white space (space/cr/lf/tab) */ #define CT_HEX 0x40 /* hex digit */ #define CT_SP 0x80 /* hard space (0x20) */ #define isalnum(c) ((_ctype + 1)[(unsigned)(c)] & (CT_UP | CT_LOW | CT_DIG)) #define isalpha(c) ((_ctype + 1)[(unsigned)(c)] & (CT_UP | CT_LOW)) #define iscntrl(c) ((_ctype + 1)[(unsigned)(c)] & (CT_CTL)) #define isdigit(c) ((_ctype + 1)[(unsigned)(c)] & (CT_DIG)) #define isgraph(c) ((_ctype + 1)[(unsigned)(c)] & (CT_PUN | CT_UP | CT_LOW | CT_DIG)) #define islower(c) ((_ctype + 1)[(unsigned)(c)] & (CT_LOW)) #define isprint(c) ((_ctype + 1)[(unsigned)(c)] & (CT_PUN | CT_UP | CT_LOW | CT_DIG | CT_SP)) #define ispunct(c) ((_ctype + 1)[(unsigned)(c)] & (CT_PUN)) #define isspace(c) ((_ctype + 1)[(unsigned)(c)] & (CT_WHT)) #define isupper(c) ((_ctype + 1)[(unsigned)(c)] & (CT_UP)) #define isxdigit(c) ((_ctype + 1)[(unsigned)(c)] & (CT_DIG | CT_HEX)) #define isascii(c) ((unsigned)(c) <= 0x7F) #define toascii(c) ((unsigned)(c) & 0x7F) #define tolower(c) (isupper(c) ? c + 'a' - 'A' : c) #define toupper(c) (islower(c) ? c + 'A' - 'a' : c) Pretty simple stuff so far. The above macros may be used to determine and modify individual characters. For C++, There is also cctype that may be used instead of ctype.h . va_list.h and stdarg These are standard headers containing macros for accessing unnamed parameters whithin a variable argument list. va_list.h va_list.h abstracts the data type used for variable length parameter lists. /* va list parameter list */ typedef unsigned char *va_list; stdarg.h and cstdarg This is our final basic library include file that we will look at. It defines some nice macros that we may use for C and C++ variable length parameter lists. These macros are fairly tricky, so lets look at them one at a time. VA_SIZE /* width of stack == width of int */ #define STACKITEM int /* round up width of objects pushed on stack. The expression before the & ensures that we get 0 for objects of size 0. */ #define VA_SIZE(TYPE) \\ ((sizeof(TYPE) + sizeof(STACKITEM) - 1) \\ & ~(sizeof(STACKITEM) - 1)) This is a little tricky. VA_SIZE returns the size of the parameters pushed on the stack. Remember that C and C++ uses the stack to pass parameters to routines. On 32bit machines, each stack item is normally 32 bits. va_start /* &(LASTARG) points to the LEFTMOST argument of the function call (before the ...) */ #define va_start(AP, LASTARG) \\ (AP=((va_list)&(LASTARG) + VA_SIZE(LASTARG))) The standard va_start macro takes two parameters. AP is a pointer to the parameter list (of type va_list), and LASTARG, which is the last parameter in the parameter list (The parameter right before the ...). All this routine does is get the address of the last parameter, and adds the size of the parameter size to that address. If the stack size is 32, then all it does it add 32 to the last parameters address on the stack, which is where the first parameter in the parameter list is at. va_end /* nothing for va_end */ #define va_end(AP) There isnt much to do here. va_arg #define va_arg(AP, TYPE) \\ (AP += VA_SIZE(TYPE), *((TYPE *)(AP - VA_SIZE(TYPE)))) This is a little tricky. va_arg() returns the next parameter in the parameter list. AP should contain the pointer to the parameter list that we are working with. TYPE contains the data type (int, char, etc.) All we need to do is add the number of bytes of the data type (TYPE) to the variable parameter list pointer (AP). This insures the variable parameter list pointer now points to the next parameter in the list. After this, we dereference that data that we have just passed (by incrementing the pointers location) and return that data. Demo This demo is fairly complex. I wanted to provide some basic C++ library routines, as well as a way to provide displaying text for debugging purposes. With this, all of the project files include the libraries for the Hardware Abstraction Layer (HAL), Kernel, and C++ Library code. In other words...It looks more complex then it actually is ðŸ˜€ Demo Download (MSVC++) Conclusion Now that the basic necessities are taken care of, in the next tutorial we will start building the actual Kernel and Hardware Abstraction Layer (HAL). We will cover error and exception handling theory and concepts, interrupt handling, the Interrupt Descriptor Table (IDT), and how to trap processor exceptions so it will no longer triple fault. We can also build our own super 1337 BSoD too ðŸ˜‰"
  },
  "articles/61_unorganised_tutorial/T14-25.html": {
    "href": "articles/61_unorganised_tutorial/T14-25.html",
    "title": "The Kernel | BrokenThorn OS Dev Tutorials",
    "keywords": "The Kernel"
  },
  "articles/61_unorganised_tutorial/T15.html": {
    "href": "articles/61_unorganised_tutorial/T15.html",
    "title": "Errors, Exceptions, Interruptions | BrokenThorn OS Dev Tutorials",
    "keywords": "Errors, Exceptions, Interruptions Please note: This tutorial covers software interrupt handling, not hardware interrupt handling. If you are looking for hardware interrupts, please see our 8259A PIC tutorial. The software side of handling hardware interrupts is discussed here. This tutorial will cover a very important concept: Error Handling . Error Handling involves a lot more then simply handling problems, but catching them as well. This is where Exception Handling comes in. Because Exception Handling requires interrupts , we will also cover interrupt handling as well. Interrupts are architecture dependent. Because of this, we will be developing an interface for managing interrupts through our uber 1337, yet very empty (at the moment) Hardware Abstraction Layer , and interfacing with our Kernel to install our own Trap Gates which will be used to catch processor exception errors, and allow us to prevent triple faults now, and forever, while remaining completely hardware independent. Sound fun? So, here's what's up: Error Handling Exception Handling IRs, IRQs, ISRs Gates: Traps, Interrupts, Tasks IDTs and IVTs IDTR processor register LIDT and SIDT instructions FLIHs and SLIHs How interrupts work, stack, error codes Developing a kernel panic error screen. i.e., BSoD ...A lot of stuff going on here, so lets get started, shall we? Errors, Errors, Errors Okay, lets face it: No one is perfect. With computers, this is even truer. As we are working in the wonderful world of kernel land, things are even worse as a simple error can cause unpredictable software to hardware problems. I am sure a lot of our readers have already experienced this through Triple Faults. In applications programming, we are not working directly with the hardware. Because of this, there are less problems that can result to errors. In kernel land, things are a bit different. Triple faults are caused do to errors with our instructions or data. If there is a problem that the processor cannot resolve, it reboots the system before it gets worse. Triple faults and no error handling is very bad in OS development, as the problems can get much worse, rom data corruption to hardware failures, to even completely destroying the system. Knowing the importance of error handling is critical in resolving these, and insuring that our system stays stable to its end release. Exception Handling exception Handling comes in two flavors: A programming language construct (For example, standard C++? try/catch/throw keywords. Some compilers also include additional keywords like _except; or mechanisms like SEH, or VEH). The other flavor is the one we are interested in: Hardware mechanisms that are designed to change (interrupt) the current flow of execution. The condition that changes this flow of execution is called an exception. Exceptions should only be used to signal error (exceptional) conditions, and not for conditionals that are used for normal operation. When an exception occurs, the flow of execution changes as a subroutine (the exception handler) is executed. This allows the subroutine to handle the error condition in some way. Normally, the current state will be saved before the handler is called. This will allow the handler to continue execution later, if possible. Remember that exceptions are designed from the hardware. i.e., They are hardware mechanisms. This is similar to hardware interrupts, and the bases of interrupt handling, as they are related. Because of this, in order to understand exception handling from the hardware, we need to look at interrupts. Lets look at that next. Interrupt Handling Interrupts An Interrupt is an external asynchronous signal requiring a need for attention by software or hardware. It allows a way of interrupting the current task so that we can execute something more important. Not to hard. Interrupts provide a way to help trap problems, such as divide by zeros. If the processor finds a problem with the currently executing code, it provides the processor alternative code to execute to fix that problem. Other interrupts may be used to provide a way to service software as routines. These interrupts can be called by any software from within the system. This is used a lot for System API's, which provide a way for ring 3 applications to execute ring 0 level routines. Interrupts provide a lot of use, especially as a way of receiving information from hardware that may change its state at asynchronous times. Interrupt Types There are two types of interrupts: Hardware Interrupts and Software Interrupts. In the 8259A PIC tutorial, we have covered hardware interrupts. This tutorial focuses on software interrupts. Hardware Interrupts A hardware interrupt is an interrupt triggered by a hardware device. Normally, these are hardware devices that require attention. The hardware Interrupt handler will be required to service this hardware request. This tutorial does not cover hardware interrupt handling, as that is hardware specific. For the x86 architecture, hardware interrupts are handled by programming the 8259A Programmable Interrupt Controller (PIC). Please see our 8259A PIC tutorial for more information on hardware interrupt handling. Spurious Interrupt : This is a hardware interrupt generated by electrical interference in the interrupt line, or faulty hardware. We do NOT want this! Software Interrupts This is where the fun stuff is at! Software Interrupts are interrupts implemented and triggered in software. Normally, the processor's instruction set will provide an instruction to service software interrupts. For the x86 architectures, these are normally INT imm, and INT 3. It also uses IRET and IRETD instructions. INT imm and INT 3 instructions are used to generate an interrupt, while the IRET class of instructions are used to return from Interrupt Routines (IRs). For example, here we generate an interrupt through a software instruction: int 3 ; generates software interrupt 3 These instructions may be used to generate software interrupts and execute Interrupt Routines (IR)'s through software. As you know, software interrupts were available in real mode. However, as soon as we made the jump to protected mode, the Interrupt Vector Table (IVT) became invalid. Because of this, we cannot use interrupts. Instead, we have to make our own. We will cover software interrupt handling in this tutorial. Interrupt Routines (IRs) An Interrupt Routine (IR) is a special function used to handle an Interrupt Request (IRQ). When the processor executes an interrupt instruction, such as INT, it executes the Interrupt Routine (IR) at that location within the Interrupt Vector Table (IVT). This means, it simply executes a routine that we define. Not to hard, huh? This special routine determines the Interrupt Function to execute normally based off of the value in the AX register. This allows us to define multiple functions in an interrupt call. Such as, the DOS INT 21h function 0x4c00. Remember: Executing an interrupt simply executes an interrupt routine that you created. For example, the instruction INT 2 will execute the IR at index 2 in the IVT. Cool? IRs are commonly also referred to as Interrupt Requests (IRQs) . However, the naming convention of IRs are still used within the ISA bus, so understanding both names is important. Interrupt Requests (IRQs) An Interrupt Request (IRQ) refers to the act of interrupting an event by signaling the system either through the Control Bus IR line or through one of the 8259A Programmable Interrupt Controller (PIC) IR lines. For systems with a single 8259 PIC, there are 8 IRQ lines, labeled IR0 IR7. For systems with 2 8259 PICs, there are 16 possible IRQ? labeled IR0 IR15. On the system ISA bus, These lines are labeled as IRQ0 IRQ15. Newer intel based systems integrate an Advanced Programmable Interrupt Controller (APIC) device that allows 255 IRQs per controller. For more information about IRQs, please see either the 8259A PIC tutorial or the APIC tutorial. What this means is that the 8259A PIC can signal the processor to generate a software interrupt call through a hardware device by activating the processors IR line, and the processor to execute the correct interrupt handler. This allows us to handle hardware device requests through software. Please see the 8259A PIC tutorial for more information on this...It is very important to understand this. Interrupt Service Routines (ISRs) Interrupt Service Routines (ISRs) is an Interrupt Handler. These are important to understand, so lets look closer. Interrupt Handlers An interrupt handler is an IR for handling interrupts and IRQs. In other words, they are callback methods that we define for handling both hardware and software interrupts. There are two types of ISRs: FLIH , and SLIH . First Level Interrupt Handler (FLIH) : A FLIH is considered to be part of the lower half of a device driver or kernel. These interrupt handlers are platform specific, and usually service hardware requests, executing similar to Interrupt Routines (IRs) and Interrupt Requests (IRQs). They have short execution time. Their primary duty is to service the interrupt, or to record platform specific information which is only available at the time of the interrupt (As it is running in a lower level.) It may also schedule or execute a SLIH, if needed. Second Level Interrupt Handler (SLIH) : These interrupt handlers are longer lived then FLIHs. In this way, it is similar to a task or process. SLIHs are normally executed and managed by a kernel program, or by FLIHs. Nested Interrupt Handlers : When an interrupt handler is executed and the Interrupt Flag (IF) is set, interrupts can still be executed during the current interrupt. This is known as a nested interrupt. Interrupts in Real Mode Interrupts in Real Mode are handled through the Interrupt Vector Table (IVT). The Interrupt Vector Table (IVT) is a list of Interrupt Vectors. There are 256 Interrupts in the IVT. IVT Map The IVT is located in the first 1024 bytes of physical memory, from addresses 0x0 through 0x3FF. Each entry inside of the IVT is 4 bytes, in the following format: Byte 0: Offset Low Address of the Interrupt Routine (IR) Byte 1: Offset High Address of the IR Byte 2: Segment Low Address of the IR Byte 3: Segment High Address of the IR Notice that each entry in the IVT simply contains the address of the IR to call. This allows us to create a simple function anywhere in memory (Our IR). As long as the IVT contains the addresses of our functions, everything will work fine. Okay, Lets take a look at the IVT. The first few interrupts are reserved, and stay the same. x86 Interrupt Vector Table (IVT) Base Address Interrupt Number Description 0x000 0 Divide by 0 0x004 1 Single step (Debugger) 0x008 2 Non Maskable Interrupt (NMI) Pin 0x00C 3 Breakpoint (Debugger) 0x010 4 Overflow 0x014 5 Bounds check 0x018 6 Undefined Operation Code (OPCode) instruction 0x01C 7 No coprocessor 0x020 8 Double Fault 0x024 9 Coprocessor Segment Overrun 0x028 10 Invalid Task State Segment (TSS) 0x02C 11 Segment Not Present 0x030 12 Stack Segment Overrun 0x034 13 General Protection Fault (GPF) 0x038 14 Page Fault 0x03C 15 Unassigned 0x040 16 Coprocessor error 0x044 17 Alignment Check (486+ Only) 0x048 18 Machine Check (Pentium/586+ Only) 0x05C 19-31 Reserved exceptions 0x068 - 0x3FF 32-255 Interrupts free for software use Not to hard. Each of these interrupts are located at a base address within the IVT. Interrupts in Protected Mode As we are developing a protected mode operating system. This will be important to us. As you know, we cannot access the IVT in protected mode do to a lot of reasons. Because of this, we cannot access or use any more interrupts. So, instead, we need to create our own. ...And it all starts with the Interrupt Descriptor Table. Interrupt Descriptor Table (IDT) The Interrupt Descriptor Table (IDT) is a special table used by the processor for the management of IRs. Its use depends on the mode of the processor. The IDT itself is an array of 256 descriptors , similar to the LDT and GDT. Real Mode In Real Mode, The IDT is also known as the IVT. Please see the description of the IVT in the above sections for more information. Protected Mode The way the IDT works in protected mode is very different then that of Real Mode (This is one of the many reasons why we cannot use the IVT in protected mode.) The IVT is still used, however. The IDT is an array of 256 8 byte descriptors stored consecutively in memory and indexed by an interrupt vector within the IVT. We will take a look at these descriptors, descriptor types, and the details of the IDT next. Interrupt Descriptor: Structure A descriptor for an IDT takes the following formats. Some of the format changes depending on what type of descriptor this is. Bits 0...15: Interrupt / Trap Gate: Offset address Bits 0-15 of IR Task Gate: Bits 16...31: Interrupt / Trap Gate: Segment Selector (Usually 0x10) Task Gate: TSS Selector Bits 31...35: Not used Bits 36...38: Interrupt / Trap Gate: Reserved. Must be 0. Task Gate: Not used. Bits 39...41: Interrupt Gate: Of the format 0D110, where D determines size 01110 - 32 bit descriptor 00110 - 16 bit descriptor Task Gate: Must be 00101 Trap Gate: Of the format 0D111, where D determines size 01111 - 32 bit descriptor 00111 - 16 bit descriptor Bits 42...44: Descriptor Privelige Level (DPL) 00: Ring 0 01: Ring 1 10: Ring 2 11: Ring 3 Bit 45: Segment is present (1: Present, 0:Not present) Bits 46...62: Interrupt / Trap Gate: Bits 16...31 of IR address Task Gate: Not used That's it!? Yep--That's all there is to it ðŸ˜‰ All we need to do is fill in our IDT, and install it, just like what we done with the GDT. The IDT is a lot more simpler then the IDT, so its even easier ðŸ˜€ The above list is the complete descriptor format. We only need to worry about developing an interrupt gate for now, so we will only focus on that. Interrupt Descriptor: Example Just like with the GDT, we will create an example at the bit level to help describe exactly how everything works. First, lets look at an example interrupt descriptor. This is going to be in shown in assembly so we can get a better view of everything. idt_descriptor: .m_baseLow dw 0 .m_selector dw 0x8 .m_reserved db 0 .m_flags db 010001110b .m_baseHi dw 0 Yep--That's all there is to a descriptor. That's not that hard, is it? Lets see how this relates to our table above by breaking it down and seeing each bit: 00000000 00000000 00000000 00001000 00000000 10001110 00000000 00000000 This is our descriptor, but in binary form. For the most part this is easy as most of it is all 0's. The first two bytes is our m_baseLow member shown in the above code. Looking at the table above, we can see that this is the first 16 bits of the descriptor. Because this is an interrupt gate, this represents bits 0-15 of the base address of the IR . This means, if this was our field, our IR would be located at address 0. (This normally would NOT be the case, as the location of the IR varies. This works for this example, though.) The next 2 bytes is our m_selector field. This is bytes 16-31 of the descriptor. Looking at our table, we can see that this represents our segment selector. Our interrupt handler contains code, so it should be using one of our code selectors. This is defined at offset 0x8 within the GDT, so that is our segment selector. The next few bits are not used. We can see that bits 31-35 are not used, while bits 36-38 must be 0 for interrupt gates. Because of this, we can safely say bits 31-38 are 0. This is the size of a byte, which is our m_reserved member. The next byte is where the interesting stuff happens. Lets break it down, bit by bit--literally: 10001110 Okay...Right now we are at bit 39. Looking at our table above, we can see bits 39-41 must be 0D110. If the D bit is set, this is a 32bit descriptor. It is equal to 01110, so it is indeed a 32bit descriptor. The next two bits (00 above) are bytes 42-45 of the descriptor, which represents the privelige level (DPL). It is 00, so the DPL is to execute at ring 0. The final two bytes within our example are the last two bytes within the above table. This is the high 16 bits of the IR base address (Which, in our case, is 0.) This is the m_baseHi member displayed above. As you can see, there really is not that much going on here. The selector is always going to be that of the code selector within the GDT (0x8 for our needs); then all we need to do is set the flag bits and the IR base address within m_baseLow and m_baseHi . We will see a complete example a little later which will help in understanding everything. IDTR Processor Register The IDTR register is the processor register that stores the base address of the IDT. The IDTR register has the following format: IDTR Register Bits 16...46 (IDT Base Address) Bits 0...15 (IDT Limit) Simple enough, huh? Notice that the base address of our created IDT is stored in this register. The processor uses this register to determine where our IDT is located at. Knowing this format is very important, as it contains both the limit and base address. Because of this, simply giving it the base address of our idt will NOT work. This is usually resolved by creating a new structure in the format shown above like this: idt_ptr: .limit dw idt_end - idt_start ; bits 0...15 is size of idt .base dd idt_start ; base of idt ; load register with idt_ptr Oh, wait...How do we even access this register? Oh right... LIDT Instruction - Loading our IDT This instruction is used to store a new address of an IDT into the IDTR register. This instruction can only be used if the Current Protection Level (CPL) is 0 (Ring 0). It is very easy to use: lidt [idt_ptr] Thats all there is to it. As long as idt_base is the base address of the IDT, this will copy the address into IDTR. SIDT Instruction - Storing our IDT This instruction is used to store the value in IDTR into a 6 byte memory location. This instruction may be used in both ring 0 and ring 3 applications. sidt [idt_ptr] How Interrupts Work: Detail Finding the interrupt procedure to call When an interrupt or exception is fired, the processor uses the exception or interrupt number as an index into the IDT. As you know, our IDT is nothing more then an array of 256 descriptors of the format shown above. The processor performs the calculation IDTR.baseAddress + index * 8 , where 8 is the size of a descriptor (Remember that descriptors are 8 bytes in size?), and index is the interrupt number. IDTR.baseAddress is the base address of the IDT stored within the upper bits of IDTR. This allows the processor to retrieve the base address of the descriptor index for the interrupt handler. If the value of the calculation is greater then the IDT limit size (stored in IDTR.limit), the processor will execute a General Protection Fault (GPF) as this will result into a call beyond the size of the IDT. Remember that the descriptor is either an interrupt, trap, or task gate. If the index points to an interrupt or trap gate, the processor calls the exception or interrupt handler. This is done similar to CALLing a call gate. If the index points to a task gate, the processor executes a task switch to the exception or interrupt handler task similar to a CALL to a task gate. The information and addresses for the handler are stored within this descriptor. When the processor performs the switch: Executing the handler If the handler is going to be executed at a lower privilege level (bits 42-45 of descriptor), a stack switch occurs. The segment selector and stack pointer for the stack to be used by the handler are obtained from the TSS for the currently executing task. The processor pushes the stack segment selector and stack pointer of the interrupt handler on this new stack. The processor saves the current state of EFLAGS,CS, and EIP on the new stack If an exception causes an error code to be saved, the error code is pushed on the new stack after EIP If the handler is going to be executed at the same privilege level (current privilege level (cpl) is the same as (bits 42-45 of descriptor)) The processor saves the current state of EFLAGS, CS, EIP on the current stack . If an exception causes an error code to be saved, the error code is pushed on the current stack after EIP It is very important to know how the stack is pushed when our interrupt handler is called, and what exceptions also push error codes. We will look at this next. Inside of our interrupt handler Because the location of our interrupt handler is stored within the descriptor, the processor is now able to execute our handler. As you know, when the processor executes our handler, it pushes some extra information on the stack. If our handler is running in the same ring level as ours (As it will be), then we must remember that the processor will push EFLAGS, CS, EIP and an Error code on our current stack. This allows us to continue execution if we are able to. Putting all of this together, when our handler is called, our stack will be set up like this: +---------------+ -- Bottom of stack | EFLAGS | +---------------+ | Return CS | +---------------+ | Return EIP | +---------------+ | Error Code | +---------------+ -- ESP points here when handler is executed. If there is no error code, ESP points to return EIP We use this information to return back from our handler, and to determine what caused the exception (If there is an error code.) Inside of our interrupt handler: Error code format If an error code is pushed on the stack when our handler is called, we can use its information to help in determining the error. It has the following format: Bit 0: External event 0: Internal or software event triggered the error. 1: External or hardware event triggered the error. Bit 1: Description location 0: Index portion of error code refers to descriptor in GDT or current LDT. 1: Index portion of error code refers to gate descriptor in IDT. Bit 2: GDT/LDT. Only use if the descriptor location is 0. 0: This indicates the index portion of the error code refers to a descriptor in the current GDT. 1: This indicates the index portion of the error code refers to a segment or gate descriptor in the LDT. Bits 3-15: Segment selector index. This is an index into the IDT, GDT, or current LDT to the segment or gate selector bring referenced by the error code. Bits 16-31: Reserved Error codes are not pushed on the stack for exceptions that are generated externally (via the INTR,LINT0,LINT1 pins), or INT n instruction. The error code format is different for page fault exception errors. We will look at that in the next section. Returning from a handler All handlers must use either IRET or IRETD instructions to return. IRET is similar to RET except that it restores the saved EFLAGS (that was pushed on the stack when the handler was getting executed), and the IOPL field in EFLAGS is only set to 0 if the current protection level (CPL) is 0. The IF flag is also changed only if the CPL is less then or equal to the IOPL. If a stack switch occurred when executing the handler, IRET switches back to the interrupted procedures stack as well. x86 Exceptions Exceptions: Listing All of the exceptions are defined as the first few interrupts within the IVT or IDT. Here is the complete list of generated exceptions from the x86 class of processors. Fault - the return address (Return CS:EIP that was pushed on stack when handler was called. See Inside of our interrupt handler for more information.) points to the instruction that caused the exception. The exception handler may fix the problem and then restart the program, making it look like nothing has happened. Trap - the return address points to the instruction after the one that has just completed. Abort - the return address is not always reliably supplied. A program which causes an abort is never meant to be continued. x86 Processor Exceptions Interrupt Number Class Description Error Code 0 Fault Divide by 0 None 1 Trap or Fault Single step (Debugger) None. Can be retrieved from debug registers 2 Unclassed Non Maskable Interrupt (NMI) Pin Not applicable 3 Trap Breakpoint (Debugger) None 4 Trap Overflow None 5 Fault Bounds check None 6 Fault Invalid OPCode None 7 Fault Device not available None 8 Abort Double Fault Always 0 9 Abort (Reserved, do not use) Coprocessor Segment Overrun None 10 Fault Invalid Task State Segment (TSS) See error code below 11 Fault Segment Not Present See error code below 12 Fault Stack Fault Exception See error code below 13 Fault General Protection Fault (GPF) See error code below 14 Fault Page Fault See error code below 15 - Unassigned - 16 Fault x87 FPU Error None. x87 FPU provides own error information 17 Fault Alignment Check (486+ Only) Always 0 18 Abort Machine Check (Pentium/586+ Only) None. Error information obtained from MSRs 19 Fault SIMD FPU Exception None 20-31 - Reserved - 32-255 - Available for software use Not applicable IRQ 0 and the System Timer As you know, if we enter protected mode all interrupts must be disabled. If we have not done this, our system will triple fault immediately on the next clock tick. Why is this? The System Timer , usually a form of the 8253 Programmable Interval Timer (PIT) uses IRQ 0 to let us know when a clock tick happens. This device is configured this way by the system BIOS. But WAIT! looks at above table , Isn't that the Divide by 0 error? Bingo. Because the tables are now invalid because we switched to protected mode, Who knows where this will lead us. Because of this, an immediate triple fault on the next system tick, and the reason we must disable interrupts before switching. We should also note that the 8253 Programmable Interval Timer (PIT) is a hardware device . Notice how, using the table above, it will fire an exception (IRQ 0)? How will we know its an actual error, or just a simple tick? Lets take a look closer... Remapping the 8259A Programmable Interrupt Controller (PIC) The 8259A PIC is a standard controller used to control hardware interrupts. Hardware microcontrollers signal the PIC on their respective IR line that connects to the PIC. This allows the PIC to \"know\" a hardware device needs attention, and to signal the processor to fire an interrupt to handle the devices request. In our above example, the 8253 PIT was signaling the 8259A PIC to handle a system tick in this manner, which caused IRQ 0 (Remember that the 8253 PIT uses IRQ 0) to fire--which caused a triple fault as it was also a divide by 0 exception, and invalid code as we have not written it yet. To resolve this problem, we will need to reprogram the 8259A PIC Microcontroller to remap the hardware devices to use different IRQs. Please keep in mind that we can still use software interrupts if the IF is 0 (interrupts disabled), as IF only applies to hardware interrupts. However, if we want to re-enable hardware interrupts, we must reprogram the PIC. The 8259A PIC is a fairly complex microcontroller to program. Luckily, most of its modes do not apply to us. The demo at the end reprograms the PIC and re-enable interrupts. In order to completely get the most out of this tutorial, it is recommended to read our [8259A Programmable Interrupt Controller] (fix link) tutorial. Demo The first screenshot displays the kernel initializing the HAL. The second screenshot displays what happens when an interrupt is fired. Notice how our default handler catches the interrupt. This demo is fairly complex, as we have covered a lot of material in this tutorial. This demo installs a new Global Descriptor Table (GDT) for the kernel to use and an Interrupt Descriptor Table (IDT). It also creates a nice interface that we can use to handle software interrupts. Note that we do NOT cover hardware interrupts yet. In the next tutorial, we will be adding both 8259A PIC and 8253 PIT microcontroller interfaces to the HAL. This will allow us to catch hardware interrupts, enable hardware interrupts, and provide ourselves with a system timer. It will be fun ðŸ˜€ Lets cover the demo a little more so that we can see everything working. Hardware Abstraction This demo includes a lot of extra files that we have not seen until now. Because of this, it is kind of like a code dump, which is what I want to avoid here. A lot of it is very simple and things that we have looked at and even implemented in our bootloader. Some of it Inside idt.h and idt.cpp may be new to you, and covers what we have learned here: The Interrupt Descriptor Table (IDT) . This is also the beginning of our Hardware Abstraction Layer (HAL) ! As you know, I have been stressing hardware abstraction, and the importance of it, sense this series begun. You will see why soon as we continue to build on the Hal. You might even see the pluses of keeping the Hal completely independent of the kernel here! Without further ado, lets look at the beginnings of the primary interface for the HAL. Hal - include/hal.h - Platform independent interface for the HAL This is the interface between the HAL and the kernel. It is part of the standard include directory, and is completely separate from its implementation. All routines are declared extern as the header file is meant to be used by any implementation that defines the routines inside of it. The implementations are architecture specific, but the interface is in no way coupled to any specific implementation, making it completely hardware independent. While the implementations themselves are architecture specific, we can simply build the implementations for different architectures. Because each implementation uses this common interface, and we can support dynamic loading (like hal.dll), we can either link what static hal implementation to use when building for different architectures, or Build the different Hals independently, and choose which HAL to use at startup. Because they all use the same interface (Hal.h), we dont need any changes in the kernel to use different implementations (and hence different hardware setups.) Cool? There are currently only two functions in it. We will add more when we need to: //! Initialize and shutdown hal extern int Hal_Initialize (); extern int Hal_Shutdown (); I will most likely change the prototypes of these routines to allow startup and shutdown parameters. In any case, these are very generic routines that is meant to provide a way to setup and shutdown the hardware, if needed, for the implementation. There are a couple of very simple layers of software within the hal for the gdt, idt, and CPU, and hal.cpp. Because all they do is initialize the layer below it (Hal.cpp calls the CPU initialize routine, which calls the gdt and idt initialize methods), I am not going to post it here as it may add more complexity in this tutorial then is required. Instead, lets focus on the bulk of the hal: The gdt setup code, The idt setup code (This contains the bulk of what we looked at in this tutorial), and the kernel's main() routine. Cool? We will not cover the GDT in detail. Please see [Tutorial 8] (fix link) for a complete description of it. Hal - hal/gdt.h - global descriptor table Descriptor Tables ...again Yes, the GDT has come back to haunt you!!! ...yes, YOU!! Anyhow... the GDT is quite a complex structure, huh? As you know, a GDT is an array of descriptors. What was the format of a GDT descriptor again? Right, okay then... Bits 56-63: Bits 24-32 of the base address Bit 55: Granularity 0: None 1: Limit gets multiplied by 4K Bit 54: Segment type 0: 16 bit 1: 32 bit Bit 53: Reserved-Should be zero Bits 52: Reserved for OS use Bits 48-51: Bits 16-19 of the segment limit Bit 47 Segment is in memory (Used with Virtual Memory) Bits 45-46: Descriptor Privilege Level 0: (Ring 0) Highest 3: (Ring 3) Lowest Bit 44: Descriptor Bit 0: System Descriptor 1: Code or Data Descriptor Bits 41-43: Descriptor Type Bit 43: Executable segment 0: Data Segment 1: Code Segment Bit 42: Expansion direction (Data segments), conforming (Code Segments) Bit 41: Readable and Writable 0: Read only (Data Segments); Execute only (Code Segments) 1: Read and write (Data Segments); Read and Execute (Code Segments) Bit 40: Access bit (Used with Virtual Memory) Bits 16-39: Bits 0-23 of the Base Address Bits 0-15: Bits 0-15 of the Segment Limit Building the C structure We can hide this structure behind a nice C style structure using C's built in types. Knowing that the first 15 bits is the segment limit (Size of an uint16_t), that's data member one . The next 16 bits is bits 0-23 of the base address, and that can be either expressed as 1 uint16_t or 2 uint8_t's. That's data member two and/or three . The next 16 bits (bits 41-56 of GDT) is 16 bits. This is the bulk of the ugly structure that contains flag values, and can be represented, of course, using either 2 uint8_t's or 1 uint16_t. That's the next data member. The last byte is our base address. That's the last data member! Looking at the above, that ugly structure can be represented in 4 to 5 nice members within a structure. Here is our structure. Try to compare this structure with the above description and table to see where everything fits in. Also, remember that this structure is packed to 1 byte, so it is guaranteed to be 64 bits in size. #ifdef _MSC_VER #pragma pack (push, 1) #endif //! gdt descriptor. A gdt descriptor defines the properties of a specific //! memory block and permissions. struct gdt_descriptor { //! bits 0-15 of segment limit uint16_t limit; //! bits 0-23 of base address uint16_t baseLo; uint8_t baseMid; //! descriptor bit flags. Set using bit masks above uint16_t flags; //! bits 24-32 of base address uint8_t baseHi; }; #ifdef _MSC_VER #pragma pack (pop, 1) #endif Easy enough! There are a lot of bit flags that can be set to help build the flags bytes within the structure. Please see the header file to see them all, and notice how they work. Basically, we would bitwise OR the bit flags that we want to set. You will see us do this in the next section. gdtr abstraction Remember from [tutorial 8] (fix link), we have covered protected mode, the gdt, and gdtr? gdtr Is the processors internal register used to point to the GDT to be used. It is a 48 bit pointer that must follow the following format: Bits 0-15: size of entire gdt Bits 16-48: base address of gdt Okay...This one is an easy one to convert to a C struct. Notice how it follows the above format: #ifdef _MSC_VER #pragma pack (push, 1) #endif //! processor gdtr register points to base of gdt. This helps //! us set up the pointer struct gdtr { //! size of gdt uint16_t m_limit; //! base address of gdt uint32_t m_base; }; #ifdef _MSC_VER #pragma pack (pop, 1) #endif // Global Descriptor Table (GDT) static struct gdt_descriptor _gdt [MAX_DESCRIPTORS]; //! gdtr data static struct gdtr _gdtr; Here you can also see our new GDT and _gdtr, which will be used for reference when setting up the processors GDTR register. gdt_install(): Installs a gdt into gdtr This routine is a very simple one. All it does is use the lgdt instruction to load GDTR with our gdtr pointer. We do not need to do any far jumps here, though, as CS should never change. //! installs gdtr static void gdt_install () { #ifdef _MSC_VER _asm lgdt [_gdtr] #endif } gdt_set_descriptor(): Sets up a new descriptor in the gdt This routine is used to install a new descriptor in the GDT. For the most part, it is not too hard; the ugly code is when we get to setting up the flags. //! Setup a descriptor in the Global Descriptor Table void gdt_set_descriptor(uint32_t i, uint64_t base, uint64_t limit, uint8_t access, uint8_t grand) { if (i MAX_DESCRIPTORS) return; //! null out the descriptor memset ((void*)&_gdt[i], 0, sizeof (gdt_descriptor)); //! set limit and base addresses _gdt[i].baseLo = base & 0xffff; _gdt[i].baseMid = (base >16) & 0xff; _gdt[i].baseHi = (base >24) & 0xff; _gdt[i].limit = limit & 0xffff; //! set flags and granularity bytes _gdt[i].flags = access; _gdt[i].grand = (limit >16) & 0x0f; _gdt[i].grand |= grand & 0xf0; } i86_gdt_initialize() - initializes the gdt This brings everything together. All it does is set up our GDTR structure, installs some default descriptors into our GDT, and finally installs the GDT. To make things easier, this GDT is the same one we have used for our bootloader. The base address is 0, the limit (Maximum addressable address) is 4GB (0xffffffff). All of the flags are defined in gdt.h . They are defined to increase readability and to get rid of ugly magic numbers. It should be much easier to see what the descriptors are for with the flags! //! initialize gdt int i86_gdt_initialize () { //! set up gdtr _gdtr.m_limit = (sizeof (struct gdt_descriptor) * MAX_DESCRIPTORS)-1; _gdtr.m_base = (uint32_t)&_gdt[0]; //! set null descriptor gdt_set_descriptor(0, 0, 0, 0, 0); //! set default code descriptor gdt_set_descriptor (1,0,0xffffffff, I86_GDT_DESC_READWRITE|I86_GDT_DESC_EXEC_CODE|I86_GDT_DESC_CODEDATA|I86_GDT_DESC_MEMORY, I86_GDT_GRAND_4K | I86_GDT_GRAND_32BIT | I86_GDT_GRAND_LIMITHI_MASK); //! set default data descriptor gdt_set_descriptor (2,0,0xffffffff, I86_GDT_DESC_READWRITE|I86_GDT_DESC_CODEDATA|I86_GDT_DESC_MEMORY, I86_GDT_GRAND_4K | I86_GDT_GRAND_32BIT | I86_GDT_GRAND_LIMITHI_MASK); //! install gdtr gdt_install (); return 0; } Hal: Interrupt Descriptor Table THIS is where the fun stuff is at! The IDT interface is within the idt.h and idt.cpp source files. hal.h - idt_descriptor This is the structure for an interrupt descriptor. Compare this format with the descriptor format we looked at in this tutorial, and you should notice that they follow exactly the same format: #ifdef _MSC_VER #pragma pack (push, 1) #endif //! interrupt descriptor struct idt_descriptor { //! bits 0-16 of interrupt routine (ir) address uint16_t baseLo; //! code selector in gdt uint16_t sel; //! reserved, shold be 0 uint8_t reserved; //! bit flags. Set with flags above uint8_t flags; //! bits 16-32 of ir address uint16_t baseHi; }; #ifdef _MSC_VER #pragma pack (pop, 1) #endif Lets look at what each member represents, and where at within the interrupt descriptor: baseLo - This is the first 16 bits of the base address of the interrupt routine (IR) This is bits 0-15 within the overall interrupt descriptor. Compare this with the table listed in Interrupt Descriptor: Structure sel - Segment Selector This is bits 16-31 within the overall interrupt descriptor. reserved - er... very usefull information here ðŸ˜‰ This is bits 31-38 within the overall interrupt descriptor. flags - Where the fun stuff is at! Interrupt Descriptor Bits 39-41. This is where the bit flags are at Interrupt Descriptor Bits 42-45. This is the Descriptor Priveldge Level (DPL) baseHi - Bits 16-31 of base address of the IR This is bits 46-64 within the overall interrupt descriptor. Simple enough! Notice how this struct directly matches how the interrupt descriptor is laid out. So, now that we have the description for an interrupt descriptor, lets take a look at installing a IDT! idt.cpp - idtr similar to how we set up the gdtr structure, we also have one for idtr. Notice how this structure followes the exact structure for the idtr register. #ifdef _MSC_VER #pragma pack (push, 1) #endif //! describes the structure for the processors idtr register struct idtr { //! size of the interrupt descriptor table (idt) uint16_t limit; //! base address of idt uint32_t base; }; #ifdef _MSC_VER #pragma pack (pop, 1) #endif //! interrupt descriptor table static struct idt_descriptor _idt [I86_MAX_INTERRUPTS]; //! idtr structure used to help define the cpu's idtr register static struct idtr _idtr; Okay... Remember that the IDT is nothing more then an array of interrupt descriptors? With this, _idtr is here for reference; it stores the current information in the processors IDTR register for our use. Basically, all we need to do from here is to set up the IDT, and _idtr; then install the IDT! Not to hard ðŸ˜€ idt_install() - installs a new IDT This is used to install the IDT into IDTR, no more, and no less. It is a helper method used to abstract the inline assembly language (Which is compiler dependent) behind a common interface to help with portability between compilers. //! installs idtr into processors idtr register static void idt_install () { #ifdef _MSC_VER _asm lidt [_idtr] #endif} i86_default_handler() - default interrupt handler Our IDT interface will provide a way to install our own interrupt handling routines directly into the IDT, which is as cool as it can get! Because there are 256 interrupts, there are 256 interrupt handlers. Odds are, we will not be using every one of them early on. So, what happens if an interrupt is generated that the kernel does not yet handle? That is what this is for! This is a basic unhandled exception handler that our IDT interface will install (You will see this later on.) All it does is, if being built for debug mode, prints out an error. It then halts the system. //! default handler to catch unhandled system interrupts. void i86_default_handler () { #ifdef _DEBUG DebugClrScr (0x18); DebugGotoXY (0,0); DebugSetColor (0x1e); DebugPrintf (\"*** [i86 Hal] i86_default_handler: Unhandled Exception\"); #endif for(;;); } Returning from an interrupt... C and C++ automatically pops the values off the stack and issues a RET instruction when returning from an IR. This is bad! Because of this, we need to issue our own way of returning through an IRET instruction. geninterrupt() - generate interrupt call This is a little tricky. This is another helper method provided to abstract the inline assembly language behind a common interface for better portability for more compilers. However, it also hides the challenge of generating an arbitrary interrupt call. The problem is that of the OPCode for an interrupt (INT instruction) only has one format: 0xCDimm, where imm is an intermediate value. Because of this, we cannot use any registers nor memory locations in the INT instruction; as there is no OPCode form that accepts that (Invalid instruction.) So, how do we fix this? There are a lot of different ways, of course. I opted to use a fast and small solution: self modifying code. Basically, all we need to do is modify the second byte of the INT OPCode. Knowing it is always two bytes (First being 0xCD, second is the interrupt number to call) it is quite an easy solution: //! generate interrupt call void geninterrupt (int n) { #ifdef _MSC_VER _asm { mov al, byte ptr [n] mov byte ptr [genint+1], al jmp genint genint: int 0 // above code modifies the 0 to int number to generate } #endif } i86_install_ir () - installs interrupt handler into IDT This is a little tricky, but not too hard. Remember that the baseLo and baseHi members of our structure contain the high and low bits of our Interrupt Routine (IR) ? So, all we need to do is get the address of the IR function, and store its high and low bits. This is done here by means of a function pointer . We pass in a function pointer as a parameter. This routine gets the address of the function the pointer points to, and masks out the low and high bits, storing it into the structure at _idt [i] , where i is the descriptor offset (the Interrupt number) in the IDT. //! installs a new interrupt handler int i86_install_ir (uint32_t i, uint16_t flags, uint16_t sel, I86_IRQ_HANDLER irq) { if (i>I86_MAX_INTERRUPTS) return 0; if (!irq) return 0; //! get base address of interrupt handler uint64_t uiBase = (uint64_t)&(*irq); //! store base address into idt _idt[i].baseLo = uiBase & 0xffff; _idt[i].baseHi = (uiBase >16) & 0xffff; _idt[i].reserved = 0; _idt[i].flags = flags; _idt[i].sel = sel; return 0; } There is some beauty in this. Remember that, when an interrupt is generated, the processor pushes some information on the stack for us? This information will now be in the parameters list when our routine is called! Cool, huh? This also means, however, that we need to be careful as only some interrupts push error codes, others do not. i86_idt_initialize () - Initialize IDT Interface Now, lets bring everything together. The following code sets up IDTR, sets our default interrupt handler to catch all interrupts (This is so we only need to define the needed interrupts in the Kernel); and finally installs the IDT using the above methods. The bit flags used for setting up the IDT are defined in idt.h and are provided to make the code more readable and easier to modify. //! initialize idt int i86_idt_initialize (uint16_t codeSel) { //! set up idtr for processor _idtr.limit = sizeof (struct idt_descriptor) * I86_MAX_INTERRUPTS -1; _idtr.base = (uint32_t)&_idt[0]; //! null out the idt memset ((void*)&_idt[0], 0, sizeof (idt_descriptor) * I86_MAX_INTERRUPTS-1); //! register default handlers for (int i=0; i<I86_MAX_INTERRUPTS; i++) i86_install_ir (i, I86_IDT_DESC_PRESENT | I86_IDT_DESC_BIT32, codeSel, (I86_IRQ_HANDLER)i86_default_handler); //! install our idt idt_install (); return 0; } Demo Conclusion This demo is a bit complex, I am to admit. At least we got the ugly necessities out of the way! You will see that, if you issue any INT instruction, the default handler will be called. If you install your own interrupt handlers, try to experiment with them - both the ones with the error codes, and the ones without them. You will see the interrupts being fired. Anytime you call geninterrupt() or an INT instruction, you will see that the correct interrupt handler (Or, if the interrupt handler was not defined, the default handler) is executed. To keep this tutorial from getting much more complex, I decided to NOT handle hardware interrupts yet. We will cover this in the next tutorial, as well as developing the code for the 8253 Programmable Interval Timer (PIT) for use as the Kernels System Timer as well as for the 8259A Programmable Interrupt Controller , which is needed for hardware interrupts. Study the demo well and how everything works. Modify a few things; try to register your own interrupt handlers using i86_install_ir() and generating the interrupts. To do this, all we need to do is: //! our uber 1337 interrupt handler. handles int 5 request void int_handler_5 () { _asm add esp, 12 _asm pushad // do whatever... _asm popad _asm iretd } //! registers our interrupt handler i86_install_ir (5, I86_IDT_DESC_PRESENT | I86_IDT_DESC_BIT32, 0x8, (I86_IRQ_HANDLER)int_handler_5); //! generates int 5 instruction. You can also use inline assembly, of course geninterrupt (5); I decided to leave out the parameter lists for the interrupt handlers as the format may change. So, in order to access parameters, we would need to access it through ESP. I might decide to give it parameters later on to make things easier, though. Demo Download Here (MSVC++) Conclusion In the next tutorial, we will be starting to develop our kernel even more. We will be handling timing through the 8254 Programmable Interval Timer (PIT) microcontroller , which will be covered similar to the 8259A PIC tutorial. Afterwards, we plan on moving onto more memory management and process management. ...We might even develop a basic debugging text based console to spice things up a bit."
  },
  "articles/61_unorganised_tutorial/T16.html": {
    "href": "articles/61_unorganised_tutorial/T16.html",
    "title": "PIC, PIT, and exceptions | BrokenThorn OS Dev Tutorials",
    "keywords": "PIC, PIT, and exceptions Note This tutorial covers hardware interrupt handling, not software interrupt handling. If you are looking for software interrupts, please see [Tutorial 15] (fix link). This tutorial requires knowledge of software interrupt handling. Welcome to...what? Tutorial 16 already? In the last tutorial, we have dived deep into the world of interrupt handling. We have covered, and even implimented, interfaces for the GDT and IDT inside of our hardware abstraction layer . We have covered almost everything we needed for software interrupt handling to work. ...But WAIT! What about hardware interrupts? o_0 Because alot of critical system devices use interrupts, it is necessary for us to be able to handle and catch interrupts triggered by hardware devices. The good news? This is already done for us! By what? The 8259 Programmable Interrupt Controller (PIC) . We will look closer in the next section. Even if we get hardware interrupts working by itself, we will still be running into problems do to the system timer. As long as the system timer does not use a valid interrupt handler that we have set up for it, it will triple fault a few milliseconds after you enable hardware interrupts. After all, it will call an invalid interrupt handler, remember? Thus, we will also fix this small problem by reprogramming the system timer, otherwise known as the Programmable Interval Timer (PIT) . Alot of stuff in this tutorial. We will look at: Hardware Interrupts Interrupt Chaining Hal: Programmable Interrupt Controller Hal: Programmable Interval Timer Hardware Abstraction Interrupts Implimentation and Design for our HAL Please note that this does not cover interrupt handling. Please see [Tutorial 15] (fix link) for interrupt handlng. With all of that in mind, lets take a look... Hardware Interrupts There are two types of interrupts, those generated by software (Useually by an instruction, such as INT, INT 3, BOUND, INTO), and an interrupt generated by hardware. Hardware interrupts are very important for PC's. It allows other hardware devices to signal the CPU that something is about to happen. For example, a keystroke on the keyboard, or a single clock tick on the internal timer, for example. We will need to map what Interrupt Request (IRQ) to generate when these interrupts happen. This way, we have a way to track these hardware changes. Lets take a look at these hardware interrupts. x86 Hardware Interrupts 8259A Input pin Interrupt Number Description IRQ0 0x08 Timer IRQ1 0x09 Keyboard IRQ2 0x0A Cascade for 8259A Slave controller IRQ3 0x0B Serial port 2 IRQ4 0x0C Serial port 1 IRQ5 0x0D AT systems: Parallel Port 2. PS/2 systems: reserved IRQ6 0x0E Diskette drive IRQ7 0x0F Parallel Port 1 IRQ8/IRQ0 0x70 CMOS Real time clock IRQ9/IRQ1 0x71 CGA vertical retrace IRQ10/IRQ2 0x72 Reserved IRQ11/IRQ3 0x73 Reserved IRQ12/IRQ4 0x74 AT systems: reserved. PS/2: auxiliary device IRQ13/IRQ5 0x75 FPU IRQ14/IRQ6 0x76 Hard disk controller IRQ15/IRQ7 0x77 Reserved You do not need to worry to much about each device just yet. The 8259A Pins are described in detail in the [8259 PIC tutorial] (fix link). The Interrupt Numbers listed in this table are the default DOS interrupt requests (IRQ) to execute when these events trigger. In most cases, we will need to recreate a new interrupt table. As such, most operating systems need to remap the interrupts the PIC's use to insure they call the proper IRQ within their IVT. This is done for us by the BIOS for the real mode IVT. We will cover how to do this later in this tutorial as well. Wait...What is this PIC thing? All of these hardware devices that can signal hardware devices are connected indirectly to the 8259A Programmable Interrupt Controller (PIC) . This is a special, and very important microcontroller that is used to signal the microprocessor when it needs to fire a hardware interrupt. We will be programming this microcontroller a little later in this tutorial. Because this microcontroller is fairly complex, we have dedicated another tutorial for it. Please read it [here] ( fix link: OSDevPic.html). Interrupt Chaining We will be able to install our own interrupt handlers within the Interrupt Descriptor Table (IDT) very easily. We create interrupt handlers to handle not only software interrupts, but interrupts triggered by hardware devices. Remember: The hardware devices signal the Programmable Interrupt Controller to signal the processor to request a hardware interrupt to be triggered. The PIC lets the processor know what Interrupt Request (IRQ) to call within out Interrupt Descriptor Table (IDT) . But wait... How does the PIC know what IRQs to call within our IDT? We tell it . This is why we must reprogram the PIC in order to let it know what interrupts to use. Okay, lets say we now have interrupt handlers to handle software and hardware interrupts. What now? How does this work from our perspecitive? Sure, we can easily install handlers for different devices, but what if multiple devices require the same interrupt? What about multiple functions for a software interrupt? This is where Interrupt Chaining comes in. Interrupt chaning is a technique used to restore and call all of the interrupt handlers that share that same interrupt number. This is done by saving the previus Interrupt Routine (IR) in a function pointer. Then, installing the new handler, and calling the previus interrupt handler whenever the new IR is called. Here is an example: void deviceInitialize () { //store previus interrupt handler prevhandler = getvect (0); //install new interrupt handler setvect (0, handler); } void deviceShutdown () { //install previus interrupt handler setvect (0, prevhandler); } void handler () { // do stuff... // call previus interrupt handler (*prevhandler) (); } As you can see, interrupt chaining is rather easy. Notice how the previus interrupt handlers will always be called whenever this interrupt fires? setvect() installs a new interrupt vector. getvect() returns an interrupt vector. These interrupt vectors can be stored in either the Interrupt Vector Table (IVT) or Interrupt Descriptor Table (IDT) . Wait, what? Thats right--ours ðŸ˜€ Get Ready - Implimenting Interrupt Handling We have covered alot of ground with interrupts and interrupt handling. Text alone can only go so far. We have even looked a little bit about how hardware interrupt handling works, but not enough to get very far. We cannot impliment hardware interrupt handling until we learn how to program the Programmable Interrupt Controller . Also, we cannot enable hardware interrupts until we fix the timing problem (Remember that the Programmable Interval Timer is still connected to IRQ8 thanks to the BIOS? That means, as soon as we re-enable hadware interrupts, the next timer tick will result in a double fault.) Because of this, we also have to learn how to reprogram the Programmable Interval Timer . This, dear readers, is where things get complex. Welcome back to the world of hardware programming ðŸ˜€ There is good news, however... None of these microcontrollers are very complex. However, to keep the main series from getting too complex, I have decided to write 2 tutorials dedicated to these microcontrollers. This is required reading for understanding of the demo and code that lies ahead. Because of this, I recommend for all of our readers to read the following tutorials before continuing: [8259 Programmable Interrupt Controller] (fix link OSDevPic.html) [8253 Programmable Interval Timer] (fix link OSDevPit.html) Do not worry if you do not understand everything in these tutorials yet. You will see us implimenting everything within the above tutorials in the sections to come. ðŸ˜€ I will also still be describing everything here, so I will not lead you in the dark. It may also be helpful to use the above tutorials as a refrence, as we will be refrencing the above tutorials alot throughout the upcoming sections. So..? What are you waiting for? Jump into those tutorials! And come back here when you are done. Don't worry, I am just text... I will still be here when you get back.. ...unless I am deleted of course ðŸ˜€ Demo The new demo in action Demo Download (MSVC++) I am going to admit, this demo is a little complex. It is not too hard, though, as most of the code should look familiar. This demo uses our hardware abstraction layer (HAL) to install its own exception handlers. This allows us to catch processor exception errors (Like divide by 0.) It also initializes the HAL, which in turns initializes processor tables, the PIC, and the PIT. This allows us to enable hardware exceptions (Finally!) and start a timer. The demo displays the current tick count (Updated by the PIT's interrupt handler) on screen. Any other interrupt generated will be handled by the IDT's default interrupt handler. We have set this up in our IDT tutorial remember? Because the keyboard generates IRQ 9, and we have not defined an interrupt for it yet, anytime a key is pressed the default handler for the IDT will execute. Okay... I have tried to make this demo look a little cooler then the other ones. At the same time, I did not want to add even more complexity to it. Because we have looked at creating interfaces for the PIC and PIT microcontrollers, lets look a little bit at the demo code itself, shall we..? Hardware Abstraction The first interface that we will look at is the one provided by the hardware abstraction layer. This can be seen by looking at include/hal.h and hal/hal.cpp . I will not be describing the routines in depth as most of it is very simple and simply use the other interfaces (GDT, IDT, CPU, PIC, PIT, etc) that we have developed (And are about to develop). Instead, I want to look at the interface itself. This will be the interface used by the kernel and device drivers, so why not? The new hal.h This is where we start seeing how useful hardware abstraction can be. I wanted to provide a \"DOS\"-like interface that is just as easy to use as programming 16bit DOS is. In doing so, I came up with a very easy list of routines that can be used for alot of different purposes. Looking at these routines, you will see there is absolutley no refrence to the hardware devices or tables that are used by them. This is what hardware abstraction is all about. It does not abstract the architecture; but rather the hardware that it uses. Alot of the code that we use later use the routines within the HAL to perform its task. Because of this, I wanted you to take a look at the hardware abstraction layer now, and the routines it provides. extern int _cdecl hal_initialize (); extern int _cdecl hal_shutdown (); extern void _cdecl enable (); extern void _cdecl disable (); extern void _cdecl geninterrupt (int n); extern unsigned char _cdecl inportb (unsigned short id); extern void _cdecl outportb (unsigned short id, unsigned char value); extern void _cdecl setvect (int intno, void (_cdecl far &vect) ( ) ); extern void (_cdecl far * _cdecl getvect (int intno)) ( ); extern bool _cdecl interruptmask (uint8_t intno, bool enable); extern inline void _cdecl interruptdone (unsigned int intno); extern void _cdecl sound (unsigned frequency); extern const char* _cdecl get_cpu_vender (); extern int _cdecl get_tick_count (); If you have ever programmed 16bit DOS, you should feel at home right about now! ðŸ˜€ Programmable Interrupt Controller 8259: Microcontroller The 8259 Microcontroller familiy is a set of Programmable Interrupt Controller (PIC) Integrated Circuits (ICs) . Hardware controllers are indirectly connected to the PIC when a hardware interrupt is requested. Because of this, in order to handle hardware interrupts, we must have an understanding of how to program this microcontroller. I will still go over everything here, however the 8259 is a complex microcontroller. Because of this, we have dedicated a full tutorial to cover just this controller. Because of this, in order to get the most out of this section, Please see (and refrence) the following tutorial to learn about the PIC: [8259A Programmable Interrupt Controller Tutorial] (fix link OSDevPic.html) Please note: We will not cover everything about the PIC nor hardware interrupt handling here. Please see the above tutorial for this. 8259: Abstract The Programmable Interrupt Controller (PIC) is a microcontroller used to provide the connection between devices and the processor through interrupt lines . This allows devices to signal the processor whenever it requires attention from the system software or executive. This is the Interrupt Request (IRQ) . The PIC controls all of the hardware interrupt requests. It allows us to recieve signals from different hardware devices whenever they require attention. When a device, such as the Floppy Disk Controller (FDC) requires attention, it tells the PIC to fire the IRQ it is assigned to. From here, the PIC will signal the processor, and give the interrupt number to call. The processor then offsets into the IDT, and executes the interrupt handler at ring 0. We define all of the interrupt handlers, so we now take control. The best thing about this is that it is all automatic thanks to the PIC. Whenever a device signals the PIC, our interrupt handler will be executed automatically. The processor also performs a task switch to ring 0, so we will always end up in kernal land to handle the request. Cool, huh? The PIC itself is a complex microcontroller. I will try to cover everything in detail here, but please keep in mind that--in order to get the most out of this tutorial, we encourage our readers to read the above PIC tutorial. With all of that in mind--lets dive into the interface. All of this code can be found in the demo at the end of this tutorial. Operation Commands An Operation Command is a special command that is composed of a bit pattern. This bit pattern must be set up to describe the command for a microcontroller. There are basically two types of operation commands: Initialization Command Words (ICWs) and Operation Command Words (OCWs) . ICWs are operation commands that must only be used during the initialization of the device. OCWs are used to control the device after the device has been initialized. pic.h: Interface This file provides the overall minidriver interface for the rest of the system. This is the interface to controlling and managing the PIC. I define a \"minidriver\" as a driver embedded in a peice of software, and not as stand alone software. pic.h: Device Connections In the PIC tutorial, we have looked at hardware interrupts in alot of depth. We have looked at how hardware devices signal the PIC whenever it requires attention of the system software or executive. For this to work, each device is indirectly connected to an Interrupt Request (IR) line on the PIC. This line not only represents the Interrupt Request (IRQ) the device uses but also its pririty level (The lower the IRQ number, the higher pririty.) To help when working with individual devices and their IRQs, we will want to abstract the IRQ they use. This helps increase portability but also readability as they are behind nice constants. Remember: Magic numbers are bad! //! The following devices use PIC 1 to generate interrupts #define I86_PIC_IRQ_TIMER 0 #define I86_PIC_IRQ_KEYBOARD 1 #define I86_PIC_IRQ_SERIAL2 3 #define I86_PIC_IRQ_SERIAL1 4 #define I86_PIC_IRQ_PARALLEL2 5 #define I86_PIC_IRQ_DISKETTE 6 #define I86_PIC_IRQ_PARALLEL1 7 //! The following devices use PIC 2 to generate interrupts #define I86_PIC_IRQ_CMOSTIMER 0 #define I86_PIC_IRQ_CGARETRACE 1 #define I86_PIC_IRQ_AUXILIARY 4 #define I86_PIC_IRQ_FPU 5 #define I86_PIC_IRQ_HDC 6 The above constants list all of the devices (along with their IRQ line/number) that they use. There are only 8 IR lines per PIC , hence only 8 possible IRQs per PIC. Remember that PIC's can be cascaded with secondary PICs (Up to 8 PICs can be cascaded with each other.) Typical x86 architectures only have 2--One primary and one secondary. The two most important devices for us right now are the timer (I86_PIC_IRQ_TIMER) and keyboard (I86_PIC_IRQ_KEYBOARD). We will be using I86_PIC_IRQ_TIMER in this tutorial, so you will see how everything works together, cool? pic: 8259 Commands Setting up the PIC is farily complex. It is done through a series of Command Words , which are a bit pattern that containes various of states used for initialization and operation. This might seem a little complex, but it is not to hard. We will first look at the Operation Command Word (OCW) that are used to control the PIC. We will look at the initialization commands a little later. pic: Operation Command Word 1 This represents the value in the Interrupt Mask Register (IMR) . It does not have a special format, so it is handled directly in the implimentation file to enable and disable hardware interrupts. It is a single byte in size. We enable and disable (\"mask and unmask\") an interrupt request line by setting the correct bit. Remember that there are only 8 IRQ's per PIC? So, bit 0 in the IMR is IRQ 0, bit 1 is IRQ 1, bit 2 is IRQ 2, and so on. We will take a look at the Interrupt Mask register a little later on, cool? pic: Operation Command Word 2 This is the primary control word used to control the PIC. Lets take a look... Operation Command Word 2 table Bit Number Value Description 0-2 L0/L1/L2 Interrupt level upon which the controller must react 3-4 0 Reserved, must be 0 5 EOI End of Interrupt (EOI) request 6 SL Selection 7 R Rotation option Okay then! The format of OCW 2 is very easy. The first three bits are the current interrupt level. Bits 3-4 are reserved (Must be 0). Bit 5 represents End of Interrupt (EOI) . Bit 6 is the Selection bit. Bit 7 provides a Rotation command. Because each command is selected in individual bits, we can bitwise OR these commands together to produce OCW 2. //! Command Word 2 bit masks. Use when sending commands #define I86_PIC_OCW2_MASK_L1 1 //00000001 //Level 1 interrupt level #define I86_PIC_OCW2_MASK_L2 2 //00000010 //Level 2 interrupt level #define I86_PIC_OCW2_MASK_L3 4 //00000100 //Level 3 interrupt level #define I86_PIC_OCW2_MASK_EOI 0x20 //00100000 //End of Interrupt command #define I86_PIC_OCW2_MASK_SL 0x40 //01000000 //Select command #define I86_PIC_OCW2_MASK_ROTATE 0x80 //10000000 //Rotation command There you have it! This is an important command word for us. We will be required to send this command word from all interrupt handlers. Remember that the PIC masks off the interrupt when it gets executed? This means that no more interrupt requests on that IR line can execute until the processor acknowledges the PIC. This is done by sending an End of Interrupt command word to the correct PIC. We can do this by masking off the EOI bit in the command word. This is what I86_PIC_OCW2_MASK_EOI is used for. A little later on, you will see that the interface has a i86_pic_send_command routine that is used to...erm...send commands to the PIC. Lets look at an example of sending the EOI command using this routine so that you can see how it works: i86_pic_send_command (I86_PIC_OCW2_MASK_EOI, picNumber); The above code will send an EOI command to the pic in picNumber , cool? I suppose thats it for OCW 2. On to the next one! pic: Operation Command Word 3 I plan on adding to this section. //! Command Word 3 bit masks. Use when sending commands #define I86_PIC_OCW3_MASK_RIS 1 //00000001 #define I86_PIC_OCW3_MASK_RIR 2 //00000010 #define I86_PIC_OCW3_MASK_MODE 4 //00000100 #define I86_PIC_OCW3_MASK_SMM 0x20 //00100000 #define I86_PIC_OCW3_MASK_ESMM 0x40 //01000000 #define I86_PIC_OCW3_MASK_D7 0x80 //10000000 pic.cpp: Implimentation Okay...Everything was easy so far, right? You are probably asking \"Where is the challenge!??\" Well, okay then. pic.cpp provides the implimentation for our PIC interface. First thing we must look at are the registers. pic.cpp: Register constants This is where we define the constants to abstract the port locations for the PICs. Notice that I have defined constants for all register names, even though they share the same port address. The reason is for completness: Even though they share the same port location, they still are different registers. //! PIC 1 register port addresses #define I86_PIC1_REG_COMMAND 0x20 // command register #define I86_PIC1_REG_STATUS 0x20 // status register #define I86_PIC1_REG_DATA 0x21 // data register #define I86_PIC1_REG_IMR 0x21 // interrupt mask register (imr) //! PIC 2 register port addresses #define I86_PIC2_REG_COMMAND 0xA0 // ^ see above register names #define I86_PIC2_REG_STATUS 0xA0 #define I86_PIC2_REG_DATA 0xA1 #define I86_PIC2_REG_IMR 0xA1 Not to hard. We send commands to the command register , and read data from the data register . If we are writing from a data register, we are accessing the Interrupt Mask Register (IMR) which can be used to manually mask off or unmask interrupt requests. This is how we enable or disable interrupt requests. The register we are accessing depends on wether it is a write or read operation. If we write to port 0x20, we are accessing the command register. If we are reading from it, we are accessing the status register. Lastly, because this is an implimentation detail, it is part of the implimentation (pic.cpp), not interface. Lets take a look at the constants used during initialization next. pic.cpp: Initialization Control Word 1 This is the primary control word used when initializing the PICs. This is a 7 bit value that must be put in the primary PIC command register. This is the format: Operation Command Word 1 table Bit Number Value Description 0 IC4 If set(1), the PIC expects to recieve IC4 during initialization. 1 SNGL If set(1), only one PIC in system. If cleared, PIC is cascaded with slave PICs, and ICW3 must be sent to controller. 2 ADI If set (1), CALL address interval is 4, else 8. This is useually ignored by x86, and is default to 0 3 LTIM If set (1), Operate in Level Triggered Mode. If Not set (0), Operate in Edge Triggered Mode 4 1 Initialization bit. Set 1 if PIC is to be initialized 5 0 MCS-80/85: Interrupt Vector Address. x86 Architecture: Must be 0 6 0 MCS-80/85: Interrupt Vector Address. x86 Architecture: Must be 0 7 0 MCS-80/85: Interrupt Vector Address. x86 Architecture: Must be 0 As you can see, there is alot going on here. We have seen some of these before. This is not as hard as it seems, as most of these bits are not used on the x86 platform. There are two types of constants for each command word. The first type are bit masks that are used to mask off the bits that the data represents. The second type of constants used are command control bits which are used in conjunction with the masks to set them to their correct values. Lets look closer. Here are the ICW 1 bit masks. Notice how they follow the format shown in the above table. We do not define anything for the last three bits as they are always zero for x86 architectures. //! Initialization Control Word 1 bit masks #define I86_PIC_ICW1_MASK_IC4 0x1 //00000001 // Expect ICW 4 bit #define I86_PIC_ICW1_MASK_SNGL 0x2 //00000010 // Single or Cascaded #define I86_PIC_ICW1_MASK_ADI 0x4 //00000100 // Call Address Interval #define I86_PIC_ICW1_MASK_LTIM 0x8 //00001000 // Operation Mode #define I86_PIC_ICW1_MASK_INIT 0x10 //00010000 // Initialization Command Okay...We can easily use the above bit masks to set the bits in the ICW 1. But, how do we know what they mean? That is, when we mask off the bits that we are wanting to set, how do we know what the value we are setting them to mean? This is where command control bits come in. They contain the constant values that may be used to set the above masked off bits to. This helps increase readability and extendability alot. Here are the command control bits for ICW 1. Lets take a look... #define I86_PIC_ICW1_IC4_EXPECT 1 //1 //Use when setting I86_PIC_ICW1_MASK_IC4 #define I86_PIC_ICW1_IC4_NO 0 //0 #define I86_PIC_ICW1_SNGL_YES 2 //10 //Use when setting I86_PIC_ICW1_MASK_SNGL #define I86_PIC_ICW1_SNGL_NO 0 //00 #define I86_PIC_ICW1_ADI_CALLINTERVAL4 4 //100 //Use when setting I86_PIC_ICW1_MASK_ADI #define I86_PIC_ICW1_ADI_CALLINTERVAL8 0 //000 #define I86_PIC_ICW1_LTIM_LEVELTRIGGERED 8 //1000 //Use when setting I86_PIC_ICW1_MASK_LTIM #define I86_PIC_ICW1_LTIM_EDGETRIGGERED 0 //0000 #define I86_PIC_ICW1_INIT_YES 0x10 //10000 //Use when setting I86_PIC_ICW1_MASK_INIT #define I86_PIC_ICW1_INIT_NO 0 //00000 Not to hard. The naming convention used allows us to easily know what to use, and where. For example, I86_PIC_ICW1_SNGL_YES is used with I86_PIC_ICW1_MASK_SNGL , I86_PIC_ICW1_LTIM_EDGETRIGGERED is used with I86_PIC_ICW1_MASK_LTIM . Here is an example of how they work together. When we are initializing the PIC, we will need to enable initialization, and to send ICW 4. To do this, we simply set up ICW 1 like this: uint8_t icw=0; icw = (icw & ~I86_PIC_ICW1_MASK_INIT) | I86_PIC_ICW1_INIT_YES; icw = (icw & ~I86_PIC_ICW1_MASK_IC4) | I86_PIC_ICW1_IC4_EXPECT; Thats it!? Yep. Notice how everything works and fits together. This is used throughout the implimentations to set specific bits (or a series of bits) to known values. The best thing here as that--just by looking at the above code--you know what it is doing. (Begin initialization, and to expect ICW 4). Pretty cool, huh? We will be using this method throughout this series when needed when setting and masking off bits. Initialization Control Word 2 This control word is used to map the base address of the IVT of which the PIC are to use. Initialization Control Word (ICW) 2 table Bit Number Value Description 0-2 A8/A9/A10 Address bits A8-A10 for IVT when in MCS-80/85 mode. 03-Jul A11(T3)/A12(T4)/A13(T5)/A14(T6)/A15(T7) Address bits A11-A15 for IVT when in MCS-80/85 mode. In 80x86 mode, specifies the interrupt vector address. May be set to 0 in x86 mode. During initialization, we need to send ICW 2 to the PICs to tell them where the base address of the IRQ's to use. If an ICW1 was sent to the PICs (With the initialization bit set), you must send ICW2 next. Not doing so can result in undefined results. Most likley the incorrect interrupt handler will be executed. Because this command does not have a complex format, it is handled directly inside of pic.cpp and does not have any constants. Initialization Control Word 3 This command word is used to let the PIC controllers know how they are cascaded. To cascade multiple PICs, we must connect one of the PIC's IR lines to each other. We use this command word to let them know what line it is. Initialization Control Word 3 table Bit Number Value Description 0-7 S0-S7 Specifies what Interrupt Request (IRQ) is connected to slave PIC Because this command does not have a complex format, it is handled directly inside of pic.cpp and does not have any constants. Initialization Control Word 4 Yey! This is the final initialization control word. This controls how everything is to operate. Initialization Control Word 4 table Bit Number Value Description 0 uPM If set (1), it is in 80x86 mode. Cleared if MCS-80/86 mode 1 AEOI If set, on the last interrupt acknowledge pulse, controller automatically performs End of Interrupt (EOI) operation 2 M/S Only use if BUF is set. If set (1), selects buffer master. Cleared if buffer slave. 3 BUF If set, controller operates in buffered mode 4 SFNM Special Fully Nested Mode. Used in systems with a large amount of cascaded controllers. 05-Jul 0 Reserved, must be 0 This is a pretty complex command word, but not to bad. Lets take a look at our defined bit masks. Notice how they follow the format shown above. //! Initialization Control Word 4 bit masks #define I86_PIC_ICW4_MASK_UPM 0x1 //00000001 // Mode #define I86_PIC_ICW4_MASK_AEOI 0x2 //00000010 // Automatic EOI #define I86_PIC_ICW4_MASK_MS 0x4 //00000100 // Selects buffer type #define I86_PIC_ICW4_MASK_BUF 0x8 //00001000 // Buffered mode #define I86_PIC_ICW4_MASK_SFNM 0x10 //00010000 // Special fully-nested mode Simular to ICW 1 , we have a set of control bits that are used in conjunction with the bit masks to set properties. Here they are... #define I86_PIC_ICW4_UPM_86MODE 1 //1 //Use when setting I86_PIC_ICW4_MASK_UPM #define I86_PIC_ICW4_UPM_MCSMODE 0 //0 #define I86_PIC_ICW4_AEOI_AUTOEOI 2 //10 //Use when setting I86_PIC_ICW4_MASK_AEOI #define I86_PIC_ICW4_AEOI_NOAUTOEOI 0 //00 #define I86_PIC_ICW4_MS_BUFFERMASTER 4 //100 //Use when setting I86_PIC_ICW4_MASK_MS #define I86_PIC_ICW4_MS_BUFFERSLAVE 0 //000 #define I86_PIC_ICW4_BUF_MODEYES 8 //1000 //Use when setting I86_PIC_ICW4_MASK_BUF #define I86_PIC_ICW4_BUF_MODENO 0 //0000 #define I86_PIC_ICW4_SFNM_NESTEDMODE 0x10 //10000 //Use when setting I86_PIC_ICW4_MASK_SFNM #define I86_PIC_ICW4_SFNM_NOTNESTED 0 //00000 This is simple snough, huh? ^_^ We can use the above control bits in conjunction with the bit masks to build up the control word. The naming convention used allows us to easily identify what bit masks they are used with. I suppose thats it for the constants used in the implimentation. Lets get on with the functions... i86_pic_send_command (): Sends a command to a PIC This routine sends a command byte to the PIC's command register. picNum is a zero-based index representing the PIC we are accessing. On x86, this should either be a 0 or 1. Notice that we test what PIC we are working with in order to get the correct command register. While this is part of the interface, it should not be used that much outside of the interface. It provides a method so we can manually send and control the PICs, if needed. This will be required by the interrupt handlers to send the EOI command. inline void i86_pic_send_command (uint8_t cmd, uint8_t picNum) { if (picNum > 1) return; uint8_t reg = (picNum==1) ? I86_PIC2_REG_COMMAND : I86_PIC1_REG_COMMAND; outportb (reg, cmd); } i86_pic_send_data () and i86_pic_read_data (): Send and return a data byte to or from a PIC These routine are very simular to the above routine, however it writes or reads to the PIC's data register depending on the PIC in picNum . Notice how both of these routines are inline . Because these routines are small, we want to take out the function call. inline void i86_pic_send_data (uint8_t data, uint8_t picNum) { if (picNum > 1) return; uint8_t reg = (picNum==1) ? I86_PIC2_REG_DATA : I86_PIC1_REG_DATA; outportb (reg, data); } inline uint8_t i86_pic_read_data (uint8_t picNum) { if (picNum > 1) return 0; uint8_t reg = (picNum==1) ? I86_PIC2_REG_DATA : I86_PIC1_REG_DATA; return inportb (reg); } i86_pic_initialize (): Initializes the PICs This is the final routine for the PIC interface. This initializes both PICs for operation using all of the routines above, and our constants defined for the initialization control words. This routine is not too complex. Or, rather, not as complex as it looks ðŸ˜‰ All it does is send the initialization command to the PIC. It does this by setting the I86_PIC_ICW1_INIT_YES bit in the command word. We also set the I86_PIC_ICW1_IC4_EXPECT bit. This insures that the controller expects us to send ICW 4. Notice how the constants help improve readability? The ICW is stored in..well... icw . We send the command to both PICs using our i86_pic_send_command() routine. After ICW 1 is sent, we begin initialization by sending ICW 2. Remember that ICW 2 containes the base interrupt numbers? This is passed into the base0 and base1 parameters. Afterwords, we simply send ICW 3. Remember that ICW 3 provides the connection between the master and secondary PIC controllers. Lastly is ICW 4. We set up x86 mode by setting the I86_PIC_ICW4_UPM_86MODE bit. Compare this routine with the example found in the [PIC tutorial] (fix link OSDevPic.html) and be amazed...very amazed on their simularities! //! Initialize pic void i86_pic_initialize (uint8_t base0, uint8_t base1) { uint8_t icw = 0; //! Begin initialization of PIC icw = (icw & ~I86_PIC_ICW1_MASK_INIT) | I86_PIC_ICW1_INIT_YES; icw = (icw & ~I86_PIC_ICW1_MASK_IC4) | I86_PIC_ICW1_IC4_EXPECT; i86_pic_send_command (icw, 0); i86_pic_send_command (icw, 1); //! Send initialization control word 2. This is the base addresses of the irq's i86_pic_send_data (base0, 0); i86_pic_send_data (base1, 1); //! Send initialization control word 3. This is the connection between master and slave. //! ICW3 for master PIC is the IR that connects to secondary pic in binary format //! ICW3 for secondary PIC is the IR that connects to master pic in decimal format i86_pic_send_data (0x04, 0); i86_pic_send_data (0x02, 1); //! Send Initialization control word 4. Enables i86 mode icw = (icw & ~I86_PIC_ICW4_MASK_UPM) | I86_PIC_ICW4_UPM_86MODE; i86_pic_send_data (icw, 0); i86_pic_send_data (icw, 1); } Whew , I guess thats all of the big stuff for the PIC. All that is left is reprogramming the PIT. Don't worry--its not as complex as the PIC is. Lets take a look... Programmable Interval Timer Okay... So the PIC is ready to go, so we can now enable hardware interrupts, right? Yep--Kind of. While everything is okay so far, we still do not have an interrupt handler installed for the PIT yet. So, what will happen on the next timer tick? ...I think you know where I am getting at ðŸ˜€ A Programmable Interval Timer (PIT) is a counter which triggers an interrupts when they reach their programmed count. The 8253 and 8254 microcontrollers are PITs avialble for the i86 architectures used as timer for i86-compatable systems. On x86 architectures, The PIT acts as the system timer , and is connected to the PIC's IR0 line. This allows the PIT to fire IRQ 0 each timer tick. Because of this, we will need to reprogram this microcontroller before we can use it. The PIT is a complex microcontroller to program. Because of this, we have created a separate tutorial for it. While I will still try to cover everything in detail, I will not cover everything about the PIT here. Please see (and refrence) the following tutorial to learn about the PIT: [8253 Programmable Interval Timer Tutorial] (fix link OSDevPit.html) pit.h: Interface The good thing about the PIT is that it is not that complex to program. It does not contain that much commands, and yet does not need that much commands. It is a small, but powerful chip used for hardware timing and requests. Operation Command Word The PIT only containes one Operation Command Word (OCW) which is used to initialize a counter. It sets up the counters counting mode, operation mode, and allows us to set up an initil count value. The command word is a little complex. Here is the complete command word: Bit 0: (BCP) Binary Counter 0: Binary 1: Binary Coded Decimal (BCD) Bit 1-3: (M0, M1, M2) Operating Mode. See above sections for a description of each. 000: Mode 0: Interrupt or Terminal Count 001: Mode 1: Programmable one-shot 010: Mode 2: Rate Generator 011: Mode 3: Square Wave Generator 100: Mode 4: Software Triggered Strobe 101: Mode 5: Hardware Triggered Strobe 110: Undefined; Don't use 111: Undefined; Don't use Bits 4-5: (RL0, RL1) Read/Load Mode. We are going to read or send data to a counter register 00: Counter value is latched into an internal control register at the time of the I/O write operation. 01: Read or Load Least Significant Byte (LSB) only 10: Read or Load Most Significant Byte (MSB) only 11: Read or Load LSB first then MSB Bits 6-7: (SC0-SC1) Select Counter. See above sections for a description of each. 00: Counter 0 01: Counter 1 10: Counter 2 11: Illegal value Simular to the PIC's interface, we set up several bit masks that are used to describe the format of the command. Here it is... #define I86_PIT_OCW_MASK_BINCOUNT 1 //00000001 #define I86_PIT_OCW_MASK_MODE 0xE //00001110 #define I86_PIT_OCW_MASK_RL 0x30 //00110000 #define I86_PIT_OCW_MASK_COUNTER 0xC0 //11000000 Okay...While this is smaller then the ICWs and OCWs we set up in the PIC, this is actually more complex. The commands used in the PIC are simple in that they are 1 bit in size. The commands used in this operation command word are not. This is where Command Control Bits shine. These help define the different settings and bit combinations for the different bit masks above. Here they are. #define I86_PIT_OCW_BINCOUNT_BINARY 0 //0 //! Use when setting I86_PIT_OCW_MASK_BINCOUNT #define I86_PIT_OCW_BINCOUNT_BCD 1 //1 #define I86_PIT_OCW_MODE_TERMINALCOUNT 0 //0000 //! Use when setting I86_PIT_OCW_MASK_MODE #define I86_PIT_OCW_MODE_ONESHOT 0x2 //0010 #define I86_PIT_OCW_MODE_RATEGEN 0x4 //0100 #define I86_PIT_OCW_MODE_SQUAREWAVEGEN 0x6 //0110 #define I86_PIT_OCW_MODE_SOFTWARETRIG 0x8 //1000 #define I86_PIT_OCW_MODE_HARDWARETRIG 0xA //1010 #define I86_PIT_OCW_RL_LATCH 0 //000000 //! Use when setting I86_PIT_OCW_MASK_RL #define I86_PIT_OCW_RL_LSBONLY 0x10 //010000 #define I86_PIT_OCW_RL_MSBONLY 0x20 //100000 #define I86_PIT_OCW_RL_DATA 0x30 //110000 #define I86_PIT_OCW_COUNTER_0 0 //00000000 //! Use when setting I86_PIT_OCW_MASK_COUNTER #define I86_PIT_OCW_COUNTER_1 0x40 //01000000 #define I86_PIT_OCW_COUNTER_2 0x80 //10000000 Lets look at an example. Lets say we want to initialize counter 0 as a square wave generator in binary count mode. This is how we can do it: uint8_t ocw=0; ocw = (ocw & ~I86_PIT_OCW_MASK_MODE) | I86_PIT_OCW_MODE_SQUAREWAVEGEN; ocw = (ocw & ~I86_PIT_OCW_MASK_BINCOUNT) | I86_PIT_OCW_BINCOUNT_BINARY; ocw = (ocw & ~I86_PIT_OCW_MASK_COUNTER) | I86_PIT_OCW_COUNTER_0; I think I am making this too easy, what do you think? :p This is all you need to do, and ocw will contain the operation command word that can be sent to the PIC. Notice how using these constants help both improve readabilty, but also to decrease the possibility for errors. I guess thats all there is to pit.h. Lets dive into pit.cpp next, shall we? Wee...!! pit.cpp: Implimentation This containes the bulk of the PIT minidriver. It containes the implimentations of each routine used by both the interface and implimentation. pit.cpp: Registers This is where we define the constants to abstract the port locations for the PIT. #define I86_PIT_REG_COUNTER0 0x40 #define I86_PIT_REG_COUNTER1 0x41 #define I86_PIT_REG_COUNTER2 0x42 #define I86_PIT_REG_COMMAND 0x43 //! Global Tick count uint32_t _pit_ticks=0; Not to bad. I86_PIT_REG_COUNTER0, I86_PIT_REG_COUNTER1, and I86_PIT_REG_COUNTER2 are the data registers for each counter. Remember that the PIT has three internal counters? I86_PIT_REG_COMMAND is our command register. We will need to write commands to the command register to control and operate the PIT. Also, notice _pit_ticks . This is a very special and important global. Remember that the PIT counter 0 connects to the IR0 line on the PIC? This means, when counter 0 fires, it will generate Interrupt Request (IRQ) 0 . We will need to create and install an interrupt handler to handle this request. All the interrupt handler needs to do is update the Global Tick Count for the system. That is what _pit_ticks is for. i86_pit_irq(): PIT Counter 0 Interrupt Handler This is the interrupt handler that handles the IRQ 0 request. Whenever Counter 0 fires, it will call this interrupt handler. All it does is increment the global tick count whenever it fires. Note the general format for an interrupt handler. intstart() is a macro used to disable hardware interrupts and save the stack frame so that we can return to the task without missing up its stack. intret() is a macro that disables hardware interrupts, restors the stack frame and returns from the handler using the IRETD instruction. The purpose of this is simply so that we can protect the current stack from being changed, and return back to the task with its stack intact. These macros are defined in asm/system.h so they can be used by the kernel and device drivers interrupt handlers. interrupt is a special constant that is only used on certain compiliers. For MSVC++, it is defined as __declspec (naked) . This is so we don't need to worry about the compiliers added code. Some compiliers support this keyword directly (Most notably 16 bit compiliers). Others (Like MSVC++) do not, so we must define it. interruptdone() is a special routine defined in the Hardware Abstraction Layer . It is resposible for sending the End of Interrupt commands to the PIC. This is the generic format that all of our interrupt handlers will use. void interrupt _cdecl i86_pit_irq () { //! macro to hide interrupt start code intstart (); //! increment tick count _pit_ticks++; //! tell hal we are done interruptdone(0); //! macro used with intstart to return from interrupt handler intret (); } i86_pit_send_command (): Send Command to PIT This is a very important routine that allows us to send command to the PIT. This hides the command port we are sending it to, which is nice if we need to change the port name. The command is in the form of an Operation Command Word (OCW) . //! send command to pic void i86_pit_send_command (uint8_t cmd) { outportb (I86_PIT_REG_COMMAND, cmd); } For an example, we can build up an OCW using our bit masks and command control bits above. Then, we can use i86_pit_send_command() to send the OCW to the PIT. i86_pit_send_data() and i86_pit_read_data(): Sends and reads data from counter These routines help abstract the port name used when reading or writing to a counter. These are used to set and get the current count value. All they do is test the counter passed in counter to insure we get the correct port. Then, its just a simple read or write operation through that port. //! send data to a counter void i86_pit_send_data (uint16_t data, uint8_t counter) { uint8_t port= (counter==I86_PIT_OCW_COUNTER_0) ? I86_PIT_REG_COUNTER0 : ((counter==I86_PIT_OCW_COUNTER_1) ? I86_PIT_REG_COUNTER1 : I86_PIT_REG_COUNTER2); outportb (port, data); } //! read data from counter uint8_t i86_pit_read_data (uint16_t counter) { uint8_t port = (counter==I86_PIT_OCW_COUNTER_0) ? I86_PIT_REG_COUNTER0 : ((counter==I86_PIT_OCW_COUNTER_1) ? I86_PIT_REG_COUNTER1 : I86_PIT_REG_COUNTER2); return inportb (port); } i86_pit_initialize (): Initialize the PIT Okay, lets talk about initializing the PIT. Yeah! Well... er.. There really is not much to talk about, as it really does not require initialization. What we will need to do, however, is provide a way to install our interrupt handler. irq is the interrupt number to use and irCodeSeg is the code seletor offset into the Global Descriptor Table (GDT) . We use our i86_install_ir() routine to install our interrupt handler ( i86_pit_irq ) into the Interrupt Descriptor Table . From here on out, IRQ 0 is mapped to our interrupt handler at irq . irq should be the same base IRQ number that the primary PIC was mapped to use to insure it is mapped to IRQ 0. //! initialize minidriver void i86_pit_initialize (uint8_t irq, uint8_t irCodeSeg) { //! Install our interrupt handler i86_install_ir (irq, I86_IDT_DESC_PRESENT | I86_IDT_DESC_BIT32, irCodeSeg, i86_pit_irq); } i86_pit_start_counter (): Starts an internal counter This is the final routine in the PIT interface. This starts up a counter. We pass the counter into counter that we want to start (Such as I86_PIT_REG_COUNTER0 ). mode containes the operation mode that we want the counter to use (Such as I86_PIT_OCW_MODE_SQUAREWAVEGEN ). freq containes the frequency rate that we want the counter to operate at. This routine builds up the operational command word based on the paramaters passed into the routine. void i86_pit_start_counter (uint32_t freq, uint8_t counter, uint8_t mode) { if (freq==0) return; uint16_t divisor = 1193180 / freq; //! send operational command uint8_t ocw=0; ocw = (ocw & ~I86_PIT_OCW_MASK_MODE) | mode; ocw = (ocw & ~I86_PIT_OCW_MASK_RL) | I86_PIT_OCW_RL_DATA; ocw = (ocw & ~I86_PIT_OCW_MASK_COUNTER) | counter; i86_pit_send_command (ocw); //! set frequency rate i86_pit_send_data (divisor & 0xff, 0); i86_pit_send_data ((divisor >> 8) & 0xff, 0); //! reset tick count _pit_ticks=0; } Conclusion From here on out, all of the basics are completed. We have covered alot in this series, from processor modes and architecture, to processor tables, interrupts, interrupt management, and more. This is the beginning of the kernel, and where the kernel builds off from. In this tutorial, we have added support for the PIC, PIT, exceptions, and hardware interrupt management. This is a important steps, as alot of important devices use hardware interrupts. Also, this gives us a chanch to re-enable hardware interrupts (Remember that we needed to disable hardware interrupts before the switch to protected mode?) In the next tutorial, we will go back to the kernel itself. Its time to talk about one of the most fundemental aspects of any computer system: Paging and Low Level Memory Management . This will also be the foundation of our own System API . I'll see you there... ðŸ˜‰"
  },
  "articles/61_unorganised_tutorial/T17.html": {
    "href": "articles/61_unorganised_tutorial/T17.html",
    "title": "Physical Memory | BrokenThorn OS Dev Tutorials",
    "keywords": "Physical Memory Welcome! In this tutorial we will be looking at managing one of our most important resources within a computer system: Physical Memory. We will be looking at how to get memory information, some more BIOS interrupts, memory manager concepts, and the design and implimentation for our complete physical memory manager. This is one of those things that no one likes to do--but in the end it makes things much easier to work with. With that in mind, lets take a look at the list for this tutorial: Physical Memory Translation Lookaside Buffer (TLB) Memory Management Unit (MMU) Memory Managers Abtaining memory information Passing information from bootloader to kernel Designing and developing a physical memory manager Alirighty then! Notice that I am not covering paging or virtual memory here. Instead, I want to keep the concepts of physical memory management and virtual memory management completely separate. The reasons for this is simplicity; we can focus on one without the other. Don't worry--we will cover paging and virtual memory in the next tutorial when we cover the development of a virtual memory manager. Memory: A deeper look Rather then jumping directly into memory management, I want to take a different approch here. That is, How can we even understand what memory management is about without even understanding what memory itself is? That is, we should know what is it that we are trying to manage, right? Because of this, we will first look at what physical memory is first. You know... Those little RAM chips inside of your computer? ðŸ˜€ Here we go...! The Physical Memory Physical Memory: Abstract Physical Memory is an abstract block of memory stored within the computers Random Access Memory (RAM) . The way physical memory is \"stored\" within the RAM depends on the type of RAM the system uses. For example, Dynamic Random Access Memory (DRAM) stores each bit of data in its own capacitor that must be refreshed periodically. A capacitor is an electronic device that stores a current for a limited time. This allows it to either store a current (a binary 1), or no current (a binary 0). This is how DRAM chips store individual bits of data in a computer. Most of the time, the memory types (RAM, SRAM, DRAM, etc.) require a specific type of Memory Controller to interface with the processor and System Bus . The Memory Controller provides a way of reading and writing memory locations through software. The Memory Controller is also responsible for the constant refreshing of the RAM chips to insure they retain their information. Memory Controllers contain Multiplexer and Demultiplexer circuits to select the exact RAM chip, and location that refrences the address in the Address Bus . This allows the processor to refrence a specific memory location by sending the memory address through the address bus. ...This is where the software come in, as they tell the processor what memory address to read ðŸ˜€ The Memory Controller selects the location within the RAM chip in a sequence manner. This means, if we access a physical memory location greater then the total amount of memory in the system, nothing will happen. That is, you can write a value to that memory location and read it back--you will get whatever left over data on the data bus. It is possible for memory holes to appear in the Physical Address Space . This can happen if, for example, a RAM chip is in slots 1 and 3, with no RAM chip in slot 2. This means that there is an area of memory between the last byte stored in the RAM at slot 1 and the first byte-1 in slot 3 that does not exist. Reading or writing to these locations have almost the same effect when reading or writing beyond memory. If this nonexistant memory location has been remapped by the memory controller, you may be reading or writing to a different part of memory. If the memory has not been remapped (Which most of memory is not), Reading or writing to a memory location that does not exist does nothing at all. That is, writing to the non existant memory location will not write anything anywhere, reading from a non existant memory location reads whatever garbage was left over on the data bus. Knowing that writing a value to a non existant location and reading it back will NOT yeld the same value, methods have come up of manually parsing memory via pointers to determin what areas of memory are good or not. However, doing this can be dangerous as we will look at later. Well, Thats all for what physical memory really is. Knowing how memory stores each bit you can probably start seeing where the bytes, words, dword, qwords, tbytes, etc.. start to come in. The most important of these are the byte , as that is the smallest data that the processor can access. But how does the processor know where a byte is located in memory? This is where the Physical Address Space comes in. Lets take a look ðŸ˜€ Physical Address Space (PAS) This is the address space used by the processor (and translated by the memory controller) to refer to an 8 bit peice of data (ie, a byte) stored in physical memory (RAM). A Memory Address is just a number selected by the Memory Controller for a byte of data. For example, memory address 0 can refer to the first 8 bits of physical memory, memory address 1 can refer to the next 8 bits, and so on. The Physical Address Space is the array of these memory addresses and the actual memory that the memory addresses refer to. The physical address space is accessed by the processor through the systems address bus (Remember this from [Chapter 7] (fix link OSDev7.html)?) Okay, so lessee... the processor now can use an address to refer to a byte of memory. It useually starts from address 0, and increments for each byte in memory. Thats as simple as it can get! But, it still doesnt describe how the software can access memory. Sure, the processor itself now has a way of refrencing memory, but the software does not . The processor, depending on its needs, need to provide specific ways for software to provide software a way to refrence memory. Wait, what? Thats right... different ways of addressing and accessing memory... Addressing Modes The Addressing Mode is an abstraction made by the processor to manage how the software accesses the Physical Address Space . This useually allows the software to set up the processors' registers so the processor knows how to refrence memory. We have already seen two: segment:offset memory addressing and descriptor:offset memory addressing . This is the interface given by the processor for the software to allow a way to access memory. We have covered the segment:offset addressing mode in [Chapter 4] (fix linkOSDev4.html) and the descriptor:offset memory addressing mode in [Chapter 8] (fix linkOSDev8.html). How Memory Works: Detail Okay, now lets look at memory in a new way. We have already covered alot of details on what memory is, address space and addressing modes. Now, lets put everything together, shall we? Alot of the information in this section is not needed, but I decided to include it for completness sake. Don't worry to much if you do not understand everything here. In [Chapter 7] (fix link OSDev7.html), we have looked at a basic overview of a computer system and system architecture. We have talked about how the processor's system bus connects to the memory controller which is used to provide the system a way to control physical RAM. Kind of like this: Thats it! This is how the physical RAM connects and communicates with the rest of the system. In the above image, the DDR Controller is the memory controller. The Translation Lookaside Buffer (TLB) sits between the memory controller and processor. With this, the system bus connects all three of them through its address bus , data bus and control bus . The only 2 lines from the control bus that are important to us right now are the RW line and CLK line. The TLB is only used when paging is enabled. Because of this, we will look at it a little more later. Okay, so what actually happens when we write data to a physical memory location? During a write operation , the processor sets the RW pin to high (a logical 1). This tells the devices it connects to that a write operation is to take place. The processor resets the IO Control line to low (a logical 0). This insures the IO SubSystem ignores the command (Meaning its not an IN/OUT port instruction), but rather for the memory controller. The processor then copies the address to write to onto the address bus and the data to write onto the data bus. Because these lines are connected indirectly to the memory controller, the memory controller is able to see it is a write operation. So, all the memory controller needs to do is translate the memory address on the address bus using its demultiplexer circuit to find the RAM chip to use, and linear offset byte into the RAM chips memory space. The memory controller then copies the data from the data bus to this location, and refreshes the memory state on the next clock signal. During a read operation it follows almost the same process as a write operation. Except, the RW line is set low to indicate a read operation. Also, the memory controller, after translating the memory address into an offset into the RAM chip, copies the data stored in that location and places it on the data bus for the processor. The memory controller then refreshes the memory state on the next clock signal. The CLK signal is used to synchronize the exchange of addresses and data values through the reads and writes. Communication with the memory chip is started when the CLK line is a logical 1 (set high). During this period that the CLK line is held high the address is placed on the address lines and the R/W line is either taken high for a write or low for a read. During execution the processor will constantly be flipping the clock line high and low in order to perform reads and writes with the memory controller. While paging is disabled, the TLB itself does nothing at all. Notice that the TLB is not used at all when reading or writing memory. Physical Memory Managers As you may know, managing memory is critically important. All of our data and code share the same physical address space. If we attempt to load and work with more data or programs, we will need to some how find a way of managing memory to allow this. At this stage, our kernel has full control of all of the hardware and memory in your computer. This is great but bad at the same time. We have no way of knowing what areas of memory are currently in use nor what areas are free. Because of this, there is no real way of working with memory without the possibility of problems: program corruption, data corruption, no way of knowing how memory is mapped, triple faults or other exception errors, etc... The results may be unpredictable. Because of this, effectivly managing physical memory is very important. Lets look closer! Detecting Memory Abstract (Detecting Memory) The first thing we need to do is abtain the amount of RAM inside of the computer system. There are alot of different ways to do this. Some methods may work on some systems while others may not. Getting the amount of memory can be very system dependent. More specifically, motherboard chipset dependent. During initialization, the BIOS abtains memory information from the memory controller and configures the chipset to work with the detected memory. Because of this, Operating systems need to go through the system BIOS to abtain this information. But Wait! I thought we were not able to use the Bios in protected mode!? Thats right...we can't. Instead we must get this information some other way... The bootloader, perhaps? I should point out that there is indeed other methods that we can do to abtain the amount of memory within the system. For example, the CMOS, PnP, and SMBios. However the only way to guarantee that you get the correct amount is from the device that configuares it: The BIOS. The last thing to note here is that all PCs are required to have a memory region just below the 4 GB mark for use by additional possible devices (Memory mapped hardware or the BIOS ROM). We will look at how to get around this a little later, don't worry ðŸ˜€ \"Low Memory\" , otherwise known as Conventional Memory is memory below the 1MB mark. Memory above 1MB is known as Extended Memory . With all of that in mind, lets take a look at some nice Bios interrupts to help us out... Bios: Getting Memory Size All of the following routines can be found in memory.inc in the demo at the end of this tutorial inside of the 2nd stage boot loader. BIOS INT 0x12 - Get Memory Size (Conventional Memory) Return CF = Clear if successful AX = Number of KB conventional memory AH = status if error (0x80: Invalid command; 0x86) Unsupported function This is quite possible the easiest method. This interrupt returns the value found in the BIOS data area (The word at physical address 0x413). Because it returns a WORD sized value, it is limited to 0xFFFF (65535 decimal). That is, it will only detect memory below 64KB. Because of this, on systems with more then 64KB of memory, it will not return the correct size. Thus, I will not be using this method. While this method may not return the complete memory size, it is quite possibly the only one guranteed to work on almost all, if not all, PCs. BiosGetMemorySize: int 0x12 jc .error test ax, ax ; if size=0 je .error cmp ah, 0x86 ;unsupported function je .error cmp ah, 0x80 ;invalid command je .error ret .error: mov ax, -1 ret BIOS INT 0x15 Function 0x88 - Get Extended Memory Size Return (BIOS INT 0x15 Function 0x88) CF = Clear if successful AX = Number of contiguous KB starting at 1MB physical address AH = status if error (0x80: Invalid command; 0x86) Unsupported function This interrupt returns the amount of KB extended memory in AX. Because it uses 16 bit registers, it is limited to returning 64MB, or 0xFFFFF (65535). On some versions of Windows, this function may return 15MB instead. BiosGetExtendedMemorySize: mov ax, 0x88 int 0x15 jc .error test ax, ax ; if size=0 je .error cmp ah, 0x86 ;unsupported function je .error cmp ah, 0x80 ;invalid command je .error ret .error: mov ax, -1 ret BIOS INT 0x15 Function 0xE881 - Get Memory Size For > 64 MB Configuations (32 Bit) Return (BIOS INT 0x15 Function 0xE881) CF = Clear if successful EAX = Extended memory between 1MB and 16MB in KB EBX = Extended memory above 16MB, in 64KB blocks ECX = Configured memory 1MB to 16MB in KB EDX = Configured memory above 16MB in 64JB blocks This interrupt is exactally like INT 0x15 Function 0xE801 except it uses the extended registers (EAX/EBX/ECX/EDX). BIOS INT 0x15 Function 0xE801 - Get Memory Size For > 64 MB Configuations Return (BIOS INT 0x15 Function 0xE801) CF = Clear if successful EAX = Extended memory between 1MB and 16MB in KB EBX = Extended memory above 16MB, in 64KB blocks ECX = Configured memory 1MB to 16MB in KB EDX = Configured memory above 16MB in 64JB blocks This is the method that I tend to use. This interrupt is used by both Windows NT and Linux during boot up to detect memory size if INT 0x15 function 0xe820 is not supported (Get System Memory Map). We will look at that later. This method has been around since around 1994 so older systems may not support this method. The \"Extended Memory\" and \"Configured Memory\" values are almost always the same. Some BIOSs may store the results in either EAX and EBX or ECX and EDX. In other words, some BIOS may use EAX and EBX but leave ECX and EDX alone. Other BIOSs may do the exact opposite. Yey for standards! ðŸ˜€ Uh, okay...Sorry ðŸ˜‰ The typical way of using this method is to null out all of the general-purpose registers first before calling the BIOS. This way, after the BIOS call, we can test if a register is null or not so we know what pair of registers to use: EAX/EBX or ECX/EDX: ;--------------------------------------------- ; Get memory size for >64M configuations ; ret\\ ax=KB between 1MB and 16MB ; ret\\ bx=number of 64K blocks above 16MB ; ret\\ bx=0 and ax= -1 on error ;--------------------------------------------- BiosGetMemorySize64MB: push ecx push edx xor ecx, ecx ;clear all registers. This is needed for testing later xor edx, edx mov ax, 0xe801 int 0x15 jc .error cmp ah, 0x86 ;unsupported function je .error cmp ah, 0x80 ;invalid command je .error jcxz .use_ax ;bios may have stored it in ax,bx or cx,dx. test if cx is 0 mov ax, cx ;its not, so it should contain mem size; store it mov bx, dx .use_ax: pop edx ;mem size is in ax and bx already, return it pop ecx ret .error: mov ax, -1 mov bx, 0 pop edx pop ecx ret Notice what this routine returns. In order for us to get the amount of KB in the system, we need to do some math. EBX contains the number of 64KB blocks of memory. If we multiply this by 64, we effectivly convert the value in EBX into the amount of KB above 16MB. Afterwords, simply add this number to the number returned in EAX to get the amount of KB above 1MB. Knowing there is 1024 KB in a one megabyte, add 1024 to this number and we now have the total amount of KB in the system! Manually Probing Memory Manually probing memory means to manually detect memory from a pointer by directly accessing memory. While it is possible that doing this may detect all of memory, it is also the most dangerous. Remember that there may be devices that we may or may not know of that uses regions of memory for different things. There may also be memory mapped devices, the ROM BIOS, and other devices that use memory. We also have not taken into account memory holes within the physical address space. To directly probe memory comes from the fact that reading or writing to nonexistant memory does nothing. That is, if you write to a physical memory address that does not exist, you will not get an error. However, if you attempt to read from that same location again, the value that you get back may be completely random garbage--whatever was left on the data bus. Thus to probe memory, just go into a loop for every 1k (or so) of memory. Use a pointer to read and write to a memory location. Continue incrementing the pointer (Hence reading from another location in memory) until the value read from the pointer containes an invalid value. I might create a little demo code for this method, but we would probably never use it do to its many problems. I decided to include this method as it is a method to detect memory, although it is the most unsafe method to use and can cause unpredictable results. Use at your own risk! Getting the Memory Map Yippie! Now we have gotten the amount of memory in the system. But Wait! Not all of this memory is available to us, remember? This is where a Memory Map comes in. A memory map defines what regions of memory are used for what. Using this, we can also abtain what regions that are safe for us to use. BIOS INT 0x15 Function 0xE820 - Get Memory Map Input EAX = 0x0000E820 EBX = continuation value or 0 to start at beginning of map ECX = size of buffer for result (Must be >= 20 bytes) EDX = 0x534D4150h ('SMAP') ES:DI = Buffer for result Return (BIOS INT 0x15 Function 0xE820) CF = clear if successful EAX = 0x534D4150h ('SMAP') EBX = offset of next entry to copy from or 0 if done ECX = actual length returned in bytes ES:DI = buffer filled If error, AH containes error code Address Range Descriptor The buffer used by this interrupt as an array of descriptors that follow the following format: struc MemoryMapEntry .baseAddress resq 1 ; base address of address range .length resq 1 ; length of address range in bytes .type resd 1 ; type of address range .acpi_null resd 1 ; reserved endstruc Types of Address Ranges The types of address ranges defined for this function is shown below: 1: Available Memory 2: Reserved, do not use. (e.g. system ROM, memory-mapped device) 3: ACPI Reclaim Memory (usable by OS after reading ACPI tables) 4: ACPI NVS Memory (OS is required to save this memory between NVS sessions) All other values should be treated as undefined. Code to get the Memory Map This interrupt might seem a little complex, but its not to bad. First take a look at the inputs that this interrupt requires. We put the function number (0xe820), of course, in AX. However some BIOSs require that the upper half of EAX is zero. Because of this, you should us EAX here instead of AX. Also notice that EDX must contain the value of 'SMAP'. This is another requirement . Some BIOSs may trash this register after calling the interrupt. Okay... When we execute this interrupt, the BIOS will return a single entry of the memory map (This entry has a format. Please see the Address Range Descriptor above). If, after calling the interrupt, EBX is NOT zero, then there are more entries in the memory map. We will need to loop for each entry in the map. If the entry length is 0, then skip the entry as there is nothing there and go to the next entry in the list until we reach the end. This routine uses the MemoryMapEntry structure we have defined above to get information from the entries that we abtain from the bios. ;--------------------------------------------- ; Get memory map from bios ; /in es:di->destination buffer for entries ; /ret bp=entry count ;--------------------------------------------- BiosGetMemoryMap: pushad xor ebx, ebx xor bp, bp ; number of entries stored here mov edx, 'PAMS' ; 'SMAP' mov eax, 0xe820 mov ecx, 24 ; memory map entry struct is 24 bytes int 0x15 ; get first entry jc .error cmp eax, 'PAMS' ; bios returns SMAP in eax jne .error test ebx, ebx ; if ebx=0 then list is one entry long; bail out je .error jmp .start .next_entry: mov edx, 'PAMS' ; some bios's trash this register mov ecx, 24 ; entry is 24 bytes mov eax, 0xe820 int 0x15 ; get next entry .start: jcxz .skip_entry ; if actual returned bytes is 0, skip entry .notext: mov ecx, [es:di + MemoryMapEntry.length] ; get length (low dword) test ecx, ecx ; if length is 0 skip it jne short .good_entry mov ecx, [es:di + MemoryMapEntry.length + 4]; get length (upper dword) jecxz .skip_entry ; if length is 0 skip it .good_entry: inc bp ; increment entry count add di, 24 ; point di to next entry in buffer .skip_entry: cmp ebx, 0 ; if ebx return is 0, list is done jne .next_entry ; get next entry jmp .done .error: stc .done: popad ret Multiboot Specification I do not plan on covering the multiboot specification too soon. Mabey in the future, but not now. However, we need a way to pass the information that we abtained from the BIOS inside of our bootloader to our Kernel. We can do this any way that we want. Because the multiboot specification defines a standard boot time information structure, and I dont know if we will fully support the multiboot standard, I decided why not use the same structure? Also, if you decide to use another boot loader (Such as GRUB), we can have it boot our kernel as well. Anyways, the entire specification itself is rather large, so covering it in a tutorial about memory management is not a good idea ðŸ˜‰ Thus, I will cover just enough so we can use it to pass the information that we need, sound cool? Abstract The Multiboot specification is a list of standards used to describe standards for boot loaders for loading and executing operating system kernels. This specification makes it easier to boot multiple operating systems because the specification describes a standard state that the machine must be in before the operating system takes control. This also includes how and what information is passed from the bootloader to the kernel. I will not be covering the complete multiboot specification right now. However, we will be looking at what the machine state must be in when the kernel is executed. We will also be looking a little bit at the Multiboot information structure which containes the information passed from the boot loader to the kernel. We will also be using this structure to pass our bootloader memory information using this structure as well. Machine State The Multiboot specification states that, when we invoke a 32 bit operating system (That is, execute our kernel), the machine registers must be set to a specific state. More specifically: When we execute our kernel, set up the registers to the following values: EAX - Magic Number. Must be 0x2BADB002 . This will indicate to the kernel that our boot loader is multiboot standard EBX - Containes the physical address of the Multiboot information structure CS - Must be a 32-bit read/execute code segment with an offset of 0 and a limit of 0xFFFFFFFF . The exact value is undefined. DS,ES,FS,GS,SS - Must be a 32-bit read/write data segment with an offset of 0 and a limit of 0xFFFFFFFF . The exact values are all undefined. A20 gate must be enabled CR0 - Bit 31 (PG) bit must be cleared (paging disabled) and Bit 0 (PE) bit must be set (Protected Mode enabled). Other bits undefined All other registers are undefined. Most of this is already done in our existing boot loader. The only additional two things we must add are for the EAX register and EBX. The most important one for us is stored in EBX. This will contain the physical address of the multiboot information structure. Lets take a look! Multiboot Information Structure This is possibly one of the most important structures contained in the multiboot specification. The information in this structure is passed to the kernel from the EBX register, This allows a standard way for the boot loader to pass information to the kernel . This is a fairly big structure but isnt to bad. Not all of these members are required. The specification states that the operating system must use the flags member to determin what members in the structure exist and what do not. struc multiboot_info .flags resd 1 ; required .memoryLo resd 1 ; memory size. Present if flags[0] is set .memoryHi resd 1 .bootDevice resd 1 ; boot device. Present if flags[1] is set .cmdLine resd 1 ; kernel command line. Present if flags[2] is set .mods_count resd 1 ; number of modules loaded along with kernel. present if flags[3] is set .mods_addr resd 1 .syms0 resd 1 ; symbol table info. present if flags[4] or flags[5] is set .syms1 resd 1 .syms2 resd 1 .mmap_length resd 1 ; memory map. Present if flags[6] is set .mmap_addr resd 1 .drives_length resd 1 ; phys address of first drive structure. present if flags[7] is set .drives_addr resd 1 .config_table resd 1 ; ROM configuation table. present if flags[8] is set .bootloader_name resd 1 ; Bootloader name. present if flags[9] is set .apm_table resd 1 ; advanced power management (apm) table. present if flags[10] is set .vbe_control_info resd 1 ; video bios extension (vbe). present if flags[11] is set .vbe_mode_info resd 1 .vbe_mode resw 1 .vbe_interface_seg resw 1 .vbe_interface_off resw 1 .vbe_interface_len resw 1 endstruc Alot of information in this structure! Most of this does not apply to use, so we will only focus on a few. memLo and memHi containes the amount of memory we detected from the BIOS. mmap_length and mmap_addr will point to the memory map that we abtained from the BIOS. Thats it! Now we have a nice way of passing our memory information (And mabey more ðŸ˜‰ ) to the kernel: mov eax, 0x2BADB002 ; multiboot specs say eax should be this mov ebx, 0 mov edx, [ImageSize] push dword boot_info call ebp ; Execute Kernel add esp, 4 cli hlt ...And inside of our kernel: //! kernel entry point is called by boot loader void __cdecl kernel_entry (multiboot_info* bootinfo) { //*snip* } The kernels multiboot_info structure is the same one shown above but in C. Thanks to this setup, all the kernel needs to do is access the memory information (And any information passed from the bootloader) through bootinfo . Cool, huh? Now that we got the memory information from the Bios and passed it to the kernel, the kernel can use it for its physical memory manager. Thats right...Its finally time to develop a physical memory manager! Physical Memory Management We have covered alot already, don't you think? We have looked at how to abtain memory information from the BIOS and using the multiboot information structure to pass this information to the kernel. This allows the kernel to be able to retrieve this memory information anytime it wants. Yet, we have yet to cover the most important topic: Managing this memory. Lets look closer... Memory Management: Abstract Okay, so we know we need a way to manage memory. To do this, we--of course--need a way of keeping track of how memory is being used. Doing this for every byte in memory is simply not possible: How can we store information about every byte in memory without running out of memory? Because of this, we need to come up with another way. What we need to insure is that, whatever data structure we use to manage the rest of memory, is smaller then the total size of memory. For example, we can use an array of bytes, for example. Every byte can store information about a larger block of memory. This is the only way we can insure we do not run out of memory. The size of a \"block\" of memory must be a feasable and efficiant size. Using this method, we can split up the physical address space into \"block\" sized chunks. When we allocate memory, we do not allocate bytes. Rather, we allocate blocks of memory. This is what a physical memory manager does . The purpose of a physical memory manager is to split up the computers physical address space into block-sized chunks of memory and provide a method to allocate and release them. On the x86 architecture, when paging is enabled, each page represents a 4KB block of memory. Because of this, to keep things simple, each memory block for our physical memory manager will also be 4KB in size. Setting up Allright...We know that a physical memory manager is important. We also know that the physical memory manager needs to split up the physical address space and keep track of what memory blocks are being used or available. But wait! We immediately run into a problem: The kernel needs an area of memory for managing memory. How can we allocate an area of memory before we can allocate memory? We cant. Because of this, the only method that we have is using a pointer to a location in memory. Think of this location as simply some more reserved memory, simular to the BIOS, Bios Data Area (BDA) and the kernel itself. We want to stick this somewhere in reserved memory, so how about at the end of the kernel? Afterwords, we can mark this region (along with the kernel itself) as reserved within the data structure to insure nothing touches it. Great! Now that we have a pointer to some location in memory, we can store the information needed to keep track of each block in memory. But... how? That is, all we have is a pointer. The data this pointer points to must be in some useable structure so that we can use the area of memory effectivly. How can we create a structure to manage all of physical memory? There are two common solutions to this: Stack or a bit map. Stack based allocation Bit map based allocation This is the simplest to impliment. All our physical memory manager needs to know is if a block of memory is allocated or not. If it is allocated, we can use a binary bit 1. If it is not, a binary bit 0. In other words, for every block in memory, we use a single bit to represent if it has been allocated or not. This is the method that we will be using. However, the physical memory manager is designed in a way to allow other methods (Like the stack-based approch) if we decide too switch. ðŸ˜‰ The bit map approach is very efficiant in size. Because each bit represents a block of memory, a single 32 bits using this bit map approach represents 32 blocks. Because 32 bits is 4 bytes, this means we can watch--out of 32 blocks of memory--using only 4 bytes of memory. This approach is a bit slower though as it requires searching the bit map for a free block (The first bit that is 0) every time we want to allocate a block of memory. Developing a Physical Memory Manager (PMM) In the upcoming demo code, the entire physical memory manager can be found in mmngr_phys.h and mmngr_phys.cpp . It may also help to study the updated 2nd stage boot loader to see how the memory information is passed from the boot loader to the kernel, and how the kernel initializes the PMM. Globals and Constants I never like \"magic numbers\" as you may have noticed ðŸ˜‰ This is why I tend to hide all of these numbers behind more readable constants. //! 8 blocks per byte #define PMMNGR_BLOCKS_PER_BYTE 8 //! block size (4k) #define PMMNGR_BLOCK_SIZE 4096 //! block alignment #define PMMNGR_BLOCK_ALIGN PMMNGR_BLOCK_SIZE These are just to help with the readability of the code. The PMM creates an abstraction known as a Memory Block . A Memory Block is 4096 bytes in size (4K). This is important as it is also the size of a page when we enable paging. There are also several globals defined for keeping track of everything. //! size of physical memory static uint32_t _mmngr_memory_size=0; //! number of blocks currently in use static uint32_t _mmngr_used_blocks=0; //! maximum number of available memory blocks static uint32_t _mmngr_max_blocks=0; //! memory map bit array. Each bit represents a memory block static uint32_t* _mmngr_memory_map= 0; The most important of these is _mmngr_memory_map . This is a pointer to the bit map structure that we use to keep track of all of physical memory. _mmngr_max_blocks containes the amount of memory blocks available. This is the size of physical memory (Retrieved from the BIOS from the boot loader) divide by PMMNGR_BLOCK_SIZE. This essentally divides the physical address space into memory blocks (Remember this from before?) _mmngr_used_blocks containes the amount of blocks currently in use, _mmngr_memory_size is for refrence only--it containes the amount of physical memory in KB. Memory Bit Map Okay then! _mmngr_memory_map is a pointer to an uint32_t...right? Well, of course... sort of. Rather, we should think of it as \"a pointer to a series of bits\" as that is the way we treat it. Each bit is a 0 if that block has not been allocated (Useable) or a 1 if it is reserved (In use). The number of bits in this array is _mmngr_max_blocks . In other words, each bit represents a single memory block, which in turn, is 4KB of physical memory. Knowing this, all we need to do with the bit map is be able to set a bit, unset a bit, and test if a bit is set. Lets take a look... mmap_set () - Sets a bit in the bit map What we want to do is provide a way so that we can think of the memory map as an array of bits rather then an array of ints. This is not to hard: inline void mmap_set (int bit) { _mmngr_memory_map[bit / 32] |= (1 << (bit % 32)); } The bit is a value from 0...x, where x is the bit that we want to set in the memory map. We divide the bit by 32 to get the integer index in _mmngr_memory_map that the bit is in. To use this routine, simply call it passing in the bit that you want to set. You are not limited to 32 bits: mmp_set(62) sets the 62nd bit in the memory map bit array. mmap_unset () - Unsets a bit in the bit map This is very simular to the above routine but clears the bit instead: inline void mmap_unset (int bit) { _mmngr_memory_map[bit / 32] &= ~ (1 << (bit % 32)); } mmap_test () - Test if a bit is set This routine simply returns true if a bit is 1 or false if it is 0. It is very simular to the above routine, but instead of setting the bit we use it as a mask and return its value: inline bool mmap_test (int bit) { return _mmngr_memory_map[bit / 32] & (1 << (bit % 32)); } Thats all too it! Now that we have a way to set, unset, and test bits inside of the bit map, we need a way of searching through the bit map for free bits. These will be used so we can find free memory blocks that we can use. mmap_first_free () - Returns index of first free bit in bit map This routine is a little complex. We have a way to set, clear, and test a bit in the memory bit map. Lets say that we want to allocate a block of memory. How do we find a free block of memory? Thanks to our bit map, all we need to do is traverse the bit map for a bit that is not set. This isnt to complex: int mmap_first_free () { //! find the first free bit for (uint32_t i=0; i< pmmngr_get_block_count() / 32; i++) if (_mmngr_memory_map[i] != 0xffffffff) for (int j=0; j<32; j++) { //! test each bit in the dword int bit = 1 << j; if (! (_mmngr_memory_map[i] & bit) ) return i*4*8+j; } return -1; } pmmngr_get_block_count() returns the maximum number of memory blocks in this system (Remember this is also the number of bits in the bit array?) We divide this by 32 (32 bits per dword) to get the amount of integers in ths bit map. In other words: The outmost loop simply loops through each integer in the array. We then test to see if the dword is all set. We loop this in dwords rather then bits because it is much more efficiant and faster. We test it by insuring its not 0xffffffff. If it is, go on to the next dword. If it is not, then a bit must be clear. Afterwords we simply go through each bit in that dword to find the free bit and returns its physical frame address. The physical memory manager includes another version of this routine-- mmap_first_free_s() that returns the index of the first free series of frames of a specific size. This allows us to insure a certain region of memory blocks are free rather then a single block. This routine is a little tricky I admit; if any of our readers do not understand the code I would be glad to describe it in more detail in this tutorial. Physical Memory Allocater We now have a way of managing memory. Wait, what? Thats right. The way this works is to remember that each bit in the bit map represents 4KB of physical memory. If we want to allocate the first memory block (The first 4k) just set bit 0. If you want to allocate the second 4k, just set bit 1. This continues to the end of memory. This provides a way for us to not only work in 4k blocks of memory, but also to know what memory is currently in use or reserved (The bit is 1) or free for use (Bit 0). All of this provided by the three simple routines above and our bit map array. Cool, huh? Now we just need the actual allocation and deallocation routines. Before that, however, we need to initialize the bit map regions to that of the BIOS memory map. And even before THAT, we need to provide a way so the kernel can provide some information for our physical memory manager to use. Lets take a look... pmmngr_init () - Initialize the physical memory manager This routine is called by the kernel to initialize the physical memory manager (PMM). memSize is the maximum amount of memory the PMM is allowed to access. This should be the size of RAM in KB passed to the kernel from the bootloader. bitmap is the location that the PMM will use for its memory bit map structure. Another important thing to note is how we set all the bits in the memory bit map using a memset() call. There is a reason for this which will be looked at very soon. void pmmngr_init (size_t memSize, physical_addr bitmap) { _mmngr_memory_size = memSize; _mmngr_memory_map = (uint32_t*) bitmap; _mmngr_max_blocks = (pmmngr_get_memory_size()*1024) / PMMNGR_BLOCK_SIZE; _mmngr_used_blocks = pmmngr_get_block_count(); //! By default, all of memory is in use memset (_mmngr_memory_map, 0xf, pmmngr_get_block_count() / PMMNGR_BLOCKS_PER_BYTE ); } pmmngr_init_region () - Initializes a region of memory for use Remember the memory map? We do not know what areas of memory are safe to work with, only the kernel does. Because of this, by default all of memory is in use. The kernel abtains the memory map from the kernel and uses this routine to initialize available regions of memory that we can use. The routine is very simple. It just finds out how much memory blocks to set and loops--clearing the appropariate bits in the memory bit map. This allows the allocation routines to use these now free areas of memory again: void pmmngr_init_region (physical_addr base, size_t size) { int align = base / PMMNGR_BLOCK_SIZE; int blocks = size / PMMNGR_BLOCK_SIZE; for (; blocks>0; blocks--) { mmap_unset (align++); _mmngr_used_blocks--; } mmap_set (0); //first block is always set. This insures allocs cant be 0 } Notice the call to mmap_set() at the end. In our PMM, the first memory block block will always be set. This insures us that the PMM can return null pointers for allocation errors. This also insures that any data structures defined within the first 64 KB of memory are not overwritten or touched, including the Interrupt Vector Table (IVT) and Bios Data Area (BDA). pmmngr_deinit_region () - Deinitializes a region of memory for use This routine is simular to the above routine, but sets the bits instead of clearing them. Because the bits become a binary 1, that 4KB block of memory the bit represents is effectivly set to reserved so that area of memory will never be touched when this routine is called. void pmmngr_deinit_region (physical_addr base, size_t size) { int align = base / PMMNGR_BLOCK_SIZE; int blocks = size / PMMNGR_BLOCK_SIZE; for (; blocks>0; blocks--) { mmap_set (align++); _mmngr_used_blocks++; } } Woohoo! Now that we have a way to initialize and deinitialize regions of memory for use, and initialize the PMM we can work on allocating and deallocating blocks next! pmmngr_alloc_block () and pmmngr_alloc_blocks () - Allocates a single block of physical memory To allocate a block of memory is very simple. All of physical memory is already there, all we need to do is return a pointer to a free block of memory. We can find a free block of memory by looking through the bit map using out mmap_first_free() routine. Also notice that we call mmap_set to set the same frame returned from mmap_first_frame () . This is what marks that block of memory just allocated is now \"in use\". This routine returns a void* to the 4KB of physical memory just allocated. void* pmmngr_alloc_block () { if (pmmngr_get_free_block_count() <= 0) return 0; //out of memory int frame = mmap_first_free (); if (frame == -1) return 0; //out of memory mmap_set (frame); physical_addr addr = frame * PMMNGR_BLOCK_SIZE; _mmngr_used_blocks++; return (void*)addr; } The PMM also containes another allocation routine: pmmngr_alloc_blocks() . This routine is almost exactally like the above so I decided to leave it out of this tutorial for space purposes. It provides a way to allocate a sequencial amount of blocks rather then a single block. pmmngr_free_block () and pmmngr_free_blocks () - Releases a block of physical memory Alright...We now have a way to allocate blocks of physical memory. Now we need a way to free these blocks of memory so we do not run out of memory. This is too easy: void pmmngr_free_block (void* p) { physical_addr addr = (physical_addr)p; int frame = addr / PMMNGR_BLOCK_SIZE; mmap_unset (frame); _mmngr_used_blocks--; } pmmngr_free_blocks() works almost the same way but is used in conjunction with pmmngr_alloc_blocks() used to free a sequencial amount of blocks rather then a single block. Demo The Physical Memory Manager running in VirtualPC Demo Download (MSVC++) I decided to spice things up a little. The memory map from Bochs is boring ðŸ˜‰ This demo is quite nice in a way that you can run it on alot of different machines and see how different computer systems map the regions of physical memory. This demo should work with all optomization levels as well. This demo uses the passed multiboot information structure from the bootloader to get the size of physical memory. My VirtualPC is set to use 130 MB of memory so I would say it detected it pretty well ðŸ˜€ There is alot going on in this demo. Some updates in the second stage boot loader is used to detect memory using the methods we looked at above, and passes this information to the kernel using the multiboot information structure in which we looked at above, remeber? Play around with the allocations and deallocations and study the way the code works. If any of the allocation routines return null (0) then it indicates that there is no more free blocks left. If you are out of memory, try to free some memory or allocate the objects on the stack or globally instead. There is an important thing to note here: Notice how all allocations are aligned on 4k boundaries? This is a very important characteristic when we start getting into pages and virtual memory in the next tutorial. Conclusion This tutorial was not to bad, huh? We first looked at physical memory itself; understanding what it is and how it works, the physical address space and addressing modes. We have also looked at how to abtain memory information from the BIOS and give it to the kernel as well as the development of a physical memory manager. Now we have a way of allocating and releasing physical memory blocks. This is great, but it still has some problems. That is, if we load a file or program we can simply use our physical memory manager to allocate an area of memory large enough for the file or program. But...What if there is no area big enough for it? This also means any programs loaded must be linked to a specific address that it is loaded at by the kernel. This is where virtual memory and paging comes in. In the next tutorial, we will be looking at paging and virtual memory. We will learn how we can map and control the full 4GB address space. We will look at what virtual addressing is all about, and how we can use it to fix all of the above problems and more. I'll see you there."
  },
  "articles/61_unorganised_tutorial/T18.html": {
    "href": "articles/61_unorganised_tutorial/T18.html",
    "title": "Virtual Memory | BrokenThorn OS Dev Tutorials",
    "keywords": "Virtual Memory Welcome back! Jeeze, I cant believe we are already going on tutorial eighteen. See? OS development isn't too bad ðŸ˜‰ In the last tutorial we have looked at physical memory management and even developed a full working physical memory manager. In this tutorial, we will take it to a new level by introducing paging and virtual memory. We will learn how we can mimic a full virtual address space for our programs and learn how we can manage virtual memory. Heres the list for this chapter: Virtual Memory Memory Management Unit (MMU) Translation Lookaside Buffer (TLB) PAE and PSE Paging Methods Pages and Page Faults The Page Table The Page Directory Table Implimenting Paging ...And a whole lot more! This tutorial will build off of the physical memory manager we developed in the last chapter. This may also be the last chapter on memory management! With that in mind, lets get started! Virtual Memory Concepts The need for Virtualization You might be curious as to why we should worry about this \"virtual memory\" thing. After all, we already have a nice and effective way of managing memory, right? Well, sort of. While it manages blocks of memory well, thats all our physical memory manager does. This alone is pretty useless, don't you think? There are alot of very important concepts that we should look at to better understand virtual memory and the need for it. Right now all we have is a way to directly and indirectly work with physical memory. There are alot of big problems with this that you may already know (or even have experience with yourself ðŸ˜‰ ) One that we have just seen was when we would access to a block of memory that does not exist. Knowing that both programs and data are in memory, it is also possible for programs to access each others memory spaces, or even corrupt and overwrite themselves or other programs without knowing it. After all, there is no memory protection. Also, it is not always possible to load a file or program into a sequencial area of memory. This is when fragmentation happens. For an example, lets say we have 2 programs loaded. One at 0x0, the other at 0x900. Both of these programs requested to load files, so we load the data files: Notice what is happening here. There is alot of unused memory between all of these programs and files. Okay...What happens if we add a bigger file that is unable to fit in the above? This is when big problems arise with the current scheme. We cannot directly manipulate memory in any specific way, as it will currupt the currently executing programs and loaded files. As you can see, there are alot of problems that will arise when working with physical memory. If your operating system is single-tasking (Where only one ring 0 program runs at a time), then this might be fine. For anything more complex, we will be needing more control over how memory works within the system. What we need is a way to abstract physical memory in such a way that we do not need to worry about these details anymore. I think you know where I am getting at here -- this is where virtualization comes in. Lets take a look! The Virtual Memory Concepts Understanding what virtual memory is can be a little tricky. Virtual Memory is a special Memory Addressing Scheme implimented by both the hardware and software. It allows non contigous physical memory to act as if it was contigius memory. Notice that I said \"Memory Addressing Scheme\" . What this means is that virtual memory allows us to control what a Memory Address refers to. Virtual Address Space (VAS) A Virtual Address Space is a Program's Address Space. One needs to take note that this does not have to do with Physical Memory . The idea is so that each program has their own independent address space. This insures one program cannot access another program, because they are using a different address space. Because VAS is Virtual and not directly used with the physical memory, it allows the use of other sources, such as disk drives, as if it was memory. That is, It allows us to use more \"memory\" then what is physically installed in the system. This fixes the \"Not enough memory\" problem. Also, as each program uses its own VAS, we can have each program always begin at base 0x0000:0000. This solves the relocation problems discussed ealier, as well as memory fragmentation--as we no longer need to worry about allocating continous physical blocks of memory for each program. Virtual Addresses are mapped by the Kernel trough the MMU. More on this a little later. Memory Management Unit (MMU) The Memory Management Unit (MMU) (Also known as Paged Memory Management Unit (PMMU) ) sets between (Or as part of) the microprocessor and the memory controller . While the memory controller's primary function is the translation of memory addresses into a physical memory location, the MMU 's purpose is the translation of virtual memory addresses into a memory address for use by the memory controller . This means-- when paging is enabled, all of our memory refrences go through the MMU first! Translation Lookaside Buffer (TLB) This is a cache stored within the processor used to improve the speed of virtual address translation. It is useually a type of Content-addressable memory (CAM) where the search key is the virtual address to translate, and the result is the physical frame address. If the address is not in the TLB (A TLB miss ), the MMU searches through the page table to find it. If it is found in the TLB, it is a TLB Hit . If the page is not found or invalid inside of the page table during a TLB miss, the processor will raise a Page Fault exception for us. Think of a TLB as a table of pages stored in a cache instead of in RAM--as that is basically what it is. This is important! The pages are stored in page tables . We set up these page tables to describe how physical addresses translate to virtual addresses. In other words: The TLB translates virtual addresses into physical addresses using the page tables we set up for it to use! Yes, thats right--we set up what virtual addresses map to what. We will look at how to do this a little later, cool? Dont worry--its not that bad ðŸ˜‰ Paged Virtual Memory Virtual Memory also provides a way to indirectly use more memory then we actually have within the system. One common way of approching this is by using Page files , stored on a hard drive or a swap partition . Virtual Memory needs to be mapped through a hardware device controller in order to work, as it is handled at the hardware level. This is normally done through the MMU , which we will look at later. For an example of seeing virtual memory in use, lets look at it in action: Notice what is going on here. Each memory block within the Virtual Addresses are linear. Each Memory Block is mapped to either it's location within the real physical RAM, or another device, such as a hard disk. The blocks are swapped between these devices as an as needed bases. This might seem slow, but it is very fast thanks to the MMU. Remember: Each program will have its own Virtual Address Space--shown above. Because each address space is linear, and begins from 0x0000:00000, this immiedately fixes alot of the problems relating to memory fragmentation and program relocation issues. Also, because Virtual Memory uses different devices in using memory blocks, it can easily manage more then the amount of memory within the system. i.e., If there is no more system memory, we can allocate blocks on the hard drive instead. If we run out of memory, we can either increase this page file on an as needed bases, or display a warning/error message, Each memory \"Block\" is known as a Page , which is useually 4096 bytes in size. We will cover Pages a little later. Okay, so a Page is a memory block. This memory block can either be mapped to a location in memory, or to another device location, such as a hard disk. This is an unmapped page. If software accessed an unmapped page (The page is not currently in memory), it needs to be loaded somehow. This is done by our Page fault handler . We will cover everything later, so do not worry if this sounds hard ðŸ˜€ Because we are talking about paging in general, I think now would be a good idea to look at some extensions that may be used with paging. Lets have a look! PAE and PSE Physical Address Extension (PAE) PAE is a feature in x86 microprocessors that allows 32 bit systems to access up to 64 GB of physical memory. PAE supported motherboards use a 36 line address bus to achieve this. Paging support with PAE enabled (Bit 5 in the cr4 register) is a little different then what we looked at so far. I might decide to cover this a little later, however to keep this tutorial from getting even more complex, we will not look at it now. However, I do encourage readers to look into it if you are interested. ðŸ˜‰ Page Size Extension (PSE) PSE is a feature in x86 microprocessors that allows pages more then 4KB in size. This allows the x86 architecture to support 4MB page sizes (Also called \"huge pages\" or \"large pages\") along side 4KB pages. The World of Paging Let the madness begin ðŸ˜€ Introduction to Paging Woo-hoo! Welcome to the wonderful and twisted-minded world of paging! With all of the fundemental concepts that we have went over already, you should have a nice and good grasp at what paging and virtual memory is all about. This is a great start, don't you think? Okay, cool...but, how do we actually impliment it? How does paging work on the x86 architecture? Lets take a look! Pages A Page (Also known as a memory page or virtual page ) is a fixed-length block of memory. This block of memory can reside in physical memory. Think of it like this: A page describes a memory block, and where it is located at. This allows us to \"map\" or \"find\" the location of where that memory block is at. We will look at mapping pages and how to impliment paging a little later ðŸ˜€ The i86 architecture uses a specific format for just this. It allows us to keep track of a single page, and where it is currently located at. Lets take a look.. Page Table Entries (PTE) A page table entry is what represents a page. We will not cover the page table until a little later so dont worry too much about it. However we will need to look at what an entry in the table looks like now. The x86 architecture defines a specific bit format for working with pages, so lets take a look at it. Bit 0 (P): Present flag 0: Page is not in memory 1: Page is present (in memory) Bit 1 (R/W): Read/Write flag 0: Page is read only 1: Page is writable **Bit 2 (U/S):**User mode/Supervisor mode flag 0: Page is kernel (supervisor) mode 1: Page is user mode. Cannot read or write supervisor pages Bits 3-4 (RSVD): Reserved by Intel Bit 5 (A): Access flag. Set by processor 0: Page has not been accessed 1: Page has been accessed Bit 6 (D): Dirty flag. Set by processor 0: Page has not been written to 1: Page has been written to Bits 7-8 (RSVD): Reserved Bits 9-11 (AVAIL): Available for use Bits 12-31 (FRAME): Frame address Cooldos! Thats all? Well.. I never said it was hard ðŸ˜‰ Quite possibly the most important thing here is the frame address . The frame address represents the 4KB physical memory location that the page manages. This is vital to know when understanding paging, however it is hard to describe why it is so right now. For now, just remember that each and every page manages a block of memory. If the page is present, it manages a 4KB physical address space in physical memory. The Dirty Flag and Access Flag are set by the processor, not software. You might wonder on how the processor knows what bits to set; ie, where they are located in memory. We will look at that a little later. Just rememeber that, this will allow the software or executive to test if a page has been accessed or not. The present flag is an important one. This one single bit is used to determin if a page is currently in physical memory or not. If it is currently in physical memory, the frame address is the 32 bit linear address for where it is located at. If it is not in physical memory, the page must reside on another location--such as a hard disk. If the present flag is not set, the processor will ignore the rest of the bits in the structure. This allows us to use the rest of the bits for whatever purpose...perhaps where the page is located at on disk? This will allow--when our page fault handler gets called--for us to locate the page on disk and swap the page into memory when needed. Lets give out a simple example. Lets say that we want this page to manage the 4KB address space beginning at physical location 1MB (0x100000). What this means--to put in other words-- is that this page is \"mapped\" to address 1MB . To create this page, simply set 0x100000 in bits 12-31 (the frame address) of the page, and set the present bit. Voila--the page is mapped to 1MB. ðŸ˜€ For example: %define PRIV 3 mov ebx, 0x100000 | PRIV ; this page is mapped to 1MB Notice that 0x100000 is 4KB aligned? It ORs it with 3 (11 binary which sets the first two bits. Looking at the above table, we can see that it sets the present and read/write flags, making this page present (Meaning its in physical memory. This is true as it is mapped from physical address 0x100000), and is writable. Thats it! You will see this example expand further in the next few sections so that you can start seeing how everything fits in, so don't worry to much if you still do not understand. Also notice that there is nothing special about PTEs--they are simply 32 bit data. What is special about them is how they are used . We will look at that a little later... pte.h and pte.cpp - Abstracting page table entries and pages The demo hides all of the code to set and get the individual properties of the page table entries inside of these two files. All these do is set and get the bits and frame address from the 32 bit pattern that we have looked at in the list above. This interface does have a little overhead but greatly improves readability and makes it easier to work with them. The first thing we do is to abstract the bit pattern used by page table entries. This is too easy: enum PAGE_PTE_FLAGS { I86_PTE_PRESENT = 1, //0000000000000000000000000000001 I86_PTE_WRITABLE = 2, //0000000000000000000000000000010 I86_PTE_USER = 4, //0000000000000000000000000000100 I86_PTE_WRITETHOUGH = 8, //0000000000000000000000000001000 I86_PTE_NOT_CACHEABLE = 0x10, //0000000000000000000000000010000 I86_PTE_ACCESSED = 0x20, //0000000000000000000000000100000 I86_PTE_DIRTY = 0x40, //0000000000000000000000001000000 I86_PTE_PAT = 0x80, //0000000000000000000000010000000 I86_PTE_CPU_GLOBAL = 0x100, //0000000000000000000000100000000 I86_PTE_LV4_GLOBAL = 0x200, //0000000000000000000001000000000 I86_PTE_FRAME = 0x7FFFF000 //1111111111111111111000000000000 }; Notice how this matches up with the bit format that we looked at in the above list. What we want is a way to abstract the setting and getting of these properties (ie, bits) behind the interface. To do this, we first abstract the data type used to store a page table entry. In our case its a simple uint32_t: //! page table entry typedef uint32_t pt_entry; Simple enough. Next up is the interface routines that are used to set and get these bits. I dont want to look at the implimentation of it as all it does is (litterally) set or get individual bits within a pt_entry. So instead I want to focus on the interface: extern void pt_entry_add_attrib (pt_entry* e, uint32_t attrib); extern void pt_entry_del_attrib (pt_entry* e, uint32_t attrib); extern void pt_entry_set_frame (pt_entry*, physical_addr); extern bool pt_entry_is_present (pt_entry e); extern bool pt_entry_is_writable (pt_entry e); extern physical_addr pt_entry_pfn (pt_entry e); pt_entry_add_attrib() sets a single bit within the pt_entry. We pass it a mask (like our I86_PTE_PRESENT bit mask) to set it. pt_entry_del_attrib() does the same but clears the bit. pt_entry_set_frame() masks out the frame address (I86_PTE_FRAME mask) to set our frame address to it. pt_entry_pfn() returns this address. There is nothing special about these routines--we can easily set and get these attributes manually if we wanted to via bit masks or (if you wanted) bit fields. I personally feel this setup makes it much easier to work with though ðŸ˜‰ Okay, this is great as this setup allows us to keep track of a single page. However, it is useless by itself as a typical system will need to have alot of pages. This is where a page table comes in. Page Tables The page table...hm...where oh where did we hear that term before? looks one line up . Oh, right ðŸ˜‰ A Page Table is..well..a table of pages. (Surprised?) A page table allows us to keep track of how the pages are mapped between physical and virtual addresses. Each page entry in this table follows the format shown in the previous section. In other words, a page table is an array of page table entries (PTEs) . While it is a very simple structure, it has a very important purpose. The page table containes a list of all the pages it containes, and how they are mapped. By \"mapping\", We refer to how the virtual address \"maps\" to the physical frame address. The page table also manages the pages, weather they are present, how they are stored, or even what process they belong to (This can be set by using the AVAIL bits of a page. This may not be needed, it depends on the implimentation of the system.) Lets stop for a moment. Remember that a page manages 4KB of physical address space? By itself, a page is nothing more then a 32 bit data structure that describes the properties of a specific 4KB region of physical memory (Remember this from before?) Because each page \"manages\" 4KB of physical memory, putting 1024 pages together we have 1024*4KB=4MB of managed virtual memory. Lets take a look at how its set up: Thats an example of a page table. Notice how it is nothing more then an array 1024 page entries. Knowing that each page manages 4KB of physical memory, we can actually turn this little table into its own virtual address space . How can we do this? Simple: By deciding the format of a virtual address . Heres an example: Lets say we have designed a new virtual address format like this: AAAAAAAAAA BBBBBBBBBBBB page table index offset into page This is our format for a virtual address. So, when paging is enabled, all memory addresses will now follow the above format. For example, lets say we have the following instruction: mov ecx, [0xc0000] Here, 0xc0000 will be treated like a virtual address . Lets break it apart: 11000000 000000000000 ; 0xc0000 in binary form AAAAAAAAAA BBBBBBBBBBBB page table index offset into page What we are now doing is an example of address translating . We are actually translating this virtual address to see what physical location it refers to. The page table index, 11000000b = 192. This is the page entry inside of our page table. We can now get the base physical address of the 4KB that this page manages. If this page is present (Pages present flag is set), all we need to do is access the pages frame address to access the memory. If this page is NOT present, then generate a page fault--The page data might be somewhere on disk. The page fault handler will allow us to copy the 4KB data for the page into memory somewhere and set the page to present and update its frame address to point to this new 4KB block of physical memory. Okay okay, I know. This little example of creating a fake \"virtual address\" might seem silly, but guess what? This is how its actually done! The actual format of a virtual address is a little bit more complex in that there are three sections instead of 2. However, if we omit the first section of the real virtual address format then it would be exactally the same as our above example. I hope by now you are starting to see how everything fits together, and the importance of page tables. Page Size A system with smaller page sizes will require more pages then a system with larger page sizes. Because the table keeps track of all pages, a system with smaller page sizes will also require a larger page table because there are more pages to keep track of. Simple enough, huh? The i86 architecture supports 4MB (2MB pages if using Page Address Extension (PAE) ) and 4KB sized pages. The important things to note are: Notice how page size may effect the size of page tables. The Page Directory Table (PDT) Okay... We are almost done! A page table is a very powerful structure as you have seen. Remember our previous virtual address example? I gave an example of a virtual addressing system where each virtual address was composed of two parts: A page table entry and a offset into that page. On the x86 architecture, the virtual address format actually uses three sections instead of two: The entry number in a page directory table , the page table index, and the offset into that page. A Page Directory Table is nothing more then an array of Page Directory Entries . I know I know... How useless and non-informative was that last sentence? ðŸ˜‰ So, anyways, lets first look at a page directory entry. Then we will start looking at the directory table, and where it all fits in... Page Directory Entries (PDEs) Page directory entries help provide a way to manage a single page table. Not only do they contain the address of a page table, but they provide properties that we can use to manage them. You will see how all of this fits in within the next section, so dont worry if you dont understand it yet. Page directory tables are very simularly structured in the way page tables are structured. They are an array of 1024 entries, where the entries follow a specific bit format. The nice thing about the format of page directory entries (PDEs) is that they follow almost the exact same format that page table entries (PTEs) do (in fact they can be interchangeable). There is only a few little bit of details (pun intended ðŸ˜‰ ). Here is the format of a page directory entry: Bit 0 (P): Present flag 0: Page is not in memory 1: Page is present (in memory) Bit 1 (R/W): Read/Write flag 0: Page is read only 1: Page is writable **Bit 2 (U/S):**User mode/Supervisor mode flag 0: Page is kernel (supervisor) mode 1: Page is user mode. Cannot read or write supervisor pages **Bit 3 (PWT):**Write-through flag 0: Write back caching is enabled 1: Write through caching is enabled **Bit 4 (PCD):**Cache disabled 0: Page table will not be cached 1: Page table will be cached Bit 5 (A): Access flag. Set by processor 0: Page has not been accessed 1: Page has been accessed Bit 6 (D): Reserved by Intel Bit 7 (PS): Page Size 0: 4 KB pages 1: 4 MB pages Bit 8 (G): Global Page (Ignored) Bits 9-11 (AVAIL): Available for use Bits 12-31 (FRAME): Page Table Base address A lot of the members here should look familiar from the page table entry (PTE) list that we looked at ealier. The Present , Read/Write , and access flags are the same as it was with PTEs, however they apply to a page table rather then a page . page size determins if the pages inside of the page table are 4KB or 4MB . Page Table Base address bits contain the 4K aligned address of a page table . pde.h and pde.cpp - Abstracting Page Directory Entries Simular to what we did with PTEs, we have created an interface to abstract PDEs in the same manner. enum PAGE_PDE_FLAGS { I86_PDE_PRESENT = 1, //0000000000000000000000000000001 I86_PDE_WRITABLE = 2, //0000000000000000000000000000010 I86_PDE_USER = 4, //0000000000000000000000000000100 I86_PDE_PWT = 8, //0000000000000000000000000001000 I86_PDE_PCD = 0x10, //0000000000000000000000000010000 I86_PDE_ACCESSED = 0x20, //0000000000000000000000000100000 I86_PDE_DIRTY = 0x40, //0000000000000000000000001000000 I86_PDE_4MB = 0x80, //0000000000000000000000010000000 I86_PDE_CPU_GLOBAL = 0x100, //0000000000000000000000100000000 I86_PDE_LV4_GLOBAL = 0x200, //0000000000000000000001000000000 I86_PDE_FRAME = 0x7FFFF000 //1111111111111111111000000000000 }; //! a page directery entry typedef uint32_t pd_entry; Not to hard. We use the new type pd_entry to represent a page directory entry. Also, with the PTE interface, we provide a small set of routines used to provide a nice way of setting and getting the bits within the page directory entry: extern void pd_entry_add_attrib (pd_entry* e, uint32_t attrib); extern void pd_entry_del_attrib (pd_entry* e, uint32_t attrib); extern void pd_entry_set_frame (pd_entry*, physical_addr); extern bool pd_entry_is_present (pd_entry e); extern bool pd_entry_is_user (pd_entry); extern bool pd_entry_is_4mb (pd_entry); extern bool pd_entry_is_writable (pd_entry e); extern physical_addr pd_entry_pfn (pd_entry e); extern void pd_entry_enable_global (pd_entry e); Understanding the Page Directory Table The Page Directory Table is sort of like an array of 1024 page tables. Remember that each page table manages 4MB of a virtual address space? Well... Putting 1024 page tables together we can manage a full 4GB of virtual addresses. Sweet, huh? Okay, its a little more complex then that, but not that much. The Page Directory Table is actually an array of 1024 page directory entries that follow the format above. Look back at the format of an entry and notice the Page Table Base address bits. This is the address of the page table this directory entry manages. It may be easier to see it visually, so here you go: Notice what is happening here. Each page directory entry points to a page table. Remember that each page manages 4KB of physical (and hence virtual) memory? Also, remember that a page table is nothing more then an array of 1024 pages? 1024*4KB = 4MB. This means that each page table manages its own 4MB of address space. Each page directory entry provides us a way to manage each page table much easier. Because the complete page directory table is an array of 1024 directory entries, and that each entry manages its own table, we effectivly have 1024 page tables. From our previous calculation we know each page table manages 4MB of address space. So 1024 page tables*4MB size= 4GB of virtual address space. I guess thats it for ... believe it or not... everything. See, its not that hard, is it? In the next section, we will be revisiting the real format of an x86 virtual address, and you will get to see how everything works together! Use in Multitasking We run into a small problem here. Remember that a page directory table represents a 4GB address space? How can we allow multiple programs a 4GB address space if we can only have one page directory at a time? We cant. Not nativly, anyways. Alot of mutitasking operating systems map the high 2 GB address space for its own use as \"kernel space\" and the low 2 GB as \"user space\". The user space cannot touch kernel space. With the kernel address space being mapped to every processes 4GB virtual address space, we can simply switch the current page directory without error using the kernel no matter what process is currently running. This is possible do to the kernel always being located at the same place in the processes address space. This also makes scheduling possible. More on that later though... Virtual Memory Management We have covered everything we need to develop a good virtual memory manager. A virtual memory manager must provide methods to allocate and manage pages, page tables, and page directory tables. We have looked at each of these in separate, but have not looked at how they work together. Higher Half Kernels Abstract (Higher Half Kernels) A Higher Half Kernel is a kernel that has a virtual base address of 2GB or above. A lot of operating systems have a higher half kernel. Some examples include the Windows and Linux Kernels. The Windows Kernel gets mapped to either 2GB or 3GB virtual address (depending on if /3gb kernel switch is used), the Linux Kernel gets mapped to 3GB virtual address. The series uses a higher half kernel mapped to 3GB. Higher half kernels must be mapped properly into the virtual address space. There are several methods to achieve this, some of which is listed here. You might be interested on why we would want a higher half kernel. We can very well run our kernel at some lower virtual address. One reason has to do with v86 tasks. If you want to support v86 tasks, v86 tasks can only run in user mode and within the real mode address limits (0xffff:0xffff), or about 1MB+64k linear address. It is also typical to run user mode programs in the first 2GB (or 3GB on some OSs) as software typically never has a need to access high memory locations. Method 1 The first design is that we can have the boot loader set up a temporary page directory. With this, the base address of the kernel can be 3GB. The boot loader maps a physical address (typically 1MB) to this base address and calls the kernel's entry point. This method works, but creates a problem of how the kernel is going to work with managing virtual memory. The kernel can either try to work with the page directory and tables set up by the boot loader, or create a new page directory to manage. If we create a new page directory, the kernel will need to remap itself (1MB physical to the base virtual address of the kernel) or cloning the existing temporary page directory to the new page directory. At this time, this is the method the series uses. The series boot loader will set up a temporary page directory and maps the kernel to 3GB virtual. The kernel then creates a new page directory during VMM initialization and remaps itself. The kernel must remain position-independent during this set up phase. This is the method we use in our in-house OS. Method 2 Another possible design is that the boot loader loads the kernel into a physical memory location and keeps paging disabled. The kernel virtual base address would be the virtual address it is supposed to execute at. For example, the boot loader can load and execute the kernel at 1MB physical, although the kernels base address is 3GB. This method is a little tricky. There has to be a way for the boot loader to know what physical address to load and execute the kernel at, and the kernel has to map itself to its real base virtual address. This is usually done during kernel startup in position-independent code. This can be used in position-dependent code, but the kernel must be able to fix the addresses when accessing data or calling functions. This is the method used in our in-house OS. Method 3 This method uses Tim Robinson's GDT trick. This can be found in his documentation located here (*.pdf) This allows your kernel to run at a higher address (its base address) even though it is not loaded there. This trick works do to address wrap around. For example, lets say our kernel is loaded at 1MB physical address, but we want it to appear to be running at 3GB Virtual. The base that we want is X + 3GB = 1MB in this case. Lets look closer. Remember that the GDT descriptor base address is a DWORD. If the value becomes greater then 0xffffffff, it will wrap around back to 0. 3GB = 0xC0000000. 0xffffffff - 0xc0000000 = 0x3FFFFFFF bytes left until it wraps. We need to add an address that will make this address to point to our physical location (1MB). Knowing we have 0x3FFFFFFF bytes left until our DWORD wraps back to 0, we can add 0x100000 (1MB) + 0x3FFFFFFF = 0x400FFFFF + 1 = 0x40100000. So, by using the above example, if our kernel is loaded at 1MB physical address but has a real base address of 3GB virtual, we can create a temporary GDT with a base code and data selector of 0x40100000. The processor automatically adds the base selector addresses to the addresses it is accessing. After using LGDT to install this new GDT. After this we are now running at 3GB. This works because the processor will add the cs and ds selector base (40100000) to whatever address that is being referenced. For example, 3GB would be translated by the processor to 1MB in our example as 3GB+base selector ((40100000) = 1MB physical. This trick is fairly easy to impliment and works well but wont work for 64 bit (Long Mode). After the kernel performs this trick it can set up its page directory and map itself with ease after which can enable paging. Virtual Addressing and Mapping Addresses When we enable paging, all memory refrences will be treated as a virtual address . This is very important to know. This means we must set up the structures properly first before enabling paging. If we do not, we can run into an immiedate triple fault--with or without valid exception handlers. Remember the format of a virtual address? This is the format of a x86 virtual address : AAAAAAAAAA BBBBBBBBBB CCCCCCCCCCCC directory index page table index offset into page This is very important! This tells the processor (And us ) alot of information. The directory index portion tells us what index into the current page directory to look in. Look back up to the Directory Entry Structure format in the previous section. Notice that each directory table entry containes a pointer to a page table . You can also see this within the image again in that section. Because each index within the directory table points to a page table, this tells us what page table we are accessing. The page table index portion tells us what page entry within this page table we are accessing. ...And remember that each page entry manages a full 4KB of physical address space? The offset into page portion tells us what byte within this pages physical address space we are refrencing. Notice what happened here. We have just translated a virtual address into a physical address using our page tables. Yes, its that easy. No trickery involved. Lets look at another example. Lets assumed that virtual address 0xC0000000 was mapped to physical address 0x100000. How do we do this? We need to find the page in our structures that 0xC0000000 refer to -- just like we did above. In this case 0xC0000000 is the virtual address, so lets look at its format: 1100000000 0000000000 000000000000 ; 0xC0000000 in binary form AAAAAAAAAA BBBBBBBBBB CCCCCCCCCCCC directory index page table index offset into page Remember that the directory index tells us what page table we are accessing within the page directory table? So... 1100000000b (The directory index) = 768th page table. Remember that the page table index is the page we are accessing within this page table? That is 0, so its the first page. Also note the offset byte in this page is 0. Now, all we need to do is set the frame address of the first page in the 768th page table to 0x100000 and voila! You have just mapped 3GB virtual address to 1MB physical! Knowing that each page is 4KB aligned, we can keep doing this in increments of 4KB physical addresses. Identity Mapping Identity Mapping is nothing more then mapping a virtual address to the same physical address. For example, virtual address 0x100000 is mapped to physical address 0x100000. Yep--Thats all there is to it. The only real time this is required is when first setting up paging. It helps insure the memory addresses of your current running code of where they are at stays the same when paging is enabled. Not doing this will result in immediate triple fault. You will see an example of this in our Virtual Memory Manager initialization routine. Memory Managment: Implimentation Implimentation I suppose that is everything. What we will look at next is the virtual memory manager (VMM) itself that has been developed for this tutorial. This will bring everything that we have looked at together so that you can see how everything works. I have tried to make the routines small so that we can focus on one topic at a time as there is a couple of new things that we still need to look at. Alrighty...First lets take a look at the page table and directory table themselves: //! virtual address typedef uint32_t virtual_addr; //! i86 architecture defines 1024 entries per table--do not change #define PAGES_PER_TABLE 1024 #define PAGES_PER_DIR 1024 #define PAGE_DIRECTORY_INDEX(x) (((x) >> 22) & 0x3ff) #define PAGE_TABLE_INDEX(x) (((x) >> 12) & 0x3ff) #define PAGE_GET_PHYSICAL_ADDRESS(x) (*x & ~0xfff) //! page table represents 4mb address space #define PTABLE_ADDR_SPACE_SIZE 0x400000 //! directory table represents 4gb address space #define DTABLE_ADDR_SPACE_SIZE 0x100000000 //! page sizes are 4k #define PAGE_SIZE 4096 //! page table struct ptable { pt_entry m_entries[PAGES_PER_TABLE]; }; //! page directory struct pdirectory { pd_entry m_entries[PAGES_PER_DIR]; }; Simular to our physical_addr type, I created a new address type for virtual memory-- virtual_addr . Notice that a page table is nothing more then an array of 1024 page table entries? Same thing with the page directory table, but its an array of page directory entries instead. Nothing special yet ðŸ˜‰ PAGE_DIRECTORY_INDEX, PAGE_TABLE_INDEX, PAGE_GET_PHYSICAL_ADDRESS are macros that just returns the respective partion of a virtual address. Remember that a virtual address has a specific format, these macros allow us to obtain the information from the virtual address. PTABLE_ADDR_SPACE_SIZE represents the size (in bytes) that a page table represents. A page table is 1024 pages, where a page is 4K in size, so it is 1024 * 4k = 4MB . DTABLE_ADDR_SPACE_SIZE represents the number of bytes a page directory manages, which is the size of the virtual address space. Knowing a page table represents 4MB of the address space, and that a page directory contains 1024 page tables, 4MB * 1024 = 4GB. The virtual memory manager presented here does not handle large pages . Instead, it only manages 4K pages. The Virtual Memory Manager (VMM) we use relies on these structures heavily. Lets take a look at some of the routines in the VMM to learn how they work. vmmngr_alloc_page () - allocates a page in physical memory To allocate a page, all we need to do is allocate a 4K block of physical memory for the page to refer to, then simply create a page table entry from it: bool vmmngr_alloc_page (pt_entry* e) { //! allocate a free physical frame void* p = pmmngr_alloc_block (); if (!p) return false; //! map it to the page pt_entry_set_frame (e, (physical_addr)p); pt_entry_add_attrib (e, I86_PTE_PRESENT); return true; } Notice how our PTE routines make this much easier to do? The above sets the PRESENT bit in the page table entry and sets its FRAME address to point to our allocated block of memory. Thus the page is present and points to a valid block of physical memory and is ready for use. Cool, huh? Also, notice how we \"map\" the physical address to the page. All this means is that we set the page to point to a physical address. Thus the page is \"mapped\" to that address. vmmngr_free_page () - frees a page in physical memory To free a page is even easier. Simply free the block of memory using our physical memory manager, and clear the page table entries PRESENT bit (marking it NOT PRESENT) : void vmmngr_free_page (pt_entry* e) { void* p = (void*)pt_entry_pfn (*e); if (p) pmmngr_free_block (p); pt_entry_del_attrib (e, I86_PTE_PRESENT); } Thats it! Now that we have a way to allocate and free a single page, lets see if we can put them together in full page tables... vmmngr_ptable_lookup_entry () - get page table entry from page table by address Now that we have a way of abtaining the page table entry number from a virtual address, we need a way to get it from the page table. This routine does just that! It uses the above function to convert the virtual address into an index into the page table array, and returns the page table entry from it. inline pt_entry* vmmngr_ptable_lookup_entry (ptable* p,virtual_addr addr) { if (p) return &p->m_entries[ PAGE_TABLE_INDEX (addr) ]; return 0; } Because this routine returns a pointer, we can modify the entry as much as we need to as well. Cool? Thats it for the page table routines. See how easy paging is? ðŸ˜‰ Next up...The page directory routines! vmmngr_pdirectory_lookup_entry () - get directory entry from directory table by address Now that we have a way to covert a virtual address into a page directory table index, we need to provide a way to get the page directory entry from it. This is exactally the same with the page table routine counterpart: inline pd_entry* vmmngr_pdirectory_lookup_entry (pdirectory* p, virtual_addr addr) { if (p) return &p->m_entries[ PAGE_TABLE_INDEX (addr) ]; return 0; } vmmngr_switch_pdirectory () - switch to a new page directory Notice how small all of these routines are. They provide a minimal but very effective interface for easily working with page tables and directories. When we set up a page directory, we need to provide a way to install it for our use. In the previous tutorial, we added two routines: pmmngr_load_PDBR() and pmmngr_get_PDBR() to set and get the Page Directory Base Register (PDBR) . This is the register that stores the current page directory table. On the x86 architecture, the PDBR is the cr3 processor register. Thus, these routines simply set and gets the cr3 register. vmmngr_switch_pdirectory () uses these routines to load the PDBR and set the current directory: //! current directory table (global) pdirectory* _cur_directory=0; inline bool vmmngr_switch_pdirectory (pdirectory* dir) { if (!dir) return false; _cur_directory = dir; pmmngr_load_PDBR (_cur_pdbr); return true; } pdirectory* vmmngr_get_directory () { return _cur_directory; } vmmngr_flush_tlb_entry () - flushes a TLB entry Remember how the TLB caches the current page table? Sometimes it may be necessary to flush (invalidate) the TLB or individual entries so that it can get updated to the current value. This may be done automatically by the processor (Like during a mov instruction involving a control register). The processor provides a method for us to manually flush individual TLB entries ourself. This is done using the INVLPG instruction. We simply pass it the virtual address and the resulting page entry will be invalidated: void vmmngr_flush_tlb_entry (virtual_addr addr) { #ifdef _MSC_VER _asm { cli invlpg addr sti } #endif } Keep in mind that INVLPG is a privlidged instruction . Thus you must be running in supervisor mode to use it. vmmngr_map_page () - maps pages This is one of the most important routines. This routine allows us to map any physical address to a virtual address. Its a little complicated so lets break it down: void vmmngr_map_page (void* phys, void* virt) { //! get page directory pdirectory* pageDirectory = vmmngr_get_directory (); //! get page table pd_entry* e = &pageDirectory->m_entries [PAGE_DIRECTORY_INDEX ((uint32_t) virt) ]; if ( (*e & I86_PTE_PRESENT) != I86_PTE_PRESENT) { We are given a physical and virtual address as paramaters. The first thing that must be done is to verify that the page directory entry that this virtual address is located in is valid (That is, has been allocated before and its PRESENT bit is set.) The page directory index is part of the virtual address itself, so we use PAGE_DIRECTORY_INDEX() to obtain the page directory index. Then we just index into the page directory array to obtain a pointer to the page directory entry. Then the test to see if I86_PTE_PRESENT bit is set or not. If it is not set, then the page directory entry does not exist so we must create it... //! page table not present, allocate it ptable* table = (ptable*) pmmngr_alloc_block (); if (!table) return; //! clear page table memset (table, 0, sizeof(ptable)); //! create a new entry pd_entry* entry = &pageDirectory->m_entries [PAGE_DIRECTORY_INDEX ( (uint32_t) virt) ]; //! map in the table (Can also just do *entry |= 3) to enable these bits pd_entry_add_attrib (entry, I86_PDE_PRESENT); pd_entry_add_attrib (entry, I86_PDE_WRITABLE); pd_entry_set_frame (entry, (physical_addr)table); } The first thing the above does is to allocate a new page for the new page table and clears it. After words, it uses PAGE_DIRECTORY_INDEX() again to get the directory index from the virtual address, and indexes into the page directory to get a pointer to the page table entry. Then it sets the page table entry to point to our new allocate page table, and sets its PRESENT and WRITABLE bits so that it can be used. At this point, the page table is guaranteed to be valid at that virtual address. So the routine now just needs to map the address... //! get table ptable* table = (ptable*) PAGE_GET_PHYSICAL_ADDRESS ( e ); //! get page pt_entry* page = &table->m_entries [ PAGE_TABLE_INDEX ( (uint32_t) virt) ]; //! map it in (Can also do (*page |= 3 to enable..) pt_entry_set_frame ( page, (physical_addr) phys); pt_entry_add_attrib ( page, I86_PTE_PRESENT); } The above calls PAGE_GET_PHYSICAL_ADDRESS() to get the physical frame that the page directory entry points to in order to get the page table entry. Then, using PAGE_TABLE_INDEX to get the page table index from the virtual address, indexing into the page table it obtains the page table entry. Then it sets the page to point to the physical address and sets the pages PRESENT bit. vmmngr_initialize () - initialize the VMM This is an important routine. This uses all of the above routines (Well, most of them ðŸ˜‰ ) to set up the default page directory, install it, and enable paging. We can also use this an example of how everything works and fits together. Because this routine creates a new page directory, we also need to map 1MB physical to 3GB virtual in order for the kernel. This is a fairly big routine so lets break it down and see whats going on: void vmmngr_initialize () { //! allocate default page table ptable* table = (ptable*) pmmngr_alloc_block (); if (!table) return; //! allocates 3gb page table ptable* table2 = (ptable*) pmmngr_alloc_block (); if (!table2) return; //! clear page table vmmngr_ptable_clear (table); Remember how page tables must be located at 4K aligned addresses? Thanks to out physical memory manager (PMM), our pmmngr_alloc_block() already does just this so we do not need to worry about it. Because a single block allocated is already 4K in size, the page table has enough storage space for its entries as well (1024 page table entries * 4 bytes per entry (size of page table entry) = 4K) so all we need is a single block. Afterwords we clear out the page table to clean it up for our use. //! 1st 4mb are idenitity mapped for (int i=0, frame=0x0, virt=0x00000000; i<1024; i++, frame+=4096, virt+=4096) { //! create a new page pt_entry page=0; pt_entry_add_attrib (&page, I86_PTE_PRESENT); pt_entry_set_frame (&page, frame); //! ...and add it to the page table table2->m_entries [PAGE_TABLE_INDEX (virt) ] = page; } This parts a little tricky. Remember that as soon as paging is enabled, all address become virtual? This poses a problem. To fix this, we must map the virtual addresses to the same physical addresses so they refer to the same thing. This is idenitity mapping . The above code idenitity maps the page table to the first 4MB of physical memory (the entire page table). It creates a new page and sets its PRESENT bit followed by the frame address we want the page to refer to. Afterwords it converts the current virtual address we are mapping (stored in \"frame\") to a page table index to set that page table entry. We increment \"frame\" for each page in the page table (stored in \"i\") by 4K (4096) as that is the block of memory each page refrences. (Remember page table index 0 references address 0 - 4093, index 1 refrences address 4096--etc..?) Here we run into a problem. Because the boot loader maps and loads the kernel directly to 3gb virtual, we also need to remap the area where the kernel is at: //! map 1mb to 3gb (where we are at) for (int i=0, frame=0x100000, virt=0xc0000000; i<1024; i++, frame+=4096, virt+=4096) { //! create a new page pt_entry page=0; pt_entry_add_attrib (&page, I86_PTE_PRESENT); pt_entry_set_frame (&page, frame); //! ...and add it to the page table table->m_entries [PAGE_TABLE_INDEX (virt) ] = page; } This code is pretty much the same as the above loop and maps 1MB physical to 3GB virtual. This is what maps the kernel into the address space and allows the kernel to continue running at 3GB virtual address. //! create default directory table pdirectory* dir = (pdirectory*) pmmngr_alloc_blocks (3); if (!dir) return; //! clear directory table and set it as current memset (dir, 0, sizeof (pdirectory)); The above creates a new page directory and clears it for our use. pd_entry* entry = &dir->m_entries [PAGE_DIRECTORY_INDEX (0xc0000000) ]; pd_entry_add_attrib (entry, I86_PDE_PRESENT); pd_entry_add_attrib (entry, I86_PDE_WRITABLE); pd_entry_set_frame (entry, (physical_addr)table); pd_entry* entry2 = &dir->m_entries [PAGE_DIRECTORY_INDEX (0x00000000) ]; pd_entry_add_attrib (entry2, I86_PDE_PRESENT); pd_entry_add_attrib (entry2, I86_PDE_WRITABLE); pd_entry_set_frame (entry2, (physical_addr)table2); Remember that each page table represents a full 4MB virtual address space? Knowing that each page directory entry points to a page table, we can saftley say that each page directory entry represents the same 4MB address space inside of the 4GB virtual address space of the entire directory table. The first entry in the page directory is for the first 4MB, the second is for the next 4MB and so on. Because we are only mapping the first 4MB right now, all we need to do is set the first entry to point to our page table. In a simular way, we set up a page directory entry for 3GB. This is needed so we can map the kernel in. Notice that we also set the page directory entries PAGE and PRESENT bit as well. This will tell the processor that the page table is present and writable. //! store current PDBR _cur_pdbr = (physical_addr) &dir->m_entries; //! switch to our page directory vmmngr_switch_pdirectory (dir); //! enable paging pmmngr_paging_enable (true); } Now that the page directory is set up, we install the page directory and enable paging. If everything worked as expected, your program should not crash. If it does not work, it will probably triple fault. Page Faults As you know, as soon as we enable paging all addresses become virtual. All of these virtual addresses rely heavily on the page tables and page directory data structures. This is fine, but there will be alot of times when a virtual address requires the cpu to access a page that is not yet valid. This is when a page fault exception (#PF) is raised by the processor. A <b?page fault=\"\">will only occur when a page is marked not present . A General Protecton Fault (#GPF) will occur if the page is not properly mapped but marked present and accessable. A #GPF will also occur if the page is not accessable. A page fault is cpu interrupt 14 which also pushes an error code so that we can abtain information. The error code pushed by the processor has the following format: Bit 0: 0: #PF occured because page was present 1: #PF occured NOT because the page was present Bit 1: 0: Operation that caused the #PF was a read 1: Operation that caused the #PF was a write Bit 2: 0: Processor was running in ring 0 (kernel mode) 1: Processor was running in ring 3 (user mode) Bit 3: 0: #PF did not occure because reserved bits were written over 1: #PF occured becaused reserved bits were written over Bit 4: 0: #PF did not occure during an instruction fetch 1: #PF occured during an instruction fetch All other bits are 0. When a #PF occures, the processor also stores the address that caused the fault in the CR2 register. Normally when a #PF occurs, an operating system will need to fetch the page from the faulting address of the currently running program from disk. This requires several different components of an OS (disk driver, file system driver, volume/mount points management) that we do not yet have. Because of this, we will return back to page fault handling a little later when we have a more evolved OS. Demo This demo includes all of the source code in this tutorial, and more. This demo includes paging code inside of the bootloader and kernel to include the complete virtual memory manager (VMM) and to map the kernel to the 3GB mark within its own virtual address space. There is nothing new visually with this demo. Because of this, there is no new pics. However it does demenstrate the concepts described in this chapter in both assembly language source (The bootloaders Paging.asm file) and C source (The VMM that we have developed in this chapter.) DEMO DOWNLOAD Conclusion I am very glad to get this one done! We have covered alot of information and ground in this tutorial: Virtual Memory, Virtual addressing and translation, paging, methods, and more. With this tutorial, we are not out of the paging word yet! However, we can all saftely go to bed tonight knowing that we have a better understanding of it, how it works, and hot to work with it. See? Its not so bad ðŸ˜€ Inside of the next tutorial I am thinking about going back to the fun stuff with developing a keyboard driver. Because we already have a form of output, and we will be able to retrieve input, we may even make a simple command line as well ðŸ˜‰"
  },
  "articles/61_unorganised_tutorial/T19.html": {
    "href": "articles/61_unorganised_tutorial/T19.html",
    "title": "The Keyboard | BrokenThorn OS Dev Tutorials",
    "keywords": "The Keyboard This will also be the first device that we will program within this series. Excited? We have already learned how hardware programming works and have experience in it; now it time to put it to the test. Ready? This is also the first device that we will be programming that not only requires us to work with one controller but two . These controllers communicate with each other and our system. To make things more complex, both controllers have their own set of commands and way to work with them. Because of this, this chapter is fairly detailed in a couple of places. This chapter also includes the first interactive demo: A basic command line parser. Excited? This is also the first chapter that we look at device drivers in more depth: The importance of hardware abstraction and device drivers. Here's the list: Keyboard - Back in Time and Keyboard Layout Inside the keyboard Keyboard Protocols Keyboard Encoder Keyboard Controller Scan Code Sets Keyboard IRQ Lets get going! Keyboard - History Back in time A keyboard is an input device that we use as a form of input to a computer. They were originally modeled off of a typical typewriter when they were first introduced. However the creation of the keyboard was not directly modeled from it. When the typewriter was patented in by Christopher Latham Sholes in 1877 several manufacturers and people further developed the original design. What evolved through a series of inventions was the Telegraph. Around this same time, inside of the 1930s, IBM was using Keypunches (punch card machines combined with typewriters) in their adding machines. Early computer keyboards adapted from both the keypunch and telegraph designs. The ENIAC (Electronic Numerical Integrator And Computer) was the first general purpose computer. The ENIAC used a punchcard reader as both an input and output device. in 1946. In 1948, the BINAC (Binary Automatic Computer) used an electromechanically controlled typewriter as both an input and output device. When does the keyboard evolve from these inventions? The computer keyboard that we all know does not evolve into what it is today until 1964 when MIT (with Fernando CorbatÃ³), Bell Laboratories and General Electric joined together to create the Multics (Multiplexed Information and Computing Service) machine. With the Multics, a new interface was at hand: They combined the technology of the cathode ray tube (CRT) used in televisions and electric typewriters to create a Video Display Terminal (VDT). The VDTs allowed a way for the users to be able to see what they were typing which made the computer a lot more easier to work with. Over the course of the 1970s and 1980s almost all computers had a form of VDT technology and a form of an electronic keyboard for input. Through the years, CRT and LCD displays replaced VDT technology, and the electronic keyboard also became standard among all general purpose computers. Today, we use keyboards every time we go on a computer. Most of the keyboards layout still remains from the typewriter and the way it is used are the same. However, thanks to the new era of electronic devices keyboards now come in a lot of different forms. From the generic plastic keyboards, keyboards the fold or have back lights in them, to even laser keyboards. Keyboard Layout The generic keyboard layout is known as a QWERTY keyboard because the characters QWERTY are the first five characters on a typical keyboard. The QWERTY layout was purposely designed during the typewriter era to slow down the typing speed of typists because of the original mechanical limitations of early typewriters. This was primarily to decrease the amount of time between each keypress and to give the print heads enough time so they do not jam. The QWERTY layout has been adapted in all keyboards to this day. Inside the keyboard What actually happens when you press a key on your keyboard? How can the keyboard tell the program what keys are down? The very text that is being read right now (that's right, me ðŸ˜‰ has been input by keyboard. How can the keyboard do this? Lets take a look! Note: The exact details depend on the keyboards specific type and model. Because of this, I will only be covering a generic 102 key keyboard here. Opening the case You might be surprised by how keyboards came from being complex printed circuit boards (PCBs) to a single integrated board with its own microprocessor. If you were to open your keyboard, you might see something like this: Yep, that's it. Notice how simple this is. One circuit board and a grid. The grid might be a little hard to see in the above picture. However if you look close, you might be able to see the points in the grid and notice that the points match to the key positions on a typical keyboard . This is known as the key matrix . In almost all keyboards, the circuits that make up the key matrix is broken between each point in the grid. Knowing that a key is above a point in the key matrix, when we press down the key, it presses the switch at that point completing the horizontal circuit and allowing current to run through it. The vibration of the line caused by the mechanical movement of the keys is known as bounce and is filtered out by the keyboards own microprocessor otherwise known as the Keyboard Encoder . Don't worry if this seems a little complex. We will look at everything more closely in the next couple of sections. Keyboard Encoder The microprocessor used by the keyboard is usually a form of the original Intel 8048 , which just so happens to be also Intel's first microcontroller. This controller is known as the Keyboard Encoder . The exact keyboard encoder used is very dependent on your keyboard. There are hundreds of different keyboard encoders but they all do basically the same thing. The rows and columns within the key grid are connected to 8 bit I/O ports on the keyboard encoder. When a key is down, the switch at that location within the key grid is closed which allows current to flow through it completing the circuit. This current enables the pin on the keyboard encoder of the correct ports that the key location corresponds to. Thus, all the controller needs to do is scan its ports to see if a key is down or not by checking if a port line is active. If a key is down, the keyboard encoder looks up the location within its Read Only Memory (ROM) character map to see what the Scan Code is for that character and stores it in its internal 16 byte memory. The keyboards processor includes its own timer, 33 instruction set, and can even access 128K of external memory. Using its timer, it can determine if the key is down based on weather it is by user input or a bounce . If a bounce happens, it will usually be much faster then any human can input. If the key is still down when its timer reaches 0, it is reset and the character is inserted into its internal 16 byte buffer. It is important to note that there are two keyboard controllers that we can communicate with: The keyboard encoder inside of the keyboard and the keyboard controller inside on the motherboard. We will look at the other controller a little later, don't worry ðŸ˜‰ For now, keep in mind that their are two controllers, and the keyboard encoder is one of them . The keyboard encoder communicates with the system through a method defined by the keyboard protocol . Lets take a look. Keyboard Protocol The keyboard encoder sends data as bytes to the motherboards onboard keyboard controller. The way it is sent depends on the protocol used by the keyboards interface. This is usually a 5-pin DIN connector, 6 pin Mini-DIN connector, USB connector, SDL connector, or wireless using an infra red (IR) interface. The 5 pin DIN connector used for AT/XT keyboards normally is on the back of the computer and looks like this: 1: Clock 2: Data 3: N/A 4: Ground 5: Vcc (+5V) The motherboard supplies power from the power supply unit (PSU) through the Vcc and Ground pins. The clock pin is used for synchronization between the keyboards data and the system clock. The data from the keyboard is sent as serial data over the data pin. The more common 6 pin Mini-DIN connector used for PS/2 keyboards is very similar: 1: Data 2: N/A 3: Ground 4: Vcc (+5V) 5: Clock 6: N/A Nothing much new to add here. DIN does not really stand for anything in particular but refers to the standards group that developed it (Deutsches Institut fÃ¼r Normung, or in English, German Institute for Standardization). The SDL (Shielded Data Link) connector is very simular: A: N/A B: Data C: Ground D: Clock E: Vcc (+5V) F: N/A Universal Serial Bus (USB) connectors are a standard that is used by a lot of different devices. Working with USB devices directly are a fairly complex topic. They only contain four pins: 1: Vcc (+5V), 2: Data-, 3: Data+, 4: Ground. USB Legacy Support is used on most modern computers that come with USB ports. This means that these computer motherboards can emulate USB keyboards and mice as PS/2 keyboard and mice. Because of this: Communicating with a USB keyboard or mice using PS/2 compatible interfaces will work. In other words, do not worry if you have a USB keyboard or mouse as most of us do. The code and demo in this tutorial will still work fine thanks to the emulation provided by the motherboard. As you can see, the interfaces between the keyboard and the computer are not too complex. All they do is provide a way to send data as bits between the keyboard controller and the keyboard encoder. The data are routed to the onboard or integrated keyboard controller on the motherboard. The keyboard controller takes control. Keyboard Controller The keyboard controller used inside of the system case is usually a form of the original 8042 keyboard controller . The keyboard controller interfaces with the keyboard encoder through the keyboards protocol and provides a way to interface to it. On most newer systems, the keyboard controller is not a separate integrated circuit (IC) but rather part of the motherboards Super Input/Output (IO) controller that also houses the floppy disk controller (FDC) , parallel port interface , serial port interfaces and mouse interface . Most newer systems super IO controller uses the Low Pin Count (LPC) bus rather then Industry Standard Architecture (ISA) on the southbridge of the motherboard. Scan Codes A Scan Code is a data packet that represents the state of a key. If a key is pressed, released, or held down, a scan code is sent to the computers onboard keyboard controller . There are two types of scan codes: Make Codes and Break Codes . A Make Code is sent when a key is pressed or held down while a break code is sent when a key is released. There is a unique make code and break code for each key on the keyboard. The entire set of numbers that represent all of the scan codes make up the keyboards scan code set . There are generally three different scan sets that the keyboard can use. However there is no easy way to determine what scan set it uses as the scan values are random. Because of this, you will need to use a lookup table to determine the key the scan code represents. Lets take a look at the scan code tables. Note: These tables are important! We will need to use these to determine what keys are pressed on the keyboard. Also note: All scan codes in these tables in are hexadecimal. These are fairly large tables so I decided to put them as a separate resource. Please see the tables in the resources section [here] (Fix link OSDevScanCodes.html). Lets have an example. If you press shift+A keys on your keyboard, what will be the make code sent to your computer? In order to better understand this, lets take a look at the sequence of events that happens. First the shift key is pressed, then the A key is pressed. Then the A key is released followed by the shift key being released. Assuming that the scan code set is the default scan code set for modern keyboards, the left shift key make code is 0x12, break code is 0xF0 and 0x12. The make code for the A key is 0x1C while the break code is 0xF0 and 0x1C. So when this event occurs, the following scan codes will be sent to the computer: Key events: shift down A down A released Shift released Scan codes: 0x12 0x1C 0xF0 0x1C 0xF0 0x12 Looking at the above, we can see that the scan codes sent will be 0x12, 0x1C, 0xF0, 0x1C, 0xF0, and 0x12. If you press a key and hold it, the key becomes typematic . In other words, the keyboard will keep sending the keys make code until the key is released or another key is pressed. Try it: Open up your favorite text editor and hold down a key. After a short delay another of the same character will appear followed by a long series of the character. The typematic delay determines the amount of seconds to wait before entering typematic mode, and the typematic rate determines the amount of character make codes per second to send to the computer. During typematic mode, the character data is not buffered. If multiple keys are held down, only the last key held becomes typematic. Scan codes are very important to us . When a scan code is sent to the onboard keyboard controller, the keyboard controller stores the scan code into its internal memory. The keyboard controller then toggles its Interrupt Request (IR) line to high. If the interrupt line is not masked by the Programmable Interrupt Controller (PIC) then this will cause IRQ 1 to be fired. Even if the IRQ is masked, because the read buffer can be read by us through software, we can read the scan code and determine what key was just released or pressed. Keyboard Interface: Developing a Device Driver We have covered a lot already in this chapter. We have looked at the history of the keyboard as in interface device, the QWERTY keyboard layout, and looked at the inside of the keyboard to see how it works and the primary components that make it work. We have also looked at scan code sets and the keyboards protocols. Don't worry if you do not understand everything yet, we will look at everything in more detail within the next couple of sections. We will also be developing device driver for our keyboard as well. Cool, huh? All of the code in this section will also be in the final demo. Keyboard Interfacing: Polling Remember from the previous section that there are two controllers when working with the keyboard? That is, there is the Keyboard Encoder inside of the keyboard as well as the Keyboard Controller on the motherboard. This is the first chapter in the series where we need to interface with several different controllers to control a single hardware device. That's right: We can communicate with both of these controllers. Well, kind of. When we send a command to the keyboard encoder, we still send it to the onboard keyboard controller however it reroutes it to the keyboard encoder over the keyboard protocol. Okay, so we can communicate with both controllers. How fun is that? Knowing that both controllers work with each other, they also communicate with each other. The keyboard encoder may send a lot of different codes to the onboard keyboard controller to store. These can be scan codes or error codes. This allows us to also receive information from both the keyboard encoder and onboard controller. All of this communication is done by simply using the IN and OUT instructions to read or write to the controller ports mapped in the IO address space. While we never had to worry what these ports are, understanding how IO mapping works with controllers becomes more important here. This is one way we can interface with the keyboard: We can manually communicate with the controllers to check if a key is down, up, or what not. This is known as polling the keyboard. This is how we are able to get the last scan code from the keyboard: by polling the keyboard controller for it. Keyboard Interfacing: Interrupt Request (IRQ) Remember from the PIC tutorial that the keyboard controller can be configured to use an interrupt line? We can configure the keyboard controller to issue IRQ 1 whenever a key has been pressed or released. This is the most common way to interface with the keyboard. Whenever IRQ 1 is fired, you should always test to see if a scan code has actually been sent to the keyboard controller. This is done by polling the keyboard controller to get the last scan code. Detail: 8042 Keyboard Microcontroller The original 8042 Microcontroller This is the microcontroller that interfaces with the keyboard encoder. The keyboard controller is part of a family of microcontrollers originally started with the 8042 microcontroller. In modern computers, the keyboard controller is not a separate integrated circuit (IC) but its functionality is emulated by the motherboard itself. That is, the controller functionality is integrated into the motherboard chipset. The keyboard controller can operate in two modes: AT Compatible Mode and PS/2 Compatible Mode . Depending on what mode the controller is operating in, the way it interfaces to the outside world may differ. First, lets take a look at the controller: Yep. That's it. Pins P10-P17 is the controllers input port . Pins P20-P27 is the controllers output port . And pin T0-T1 is the controller test port . The exact meaning of these pins depend on the mode of operation the controller is in. We will look closer at these ports later as there are commands that allow us to work with them. Most of the other pins are not important to us. I decided to add them here for completeness sake only; you do not need to know them. The pins XTAL 1 and XTAL 2 are for Crystal Oscillator Input . XTAL 1 can also be connected to ground if CLK is driven by an external source. Similarly, XTAL 2 can be connected to CLK if its being driven by an external source. RESET causes the controller to reset if pulled low (0). SS is the microcontrollers Single Step pin. CS is the Chip Select pin which is used for data register port interfacing. EA (No, not the company ðŸ˜‰ ) is the External Access input pin. This will disable the OTP (One Time Programmable) ROM and enable commands to be sent to the controller from an external source. RD Output enable input; used for data register port interfacing. A0 is the Command/Data Register select input; used for data register port interfacing. WR is the write enable input line, used with data register port interfacing. SYNC is the clock output signal. D0-D7 is used for data register port interfacing. GND is the ground pin (Vss). Vdd is the +5V input pin. PROG is used as an address/data strobe to the 8243 during I/O expander access. Vcc is another +5V input pin. The keyboard controller provides us an interface for controlling how we want the keyboard to work. We do this by communicating with the keyboard controller through its ports which is mapped into the port I/O space. As you know, this means in order for us to communciate with the keyboard controller, we will need to use the IN and OUT instructions and know how it is mapped. Lets take a look. Port Mapping In the i86 architecture, the following ports are used to communicate with the keyboard: Keyboard Controller Ports table Keyboard Encoder table Port Read/Write Description 0x60 Read Read Input Buffer 0x60 Write Send Command Onboard Keyboard Controller table Port Read/Write Description 0x64 Read Status Register 0x64 Write Send Command This table is not to bad I hope ðŸ˜‰ Basically: To send a command to the keyboard encoder, write the command byte to port 0x60. Before doing this however, you need to insure that bit 0 (output buffer full) of the keyboard controller status register is 0 to insure it is safe. If bit 1 (input buffer full) of the keyboard controller status register is 1 then data is in the input buffer ready to be read. Reading from port 0x60 will allow you to get this data from the keyboard encoder. The data read from the keyboard encoder will normally come from the keyboard. however you can also reprogram the microcontroller to return specific values as well. Writing a value to port 0x64 will allow you to send a command byte to the onboard keyboard controller. Reading from port 0x64 will allow you to get the status byte of the keyboard controller. Knowing all of this, we can easily provide routines for reading and writing command bytes and data to and from these controllers. We abstract the IO ports used by these controllers here: enum KYBRD_ENCODER_IO { KYBRD_ENC_INPUT_BUF = 0x60, KYBRD_ENC_CMD_REG = 0x60 }; enum KYBRD_CTRL_IO { KYBRD_CTRL_STATS_REG = 0x64, KYBRD_CTRL_CMD_REG = 0x64 }; We will not be going over the routines used to interact with these controllers just yet as it requires some knowledge of the commands of the controllers. Registers Status Register This might look familiar from When we covered enabling the 20th address line. To read the status register, simply read from I/O port 0x64. The value returned is an 8 bit value that follows a specific format. The format is a little different depending on the mode of the controller. Here it is again. I bolded the important ones: Bit 0: Output Buffer Status 0: Output buffer empty, don't read yet 1: Output buffer full, please read me ðŸ˜€ Bit 1: Input Buffer Status 0: Input buffer empty, can be written 1: Input buffer full, don't write yet Bit 2: System flag 0: Set after power on reset 1: Set after successful completion of the keyboard controllers self-test (Basic Assurance Test, BAT) Bit 3: Command Data 0: Last write to input buffer was data (via port 0x60) 1: Last write to input buffer was a command (via port 0x64) Bit 4: Keyboard Locked 0: Locked 1: Not locked Bit 5: Auxiliary Output buffer full PS/2 Systems: 0: Determines if read from port 0x60 is valid If valid, 0=Keyboard data 1: Mouse data, only if you can read from port 0x60 AT Systems: 0: OK flag 1: Timeout on transmission from keyboard controller to keyboard. This may indicate no keyboard is present. Bit 6: Timeout 0: OK flag 1: Timeout PS/2: General Timeout AT: Timeout on transmission from keyboard to keyboard controller. Possibly parity error (In which case both bits 6 and 7 are set) Bit 7: Parity error 0: OK flag, no error 1: Parity error with last byte We need to read the status register to determin the current state of the keyboard and to see what we can and cannot do. For example, we would not want to send a command to the keyboard if there is no keyboard plugged in! So we would want to read in the current status to test it before sending a command. We also need to take into consideration that the processor executes instructions alot faster then the keyboard controller can respond. Because of this, there are alot of times when we need to wait for the keyboard controller to be ready for the next command. To check this, we need to read in the status register and test bit 0 (Output Buffer Full) to see if it is okay to send the next command. If we do not do this, the previous command will be discarded and the new one will start executing, which may not be desirable. It is important to wait for the controller to be ready before sending another command or reading data from it. We can use bit masks for reading and writing to the status register. Here is the one from the demo at the end of this chapter. Notice how each bit corresponds with the correct bit in the list shown above. enum KYBRD_CTRL_STATS_MASK { KYBRD_CTRL_STATS_MASK_OUT_BUF = 1, //00000001 KYBRD_CTRL_STATS_MASK_IN_BUF = 2, //00000010 KYBRD_CTRL_STATS_MASK_SYSTEM = 4, //00000100 KYBRD_CTRL_STATS_MASK_CMD_DATA = 8, //00001000 KYBRD_CTRL_STATS_MASK_LOCKED = 0x10, //00010000 KYBRD_CTRL_STATS_MASK_AUX_BUF = 0x20, //00100000 KYBRD_CTRL_STATS_MASK_TIMEOUT = 0x40, //01000000 KYBRD_CTRL_STATS_MASK_PARITY = 0x80 //10000000 }; Great! So, all we need to do is to read from the keyboard controllers status register at port 0x64. Then test whatever bit we want to check the status of it based on the bit masks above. So, to read from the keyboard controller status register, all we need is: //! read status from keyboard controller uint8_t kybrd_ctrl_read_status () { return inportb (KYBRD_CTRL_STATS_REG); } Reading and writing: Input buffer To send a command, we first wait to insure the keyboard controller is ready for it. This is done by seeing if the input buffer is full or not. We test this by reading the keyboard controllers status register and testing the bit. If its 0, the buffer is empty so we send the command byte to it. (Remember all of this information is inside of the status register bit layout shown above.) //! send command byte to keyboard controller void kybrd_ctrl_send_cmd (uint8_t cmd) { //! wait for kkybrd controller input buffer to be clear while (1) if ( (kybrd_ctrl_read_status () & KYBRD_CTRL_STATS_MASK_IN_BUF) == 0) break; outportb (KYBRD_CTRL_CMD_REG, cmd); } The keyboard encoder is very simular as you can see below. Remember that commands sent to the keyboard encoder are sent to the keyboard controller first. Because of this, you still need to insure the keyboard controller itself is still ready for the command. //! read keyboard encoder buffer uint8_t kybrd_enc_read_buf () { return inportb (KYBRD_ENC_INPUT_BUF); } //! send command byte to keyboard encoder void kybrd_enc_send_cmd (uint8_t cmd) { //! wait for kkybrd controller input buffer to be clear while (1) if ( (kybrd_ctrl_read_status () & KYBRD_CTRL_STATS_MASK_IN_BUF) == 0) break; //! send command byte to kybrd encoder outportb (KYBRD_ENC_CMD_REG, cmd); } Keyboard Encoder Commands When writing a command byte to port 0x60 the keyboard controller transmits the value directly to the keyboard encoder. The following is a list of the command bytes: Keyboard Command Listing table Command Description 0xED Set LEDs 0xEE Echo command. Returns 0xEE to port 0x60 as a diagnostic test 0xF0 Set alternate scan code set 0xF2 Send 2 byte keyboard ID code as the next two bytes to be read from port 0x60 0xF3 Set autorepeat delay and repeat rate 0xF4 Enable keyboard 0xF5 Reset to power on condition and wait for enable command 0xF6 Reset to power on condition and begin scanning keyboard 0xF7 Set all keys to autorepeat (PS/2 only) 0xF8 Set all keys to send make code and break code (PS/2 only) 0xF9 Set all keys to generate only make codes 0xFA Set all keys to autorepeat and generate make/break codes 0xFB Set a single key to autorepeat 0xFC Set a single key to generate make and break codes 0xFD Set a single key to generate only break codes 0xFE Resend last result 0xFF Reset keyboard to power on state and start self test All of the small commands are described in the above table. Lets take a closer look at the more complex commands, shall we? Command 0xED - Set Light Emitting Diodes (LED's) This command is used to set the LEDs on the keyboard. The next byte written to port 0x60 updates the LEDs on the keyboard and follows the format shown below: Bit 0: Scroll lock LED (0: off 1:on) Bit 1: Num lock LED (0: off 1:on) Bit 2: Caps lock LED (0: off 1:on) All other bits must be 0. This command is kind of fun to play with ðŸ˜‰ Here is an example routine that the demo uses to update the lights on your keyboard. Notice how it sets or clears the bit based on if a parameter is true or false. Also notice that it writes first the command byte to the keyboard encoder followed by the data byte. They both go to the keyboard encoders command register. KYBRD_ENC_CMD_SET_LED is a constant for 0xED -- the command byte that we are using. No magic involved ðŸ˜€ //! sets leds void kkybrd_set_leds (bool num, bool caps, bool scroll) { uint8_t data = 0; //! set or clear the bit data = (scroll) ? (data | 1) : (data & 1); data = (num) ? (num | 2) : (num & 2); data = (caps) ? (num | 4) : (num & 4); //! send the command -- update keyboard Light Emetting Diods (LEDs) kybrd_enc_send_cmd (KYBRD_ENC_CMD_SET_LED); kybrd_enc_send_cmd (data); } Command 0xF0 - Set alternative scan code set (PS/2 Only) This command sets the scan code set to use. The next byte written to port 0x60 must be a byte of the following format: Bit 0: Returns current scan code set to port 0x60 Bit 1: Sets scan code set 1 Bit 2: Sets scan code set 2 Bit 3: Sets scan code set 3 All other bits should be 0. Command 0xF3 - Set autorepeat delay and repeat rate This command sets the autorepeat delay and repeat rate. Next byte written to port 0x60 must be the following format: Bit 0-4: Repeat rate. 0: approx. 30 chars/sec to 0x1F: approx. 2 chars/sec Bit 5-6: Repeat delay. 00: 1/4 sec, 01: 1/2 sec, 10: 3/4 sec, 11: 1 sec All other bits must be 0. Return Codes As you know, the keyboard encoder communicates with the systems onboard keyboard controller. Most of the values returned will be a scan code but sometimes it may also return an error. These values are sent from the keyboard decoder to the system through port 0x60. The returned value can be one of the following: Return Codes table Value Description 0x0 Internal buffer overrun 0x1-0x58, 0x81-0xD8 Keypress scan code 0x83AB Keyboard ID code returned from F2 command 0xAA Returned during Basic Assurance Test (BAT) after reset. Also L. shift key make code 0xEE Returned from the ECHO command 0xF0 Prefix of certain make codes (Does not apply to PS/2) 0xFA Keyboard acknowledge to keyboard command 0xFC Basic Assurance Test (BAT) failed (PS/2 only) 0xFD Diagnostic failure (Except PS/2) 0xFE Keyboard requests for system to resend last command 0xFF Key error (PS/2 only) Onboard Keyboard Controller Commands Some of these commands we have already seen in the A20 chapter. A lot of the commands listed here are new however and some are very low level. That is, some of these commands allow you to control specific lines connected to the controller. This is why I had to cover the controller's lines and how it interfaces with the keyboard device. Other commands allow you to read or write to the controllers internal RAM. Commands Listing Common Commands Command Description 0x20 Read command byte 0x60 Write command byte 0xAA Self Test 0xAB Interface Test 0xAD Disable Keyboard 0xAE Enable Keyboard 0xC0 Read Input Port 0xD0 Read Output Port 0xD1 Write Output Port 0xE0 Read Test Inputs 0xFE System Reset 0xA7 Disable Mouse Port 0xA8 Enable Mouse Port 0xA9 Test Mouse Port 0xD4 Write To Mouse Non Standard Commands Command Description 0x00-0x1F Read Controller RAM 0x20-0x3F Read Controller RAM 0x40-0x5F Write Controller RAM 0x60-0x7F Write Controller RAM 0x90-0x93 Synaptic Multiplexer Prefix 0x90-0x9F Write port 13-Port 10 0xA0 Read Copyright 0xA1 Read Firmware Version 0xA2 Change Speed 0xA3 Change Speed 0xA4 Check if password is installed 0xA5 Load Password 0xA6 Check Password 0xAC Diagnostic Dump 0xAF Read Keyboard Version 0xB0-0xB5 Reset Controller Line 0xB8-0xBD Set Controller Line 0xC1 Continuous input port poll, low 0xC2 Continuous input port poll, high 0xC8 Unblock Controller lines P22 and P23 0xC9 Block Controller lines P22 and P23 0xCA Read Controller Mode 0xCB Write Controller Mode 0xD2 Write Output Buffer 0xD3 Write Mouse Output Buffer 0xDD Disable A20 address line 0xDF Enable A20 address line 0xF0-0xFF Pulse output bit That's a lot of commands, huh? It would take a very long time to cover every command here, don't you think? We have already covered the A20 commands in the earlier A20 chapter. Because portability is a concern within this series, we will only be covering the more common commands listed above. However I encourage our interested readers to look for information on the commands not covered here. I am not going to cover example code until the next section. Rather we will just be looking at the commands themselves here and refer to them from the next section. Command 0x20 - Read Command Byte and reading controller RAM Look at the table above. Notice that the commands 0x20 - 0x3F is used to read the controller RAM? And yet, command 0x20 is used to read the command byte also. What is going on here? Actually, they both refer to the same thing. The command byte is stored within the controllers RAM. So, when reading the command byte, you are reading from the controllers internal RAM. Cool? When reading from the controllers RAM, the last 6 bits of the command refer to the the location within RAM to read from . On certain MCA systems, you have access to all 32 locations within the RAM. On other systems, you can only access the bytes at 0, 0x13-0x17, 0x1D, and 0x1F. These locations are: Offset 0: Command Byte Offset 0x13 (MCA): nonzero when password is enabled Offset 0x14 (MCA): nonzero when password is matched Offsets 0x16-0x17 (MCA): give two make codes to be discarded during password matching Offset 0x1D: Offset 0x1F: The command byte is the more important one here. It follows a specific bit format shown here. Don't worry - its not as complex as it looks: Bit 0 : Keyboard interrupt enable 0: Disables interrupt 1: Sends IRQ 1 when keyboard output buffer is full Bit 1 : Mouse interrupt enable ISA : Unused EISA / PS2 0: Disables mouse interrupts 1: Sends IRQ 12 when mouse output buffer is full Bit 2 : System Flag (Also bit 2 of status register) 0: Cold reboot 1: Warm reboot (BAT already completed) Bit 3 : Ignore Keyboard Lock PS/2 : Unused AT 0: No action 1: Force bit 4 of status register to 1 (not locked) Bit 4 : Keyboard Enable 0: Enable Keyboard 1: Disable Keyboard by driving clock line low Bit 5 : Mouse Enable EISA or PS/2 0: Enable Mouse 1: Disable mouse by driving clock line low ISA 0: In PC Mode, use 11-bit codes, check parity and do scan conversion 1: In PC Mode, use 8086 codes, don't check parity and don't do scan conversion Bit 6 : Translation 0: No translation 1: Translate key scan codes. MCA type 2 controllers cannot set this bit Bit 7 : Unused, should be 0 I do not think we will be needing this command so I have not written a routine for it. Command 0x60 - Write Command Byte and writing controller RAM The command bytes 0x60 - 0x7F are very similar to the above and allows you to write to the same RAM locations as described above. the more important one is reading byte 0 of the controllers RAM (The command byte, remember?) which can be done by sending command byte 0x60. Along with the above command, there is no routine written for this command for the end demo. Command 0xAA - Self Test This command causes the controller to perform a self test. It returns the result in the output buffer that can be read through port 0x60. It returns 0x55 if the test passed successfully, or 0xFC if it failed. Here is an example routine. Notice how it first sends the KYBRD_CTRL_CMD_SELF_TEST command (command 0xAA) to the keyboard controller. Afterwards, it waits for the keyboard controllers output buffer to be filled with data. This will tell us if the test completed or not. When it completes, it returns true (test successful) if the result in the output buffer is 0x55, or false (test failed) otherwise. //! run self test bool kkybrd_self_test () { //! send command kybrd_ctrl_send_cmd (KYBRD_CTRL_CMD_SELF_TEST); //! wait for output buffer to be full while (1) if (kybrd_ctrl_read_status () & KYBRD_CTRL_STATS_MASK_OUT_BUF) break; //! if output buffer == 0x55, test passed return (kybrd_enc_read_buf () == 0x55) ? true : false; } Command 0xAB - Interface Test This command causes the controller to test the serial interface between the controller and the keyboard. The result of the test is placed in the output buffer that can be read on port 0x60. The result can be one of the following: 0: Success, no errors 1: Keyboard clock line stuck low 2: Keyboard clock line stuck high 3: Keyboard data line stuck high 0xFF: General error As you can see, all of these are hardware errors. If an errors occurs, it is recommended to disable the keyboard and reset it. If it still fails, the keyboard might have malfunctioned. Command 0xAD - Disable Keyboard This command causes the controller to disable the keyboard clock line and set bit 4 (keyboard enable) of the command byte. Please see the Read Command Byte section for the format of the command byte. In other words, this command disables the keyboard. It is a good idea to store the current state of the keyboard so that your system can keep track of the current status of the keyboard. This is done in the demos keyboard driver through _kkybrd_disable. //! disables the keyboard void kkybrd_disable () { kybrd_ctrl_send_cmd (KYBRD_CTRL_CMD_DISABLE); _kkybrd_disable = true; } Command 0xAE - Enable Keyboard This command causes the controller to enable the keyboard clock line and clears bit 4 (keyboard enable) of the command byte. Please see the Read Command Byte section for the format of the command byte. In other words, this command enables the keyboard. Here is an example routine taken from the demo. Notice how easy this one is ðŸ˜€ //! enables the keyboard void kkybrd_enable () { kybrd_ctrl_send_cmd (KYBRD_CTRL_CMD_ENABLE); _kkybrd_disable = false; } Command 0xC0 - Read Input Port This command reads the input port (lines P10-P17 on the controller) and copies the binary value to the output buffer that can be read through port 0x64. Because we have not looked at the lines that this port has, lets look at it now: Line P10 / Bit 0: Keyboard data in, Unused in ISA Line P11 / Bit 1: Mouse data in, Unused in ISA Line P12 / Bit 2: Unused in ISA, EISA, PS/2 Line P13 / Bit 3: Unused in ISA, EISA, PS/2 Line P14 / Bit 4: 0: 512 KB motherboard RAM, 1: 256K RAM Line P15 / Bit 5: 0: Manufacturing jumper installed, 1: Not installed Line P16 / Bit 6: 0: CGA display 1: MDA display Line P17 / Bit 7: 0: Keyboard locked 1: Not locked If a jumper is active, the BIOS may run an infinity diagnostic loop. Lines P13 and P14 may be configured for clock switching. Don't worry if these seems complex -- Looking at the above you can probably see that this command is not very helpful on modern computers. Bits 0, 1, 2, and 3 are no longer used anymore. Bit 4 is almost useless as all modern computers have way more then 512 KB of RAM. Bit 5 can be used to test if a jumper is installed for keyboard testing (Which almost no user will do). Bit 6 is not needed as you can get that information from the video adapter and bit 7 is almost never needed as most users would not want their keyboard locked. Yep. very useful command, huh? It can be, just not for most computers. Because of the super usefulness (or lack there of ðŸ˜‰ ) this command has to offer, I decided not to write a routine for it. Command 0xD0 - Read Output Port This command tells the controller to read from its output port (P2) and place the result in the output buffer at port 0x64. By reading from port 0x64 after issuing this command, we can check the bits of the controllers output port. The controllers output port is just the P20-P27 lines of the controller (Remember this from before?). The binary value on these lines are then stored into the output buffer when this command is executed. We have not covered the output port pins and what they are yet. (Well, actually we have in the A20 chapter, but not in detail) so lets look at it here: Line P20 / Bit 0: 0: Reset CPU, 1: normal operation Line P21 / Bit 1: 0: A20 line is forced, 1: enabled Line P22 / Bit 2: Mouse data. Unused in ISA Line P23 / Bit 3: Mouse clock. Unused in ISA Line P24 / Bit 4: 0: IRQ 1 not active, 1: IRQ 1 active Line P25 / Bit 5: 0: IRQ 12 not active, 1: IRQ 12 active Line P26 / Bit 6: Keyboard Clock Line P27 / Bit 7: Data to Keyboard That's it. Bit 2 and 3 are no longer used in Industry Standard Architecture (ISA) computers (most modern computers). Bits 4 and 5 (lines P24 and P25) are connected to the Programmable Interrupt Controller (PIC) on the PIC lines IR1 and IR12. Thus, if the line is active the interrupt line is also active on the PIC (Which also means the interrupt may be executing or pending execution.) Bits 6 and 7 simply contain the current keyboard clock and data signal (Whether the line is active or not.) So far a lot of the bits here are pretty useless, huh? A lot of these bits are at the electronics level of the current operation of the controller which is useless for our needs. That is, except for the first two lines (Bits 0 and 1) which control if we want to reset the system or enable/disable the 20th address line. Well, okay, reading bit 0 is useless also as the line must be active (1) meaning we are running in normal operation. Without it the system would reboot. Thus the only useful bit here is the A20 line. This is true for at least a read operation. When this command is issued on port 0x64, the resulting byte is placed in the output buffer and can be read by reading the byte from port 0x60. I'm not worried about needing to disable A20 anytime soon. Also, there are alternative methods of resetting the system through the keyboard. Because of this, this command is pretty useless for our needs and I decided not to write a routine for it. Command 0xD1 - Write Output Port This command copies the byte from the output buffer (port 0x60) and places the byte on the controllers output port lines. Please see the previous section (Read Output Port Command) for a description of these lines. For the most part, you would want to bitwise OR specific bits that you would like to change and keep everything else unchanged to prevent possible problems. This command is useful in several ways. It allows you to enable or disable the IRQ used by the controller, enable or disable the A20 gate, or even reset the system by setting bit 0. Again, please see the previous section for the list of the bits that can be changed. Command 0xE0 - Read Test Input This command copies takes the binary value from the test port lines on the controller and places them in the output buffer so they can be read through port 0x60. The test port are the lines TEST 0 and TEST 1 of the microcontroller (please see the controller pinout diagram in this chapter). Because we have not covered them yet, lets take a look: Line TEST 0 / Bit 0: Keyboard Clock (input) Line TEST 1 / Bit 1: AT - Keyboard data (input) PS/2 - Mouse clock (input) All other bits should be assumed undefined and should not be read. While this command might not be much of use; remember that the controller may be used in other fields where the test port may be more useful. After all, it is there for testing purposes. Command 0xFE - System Reset Causes the controller to pulse bit 0 of the controllers output port (pin P0) which resets the CPU. This basically does the same thing as sending the Write Output Port command resetting bit 0. Send this command if you would like to reset the system in a nice way. //! reset the system void kkybrd_reset_system () { //! writes 11111110 to the output port (sets reset system line low) kybrd_ctrl_send_cmd (KYBRD_CTRL_CMD_WRITE_OUT_PORT); kybrd_enc_send_cmd (0xfe); } Keep in mind that this may not work on all systems. An easy way to see if it works or not is to see if your program is still executing after the above routine ðŸ˜€ Demo The first interactive demo DEMO DOWNLOAD This is the most complex demo so far. It uses all of the code from the previous chapter along with an additional keyboard driver and basic Command Line Interface (CLI) to make things more interesting. Because of this, it is also our first interactive demo and can be extended upon with your own commands as well. This demo also adds the sleep () routine which is used to delay between each key read along with scrolling to the debug output console routines allowing the screen to scroll. Cool, huh? I am not going to cover the code for the CLI itself as it is meant to be very simple. Rather, I want to focus on some of the more important parts of the demo. Keyboard: Piecing it Together We have looked at some of the routines from this demos keyboard driver already. We looked over communicating with the keyboard encoder and controller; and even routines for several different important functions for enabling, disabling, testing, LED updating, system reset, and more. This is great, but we are missing a few important details that tie everything together. Lets take a look, shall we? Keyboard: Storing the current state As you know, you can press any of the keys on your keyboard at any time. Because of this, there needs to be a way to scan each key to see if they are down or not. The good thing here is that the keyboard encoder already does this! To make things more easier, the keyboard encoder sends the scan code directly to the onboard keyboard controller which in turns invokes IRQ 1. As long as IRQ 1 is not masked, we can install our own interrupt handler at IRQ 1 so that we can get notified whenever a scan code is sent from the keyboard encoder. What does this mean? Our interrupt handler will be invoked any time a scan code is sent to the keyboard controller . This can happen at any time. Because of this, we need to somehow determine what the scan code is inside of the handler by polling the keyboard controller for it. However, we may want to do different things if a key is down (like the caps lock or num lock keys). These keys supposed to stay on or off when they are pressed. Then, what about other keys like shift? These keys must be held down and released when the key is released. Because of this, we need to come up with a method of storing the current state of these keys and the last scan code read so that they can be retrieved again later after the IRQ has already returned. This can be done by storing the current state in a few global variables or a structure and simply using them. Keyboard: Interrupt Handling This one is important. Remember that, for each key stroke and key release several bytes (The scan code) is sent to the keyboard controller? When this occurs, the keyboard controller signals the Programmable Interrupt Controller (PIC) to generate IRQ 1 . Yes, dear readers, this in turn causes the PIC to execute our keyboard interrupt handler. The purpose of the interrupt handler is to update the current state of the driver and to decipher the scan code by converting it to a format that can be used by the driver and the system. Yep, that's all that is to it ðŸ˜‰ The interrupt handler is what ties everything together. It is a little big so I decided to not put it in this text, however I urge everyone to take a look at it to see how it works. Keyboard: Initialization Remember that the keyboard controller is connected indirectly to the programmable interrupt IRQ 1 line? Because we mapped the IRQs using the PIC to start from interrupt vector 32 (IRQ 0), IRQ 1 is at interrupt vector 33. Because of this, we need to install our interrupt handler using our setvect routine to use interrupt vector 33. Everything else is pretty simple. We simply clear out the current driver state (stored as globals) and clear the LEDs using our kkybrd_set_leds routine. //! prepares driver for use void kkybrd_install (int irq) { //! Install our interrupt handler (irq 1 uses interrupt 33) setvect (irq, i86_kybrd_irq); //! assume Basic Assurance test (BAT) test is good _kkybrd_bat_res = true; _scancode = 0; //! set lock keys and led lights _numlock = _scrolllock = _capslock = false; kkybrd_set_leds (false, false, false); //! shift, ctrl, and alt keys _shift = _alt = _ctrl = false; }"
  },
  "articles/61_unorganised_tutorial/T20.html": {
    "href": "articles/61_unorganised_tutorial/T20.html",
    "title": "Floppy Disk Controller (FDC) Programming | BrokenThorn OS Dev Tutorials",
    "keywords": "Floppy Disk Controller (FDC) Programming 8272A Floppy Disk Controller Yey! Its finally time to work with the floppy drive! This chapter covers almost everything there is to know about the floppy drive and programming the floppy disk! Here is what is on the menu for this chapter: FDC and FDD History Disk Layout CHS, LBA FDD Structure FDC Hardware Interfacing with the FDC FDC registers and commands History The Floppy Disk Controller (FDC) is the controller that interfaces with the Floppy Disk Drive (FDD) . The PC useually uses a form of the NEC ?PD765 FDC . PS/2 useally uses a form of the Intel 82077A while the AT useally uses a form of the Intel 82072A microcontroller. The Floppy disk drive (FDD) is a device that is capable of reading and writing data to a floppy disk . In 1971, David L. Noble, hired by Alan Shugart, who was the IBM Direct Access Storage Product Manager, tried to develop a new storage tape format for their System/370 mainframes. IBM was looking to create something that is smaller and faster then tape drives when reloading the microcode for their Initial Control Program Load (ICPL) . Nobles team worked on a product under the code name \"Minnow\" called a \"memory disk\". It was a read only, 8 inch diskette, having the capacity of 80 kilobytes. It was commercially released in 1971 and shipped with all System/370 mainframes. When Alan Shugart left IBM and moved to Memorex, his team shipped the Memorex 650 in 1972, the first read/write floppy disk drive. Floppy disks were invented by IBM in 8 inch, 5 and 1/4 inch and 3 1/2 inch formats. Disk Structure Physical Layout Understanding the disk structure is important. Here is the layout of a floppy disk: This is the physical layout of a generic 3-1/2\" floppy disk. Here, we are looking at Head 1 (The front side), and the Sector represents 512 bytes. A Track is a collection of sectors. Note: Remember that 1 sector is 512 bytes, and there are 18 sectors per track on floppy disks. Looking at the above picture, remember: Each Track is useually divided into 512 byte sectors. On floppies, there are 18 sectors per track. A Cylinder is a group of tracks with the same radius (The Red tracks in the picture above are one cylinder) Floppy Disks have two heads (Displayed in the picture) There is 2880 Sectors total. To better understand everything, we should have a look at CHS . Lets take a look at that next! Cylinder / Head / Sector (CHS) Sectors A \"Sector\" simply represents a goupe of 512 bytes. So, Sector 1 represents the first 512 bytes of a disk. Head A \"Head\" (or Face) represents the side of the disk. Head 0 is the front side, Head 1 is the back side. Most disks only have 1 side, hence only 1 head (\"Head 1\") Track A track is one ring around the disk. In the case of floppy disks, 18 sectors span a single track. The Cylinder number represents a track number on a single disk . In the case of a floppy disk, It represents the Track to read from. There is 18 sectors per track. 80 tracks per side. Understanding CHS The floppy disk addresses using CHS format. In order to read or write from any location on disk, we must tell the FDC to move the Read/Write Head to the exact track, cylinder, and sector on the disk to read or write to. Linear Block Addressing (LBA) We can also provide a more abstract way of reading and writing to disks using Linear Block Addressing (LBA) instead. LBA allows us to be able to read or write to any sector on disk from sector 0-2880. Floppy Interfacing Software interfaces with the floppy disk drive by controlling it through a floppy disk controller. Do to differences in floppy disk controllers, I would like to focus on the original 8272A Floppy Disk Controller. The image at the beginning of this chapter shows a typical 8272A Integrated Circuit (IC) controller. This is the IC that we will look at here. Detail: 82072A Floppy Microcontroller The 8272A IC has 40 pins. Lets take a look at it here. While we will take a brief look at all 40 pins, we will not look at it in full detail here as that is when we cross into the electronics field. Most of these pins are not very useful for programming the controller. Other pins are more important to understand, however. Lets take a look. For completness sake, we will look at all of the pins brefily. You will see that the FDC indirectly communicates with both the Programmable Interrupt Controller (PIC) , the system bus, as well as the Direct Memory Access controller. RESET Pin - places the FDC in an idle state. It drives all output lines low. The Vcc pin is a +5 V power input. GND Pin - is the ground pin. CLK Pin - typical Single Phase 8 MHz Squarewave clock signal. RD Pin - tells the FDC that the current operating is a read operation. WR Pin - is simular, but for a write operation. These are set by the Control Bus in an I/O read/write operation by software. CS Pin - Chip Select DB0 - DB7 Pins - bidirectional 8 bit data bus. It connects indirectly to the systems primary Data Bus . A0 Pin - Data/Status Register Select pin. If it is high (1), it tells the FDC to place the contents in its Data Register to the data bus. If the line is low (0), it copies the contents of the Status Register to the data bus. This is done through the output data bus pins DB0 - DB7, which in turn is through the systems data bus which can be read by software. DRQ Pin - Data Direct Memory Access (DMA) Request pin. If this line is high (1), the FDC is making a DMA request. DACK Pin - DMA Acknowledge pin. When the controller is performing a DMA transfer, this line will be low (0). TC Pin - When the DMA transfer is completed, the FDC sets the Terminal Count pin, TC to high (1). IDX Pin - high when the FDC is at the beginning of a disk track. INT Pin - is high (1) when the FDC sends an Interrupt Request (IR) . This line is indirecty connected to the IR6 on the Programmable Interrupt Controller (PIC) . RW/Seek Pin - Sets seek mode of read/write mode. 1: Seek mode, 0: Read/Write mode. LCT/DIR Pin - Low current/Direction pin. FR/STP Pin - Fault reset/Step pin. HDL Pin - Head Load pin.Command causes the Read/Write head in the FDD to contact the diskette RDY Pin - Ready pin. Indicates that the FDD is ready to send or recieve data WP/TS Pin - Write protect/Two side pin. In Read/Write mode, set high if media is write protected. If seek mode, set high if media is two sided. FLT/TRK0 Pin - Fault/Track 0 pin. In Read/Write mode, set high on a detected FDD fault. PS0 - PS2 Pins - Precompensation (Pre-shift) pins. Write precompensation status during MFM mode. WR DATA Pin - Write data pin RD DATA Pin - Read data pin DS0 - DS1 Pins - Drive select pins HDSEL Pin - Head Select Pin. When high (1), the FDC sets the FDD to access Head 1. When low, it is head 0. MFM Pin - When high, FDC is in MFM mode. If low (0), it operates in FM mode. WE Pin - Write enable pin. VCO Pin - VCO Sync pin. When 0, inhibits VCO in PLL . When 1, enables VCO . DW Pin - Data Window pin. Generated by PLL, used for sample data from the FDD. WR CLK Pin - Write Clock The FDC can operate with or without a Direct Memory Access (DMA) controller . If it is operating in a non DMA mode, it will generate IRQ 6 for every transfer of a data byte between the processor and the FDC. In DMA mode, the processor will load a command into the FDC and all data transfers will occur under control of the FDC and DMA controllers. This is important! You do not need to know all of the FDC pins. Rather, just remember that the FDC communicates with three primary controllers. The first is one of possibly four Floppy Disk Drives (FDD) internal controllers, the programmable interrupt controller (PIC) , and the Direct Memory Access (DMA) controller . Software communicates with the FDC by the processors standard IN/OUT port i/o instructions. Several registers in the FDC are mapped into the processors i/o address space. As with standard I/O port reads, during an in and out operation, the processor sets the READ or WRITE line on the control bus, and the port address on the address bus. This is done on the system bus or the Industry Standard Architecture (ISA) bus. On newer hardware, the FDC is not directly connected to the ISA bus, but is rather integrated as a Super I/O IC and communicates with the processor through the Super I/O's Low Pin Count bus. Okay! We know how the software can communicate with the FDC. Where does the PIC and DMA come into play? Looking at the pin listing above, we can see that the FDC has a pin called INT . This line is indirectly connected to the Programmable Interrupt Controller IR 6 line. The FDC will pull this line high (1) whenever a byte of data is ready to be read or written. This also pulls the PIC IR 6 line high. From here, the PIC takes control. It masks out the other lines and determins if it can be services. It notifies the processor of an interrupt by activating the processors Interrupt Acknowledge (INTA) pin. After the processor verifies that it is safe to service the interrupt, it resets the INTA line to ackowledge the PIC to proceed. The PIC places the interrupt vector that this IRQ is mapped to use (set up during initializing the PIC). The processor takes the IRQ, gets its address from the idtr, and voila - our interrupt is called. The FDC can also be programmed to operate in DMA mode. The DMA is a controller that we have not looked at yet. Because of this, I do not want to get too involved with it. However we may go over it in the next chapter for completness. The FDC is connected to DMA channel 2 . Thats all there is to it for the FDC hardware. Their can be multiple FDCs inside of a computer system. Each FDC can connect up to 4 Floppy Disk Drives (FDDs). This is important! Alot of times when communicating with a FDC, you have to select which FDD that the request is for. Floppy Interface Cable The FDC communicates with a FDD through a Floppy Interface Cable , which is a form of a Parallel ATA (PATA) cable also known as an Integrated Drive Electronics (IDE) cable which evolved from Western Digital . You should notice a twist in the above cable. That will be described a little shortley. This cable has 40 pins. Through these 40 pins, the FDC can talk to different FDD's that are connected to the cable. Some registers that are used to communicate with the FDC allow you to detect the input pins of the controller and the cable. Because of this, we should probably at least take a small glance at the 40 lines of the cable. Floppy Interface Cable Pins Pin Description 0 Reset 1 Ground 2 Data pin 7 3 Data pin 8 4 Data pin 6 5 Data pin 9 6 Data pin 5 7 Data pin 10 8 Data pin 4 9 Data pin 11 10 Data pin 3 11 Data pin 12 12 Data pin 2 13 Data pin 13 14 Data pin 1 15 Data pin 14 16 Data pin 0 17 Data pin 15 18 Ground 19 Key or Vcc_in 20 DDRQ 21 Ground 22 I/O Write 23 Ground 24 I/O Read 25 Ground 26 IOCHRDY 27 Cable Select (CS) 28 DDACK 29 Ground 30 Interrupt 31 (No connection) 32 Address 1 33 GPIO_DMA66_Detect 34 Address 0 35 Address 2 36 Chip Select 1 37 Chip Select 3 38 Activity 39 Ground More to be added later. FDC Programming FDC Operating Modes Most FDC's these days are more advanced then the original 8272 microcontroller. To acheive backward compatability, newer FDC's add additional pins to the controller and allow different registers to be communicated with when operating in a specific mode. For example, the Status Register A mode is only accesable when the controller is running in PC-AT mode. Upon controller reset, the controller operates in the default 82077A mode. Waiting for an IRQ Remember that the FDC uses IRQ 6? The FDC will send a byte after the completion of a read or write command, or, depending on its mode, for every byte transferred. It will also send an IRQ when the controller is reset during initialization. For our purposes, we will be operating the FDC in a DMA mode. Basically what this means is that we will only be getting an interrupt whenever a read, write, seek, or calibrate command completes as well as during initialization. In all cases, however, this means that we will need to wait for an IRQ to fire so we know the command completes. A way for us to do this is to have the IRQ set a global when it fires, and provide an irq_wait like function that waits for the IRQ, and resets the global when it fires. Lets do that now. First the IRQ: const int FLOPPY_IRQ = 6; //! set when IRQ fires static volatile uint8_t _FloppyDiskIRQ = 0; void _cdecl i86_flpy_irq () { _asm add esp, 12 _asm pushad _asm cli //! irq fired _FloppyDiskIRQ = 1; //! tell hal we are done interruptdone( FLOPPY_IRQ ); _asm sti _asm popad _asm iretd } This looks as simple as the IRQ in the PIT, doesnt it? ðŸ˜€ Oh, right, and now we wait: //! wait for irq to fire inline void flpydsk_wait_irq () { //! wait for irq to fire while ( _FloppyDiskIRQ == 0) ; _FloppyDiskIRQ = 0; } Simple enough. So, assuming we send a command, like a read or write command, just call flpydsk_wait_irq() . When it completes, you know the command finished and its safe to continue. Cool, huh? ðŸ˜‰ DMA What? We are programming the FDC in DMA mode? But we have not covered the DMA yet! Yes, yes indeed this poses a problem. I was originally going to program the FDC in Non-DMA mode. However, while this might work in some cases, alot of emulators and even some hardware do not support it anymore. Because of this, to retain portability, I decided that the best bet is to stick with using the DMA ( Direct Memory Access Controller [DMAC]) . However, because we have not covered the DMA yet in detail, we run into a problem. I figure, rather then throwing a whole DMA interface to you without explination, we can just hack together three basic DMA routines and rewrite them more throughley later ðŸ˜‰ flpydsk_initialize_dma basically creates a buffer for the DMA to use at physical address 0x1000 - 0x10000 (64k). When we read a sector from disk, the DMA will put the sector data to this location so please be sure that nothing is there as it will be overwritten. You can choose another location if you like, however there are some rules: The buffer cannot cross 64k boundaries. It should stay at a 64k boundery for best performance The area of memory it writes to must be idenitity mapped or its frame address mapped to a page. The DMA always works with physical memory The demo uses 0x1000 + 64k for the buffer so you should keep it there if you dont feel confortable changing it. dma_read and dma_write just tells the DMA to start reading or writing the data that the FDC sends it. This will be the sector that we tell the FDC to read or write. For example, if we tell the FDC to read a sector, it will give the sector data to the DMA to be placed in the buffer that we set it to (which is at 0x1000). Cool, huh? //! initialize DMA to use phys addr 1k-64k void flpydsk_initialize_dma () { outportb (0x0a,0x06); //mask dma channel 2 outportb (0xd8,0xff); //reset master flip-flop outportb (0x04, 0); //address=0x1000 outportb (0x04, 0x10); outportb (0xd8, 0xff); //reset master flip-flop outportb (0x05, 0xff); //count to 0x23ff (number of bytes in a 3.5\" floppy disk track) outportb (0x05, 0x23); outportb (0x80, 0); //external page register = 0 outportb (0x0a, 0x02); //unmask dma channel 2 } //! prepare the DMA for read transfer void flpydsk_dma_read () { outportb (0x0a, 0x06); //mask dma channel 2 outportb (0x0b, 0x56); //single transfer, address increment, autoinit, read, channel 2 outportb (0x0a, 0x02); //unmask dma channel 2 } //! prepare the DMA for write transfer void flpydsk_dma_write () { outportb (0x0a, 0x06); //mask dma channel 2 outportb (0x0b, 0x5a); //single transfer, address increment, autoinit, write, channel 2 outportb (0x0a, 0x02); //unmask dma channel 2 } If you dont understand the above code, dont worry. Everything reguarding the DMA will be rewritten and explained in the next tutorial when we cover the DMA in more detail. FDC Port mapping The FDC has four external registers that are mapped into the i86 I/O address space. These can be accessed by software through standard I/O instructions. I bolded these registers. Some systems may provide more external registers to their FDC's then the primary four. The second FDC is typically mapped to I/O ports 0x370 - 0x377. Because there are two sets of ports for two different FDC's, this table will include both port sets. Floppy Disk Controller Ports Primary FDC Registers Port (FDC 0) Port (FDC 1) Read/Write Descripton 0x3F2 0x372 Write Only Digital Output Register (DOR) 0x3F4 0x374 Read Only Main Status Register (MSR) 0x3F5 0x375 Read / Write Data Register 0x3F7 0x377 Read Only AT only. Configuation Control Register (CCR) 0x3F7 0x377 Write Only AT only. Digital Input Register (DIR) Other FDC Registers Port (FDC 0) Port (FDC 1) Read/Write Descripton 0x3F0 0x370 Read Only PS/2 only. Status Register A (SRA) 0x3F1 0x371 Read Only PS/2 only. Status Register B (SRB) 0x3F4 0x374 Write Only PS/2 only. Data Rate Select Register (DSR) We will take a look at the registers closer - bit by bit - in the next section. Well, the important ones anyways. I may decide to update this chapter covering the other registers for completness purposes, though. For now, we will only focus on the first four registers shown above. Remember that all of this code is in the demo at the end of this chapter . enum FLPYDSK_IO { FLPYDSK_DOR = 0x3f2, FLPYDSK_MSR = 0x3f4, FLPYDSK_FIFO = 0x3f5, //data register FLPYDSK_CTRL = 0x3f7 }; Registers Status Register A (SRA) (PS2 Mode Only) You do not need to know this register. It is here for completness only. This is a read only register that monitors the state of several interface pins on the controller. It is not accessable when the controller is in PC-AT Mode. This is a read only register. The exact format of this register may depend on the model of the controller. Bit 0 DIR Bit 1 WP Bit 2 INDX Bit 3 HDSEL Bit 4 TRKO Bit 5 STEP Flip/Flop Bit 6 DRV2 Bit 7 INTERRUPT line state (interrupt pending) Warning: These bits can change between controller models. Do not worry if this register seems complex; it can be without experience in electronics. It is here for completeness only and will not be used in the series. Status Register B (SRB) (PS/2 Mode Only) You do not need to know this register. It is here for completness only. Simular to the above register, this allows us to monitor the state of several lines of the FDC. It is not accessable when the FDC is in PC-AT Mode. This is a read only register. Bit 0 MOT EN0 (Motor Enable 0) Bit 1 MOT EN1 (Motor Enable 1) Bit 2 WE Flip/Flop Bit 3 Read Data (RDDATA) Flip/Flop Bit 4 Write Data (WRDATA) Flip/Flop Bit 5 Drive Select 0 Bit 6 Undefined; Always 1 Bit 7 Undefined; Always 1 Warning: These bits can change between controller models. Do not worry if this register seems complex; it can be without experience in electronics. It is here for completeness only and will not be used in the series. Data Rate Select Register (DSR) You do not need to know this register. It is here for completness only. This is a write only register that allow you to change the timings of the drive control signals. It is used by writing to I/O port 0x3f4 (FDC 0) or 0x374 (FDC 1). This is an 8 bit register. It has the following format: Bit 0 DRATE SEL0 Bit 1 DRATE SEL1 Bit 2 PRE-COMP 0 Bit 3 PRE-COMP 1 Bit 4 PRE-COMP 2 Bit 5 Must be 0 Bit 6 POWER DOWN: Deactivates internal clocks and shuts off the internal oscillator Bit 7 S/W RESET: Reset the internal oscillator PRE-COMP 0 - PRE-COMP 2 are a little complex. These adjusts the WRDATA output pins for the bit shifting that can occur on magnetic media, such as floppy drives. To adjust the precompensation delay, we can set these bits to one of the following: 000 Default (250-500 Kbps, 125 ns. 1 Mbps, 41.67 ns) 110 250 ns 101 208.33 ns 100 166.67 ns 011 125 ns 010 83.34 ns 001 41.67 ns 111 Disabled DRATE SEL0 - DERATE SEL 1 are used to set the data rate. Valid values are shown below. 00 500 Kbps 10 250 Kbps 01 300 Kbps 11 1 Mbps Warning: Setting Data Rates greater then drive can handle may cause errors. Digital Output Register (DOR) Yey! The first useful register! This one is important to know . This is a write only register that allows you to control different functions of the FDC, such as the FDD motor control, operation mode (DMA and IRQ), reset, and drive. It has the format: Bits 0-1 DR1, DR2 00 - Drive 0 01 - Drive 1 10 - Drive 2 11 - Drive 3 Bit 2 REST 0 - Reset controller 1 - Controller enabled Bit 3 Mode 0 - IRQ channel 1 - DMA mode Bits 4 - 7 Motor Control (Drives 0 - 3) 0 - Stop Motor for drive 1 - Start Motor for drive This is an easy one! Basically when sending a command to control the functionality of the FDC, just build up a bit pattern to select what drive this is for (Remember that a single FDC can communicate with four FDD's!), the controller reset status, mode of operation (Remeber that the FDC can operate in both DMA and IRQ modes?) and the status of that particular FDD internal motor. Here is an example. Lets say we want to start up the motor for the first floppy drive (FDD 0). Starting the motor for the FDD is needed before performing any read or write operations to it! To start it, just set the bit (4-7) that corrosponds to the drive you want to start or stop the motor. Keeping all other bits at 0 will be a normal operation (IRQ mode, reset controller.) Knowing that the DOR is mapped to the processors i/o address space at port 0x3f2, this becomes very simple. First, we will create bit masks for the register to increase readability. Rememeber that all of this code is also in the demo at the end of this tutorial. enum FLPYDSK_DOR_MASK { FLPYDSK_DOR_MASK_DRIVE0 = 0, //00000000 = here for completeness sake FLPYDSK_DOR_MASK_DRIVE1 = 1, //00000001 FLPYDSK_DOR_MASK_DRIVE2 = 2, //00000010 FLPYDSK_DOR_MASK_DRIVE3 = 3, //00000011 FLPYDSK_DOR_MASK_RESET = 4, //00000100 FLPYDSK_DOR_MASK_DMA = 8, //00001000 FLPYDSK_DOR_MASK_DRIVE0_MOTOR = 16, //00010000 FLPYDSK_DOR_MASK_DRIVE1_MOTOR = 32, //00100000 FLPYDSK_DOR_MASK_DRIVE2_MOTOR = 64, //01000000 FLPYDSK_DOR_MASK_DRIVE3_MOTOR = 128 //10000000 }; Using the above bit masks, we can just bitwise OR the different bits that we would like to set. So, to start the motor for floppy drive 0: outportb (FLPYDSK_DOR, FLPYDSK_DOR_MASK_DRIVE0_MOTOR | FLPYDSK_DOR_MASK_RESET); Remember that FLPYDSK_DOR was defined ealier as 0x3f2, which is the i/o address of the DOR FDC register. The above also resets the controller. To turn this same motor off, just send the same command but without the motor bit set: outportb (FLPYDSK_DOR, FLPYDSK_DOR_MASK_RESET); Warning: Give the motor some time to start up! Remember that the internal FDD motor is mechanical. Like all mechanical devices, they tend to be slower then the speed of the running software. Because of this, whenever starting up a FDD motor, always give it a little time to spin up before attempting to read or write to it. The DOR is a write only register. To inforce this, lets create a routine for it: void flpydsk_write_dor (uint8_t val ) { //! write the digital output register outportb (FLPYDSK_DOR, val); } Lets move on to the next important register! Main Status Register (MSR) The Main Status Register (MSR) follows a gasp! specific bit format! Bet you did not see that one coming! Okay, okay, lets get back on track here (pun intended). Here is the format of the MSR: Bit 0 - FDD 0: 1 if FDD is busy in seek mode Bit 1 - FDD 1: 1 if FDD is busy in seek mode Bit 2 - FDD 2: 1 if FDD is busy in seek mode Bit 3 - FDD 3: 1 if FDD is busy in seek mode 0: The selected FDD is not busy 1: The selected FDD is busy Bit 4 - FDC Busy; Read or Write command in progress 0: Not busy 1: Busy Bit 5 - FDC in Non DMA mode 0: FDC in DMA mode 1: FDC not in DMA mode Bit 6 - DIO: direction of data transfer between the FDC IC and the CPU 0: FDC expecting data from CPU 1: FDC has data for CPU Bit 7 - RQM: Data register is ready for data transfer 0: Data register not ready 1: Data register ready This MSR is a simple one. It containes the current status information for the FDC and disk drives. Before sending a command or reading from the FDD, we will need to always check the current status of the FDC to insure it is ready. Here is an example of reading from this MSR to see if its busy. We first define the bit masks that will be used in the code. Notice how it follows the format shown above. enum FLPYDSK_MSR_MASK { FLPYDSK_MSR_MASK_DRIVE1_POS_MODE = 1, //00000001 FLPYDSK_MSR_MASK_DRIVE2_POS_MODE = 2, //00000010 FLPYDSK_MSR_MASK_DRIVE3_POS_MODE = 4, //00000100 FLPYDSK_MSR_MASK_DRIVE4_POS_MODE = 8, //00001000 FLPYDSK_MSR_MASK_BUSY = 16, //00010000 FLPYDSK_MSR_MASK_DMA = 32, //00100000 FLPYDSK_MSR_MASK_DATAIO = 64, //01000000 FLPYDSK_MSR_MASK_DATAREG = 128 //10000000 }; Easy, huh? So lets test if the FDC is busy (BUSY flag is set.) Knowing that FLPYDSR_MSR is 0x3f4, the i/o port address for the MSR, all we need to do is this: if ( inportb (FLPYDSK_MSR) & FLPYDSK_MSR_MASK_BUSY ) //! FDC is busy When sending a read or write command, all we need to do is wait until this bit is 0. Cool, huh? To make readability easier, I decided to hide this in a routine so here it is. This routine just returns the status of the FDC. uint8_t flpydsk_read_status () { //! just return main status register return inportb (FLPYDSK_MSR); } Tape Drive Register (TDR) You do not need to know this register. It is here for completness only. This register allows us to assign tape drive support to a specific drive during initialization of that drive. This is a read/write register and is 8 bits in size. However only the first two bits are defined. They both are used to select between drive 0 - 3. Selecting Drive 0 is not allowed as that is reserved for the floppy boot device. Because of this, it is not in the bit list shown below. 00: None. 01: Drive 1 10: Drive 2 11: Drive 3 Only a hardware reset will reset this register. A software reset has no effect. Do not worry if you dont know much about tape drives - this register does not apply to us and will not be used in the series. It is here only for completeness. ðŸ˜€ Data Register This is a 8 or 16 bit read/write register. The actual size of the register is specific on the type of controller. All command paramaters and disk data transfers are read to and written from the data register. This register does not follow a specific bit format and is used for generic data. It is accessed through I/O port 0x3f5 (FDC 0) or 0x375 (FDC 1). Note: Before reading or writing this register, you should always insure it is valid by first reading its status in the Master Status Register (MSR) . Remember: All command bytes and command paramaters are sent to the FDC through this register! You will see examples of this in the command section below, so dont worry to much about it yet. If an invalid command was issued, the value returned from the data register is 0x80 . The following routines read from this register and are use in the demo. It attemps to wait until the data register is safe to read or write to, then it either reads it (read_data function) or write it (send_command function). void flpydsk_send_command (uint8_t cmd) { //! wait until data register is ready. We send commands to the data register for (int i = 0; i < 500; i++ ) if ( flpydsk_read_status () & FLPYDSK_MSR_MASK_DATAREG ) return outportb (FLPYDSK_FIFO, cmd); } uint8_t flpydsk_read_data () { //! same as above function but returns data register for reading for (int i = 0; i < 500; i++ ) if ( flpydsk_read_status () & FLPYDSK_MSR_MASK_DATAREG ) return inportb (FLPYDSK_FIFO); } Digital Input Register (DIR) You do not need to know this register. It is here for completness only. Okay, there was a digital output register (DOR) so I am sure you seen this one coming ðŸ˜€ This is a read only register in all operation modes of the controller. Only bit 7 is defined when running in PC-AT Mode, all other bits are undefined and should not be used. In other operation modes, Bit 7 is undefined. Bit 7 (DSK CHG) monitors the DSK CHG pin of the FDC. Looking at our pin layout at the beginning of this chapter, you will see that there is no DSK CHG pin. This has to do with the differences between the newer FDC models and the original model. Newer models added and changed different bits in this register to monitor newer pins on the FDC, such as DMA GATE, DRATE SEL0/1, etc. The values of this register is specific to the operation mode of the FDC. Note that the bits in this register can change between models . Configuation Control Register (CCR) In PC/AT Mode, this register is known as the Data Rate Select Register (DSR) and only has the first two bits set (Bit 0=DRATE SEL0, Bit 1=DRATE SEL1.) This was listed in a table in the DSR register section. Lets take another look... 00 500 Kbps 10 250 Kbps 01 300 Kbps 11 1 Mbps Bit 2 is NOPREC in Model 30/CCR modes and has no function. Other bits are undefined and may change depending on controller. Like the other registers, I created a routine so we can write to this register. void flpydsk_write_ccr (uint8_t val) { //! write the configuation control outportb (FLPYDSK_CTRL, val); } Commands Abstract Commands are used to control a FDD connected to the FDC for different operations, like reading and writing. They are written to the data register over the data bus (D0-D7) pins during a write operation (IO and WRITE control lines are set on the control bus.) In other words, a OUT assembly language instruction to the data register at port 0x3f5 (FDC 0) or 0x375 (FDC 1.) Warning: Before sending a command or paramamter byte, insure the data register is ready to recieve data by testing bit 7 of the Main Status Register (MSR) first. There are thirteen (or more depending on controller) commands. Each command can be 1 to 9 bytes in size. The FDC knows how many bytes to expect from the first command byte. That is, the first byte is the actual command that tells the FDC what we want it to do. The FDC knows how many more bytes to expect from this command (The command paramaters.) Commands will only operate on a single head of the track. If you want to operate on both heads, you need to set the Multiple Track Bit . Alot of these commands follow bit formats (Will be shown below). This is where things get complicated. A command byte only uses the low 4 bits of the byte for the actual command (can be more.) The high bits of these command bytes are for optional settings for the command. I call these extended command bits but it does not have an official name. There is a couple of these bits that are common for alot of the commands that we will need to use. We will look at these bits in the command byte later. Okay, first lets take a look the command listing. We will then look at each one separately. Notice how they all only use the first 4 bits of the command byte. enum FLPYDSK_CMD { FDC_CMD_READ_TRACK = 2, FDC_CMD_SPECIFY = 3, FDC_CMD_CHECK_STAT = 4, FDC_CMD_WRITE_SECT = 5, FDC_CMD_READ_SECT = 6, FDC_CMD_CALIBRATE = 7, FDC_CMD_CHECK_INT = 8, FDC_CMD_WRITE_DEL_S = 9, FDC_CMD_READ_ID_S = 0xa, FDC_CMD_READ_DEL_S = 0xc, FDC_CMD_FORMAT_TRACK = 0xd, FDC_CMD_SEEK = 0xf }; To send a command to the FDC, remember that we have to write it to the data register, aka the FIFO. To do this, we first need to wait until the data register is ready by checking the bit in the MSR. Assuming flpydsk_read_status () just returns the value from the MSR, lets hide all of this inside of a simpler method: void flpydsk_send_command (uint8_t cmd) { //! wait until data register is ready. We send commands to the data register for (int i = 0; i < 500; i++ ) if ( flpydsk_read_status () & FLPYDSK_MSR_MASK_DATAREG ) return outportb (FLPYDSK_FIFO, cmd); } Extended Command Bits Some of these commands require you to pass several bytes before the command is executed. Others return several bytes. To make things easier to read, I have listed all of the commands, formats, and paramater bytes in tables. Each command comes with an explination and an example routine. Okay, now remember when we mentioned exteneded command bits and how the commands above are only four bits? The upper four bits can be used for different things and purposes. When describing the format of a command, we represent an extended bit with a character (like M or F.) For example, the Write Sector command has the format M F 0 0 0 1 1 0, where the first four bits (0 1 1 0) are the command byte and the top four bits, M F 0 0 represent different settings. M is set for multitrack, F to select what density mode to operate in for the command. Here is a list of common bits: M - MultiTrack Operation 0: Operate on one track of the cylinder 1: Operate on both tracks of the cylinder F - FM/MFM Mode Setting 0: Operate in FM (Single Density) mode 1: Operate in MFM (Double Density) mode S - Skip Mode Setting 0: Do not skip deleted data address marks 1: Skip deleted data address marks HD - Head Number DR0 - DR1 - Drive Number Bits (2 bits for up to 4 drives) The M, F, and S bits are very common to alot of the commands, so I decided to stick them in a nice enumeration. To set them, just bitwise OR these settings with the command that you would like to use. enum FLPYDSK_CMD_EXT { FDC_CMD_EXT_SKIP = 0x20, //00100000 FDC_CMD_EXT_DENSITY = 0x40, //01000000 FDC_CMD_EXT_MULTITRACK = 0x80 //10000000 }; GAP 3 GAP 3 referrs to the space between sectors on the physical disk. It is a type of GPL (Gap Length) . enum FLPYDSK_GAP3_LENGTH { FLPYDSK_GAP3_LENGTH_STD = 42, FLPYDSK_GAP3_LENGTH_5_14 = 32, FLPYDSK_GAP3_LENGTH_3_5 = 27 }; Some commands require us to pass the GAP 3 code, so there it is ðŸ˜€ Bytes Per Sector Some commands require us to pass in the bytes per sector. These cannot be any size, however, and always follows a formula: 2^n * 128, where ^ denotes \"to the power of\" n is a number from 0-7. It cannot go higher then 7, as 2^7 * 128 = 16384 (16 kbytes). It is possible to select up to 16 Kbytes per sector on the FDC. Most drives may not support it, however. Our list has the most common: enum FLPYDSK_SECTOR_DTL { FLPYDSK_SECTOR_DTL_128 = 0, FLPYDSK_SECTOR_DTL_256 = 1, FLPYDSK_SECTOR_DTL_512 = 2, FLPYDSK_SECTOR_DTL_1024 = 4 }; ...So, if a command requires us to pass the number of bytes per sector, dont put 512! rather, put FLPYDSK_SECTOR_DTL_512, which is 2. How to pass paramaters to commands If you recall, alot of commands require us to pass paramaters to it. To pass the paramaters, simply send them the same way the command was sent. For example, the specify command requires us to pass two paramaters to it. The command wont start without it so... flpydsk_send_command (FDC_CMD_SPECIFY); flpydsk_send_command (data); flpydsk_send_command (data2); Thats all there is to it ðŸ˜‰ How to get return values from commands Unlike functions in programming in which you can ignore return values, the FDC requires for them to be processed in some way. Granted, you can still ignore them, but you must get them from the FDC. The FDC wont allow any more commands until it is done. If the command returns data, it will be returned -- one at a time -- in the FIFO (Data register). So, to read them, you must continually read the FIFO to get all of the returned data. Note: If a command returns data, it will send an interrupt that you must wait for. This is how you will know when the command is done and that it is safe to read the return values from the FIFO. A good example of return values is the read sectors command. It requires us to wait for an IRQ so we know it completes, and returns 7 bytes. So to read all of the returned data bytes, we have to read from the data register one at a time: for (int j=0; j<7; j++) flpydsk_read_data (); Of course, for error checking purposes you should actually check some of the return values. Write Sector Format: M F 0 0 0 1 1 0 Paramaters: x x x x x HD DR DR0 Cylinder Head Sector Number Sector Size Track Length Length of GAP3 Data Length Return: Return byte 0: ST0 Return byte 1: ST1 Return byte 2: ST2 Return byte 3: Current cylinder Return byte 4: Current head Return byte 5: Sector number Return byte 6: Sector size This command reads a sector from a FDD. For every byte in the sector, the FDC issues interrupt 6 and places the byte read from the disk into the data register so that we can read it in. Read Sector Format: M F S 0 0 1 1 0 Paramaters: x x x x x HD DR1 DR0 = HD=head DR0/DR1=Disk Cylinder Head Sector Number Sector Size Track Length Length of GAP3 Data Length Return: Return byte 0: ST0 Return byte 1: ST1 Return byte 2: ST2 Return byte 3: Current cylinder Return byte 4: Current head Return byte 5: Sector number Return byte 6: Sector size This command reads a sector from a FDD. For every byte in the sector, the FDC issues interrupt 6 and places the byte read from the disk into the data register so that we can read it in. The following is the routine used in the demo. It first sets up the DMA to prepare for a read operation. It then executes the read sector command (FDC_CMD_READ_SECT) setting the commands M, F, and S bits with it (Multitrack read, double density, skip deleted address marks. Please see above for a list of all of these.) Afterwords, it passes all of the commands paramaters to it to begin the read command. The sector size paramater is FLPYDSK_SECTOR_DTL_512 (bytes per sector), which, if you recall, is the value 2 (Please see the above Bytes per sector section for details.) Next paramater is the sectors per track (18). The next paramater is the GAP 3 length. We pass the value of the standard 3-1/2\" floppy disk GAP 3 length (FLPYDSK_GAP3_LENGTH_3_5, which is 27). The Data Length paramater byte is only valid if the sector size is 0. Else, it should be 0xff. Because this command sends an IRQ after completion, we need to wait for the IRQ. void flpydsk_read_sector_imp (uint8_t head, uint8_t track, uint8_t sector) { uint32_t st0, cyl; //! set the DMA for read transfer flpydsk_dma_read (); //! read in a sector flpydsk_send_command ( FDC_CMD_READ_SECT | FDC_CMD_EXT_MULTITRACK | FDC_CMD_EXT_SKIP | FDC_CMD_EXT_DENSITY); flpydsk_send_command ( head << 2 | _CurrentDrive ); flpydsk_send_command ( track); flpydsk_send_command ( head); flpydsk_send_command ( sector); flpydsk_send_command ( FLPYDSK_SECTOR_DTL_512 ); flpydsk_send_command ( ( ( sector + 1 ) >= FLPY_SECTORS_PER_TRACK ) ? FLPY_SECTORS_PER_TRACK : sector + 1 ); flpydsk_send_command ( FLPYDSK_GAP3_LENGTH_3_5 ); flpydsk_send_command ( 0xff ); //! wait for irq flpydsk_wait_irq (); //! read status info for (int j=0; j<7; j++) flpydsk_read_data (); //! let FDC know we handled interrupt flpydsk_check_int (&st0,&cyl); } ...After the IRQ fires, we read in all 7 return bytes. Then we send a SENSE_INTERRUPT command with flpydsk_check_int () which tells the FDC that we have handled the interrupt. (Please see the Check Interrupt Status section below.) Wait... Where is the data at? Looking at the above command, we dont tell the FDC will to put the data at. This poses an interesting problem, dont you think? Depending on the FDCs mode of operation, in Non-DMA mode, it will fire IRQ 6 for every byte. The byte of data read from disk is in the FIFO. In DMA mode (where we are in), it will give the data to the DMA, which will put the data into a buffer (wherever location we told the DMA to put it at.) So, in our case, we set up the DMA buffer to 0x1000, remember? After calling the above routine, the sector data will be at 0x1000! Cool, huh? We can change its location by giving the DMA a different address. Fix Drive Data / Specify Format: 0 0 0 0 0 0 1 1 Paramaters: S S S S H H H H - S=Step Rate H=Head Unload Time H H H H H H H NDM - H=Head Load Time NDM=0 (DMA Mode) or 1 (DMA Mode) Return: None This command is used to pass controlling information to the FDC about the mechanical drive connected to it. To make working with this command easier, lets write a routine for it: void flpydsk_drive_data (uint32_t stepr, uint32_t loadt, uint32_t unloadt, bool dma ) { uint32_t data = 0; flpydsk_send_command (FDC_CMD_SPECIFY); data = ( (stepr & 0xf) << 4) | (unloadt & 0xf); flpydsk_send_command (data); data = (loadt) << 1 | (dma==true) ? 1 : 0; flpydsk_send_command (data); } Check Status Check Status Format: 0 0 0 0 0 1 0 0 Paramaters: x x x x x HD DR1 DR0 Return: Byte 0: Status Register 3 (ST3) This command returns the drive status. Calibrate Drive Format: 0 0 0 0 0 1 1 1 Paramaters: x x x x x 0 DR1 DR0 Return: None This command is used to position the read/write head to cylinder 0. After completion, the FDC issues an interrupt. If the disk has more then 80 tracks, you may need to issue this command several times. After issuing this command, always check to insure it is on the right track ( Check Interrupt Status command.) If, after the command, we are not on cylinder 0 yet, we issue the command again. When we find cylinder 0, we turn the motor off and return success. If we dont fine it after 10 tries we bail. Note that we have to insure that the motor is running during this command. Also notice how we use the SENSE_INTERRUPT command (the flpydsk_check_int () call) to abtain the current cylinder. int flpydsk_calibrate (uint32_t drive) { uint32_t st0, cyl; if (drive >= 4) return -2; //! turn on the motor flpydsk_control_motor (true); for (int i = 0; i < 10; i++) { //! send command flpydsk_send_command ( FDC_CMD_CALIBRATE ); flpydsk_send_command ( drive ); flpydsk_wait_irq (); flpydsk_check_int ( &st0, &cyl); //! did we fine cylinder 0? if so, we are done if (!cyl) { flpydsk_control_motor (false); return 0; } } flpydsk_control_motor (false); return -1; } Check Interrupt Status Format: 0 0 0 0 1 0 0 0 Paramaters: None Return: Byte 0: Status Register 0 (ST0) Byte 1: Current Cylinder This command is used to check information on the state of the FDC when an interrupt returnes. void flpydsk_check_int (uint32_t* st0, uint32_t* cyl) { flpydsk_send_command (FDC_CMD_CHECK_INT); *st0 = flpydsk_read_data (); *cyl = flpydsk_read_data (); } Seek / Park Head Format: 0 0 0 0 1 1 1 1 Paramaters: x x x x x HD DR1 DR0 - HD=Head DR1/DR0 = drive Cylinder Return: None This command is used to move the read/write head to a specific cylinder. Simular to the calibrate command, we may need to send the command multiple times. Notice the call to check_int () to get the current cylinder after every attempt. We then test if the current cylinder is the cylinder we are looking for. If it is not, we try again. If it is, we return success. int flpydsk_seek ( uint32_t cyl, uint32_t head ) { uint32_t st0, cyl0; if (_CurrentDrive >= 4) return -1; for (int i = 0; i < 10; i++ ) { //! send the command flpydsk_send_command (FDC_CMD_SEEK); flpydsk_send_command ( (head) << 2 | _CurrentDrive); flpydsk_send_command (cyl); //! wait for the results phase IRQ flpydsk_wait_irq (); flpydsk_check_int (&st0,&cyl0); //! found the cylinder? if ( cyl0 == cyl) return 0; } return -1; } Invalid Commands If an invalid command is sent to the FDC, the FDC ignores it and goes into standy mode. Resetting the FDC Disabling the Controller If the DOR RESET line is low, the controller will be in a disabled state. In other words, just write 0 to the DOR register to disable the controller: void flpydsk_disable_controller () { flpydsk_write_dor (0); } Enabling the Controller To enable the controller, set the RESET line high in DOR. Also, because we want the FDC to operate in DMA mode, you must also set that bit in DOR: void flpydsk_enable_controller () { flpydsk_write_dor ( FLPYDSK_DOR_MASK_RESET | FLPYDSK_DOR_MASK_DMA); } When the controller is enabled after being disabled, it will issue an interrupt. During this time, you must reinitialize the controller and drive configuation. Initializing the FDC During a controller reset, you need to reinitialize the controller. After resetting the controller, it will fire IRQ 6. After it has been fired, you must send a SENSE_INTERRUPT command to all drives connected to the FDC (by calling flpydsk_check_int 4 times.) Afterwords its time to reconfigure the controller. Remember that the CCR (Configuation Control Register) only has 2 bits for the data rate. By setting both to 0, we set the data rate to 500 Kbps, which is a nice default value. Then we call flpydsk_drive_data which sends a Fix Drive Data / Specify command to the controller to set the drives mechanical information, including: Step rate, head load and unload time, and if it supports DMA mode or not. Then we recalibrate the drive so it is on cylinder 0. void flpydsk_reset () { uint32_t st0, cyl; //! reset the controller flpydsk_disable_controller (); flpydsk_enable_controller (); flpydsk_wait_irq (); //! send CHECK_INT/SENSE INTERRUPT command to all drives for (int i=0; i<4; i++) flpydsk_check_int (&st0,&cyl); //! transfer speed 500kb/s flpydsk_write_ccr (0); //! pass mechanical drive info. steprate=3ms, unload time=240ms, load time=16ms flpydsk_drive_data (3,16,240,true); //! calibrate the disk flpydsk_calibrate ( _CurrentDrive ); } After a reset, the drive is ready to be used by us. Demo FDC Demo in action Demo Download Note: There is a known bug in the demo that causes VPC to only read the first sector read. This will be resolved as soon as possible. No known issues when running in Bochs. Updates and Changes String to int convertion - stdio.h/stdio.cpp In order to make this demo more interactive, I included three functions in the standard library that are used for converting strings into integers. This includes strtol , strtoul and atoi . The demo uses atoi to convert a string entered from the user into a useable integer. Installing the floppy driver - flpydsk.cpp The floppy driver comes with a nice install routine that allows the demo to easily set it up. All it does is install our interrupt handler using our HAL's setvect () routine, initializes the DMA for transfers, and resets the controller so it is ready for use. void flpydsk_install (int irq) { //! install irq handler setvect (irq, i86_flpy_irq); //! initialize the DMA for FDC flpydsk_initialize_dma (); //! reset the fdc flpydsk_reset (); //! set drive information flpydsk_drive_data (13, 1, 0xf, true); } The demo calls this function during initialization to set up the driver before attempting to read from it. Reading any sector - LBA and CHS - flpydsk.cpp The driver hides the details of CHS behind two nice functions. Knowing that the drive works in CHS (Cylinder/Head/Sector) and does not know anything about LBA (Linear Block Addressing), we should provide a routine to convert between these two. This way we can just pass in a sector number to read or write to/from without worry of what physical CHS it is at. Remember the formula to convert LBA to CHS? Lets apply it here: void flpydsk_lba_to_chs (int lba,int *head,int *track,int *sector) { *head = ( lba % ( FLPY_SECTORS_PER_TRACK * 2 ) ) / ( FLPY_SECTORS_PER_TRACK ); *track = lba / ( FLPY_SECTORS_PER_TRACK * 2 ); *sector = lba % FLPY_SECTORS_PER_TRACK + 1; } FLPY_SECTORS_PER_TRACK is 18. Great! So now we can just call this function to convert any linear sector number into a CHS location! Cool, huh? Because we are wanting to be able to read any sector from disk, we can provide a routine for just that. And because we already have flpydsk_read_sector_imp , which containes the code to send the read command to the controller, this routine is very simple. uint8_t* flpydsk_read_sector (int sectorLBA) { if (_CurrentDrive >= 4) return 0; //! convert LBA sector to CHS int head=0, track=0, sector=1; flpydsk_lba_to_chs (sectorLBA, &head, &track, Â§or); //! turn motor on and seek to track flpydsk_control_motor (true); if (flpydsk_seek (track, head) != 0) return 0; //! read sector and turn motor off flpydsk_read_sector_imp (head, track, sector); flpydsk_control_motor (false); //! warning: this is a bit hackish return (uint8_t*) DMA_BUFFER; } Whenever the demo wants to read a sector, it calls this routine. This routine converts the sector into a physical location on disk (CHS). It turns the motor on and seeks to the cylinder that this sector is on. After words, it calls flpydsk_read_sector_imp to perform the magic of actually reading the sector and turns the motor off afterwords. After the flpydsk_read_sector_imp call, the data for the sector should be in the DMA buffer. We return a pointer to this buffer, which now containes the sector data just read. Cool, huh? This is the magical routine that ties everything together ðŸ˜€ New Read Command - main.cpp This demo builds on the last demo. Because of this, it keeps the command line interface (CLI) that was built in the previous demo. This also makes this demo the most complex demo yet. I have added a new command to our list of commands in the CLI - read - that allows us to read any sector off disk. It uses out floppy driver built in this tutorial to do it. The command is inside of a function and is executed in the demo by typing read . It dumps the 512 bytes into 4 128-byte blocks for readability. After each block, you will be prompted to press a key to continue with the next chunk. It uses the new atoi function to convert the sector number entered (which is an LBA sector number) into an int, and reads it in. This, dear readers, is the function that makes the magic happen: void cmd_read_sect () { uint32_t sectornum = 0; char sectornumbuf [4]; uint8_t* sector = 0; DebugPrintf (\"\\n\\rPlease type in the sector number [0 is default] >\"); get_cmd (sectornumbuf, 3); sectornum = atoi (sectornumbuf); DebugPrintf (\"\\n\\rSector %i contents:\\n\\n\\r\", sectornum); //! read sector from disk sector = flpydsk_read_sector ( sectornum ); //! display sector if (sector!=0) { int i = 0; for ( int c = 0; c < 4; c++ ) { for (int j = 0; j < 128; j++) DebugPrintf (\"0x%x \", sector[ i + j ]); i += 128; DebugPrintf(\"\\n\\rPress any key to continue\\n\\r\"); getch (); } } else DebugPrintf (\"\\n\\r*** Error reading sector from disk\"); DebugPrintf (\"\\n\\rDone.\"); } Conclusion Yeesh, this is a long tutorial. I might be making some changes to help improve it and make it better and more complete. ðŸ˜€ In the next tutorial, we will be looking at the DMA. We will create an interface for programming the DMA and better use it in the FDC driver. After all of this...I suppose its filesystems again (ugh). Dont worry - After that it is Multitasking!"
  },
  "articles/61_unorganised_tutorial/T21.html": {
    "href": "articles/61_unorganised_tutorial/T21.html",
    "title": "8237A ISA DMAC Programming | BrokenThorn OS Dev Tutorials",
    "keywords": "8237A ISA DMAC Programming Note: From here on out, demo names will follow the format Demo00, where 00 is the chapter name. This is to help the current issue with demo names and chapter names not being related to each other and to help make it easier for readers to know what chapter a particular demo refers to. Older chapters will be updated with this setup. Once all chapters have been updated this comment will be removed. Also note: The Virtual PC bug has been fixed in this chapter but not the previous chapter yet. While the previous chapters demo does not work well in Virtual PC, this chapters demo seems to work fine with a minor bug fix and update in the DMA code. This demo has been tested and works on Virtual PC and Bochs. Once the previous chapter has been updated with this fix, this comment will be removed. Welcome! ðŸ˜€ In this chapter, we will take a close look at the Direct Memory Access Controller (DMAC) . The DMAC provides us a way to transfer blocks of data from a device directly into memory without the software doing it. This allows for a very fast way of transferring data as it is the hardware doing it - not the software. Here is on the list for today: DMA History DMA Hardware DMA Ports DMA Registers DMA Commands Abstract Direct Memory Access (DMA) is a feature in all modern computers that allow devices to be able to move large blocks of data without any interaction with the processor. This can be useful, as you may have already seen from the floppy programming chapter. While the device transfers the block of data, the processor is free to continue running the software without worry about the data being transferred into memory, or to another device. The basic idea is that we can schedule the DMA device to perform the task on its own. Cool, huh? Different buses and architecture designs have different methods of performing direct memory access. While our focus at this time will be the ISA Direct Memory Access Controller (DMAC) I decided to address the other methods as well for completeness. ISA The Industry Standard Architecture (ISA) provides a centric location for DMA requests through a controller based off of the Intel 8237 Microcontroller . In the ATX motherboard designs, there was only a single controller. Do to the limitations of a controller only supporting 8 devices, however, in AT and newer architectures there are two controllers. They are slaved together, in a similar way the Programmable Interrupt Controllers (PIC) are slaved together. Both controllers always run at 4MHz. Because of their performance and limited number of devices, newer devices tend to us PIO or UDMA instead. DMA is still supported in ISA for legacy devices however. All of these devices are connected to Channels on the controller. Along with these channels, each channel has a DACK (DMA Acknowledge) line and a DRQ (DMA Request) . Here are the standard assignments on both Direct Memory Access Controllers (DMAC) . XT: Channel 0: Used by system, not available (DRAM Refresh, obsolete) Channel 1: Available, no standard DMA assignment Channel 2: Floppy Disk Controller Channel 3: Hard Disk Controller (PIO or UDMA recommended instead) AT only: Channel 4: Cascaded to XT controller - Slave DMA controller input into Master Channel 5: Available, no standard DMA assignment (16 bit) Channel 6: Available, no standard DMA assignment (16 bit) Channel 7: Available, no standard DMA assignment (16 bit) To start a transfer, the software sets the channels address and count registers to the location in physical memory where the transfer is to be completed, and the size of the transfer. Afterwords it sets to either read or write from that block of memory and then sets the controller on its way to complete the transfer. After the transfer completes, the device that started the transfer issues an Interrupt Request (IRQ) to be caught by the system software for further processing. This is important! These are the steps that we will need to perform when using the DMA to start transfers. PCI PCI devices do not share the same DMA controller, nor have a central DMA controller. Instead, a PCI device on the PCI Local Bus requests to be the Bus Master (taking control of the bus) from the PCI Bus Controller . Afterwords, a request to read or write to or from physical memory is passed to the northbridge which will convert the request into memory operations and send the operations to the Memory Controller . PCI transfers are limited to 4GB physical memory. However if the device and the PCI bridge impliments Double Address Cycle (DAC) or similar technology, it will allow the PCI controller to initiate requests for reading and writing beyond 4GB physical memory. ISA DMA Hardware Direct Memory Access Controller (DMAC) The Industry Standard Architecture (ISA) uses a controller based off of the original Intel 8237 DMA chip. Most newer DMACs provide more features, but are almost entirely backward compatable with the 8237 microcontroller. While new PCs have a more advanced form of the DMAC, it is always nice to look at the device that started it all, so here it is, the original 8237A controller pin diagram when distributed in a Dual Inline Package (DIP) : Thats it - the controller that we will be programming in this chapter. THere are alot of pins, but its not too complex. Lets look at them, and focus on the important ones. Pin 1 (IOR) I/O Read Pin 2 (IOW) I/O Write Pin 3 (MEMR) Memory Read Pin 4 (MEMW) Memory Write Pin 5 Pin 6 (READY) Pin 7 (HACK) Hold Acknowledge Pin 8 (ADSTB) Address Strobe Pin 9 (AEN) Address Enable Pin 10 (HREQ) Hold Request Pin 11 (CS) Chip Select Pin 12 (CLK) Clock Pin 13 (RESET) Reset Pins 14-15 (DACK) DMA Ackowledge Pins 16-19 (DREQ0-DREQ3) DMA Request Pin 20 (GND/Vss) Ground Pins 21-23 (DB0-DB3) Data Bus Pins 24-25 (DACK) DMA Ackowledge Pins 26-30 (DB4-DB7) Data Bus Pin 31 (Vcc) +5 volt power Pins 32-35 (A0-A3) Address Lines Pin 36 (EOP) End Of Process Pins 37-40 (A4-A7) Address Lines This one is not too bad. We have Pin 20 for the ground, and pin 31 for the power source. Pin 12 (CLK) is another common one we see on all controllers. It connects to the processors CLK pin for input clock signals: controlling the timing of operations within the controller. The CS (Chip Select) pin is another common one we see on almost all controllers. Its used to select the controller as an I/O device on the data bus. RESET resets the controllers internal registers (Status, Request, Temporary, Command), clears the internal flip-flop and sets the mask register. Nothing much new so far, huh? We have the gerneric address lines, A0-A7 , which connect to the systems address bus. During inputs, the CPU is only able to write data to A0-A3 to select registers to read from. All pins are used for outputs (to a physical memory address) but are only activated during a DMA request. Last but not least is the generic D0-D7 pins that connect to the systems data bus. Now for the more interesting pins. So far we have seen that the DMAC connects to the systems address and data bus. Alot of our readers probably are not too surprised about that. As you can probably guess, however, the DMAC needs direct attention from the CPU. Because of this, there are some lines that connect to the CPU so that the DMAC can communicate with the CPU and vice-versa. This is done with the HACK and HREQ pins. HACK (Hold Acknowledge) is held high when the CPU has given the DMAC full control of the system bus. This allows the DMAC to know when it is safe to transmit data to the memory controller. After all, we cannot have both the DMAC and processor trying to use the same system bus at the same time, can we? This creates an important note: The DMAC transmits data directly into physical memory only when the system bus is not currently being used by the processor. The DMAC will need the system bus to transmit data to the memory controller for memory translation and reading/writing to physical memory. Okay, so the CPU has a way to tell the DMAC the system bus can be taken over. Great, but how does the DMAC tell the CPU it needs the system bus in the first place? Thats what the HREQ (Hold Request) line is for. When an DMA Request (DRQ) is triggered by a device connected to the DMA (such as a floppy controller), and that \"channel\" is currently not disabled, the controller puts HREQ to high on the next clock cycle to notify the CPU that it needs control of the system bus in order to complete the request. The lines DR0-DR3 (DMA Request Lines) are used by devices to notify the DMA of a request. For example, the Floppy Drive Controller (FDC) is usually connected to use DR2 (\"Channel 2\"). So, when we have enabled that channel and programmed the FDC to use the DMAC, when a read or write command is sent to the FDC, the FDC will activate the RQ2 line notifying the DMAC that it requires attention. From here everything is done through the DMAC to read or write depending on the mode that we programmed that channel to be in. This creates another important point. Knowing that there are only 4 DRQ lines: Only 4 devices can be connected to a single DMAC. This is pretty limited, huh? In the i86 architecture, the problem has been somewhat solved by attaching two DMACs together. We will look at that shortley. Everything is looking good so far! Knowing that our software instructs the CPU to program the DMAC, how does the CPU tell the DMAC that we are in needing to read or write from a register? Thats the IOR (I/O Read) and IOW (I/O Write) pins. In a similar way, the DMAC tells the memory controller that it will be reading or writing by activating the memory read or write control lines by outputting through MEMR (Memory Read) or MEMW (Memory Write) . EOP (End Of Process) is used to signal a device when the request has been completed. A request is completed when that channels Terminal Count (TC) has been reached. This is a programmable counter value. AEN (Address Enable) is used to signal the controller to load its internal 8 bit address latch register into the systems address bus. ADSTB (Address Strobe) is used to strobe the upper address byte into an external latch register. Alot of things, huh? The exact details of the operations that the controller takes depends on the mode that it is in and the transfer type. It uses the same basic steps though: A device notifies the DMAC, the DMAC notifies the CPU for control over the system bus. The DMAC waits for control. When it gets it, it loads the channels address register into its internal latch register. From there, it will either set MEMR, MEMW, and read or write from memory as needed. Wait, what? I am sure you can see how it can read from memory, but if it writes it, where does it go? Look back at the [FDC chapter] (fix link OSDev20.html) again. Notice how it also has pins D0-D7 that connect to the same data bus that the DMAC, CPU, Memory Controller, and other devices see? So, when writing from memory all it needs to do is activate its MEMR line, upload the address to the address bus, the memory controller translates and places the data on the data bus. Because the FDC is waiting for a write request, it will grab the data read, and write to disk set up by the write command that was sent to the FDC. When reading from disk, its basically the same way buth the DMAC will activate the MEMW line instead. The memory controller grabs the data to be written from the data bus sent by the FDC. When all is good to go, the DMAC releases the HREQ line on the processor which gives the CPU full control of the bus again. Its important to note that the processor cannot wait for the DMAC to finish. The CPU will bring the HACK line to low when it needs access to the system bus again. During these periods, the DMAC will have no choice but to wait until the line is high again to continue its process. And there you go, dear readers! As you recall, in the i86 architecture things are a little different. i86 added another DMAC to the mix to bring the number of channels that can be used to 8. Well, sort of. Lets take a look! DMAC in x86 Remember that newer PCs have two DMACs? Both DMACs are connected in a similar way that the two PICs are connected together...Only backwards. Huh!? I know, I know. ðŸ˜€ Lets take a look: The DMAC uses the HOLD and HLDA (Hold Acknowledge) pins on the processor when taking control of the ISA bus. The DMAC signals the processor through HOLD, and the processor acknowledges this request through HDLA. Also note how the second (slave) containes DRQ's 0-3 while the primary DMAC has DRQ's 5-7. A DRQ is a DMA Request . These lines connect the DMAC to different devices in the system that use it. Whenever a device requests the DMACs attention, it raises the line to high to signal the DMAC. Look at the image again and you might see something interesting: Where is DRQ4? DRQ4 does exist on both of the devices, but are what connects each DMAC. They are shown in the image (not labeled). Because DRQ lines are used to signal the DMAC, this allows the primary and secondary DMACs to signal each other to raise correct DRQ lines. This means when programming the DMACs, we have to remember that DRQ4 is used to connect the primary and slave controllers. Because of this we cannot use it. Looking back at the image above, we also see an OR Gate that will output true if either the primary or slave DMACs are complete (they raise their TC (Terminal Count) line). The TC line will raise when the transfer request that was sent to the DMAC has been completed. Okay, so lets put everything important that we need to remember here for reference. The DMA always works in physical memory, never virtual memory Only 8 devices can be connected to use the DMACs on the i86 architecture. DRQ4 (Channel 4) is used to connect the primary and secondary DMACs and cannot be used. You may also see something interesting about how these are configured. We have the slave DMAC which is the first DMAC that connects to the Master DMAC, not the other way around. This will explain why the slave DMAC is responsible for channels 0-3 (and technically 4, which is used to connect to the primary DMAC) and the primary DMAC is responsible for the channels 5-7. Kind of weird, huh? In this way, its somewhat different then the way the two PICs work together. It is also important to note, do to the way these controllers are connected together, the master DMAC acts like a 16 bit DMAC while the slave DMAC acts like an 8 bit DMAC . Because of this: The first DMAC is the slave (8 bit), the second is Master (16 bit) ISA DMA Interface Port Mapping Because there are two DMA controllers, there are two sets of ports. Generic Registers ISA DMAC Ports table DMAC 0 Port (Slave) DMAC 1 Port (Master) Descripton 0x08 0xD0 Status Register (Read) 0x08 0xD0 Command Register (Write) 0x09 0xD2 Request Register (Write) 0x0A 0xD4 Single Mask Register (Write) 0x0B 0xD6 Mode Register (Write) 0x0C 0xD8 Clear Byte Pointer Flip-Flop (Write) 0x0D 0xDA Intermediate Register (Read) 0x0D 0xDA Master Clear (Write) 0x0E 0xDC Clear Mask Register (Write) 0x0F 0xDE Write Mask Register (Write) These registers will be described in more detail in the next section. These registers are used when interacting with both DMACs. They can be read or written to through port mapped I/O. That is, using standard i86 in and out instructions. It is very important to remember that DMACs are backwards. DMAC 0 is the slave while DMAC 1 is the master . Also note how the port ranges are different. Remember that the slave is 8 bit, while the master is 16 bit? To help readability, lets abstract these ugly numbers in an enumeration: enum DMA0_IO { DMA0_STATUS_REG = 0x08, DMA0_COMMAND_REG = 0x08, DMA0_REQUEST_REG = 0x09, DMA0_CHANMASK_REG = 0x0a, DMA0_MODE_REG = 0x0b, DMA0_CLEARBYTE_FLIPFLOP_REG = 0x0c, DMA0_TEMP_REG = 0x0d, DMA0_MASTER_CLEAR_REG = 0x0d, DMA0_CLEAR_MASK_REG = 0x0e, DMA0_MASK_REG = 0x0f }; Notice that these values match up with the table above. Now for DMAC 2... enum DMA1_IO { DMA1_STATUS_REG = 0xd0, DMA1_COMMAND_REG = 0xd0, DMA1_REQUEST_REG = 0xd2, DMA1_CHANMASK_REG = 0xd4, DMA1_MODE_REG = 0xd6, DMA1_CLEARBYTE_FLIPFLOP_REG = 0xd8, DMA1_INTER_REG = 0xda, DMA1_UNMASK_ALL_REG = 0xdc, DMA1_MASK_REG = 0xde }; Now on with the registers! Channel Registers Along with the above registers, the i86 makes available the following registers that allow us to control the address and counters of each channel: ISA DMAC Channel Ports table DMAC 0 Port (Slave) DMAC 1 Port (Master) Descripton 0x0 0xC0 Channel 0 Address/Channel 4 Address 0x1 0xC2 Channel 0 Counter/Channel 4 Counter 0x2 0xC4 Channel 1 Address/Channel 5 Address 0x3 0xC6 Channel 1 Counter/Channel 5 Counter 0x4 0xC8 Channel 2 Address/Channel 6 Address 0x5 0xCA Channel 2 Counter/Channel 6 Counter 0x6 0xCC Channel 3 Address/Channel 7 Address 0x7 0xCE Channel 3 Counter/Channel 7 Counter Look at the table above again. Channel 0 Address on the master DMAC is at .. what? port 0! This is a historical moment in this series as we have found i/o port 0. ðŸ˜€ Again remeber that the primary DMAC is DMAC 1 while the slave DMAC is DMAC 0. Also remember how the master DMAC was 16 bits while the slave DMAC was 8? This an important characteristic, specifically here as this means you can read or write 8 bit values to the slave DMAC, but 16 bit values to the master DMAC. Anyways, before we get into the details about these registers lets first hide them. Looking at the enumerations below, you will see nothing fancy going on - they match the tables above. Remember that these registers are all accessed through port mapped i/o. In other words, you can read or write them using in and out x86 machine instructions. enum DMA0_CHANNEL_IO { DMA0_CHAN0_ADDR_REG = 0, //! Thats right, i/o port 0 DMA0_CHAN0_COUNT_REG = 1, DMA0_CHAN1_ADDR_REG = 2, DMA0_CHAN1_COUNT_REG = 3, DMA0_CHAN2_ADDR_REG = 4, DMA0_CHAN2_COUNT_REG = 5, DMA0_CHAN3_ADDR_REG = 6, DMA0_CHAN3_COUNT_REG = 7, }; ...and now for DMAC 2.. enum DMA1_CHANNEL_IO { DMA1_CHAN4_ADDR_REG = 0xc0, DMA1_CHAN4_COUNT_REG = 0xc2, DMA1_CHAN5_ADDR_REG = 0xc4, DMA1_CHAN5_COUNT_REG = 0xc6, DMA1_CHAN6_ADDR_REG = 0xc8, DMA1_CHAN6_COUNT_REG = 0xca, DMA1_CHAN7_ADDR_REG = 0xcc, DMA1_CHAN7_COUNT_REG = 0xce, } The basic purpose of these registers is to provide a way for us to tell the DMAC how to initiate the channels. Each channel has a base address and a counter. The base address is the location in memory to start reading or writing, and the counter tells the DMAC how much to transfer on that channel. It is important to note that these are always physical addresses, not virtual! Lets have an example. To set the base address that a channel will use, all we need to do is write to the correct i/o port shown in the above table. Assuming DMA0_CHAN0_ADDR_REG is 0 all the way to DMA1_CHAN7_ADDR_REG being the last value in the table (0xde), this becomes easy. Remember that all example code is in the demo at the end of this chapter. enum DMA1_CHANNEL_IO { DMA1_CHAN4_ADDR_REG = 0xc0, DMA1_CHAN4_COUNT_REG = 0xc2, DMA1_CHAN5_ADDR_REG = 0xc4, DMA1_CHAN5_COUNT_REG = 0xc6, DMA1_CHAN6_ADDR_REG = 0xc8, DMA1_CHAN6_COUNT_REG = 0xca, DMA1_CHAN7_ADDR_REG = 0xcc, DMA1_CHAN7_COUNT_REG = 0xce, }; In a very similar way, we can write a routine to set the count register of that specific channel. void dma_set_address(uint8_t channel, uint8_t low, uint8_t high) { if ( channel > 8 ) return; unsigned short port = 0; switch ( channel ) { case 0: {port = DMA0_CHAN0_ADDR_REG; break;} case 1: {port = DMA0_CHAN1_ADDR_REG; break;} case 2: {port = DMA0_CHAN2_ADDR_REG; break;} case 3: {port = DMA0_CHAN3_ADDR_REG; break;} case 4: {port = DMA1_CHAN4_ADDR_REG; break;} case 5: {port = DMA1_CHAN5_ADDR_REG; break;} case 6: {port = DMA1_CHAN6_ADDR_REG; break;} case 7: {port = DMA1_CHAN7_ADDR_REG; break;} } outportb(port, low); outportb(port, high); } In a very similar way, we can write a routine to set the count register of that specific channel. void dma_set_count(uint8_t channel, uint8_t low, uint8_t high) { if ( channel > 8 ) return; unsigned short port = 0; switch ( channel ) { case 0: {port = DMA0_CHAN0_COUNT_REG; break;} case 1: {port = DMA0_CHAN1_COUNT_REG; break;} case 2: {port = DMA0_CHAN2_COUNT_REG; break;} case 3: {port = DMA0_CHAN3_COUNT_REG; break;} case 4: {port = DMA1_CHAN4_COUNT_REG; break;} case 5: {port = DMA1_CHAN5_COUNT_REG; break;} case 6: {port = DMA1_CHAN6_COUNT_REG; break;} case 7: {port = DMA1_CHAN7_COUNT_REG; break;} } outportb(port, low); outportb(port, high); } It is very important to note that these registers are 16 bits. This means that the DMAC can only transfer 64k at most at a time from a single channel. It is also very important to note that these are physical addresses! If the system software has enabled paging, it must map the location that the channel will use into the same virtual address by idenitity mapping the region of memory that will be used. So, to recap: Knowing that there are 8 channels, after enabling the device on that channel to use the DMAC, we can initiate a read or write transfer to the DMAC by giving the channel information (the memory location, and weather to read or write to or from it.) by writing to one of the channel registers. You might be asking where this data comes from. Or, if reading, where does the data go? Thats up to the device that is controlling that channel. For example, in a floppy drive, after we send a read command to the Floppy Drive Controller (FDC), the FDC will notify the DMAC to initiate the transfer. The DMAC will get the base physical address, channel operation (read or write, hopefully read in this case ðŸ˜‰ ), and size of the buffer and the rest writes itself: The FDC will continue to transfer data to the DMAC which in turn will place it in the buffer that is pointed by the address stored in that channel. We set the location of the buffer and the size of it here, by writing to that channels address and count registers. Wait, wait, wait. Remember that the DMAC can only transfer 64K at a time? Its worse then that. Knowing the base address of each channel also has the same limitation, this also means the DMACs are limited to accessing 64K of RAM! This is a bad limitation, dont you think? A solution to this is the external page registers. Lets look closer! Extended Page Address Registers The Page Registers are used to set what page the memory location that the channel is set to resides. Each page register is 8 bits, and there is a page register for each channel (well, actually more then that but that is not important.) If we take these 8 bits and append them to the base address of the channel (making 0xFFFFFF for a channel base address), we effectively have 8 more bits so we can access up to 16MB of memory. This is how these page registers work. These page registers only store the upper 8 bits of that channels transfer address. This is an important characteristic as it means the values in these page registers are always a multiple of 64k. Sure enough, things get a little messy here. The original PCs having one DMAC used different i/o ports then AT/EISA/MCA and newer computers. And because the newer computers have two DMACs, additional registers were added and extended with more bits. The original PC page registers only added 4 bits (A16-A19). The newer computers, on the other hand, added 8 bits (A16-A23) to the base channel address. ISA DMAC Extended Page Address Registers table Port Descripton 0x80 Channel 0 (Original PC) / Extra / Diagnostic port 0x81 Channel 1 (Original PC) / Channel 2 (AT) 0x82 Channel 2 (Original PC) / Channel 3 (AT) 0x83 Channel 3 (Original PC) / Channel 1 (AT) 0x84 Extra 0x85 Extra 0x86 Extra 0x87 Channel 0 (AT) 0x88 Extra 0x89 Channel 6 (AT) 0x8A Channel 7 (AT) 0x8B Channel 5 (AT) 0x8C Extra 0x8D Extra 0x8E Extra 0x8F Channel 4 (AT) / Memory refresh / Slave Connect Okay, lets stop for a moment. grabs a cup of coffie Okay, all that we need to concern ourself with in the above table is the ports listed for AT. This means that all channel external page registers add an additional 8 bits to the base address of the channel that we stored when setting up the channel (see previous section.) Knowing that the page registers are only the top 8 bits, this means that the values in these registers must be a multiple of 64k. For example, when programming the floppy controller, we know that the floppy uses DMA channel 2. Lets say we want to store a buffer somewhere lower then 64k, we can just set that channels address to point somewhere right? Well, kind of. We will also need to set its page register because it is used to determin the top 8 bits of that address. So, to set it: If set to 0: Page 0, nothing added to the address If set to 1: Page 1, 64k added to the address If set to 2: Page 2, 128K added to the address If set to 255, Page 255 = 255*64K=0xFF0000, all top 8 bits set, 16, 320K or about 16 MB added to the address Notice how changing the page in the page table changes the address where the DMA is to read or write to. This allows the DMAC to effectively access up to 16MB of memory. Cool, huh? Still a little limiting, but alot better then being limited to 64K dont you think? Like the other registers, lets hide those ugly magic numbers: enum DMA0_PAGE_REG { DMA_PAGE_EXTRA0 = 0x80, //! Also diagnostics port DMA_PAGE_CHAN2_ADDRBYTE2 = 0x81, DMA_PAGE_CHAN3_ADDRBYTE2 = 0x82, DMA_PAGE_CHAN1_ADDRBYTE2 = 0x83, DMA_PAGE_EXTRA1 = 0x84, DMA_PAGE_EXTRA2 = 0x85, DMA_PAGE_EXTRA3 = 0x86, DMA_PAGE_CHAN6_ADDRBYTE2 = 0x87, DMA_PAGE_CHAN7_ADDRBYTE2 = 0x88, DMA_PAGE_CHAN5_ADDRBYTE2 = 0x89, DMA_PAGE_EXTRA4 = 0x8c, DMA_PAGE_EXTRA5 = 0x8d, DMA_PAGE_EXTRA6 = 0x8e, DMA_PAGE_DRAM_REFRESH = 0x8f //!no longer used in new PCs }; To set one of these registers, all we need to do is determin what register is being written to (based on what channel is passed to it) and write the value to it: void dma_set_external_page_register (uint8_t reg, uint8_t val) { if (reg > 14) return; unsigned short port = 0; switch ( reg ) { case 1: {port = DMA_PAGE_CHAN1_ADDRBYTE2; break;} case 2: {port = DMA_PAGE_CHAN2_ADDRBYTE2; break;} case 3: {port = DMA_PAGE_CHAN3_ADDRBYTE2; break;} case 4: {return;}//! nothing should ever write to register 4 case 5: {port = DMA_PAGE_CHAN5_ADDRBYTE2; break;} case 6: {port = DMA_PAGE_CHAN6_ADDRBYTE2; break;} case 7: {port = DMA_PAGE_CHAN7_ADDRBYTE2; break;} } outportb(port, val); } It is important to note that case 4 is commented. Remember that channe 4 is used to cascade with the master DMAC? Because if this, nothing can use it. Each of the above cases represent a channel that we are setting the page to. So, a call like dma_set_external_page_register (2, 0x1000); will allow us to set 0x1000 to the channel 2 page register. Cool? Registers In addition to the registers shwn above, the controller makes the following registers available as well. Command Register This register is used to control the DMAC. It has the following format: Bit 0: MMT Memory to Memory Transfer 0: Disable 1: Enable Bit 1: ADHE Channel 0 Address Hold 0: Disable 1: Enable Bit 2: COND Controller Enable 0: Disable 1: Enable Bit 3: COMP Timing 0: Normal 1: Compressed Bit 4: PRIO Priority 0: Fixed Priority 1: Normal Priority Bit 5: EXTW Write Selection 0: Late Write Selection 1: Extended Write Selection Bit 6: DROP DMA Request (DREQ) 0: DREQ sense active high 1: DREQ sense active low Bit 7: DACKP DMA Acknowledge (DACK) 0: DACK sense active low 1: DACK sense active high Most of these bits will not work on the i86 architecture. The only bit that does work is bit 2, which can be used to enable or disable the controller. I know, I know, you would think direct memory to memory transfers would be useful too. Using other bits may either not do anything, or provide unpredictable results. For completeness, these are included in the dma.h header file in the demo at the end of this chapter. Here they are as bit masks. enum DMA_CMD_REG_MASK { DMA_CMD_MASK_MEMTOMEM = 1, DMA_CMD_MASK_CHAN0ADDRHOLD = 2, DMA_CMD_MASK_ENABLE = 4, DMA_CMD_MASK_TIMING = 8, DMA_CMD_MASK_PRIORITY = 0x10, DMA_CMD_MASK_WRITESEL = 0x20, DMA_CMD_MASK_DREQ = 0x40, DMA_CMD_MASK_DACK = 0x80 }; Mode Register (Write) This mode sets the mode of the controller. It has the following format: Bits 0-1: SEL0, SEL1 Channel Select 00: Channel 0 01: Channel 1 10: Channel 2 11: Channel 3 Bits 2-3: TRA0, TRA1 Transfer Type 00: Controller self test 01: Write Transfer 10: Read Transfer 11: Invalid Bit 4: AUTO Automatic reinitialize after transfer completes (Device must support!) Bit 5: IDEC Bits 6-7: MOD0, MOD 1 Mode 00: Transfer on Demand 01: Single DMA Transfer 10: Block DMA Transfer 11: Cascade Mode This register is important. In order for us to set up a channel and prepare it to read or write a block of memory, we must write to this register the operation mode. Before writing to this register however, it is always recommended to mask off (disable) the channel you would like to set the mode for before changing anything. This has to do with the problem of changing channel modes while it is currently in use, which can cause data corruption or other issues. Before anything, the first thing I always like to do is to hide the ugly numbers behind meaningful names, so here they are. This is a little different though: These enums are a combination of masks and flags. The masks match the bit format of the above list. The flags are there just for simplicity: They will allot us to set or clear the needed bit in the above list allowing us to bitwise-OR options together. So, for example, we can combine the channel number and set the mode of the channel to read a single transfer with auto initialize by just doing: channel | DMA_MODE_READ_TRANSFER | DMA_MODE_MASK_AUTO | DMA_MODE_TRANSFER_SINGLE. Cool, huh? Because the format is the same for both controllers, we only have one enum: enum DMA_MODE_REG_MASK { DMA_MODE_MASK_SEL = 3, DMA_MODE_MASK_TRA = 0xc, DMA_MODE_SELF_TEST = 0, DMA_MODE_READ_TRANSFER 4, DMA_MODE_WRITE_TRANSFER = 8, DMA_MODE_MASK_AUTO = 0x10, DMA_MODE_MASK_IDEC = 0x20, DMA_MODE_MASK = 0xc0, DMA_MODE_TRANSFER_ON_DEMAND = 0, DMA_MODE_TRANSFER_SINGLE = 0x40, DMA_MODE_TRANSFER_BLOCK = 0x80, DMA_MODE_TRANSFER_CASCADE = 0xC0 }; Assuming DMA0_MODE_REG is 0x0b - the DMA 0 mode register, and DMA1_MODE_REG is 0xd6, the second DMA mode register, all we need to do to set the DMA mode for a specific channel is this: void dma_set_mode (uint8_t channel, uint8_t mode) { int dma = (channel < 4) ? 0 : 1; int chan = (dma==0) ? channel : channel-4; dma_mask_channel (channel); outportb ( (channel < 4) ? (DMA0_MODE_REG) : DMA1_MODE_REG, chan | (mode) ); dma_unmask_all ( dma ); } //! prepares channel for read void dma_set_read (uint8_t channel) { dma_set_mode (channel, DMA_MODE_READ_TRANSFER | DMA_MODE_TRANSFER_SINGLE | DMA_MODE_MASK_AUTO); } //! prepares channel for write void dma_set_write (uint8_t channel) { dma_set_mode (channel, DMA_MODE_WRITE_TRANSFER | DMA_MODE_TRANSFER_SINGLE | DMA_MODE_MASK_AUTO); } This routine will allow us to set the mode on any channel. Cool, huh? For example, if we want to prepare the floppy drive to write, a dma_set_mode (2, 0x5A) will do it. (Remember that the floppy uses channel 2 on the primary DMAC?) and 0x56 = 01010110 binary. Comparing it with the list above, Mode=01 (Single transfer), AutoInit is set (Auto initialize after completion), transfer type=01 (Write), channel 2 (10). The DMA_MODE_MASK_AUTO bit is a useful one. It allows us to initialize the DMAC once at the start (By resetting the controller and setting the channels buffer address and count) without needing to worry about it again. If this bit is not set, we will need to reinitialize the DMAC before every read or write operation. Note: The AutoInit bit (DMA_MODE_MASK_AUTO) does not seem to be supported well in Virtual PC. Because of this, to help maintain portability with Virtual PC, we opted to go for reinitializing the DMAC every read or write operation rather then using AUTOINIT. Other emulators or machines may or may not support it. Request Register (Write) This register allows software to send to the DMAC directly. The first 2 bits are used to select the channel. For example, 00=channel 0, 01=channel 1, 10=channel 2, 11=channel 3. The third bit, if 0, resets the channel request bit. If 1, sets the request bit. Bit 0-1: Channel select 0 Bit 2: 0=reset channel request bit, 1=set request bit The Request Register is used for Memory-to-memory operations. Remembering form the command register, you cannot/should not enable memory-to-memory transactions in the i86 architecture. Because of this, this register is not important to us. Channel Mask Register (Write) This register allows you to be able to mask a single DMA channel. Bits 0 and 1 allow you to set the channel (00=channel 0, 01=channel 1, 10=channel 2, 11=channel 3). Bit 4 determins weather to mask or unmask the channel. If bit 4 is 0, it unmasks the channel. If it is 1, it will mask it. All other bits are unused. Bit 0-1: Channel select Bit 2: 0=unmasks channel, 1=masks channel All other bits unused. Mask Register (Write) This register containes information on what channels are currently masked and unmasked. The top 4 bits in this 8 bit register are always unused. The low four bits are used to mask or unmask one of the four channels. For example, bit 0 is for channel 0, bit 1 is for channel 1, and so on. Note: Masking channel 4 will also mask channels 4,5,6,7 due to cascading. Bit 0: Channel select 0 Bit 1: Channel select 1 Bit 2: Channel select 2 Bit 3: Channel select 3 All other bits unused. For example, lets provide a routine to mask (disable) any channel, all we need to do is set the respective bit: void dma_mask_channel(uint8_t channel){ if (channel <= 4) outportb(DMA0_CHANMASK_REG, (1 << (channel-1))); else outportb(DMA1_CHANMASK_REG, (1 << (channel-5))); } In a similar way, to unmask a channel, just clear the bit: void dma_unmask_channel (uint8_t channel) { if (channel <= 4) outportb(DMA0_CHANMASK_REG, channel); else outportb(DMA1_CHANMASK_REG, channel); } Both of these routines assumes that DMA0_CHANMASK_REG is 0x0a (The i/o port for the DMAC mask register) and DMA1_CHANMASK_REG is 0xD4 (The i/o port for the second DMAC mask register.) Because you can set multiple channels at the same time, this register does allow the ability of masking or unmasking multiple channels at the same time. Status Register The status register has the following format: Bit 0: TC0 Set if Channel 0 has reached Transfer Complete (TC) Bit 1: TC1 Set if Channel 1 has reached Transfer Complete (TC) Bit 2: TC2 Set if Channel 2 has reached Transfer Complete (TC) Bit 3: TC3 Set if Channel 3 has reached Transfer Complete (TC) Bit 4: REQ0 Set if Channel 0 is pending a DMA Request (DRQ) Bit 5: REQ1 Set if Channel 1 is pending a DMA Request (DRQ) Bit 6: REQ2 Set if Channel 2 is pending a DMA Request (DRQ) Bit 7: REQ3 Set if Channel 3 is pending a DMA Request (DRQ) This register is not very useful. In most cases, the device that is controlling the DMAC will send an IRQ when the transfer is complete, so there is no need to poll the register for information. The first 4 bits tell you if the transfer on that channel is complete. the last 4 bits tell you if the channel has pending DMA requests. ISA DMA Commands The controller provides special registers that allows software to be able to send commands to the controller. These commands do not at all require any specific bit format, and can be activated by a simple i/o operation. The DMAC will recognize the command by the data on the address bus (lines A0-A3) and the status of its ORQ and IOW lines. Please note that there is nothing special about these registers. These are also in the table of generic registers near the beginning of this chapter. Clear Byte Pointer Flip-Flop This is a special i/o address port that allows us to control the flip-flop between 16 bit transfers when working with the 8 bit DMAC (the primary DMAC.) There are two ports for both DMACs: ISA DMAC Flip-Flop Ports table Port Descripton 0x0C DMAC 0 (16 bit) Slave (write) 0xD8 DMAC 1 (8 bit) Master (write) For example, assuming DMA0_CLEARBYTE_FLIPFLOP_REG is 0x0c and DMA1_CLEARBYTE_FLIPFLOP_REG is 0xD8, the following routine will set or clear the flipflop: void dma_reset_flipflop(int dma){ if (dma < 2) return; //! it doesnt matter what is written to this register outportb( (dma==0) ? DMA0_CLEARBYTE_FLIPFLOP_REG : DMA1_CLEARBYTE_FLIPFLOP_REG, 0xff); } Reset In a very similar fashion, you can reset the a DMAC by writing any value to the following registers: ISA DMAC Reset Ports table Port Descripton 0x0D DMAC 0 (16 bit) Slave (write) 0xD8 DMAC 1 (8-bit) Master (write) For example, assuming DMA0_TEMP_REG is 0x0D: void dma_reset (int dma){ //! it doesnt matter what is written to this register outportb(DMA0_TEMP_REG, 0xff); } Unmask All Registers In yet another similar fashion, the same concept applies with this command! Wouldn't it be great if all hardware programming commands were this easy? ðŸ˜‰ ISA DMAC UnMask All Ports table Port Descripton 0x0E DMAC 0 (16 bit) Slave (write) 0xDC DMAC 1 (8-bit) Master (write) So, assuming DMA1_UNMASK_ALL_REG is 0x0E, this will unmask all registers from the slave DMAC: void dma_unmask_all (int dma){ //! it doesnt matter what is written to this register outportb(DMA1_UNMASK_ALL_REG, 0xff); } Demo Demo running in Virtual PC Demo Download Yey, its time for another demo!! The bad news is that this demo looks exactally the same as the last chapter (Except it now works with both Bochs and Virtual PC). The good news is that it has been upgraded to use our new DMA interface. The core of the new code is found in the HAL - dma.h and dma.cpp which containes all of the code from this chapter. There is one minor change, however. Because the AUTOINIT bit in the Mode register for the DMAC is not well supported in Virtual PC, our dma_set_read and dma_set_write routines do NOT set the bits in the demo code: //! prepares channel for read void dma_set_read (uint8_t channel) { dma_set_mode (channel, DMA_MODE_READ_TRANSFER | DMA_MODE_TRANSFER_SINGLE); } //! prepares channel for write void dma_set_write (uint8_t channel) { dma_set_mode (channel, DMA_MODE_WRITE_TRANSFER | DMA_MODE_TRANSFER_SINGLE); } During a read sector operation, the floppy driver's flpydsk_read_sector_imp routine initializes the DMAC, and prepares the DMAC for a read operation. The rest of the routine (which has been edited out) is the same from the last chapter and is responsible for sending the READ command to the FDC. DMA_BUFFER is just a buffer of free memory that can be used for DMAC transfers. It is the same from the last chapter. dma_initialize_floppy initializes the DMAC using our new DMA minidriver to prepare it for use by the floppy driver. (We will look at that shortley.) After initializing the DMAC, we prepare the DMAC for our READ operation by calling our drivers dma_set_read routine on channel FDC_DMA_CHANNEL . FDC_DMA_CHANNEL is channel 2 (Remember that the FDC uses channel 2 on the DMAC?) //! read a sector void flpydsk_read_sector_imp (uint8_t head, uint8_t track, uint8_t sector) { uint32_t st0, cyl; //! initialize DMA dma_initialize_floppy ((uint8_t*) DMA_BUFFER, 512 ); //! set the DMA for read transfer dma_set_read ( FDC_DMA_CHANNEL ); //! rest of the code is the same... } dma_initialize_floppy is responsible for preparing the DMAC using our new minidriver for use by the floppy driver. This is where all of the fun stuff is at! We first reset the master DMAC by calling dma_reset() . We then disable (mask) channel 2 (used by the FDC) by calling dma_mask_channel() . This insures the channel is no longer in use so that we can modify it. Now for the fun stuff. To set the address the channel will use, we call our dma_set_address routine. This allows us to set the low and high parts of the address to the channel. We use an union to make it a little easier to access the byte components of the members. That is, we set a.l to the buffer that the channel will use. Thanks to the union, a.byte[0] now refers to the low byte of that value, byte[1] referrs to the second byte, etc. We do the same for the length which is the size of the buffer. So we set the buffers address by calling dma_set_address with the low and high bytes of the uhm.. buffer address and the length by calling dma_set_count in the same way. Cool, huh? Okay, okay, thats all fine and all but whats with the dma_reset_flipflop calls? The flipflop is only used with the 8 bit DMAC when working with 16 bit data. If we were working with the 16 bit DMAC, we would not need to call it. The flipflop is used to select between the high and low bytes of the 16 bit data. When you reset the flipflop, you are telling the DMAC that the next byte data will be the low byte. If the flipflop is not in its default position, it will be selected as the high byte. This has to be selected because the DMAC is working with 16 bit data on an 8 bit data bus. How does it know what part of the 16 bit data this byte refers to? Finally we set the DMAC for a read operation by calling dma_set_read() and unmasking all of the channels so that they can be used by devices again. This is important as it allows the FDC to use channel 2 on the DMAC. bool _cdecl dma_initialize_floppy(uint8_t* buffer, unsigned length){ union{ uint8_t byte[4];//Lo[0], Mid[1], Hi[2] unsigned long l; }a, c; a.l=(unsigned)buffer; c.l=(unsigned)length-1; //Check for buffer issues if ((a.l >> 24) || (c.l >> 16) || (((a.l & 0xffff)+c.l) >> 16)){ #ifdef _DEBUG _asm{ mov eax, 0x1337 cli hlt } #endif return false; } dma_reset (1); dma_mask_channel( FDC_DMA_CHANNEL );//Mask channel 2 dma_reset_flipflop ( 1 );//Flipflop reset on DMA 1 dma_set_address( FDC_DMA_CHANNEL, a.byte[0],a.byte[1]);//Buffer address dma_reset_flipflop( 1 );//Flipflop reset on DMA 1 dma_set_count( FDC_DMA_CHANNEL, c.byte[0],c.byte[1]);//Set count dma_set_read ( FDC_DMA_CHANNEL ); dma_unmask_all( 1 );//Unmask channel 2 return true; } Conclusion Well, another chapter down, huh? This chapter wasnt as complex or hard as some of the ealier chapters, so its a nice break isnt it? From here we cannot get much further without the capability of loading files from disk. We have the ability of loading data from disk - but not files. This is done through a File System Driver . But wait! We have already covered FAT12 like .. 2 times already! Ugh, just goes to show how often we need to rewrite things. Rather then recovering the same material for a third time, I will be adding another subject to the mix: Virtual File Systems (VFS) . For a little fun, I may even add the ability of executing a demo program come next chapter ðŸ˜€ With the amount of readers wanting to add a graphical touch to their operating systems, I may also release a few advanced chapters related to Vesa Bios Extensions (VBE) and Video Graphics Array (VGA) / Super VGA (SVGA) as well. As well as turning our current system into a real microkernel - DLL support, drivers, and native PE resources support. References 82C37A CMOS High Performance Programmable DMA Controller datasheet \"The Undocumented PC\""
  },
  "articles/61_unorganised_tutorial/T22.html": {
    "href": "articles/61_unorganised_tutorial/T22.html",
    "title": "FileSystems and the VFS | BrokenThorn OS Dev Tutorials",
    "keywords": "FileSystems and the VFS Welcome to the 22'th chapter in a never-ending series for operating system development! This is more then chapter 22 but also year 2 for the OS Development Series. This is yet another filesystem related tutorial (Dont worry, its the last one ðŸ˜‰ ). The first one was needed so we can load our main bootloader program from the bootcode, The second one was for our main boot program so it can load our kernel. Now we need one more for our kernel so our kernel can load programs and execute them. There is a difference between this chapter and the other two, however - this one will be in C instead of assembly language. ðŸ˜€ To spice things up, however, and introduce something new, we will also be looking into Virtual FileSystems (VFS) . This will allow us to interface with any filesystem driver and different disk devices in the same way. It can be used for both local disk drives, but can also be used to interface with any network filesystem. Ready? File Systems Abstract (File Systems) File System A File System defines a logical way to read and write information. In this way, it can be coinsidered a specification . Most PC file systems are based off of the desktop concept of files and folders. There are alot of different kinds of file systems. Some are widley use (Like FAT12, FAT16, FAT32, NTFS, ext (Linux), HFS (Used in older MACs)); other filesystems are only used by specific companies for in house use (Like the GFS - Google File System). Some filesystems are used in networking only (NFS). You can also develop and design your own file system implimentation. File Systems are used for data storage and organizing data. They help provide a straightforward way to access files and directories on removal media (floppies, flash drives, CDs, DVDs), local drives (hard disk drives), and network clients. File Systems can also exist as an in-memory image. For example, you can load a file that containes a \"foot print\" of a special type of file system in it. Files and Folders A file is a group of data that represents something to a program or to the user. This data can be anything we want it to be. It all depends on how we interprate the data. For example, a text file containes text information. A file can also be an image of something. A folder is a logical group of files. It is also known as a directory . Directories provide us a way to manage a large amount of files. Directories typically form a tree structure. This is known as a directory tree . There is only one directory that is the parent of all directories and files: the Root Directory . A File Path is the location of a file in the directory tree. For example, the file a:\\myfile.txt , myfile.txt is the filename. It is in the root directory at the device known as \"a:\". a:\\mydir\\myfile.txt is a file, myfile.txt, located in the subdirectory, mydir, that is, in turn, located in the root directory on device \"a:\". File and Folder Naming The name of a folder or file is a string representing that file or folder, usually by its contents. File Systems impliment file naming and folder naming differently, and each has their own constraints. For example, FAT12 stores filenames and folder names in a directory entry as an array of 11 bytes (8 for filename, 3 for extension. This is also known as the 8.3 naming convention ) This limits file names and folder names to 11 characters. On the other hand, NTFS is limited to 255 characters with Long File Name (LFN) support. NTFS, for another example, stores file names along with file attributes in a Master File Table . Most filesystems file names are not case sensitive. However, some filesystems may store filenames differently internally. For example, you may have found out that you can have an 8.3 lowercase file name for a file on the floppy disk, but be able to load the file from your OS by using an all uppercase file name. Windows displays the LFN of the file name, while FAT12's 8.3 file entry only containes its 8.3 all-uppercase file name. This is what makes it possible. File Types Symbolic link's Symbolic links are a way to provide shorten paths. For example: a:/folder/link.lnk points to a:/otherfolder/subfolder/subsubfolder/yet another folder/link.txt. Now you can access the text file easily. Symbolic links are also very often used to make folder organized. Like the Windows Start Menu. Contains symblic links to your programs. A symbolic link is not very hard to implement. You find the node given (which is the link). It seems to be a link, so you get the real path and read that file instead. Windows Shortcuts are a type of symbolic link. Pipes A type of InterProcess Communication (IPC) is called a pipe. A pipe is a virtual file , usually between two or more processes. The best example may be stdout, stdin and stderror on Unix. They are handled as normal files, but the data written to stdout show up onto the screen (or in stdout.txt). Special File Types Metafiles Some filesystems also impliment special files and folders specifically for filesystem use. Typically you cannot have two files or folders with the same name (nor a filename sharing the same name as a folder) in the same directory. Because of this, naming a file or folder with one of these hidden files may also not be possible depending on implimentation. For example, NTFS provides several metafiles for filesystem use. These files are located on the root directory of the system drive (typically C:). $MFT,$MFTMirr, and $LogFile are a few of these files. While they do not ever show up even when view hidden and system files are checked, watch what happens when you create a file with one of the above names there. You can create those files anywhere else, but you will get a \"file already exists\" error when creating one on the root directory do to the metafiles. Device Files Unix-like systems, DOS (and, in turn, Windows) has Device Files which are special \"files\" that represent a device. For example, NUL (null device), CLOCK$, PRN (printer), etc. Here is the list of device files: CON PRN AUX CLOCK$ NUL COM0, COM1, ... COM9 LPT0, LPT1, ... LPT9 Because these names have special meaning in DOS and Windows, you cannot name a file or folder any of the above names. some special files . and .. are special files some file systems impliment. '.' is the file name of a file that containes file information that referrs to the current directory. '..' is the file name of a file that containes information that referrs to the parent directory of that file. For example, if there is a file located at c:\\mydir\\file.txt , and c:\\mydir was the current directory, the pathname .. will refer to C: while the pathname . will refer to c:\\mydir. File System Types Flat File Systems A Flat File System is a filesystem that does not support subdirectories. Instead, all of the files are in the same (root) directory. Many early computer systems used flat file systems. Modern operating systems typically impliment more advanced hierarchical file systems. While small and easy to impliment, flat file systems are hard to orginize. Hierarchical File Systems This type of file systems supports subdirectories. Most modern file systems (including FAT12,FAT16, FAT32,etx,NTFS) fit into this categary. (The first version of FAT12 was a flat file system. Later versions support subdirectories however.) Journaling File Systems This type of file system uses a \"journal\" of file system changes. This is a log of changes the system intends to make to files or directories prior to completing the steps. This insures that, if a crash occures during a filesystem operation (like writing a file), the journal can be read to undo the changes made to repair the filesystem. File System Drivers While a file system defines a specification for reading and writing \"files\" and \"directories\", a file system driver containes the implimentation of a specific type of file system. A good example of a file system driver is ntfs.sys which containes Microsoft's implimentation of the NTFS File System. File system drivers are also sometimes implemented as minidrivers inside of larger software. Bootloaders are a good example. Because boot loaders have to be able to load files from disk without a separate driver program, they contain several filesystem minidrivers for different types of filesystems inside of the bootloader itself. If you developed the bootloader in the series, you have already experienced the FAT12 file system and developed a FAT12 minidriver for our bootloader. Virtual FileSystem (VFS) Abstract (VFS) A Virtual File System (VFS) is an abstraction layer ontop of specific filesystem implimentations. The software accesses storage devices through a VFS. This allows the software to read or write to different storage devices without any knowledge of the device or filesystem that is being used. It also allows the same code to work with any number of installed filesystems or devices. The basic idea is to allow a single system interface to work with any filesystem in a uniform way. Windows, Linux, and Mac OS all support VFS in different ways. Implimentation (VFS) There are different ways to impliment a VFS. Mount Point List A mount point list is a list of mounted file systems and where they are mounted. For example, if a file needs to be read from, the OS typically calls the VFS ReadFile() function which searches through the list of mounted file systems to locate the device and file system the file is in. It then passes the read request to that file system's ReadFile() function. Node Graph A Node Graph contains a graph of nodes that represent files of different types: files, folders, mount points, etc. Each file node structure typically containes function pointers to file system-specific routines for reading and writing files. For example, we can create a FILE structure like this: typedef struct _FILE { char name[32]; //filename uint32_t flags; //flags uint32_t fileLength; //length of file read_funct read; //function pointers to read,write,open,close file write_funct write; open_funct open; close_funct close; }FILE, *PFILE; Notice the function pointers are stored in this FILE structure. Lets say we want to read a file, so we call fopen(), which, eventually, calls our VFS OpenFile() function. All the VFS file operation routines ever need to do is pass control to that specific FILE's function pointers: void VfsOpenFile (PFILE file, const char* filename) { if (file) file->open (filename); } This allows the filesystem-defined routine to be called. DOS and Windows DOS and Windows assigns a letter from 'a' through 'z' to represent a mounted file system. Windows keeps a symbolic link between a drive letter and its Object Manager name. For example, the drive letter c: (symbolc link name \\GLOBAL??\\C:) may be mapped to the Object name \\Device\\HardDiskVolume1 device object. A File System can register themself to own a device object. If a file system is found to own the object, the rest of the file path name (\"myfile.txt\" in this example) is passed to that filesystem's FileOpen() function. Drive letter assignment Windows supports assigning drive letters to devices and partitions representing mounted file systems. (During boot, if no filesystem driver registers to own a device object, Windows uses its RAW minidriver for the devices.) Drive letters can also refer to network shared drives, virtual disk images, or a symbolic link to another location in the local or a network client. However, they are limited to 26 devices do to only 26 letters that can be used from 'a' to 'z'. Interface For simplicity, we will be using drive letter assignment along with a mount point list in our VFS implimentation. Our implimentation needs to be simple because we do not have device management nor I/O management in the OS presented in the series. I personally recommend developing the VFS first prior to the filesystem driver. This way the interface and framework of the VFS will have already been completed. FILE Anyone that has used C is already famalier with the infamous FILE* data type. FILE* is an Abstract Data Type (ADT) that represents a pointer to a file object. ISO C defines that C implimentations must define a FILE type, however does not define what is inside of the structure. That is, while FILE* is ISO C, the structure contents is implimentation-defined. We can define a file structure that will represent the current state of a file any way we want. So lessee... a file has a name and a size, so thats two members already. We need a way to flag if its the End of File (EOF) , and file-specific flags, so thats two more members. We also need a way to keep track of a files current position (its cluster and the clusters offset), and now we have something like this: typedef struct _FILE { char name[32]; uint32_t flags; uint32_t fileLength; uint32_t id; uint32_t eof; uint32_t position; uint32_t currentCluster; uint32_t device; }FILE, *PFILE; That was easy, huh? id can be used for idenitification purposes if you like. device represents the device the file resides on. Types of files There are alot of different types of files that we have talked about: files, directories, symbolic links, etc. For simplicity, we will only focus on files and directories. These will be used in the flags member of our FILE structure above to represent the type of file. #define FS_FILE 0 #define FS_DIRECTORY 1 #define FS_INVALID 2 Operations There are some typical operations we can perform on a file: Open Close Read Write Mount Unmount Open and Close operations perform opening and closing a file object (file or directory, whatever the file type is), while reading and writing operations perform reading and writing the file type. All of these are exposed to the programmer through the standard C file I/O functions. For our VFS, they are exposed through a Volume Manager located in fsys.h: extern FILE volOpenFile (const char* fname); extern void volReadFile (PFILE file, unsigned char* Buffer, unsigned int Length); extern void volCloseFile (PFILE file); extern void volRegisterFileSystem (PFILESYSTEM, unsigned int deviceID); extern void volUnregisterFileSystem (PFILESYSTEM); extern void volUnregisterFileSystemByID (unsigned int deviceID); For example, lets say we call the C fopen() routine. That will call our volOpenFile() routine which returns a FILE object. We passed a path to the file, like \"a:\\myfile.txt\". The Volume Manager indixes into the mount point list and verifies that a file system has registered for the device ID that represents 'a'. If it has, it calls that filesystem drivers FileOpen() method passing \"myfile.txt\". Dont worry if it sounds complicated. It can be; but the design of how its implemented in the demo is very easy. Volume Manager Implimentation File System Abstraction The first thing we need is a way to abstract filesystem-specific information. This includes the name of the filesystem and the operations that can be performed on files. This is done using function pointers. typedef struct _FILE_SYSTEM { char Name [8]; FILE (*Directory) (const char* DirectoryName); void (*Mount) (); void (*Read) (PFILE file, unsigned char* Buffer, unsigned int Length); void (*Close) (PFILE); FILE (*Open) (const char* FileName); }FILESYSTEM, *PFILESYSTEM; Implimentation (Volume Manager Implimentation) The Volume Manager impliments our VFS in the demo. Its in the files fsys.h and fsys.cpp. Remember that we will be using drive letter assignment to represent devices? Because there are 26 possible devices, it is helpful to make a constant, DEVICE_MAX . Because each device can only have one mountable file system, we store them in a list (like a mount point list). #define DEVICE_MAX 26 //! File system list PFILESYSTEM _FileSystems[DEVICE_MAX]; Here is how it works. Because we are storing the filesystems as a list of pointers, if a pointer is valid, the filesystem has been registered there. Each element in the array represent the drive letter that it refers to. So 'a' is ar _FileSystems[0], 'b' is at _FileSystems[1], etc. It is the filesystems responsibility to manage the disk that they are writing on. Using this method provides a very basic but easy way of accessing devices. For example volOpenFile() only needs to check the first character of the path (the drive letter) and do a lookup into the list to see if a filesystem is registered for that device. If it is, it can call that filesystem's open() method and pass the filename to the driver. We default to using 'a', however if the input path contains an ':' then we use the first character for the device instead. This allows us to call volOpenFile in two ways: passing a string like \"myfile.txt\" and \"a:myfile.txt\" , where \"a\" is the device the file is in. Cool, huh? FILE volOpenFile (const char* fname) { if (fname) { //! default to device 'a' unsigned char device = 'a'; //! filename char* filename = (char*) fname; //! in all cases, if fname[1]==':' then the first character must be device letter if (fname[1]==':') { device = fname[0]; filename += 2; //strip it from pathname } //! call filesystem if (_FileSystems [device - 'a']) { //! set volume specific information and return file FILE file = _FileSystems[device - 'a']->Open (filename); file.deviceID = device; return file; } } FILE file; file.flags = FS_INVALID; return file; } All of the other file operation routines are basically the same. Knowing how our VFS is storing filesystems, you can probably guess how volRegisterFileSystem() family of routines work. All they basically do is store a pointer to the filesystem in the list or clear it. void volRegisterFileSystem (PFILESYSTEM fsys, unsigned int deviceID) { if (deviceID < DEVICE_MAX) if (fsys) _FileSystems[ deviceID ] = fsys; } Alright then! So we initialize the filesystem driver, which calls VolRegisterFileSystem() to register itself. We call fopen(), which calls VolOpenFile(), which in turn calls our filesystem's open() method. Everything is now in place but we are missing something... something very important... the filesystem driver itself! Right, I suppose we should go into it .. again... FAT12 - Take Three We have looked at and implemented FAT12 two times in the past throughout the series. Because of this, I do not plan on covering FAT12 in great detail again. However, this will be a review of FAT12 along with the C driver code and how it works. If needed, please reference [Chapter 11] (fix link OSDev11.html) while reading. Boot Sector Remember that alot of important filesystem information is stored in the boot sector along with our boot strap program? More specifically, it is located in the Bios Paramater Block (PBP) located in the boot sector. When we mount our filesystem, we will need to read from the BPB and store this information for later use. To do this, we can create a structure that matches the boot sector: typedef struct _BOOT_SECTOR { uint8_t Ignore[3]; //first 3 bytes are ignored (our jmp instruction) BIOSPARAMATERBLOCK Bpb; //BPB structure BIOSPARAMATERBLOCKEXT BpbExt; //extended BPB info uint8_t Filler[448]; //needed to make struct 512 bytes }BOOTSECTOR, *PBOOTSECTOR; A good example of what the boot sector looks like is to think about what our Stage 1 Bootloader program looks like in memory. The very first instruction in Stage1 (Please see [Chapter 4's demo] fix link (OSDev4.html), Stage1.asm) was jmp loader . This is a three byte instruction, so the first 3 bytes in the above structure is the Operation Code (OPCode) of our jmp instruction. Also remember from [Chapter 4] fix link (OSDev4.html) that we have covered the OEM Paramater Block aka, Bios Paramater Block (BPB). The BPB is located right after our 3 byte jump instruction. Because of this, the BIOSPARAMATERBLOCK is next in this structure. I also provide the BIOSPARAMATERBLOCKEXT structure which is an extension to the BPB for some other file systems, such as FAT32. The last 448 bytes of the bootsector contain the rest of our boot sectors program code. Because its not important to us right now, we just treat it as padding in the Filler member. This insures the BOOTSECTOR structure is exactally the same size as our on-disk boot sector (512 bytes). BIOSPARAMATERBLOCK is a structure that defines the format for a BPB. It is the same structure that is in the boot sector and has been covered in more depth in [Chapter 5]fix link (OSDev5.html). typedef struct _BIOS_PARAMATER_BLOCK { uint8_t OEMName[8]; uint16_t BytesPerSector; uint8_t SectorsPerCluster; uint16_t ReservedSectors; uint8_t NumberOfFats; uint16_t NumDirEntries; uint16_t NumSectors; uint8_t Media; uint16_t SectorsPerFat; uint16_t SectorsPerTrack; uint16_t HeadsPerCyl; uint32_t HiddenSectors; uint32_t LongSectors; } BIOSPARAMATERBLOCK, *PBIOSPARAMATERBLOCK; The above structure should look familier ðŸ˜€ If not, please read its description in [Chapter 5] fix link (OSDev5.html) BIOSPARAMATERBLOCKEXT, however, may be new. While we have already covered the BPB in depth and used it in the past for FAT12 parsing, FAT12 bootsectors do not rely on the BPB extended members. FAT32, however, does. typedef struct _BIOS_PARAMATER_BLOCK_EXT { uint32_t SectorsPerFat32; //sectors per FAT uint16_t Flags; //flags uint16_t Version; //version uint32_t RootCluster; //starting root directory uint16_t InfoCluster; uint16_t BackupBoot; //location of bootsector copy uint16_t Reserved[6]; } BIOSPARAMATERBLOCKEXT, *PBIOSPARAMATERBLOCKEXT; Thats everything ðŸ˜€ There is nothing special here-everything has already been covered in detail in previous chapters. These structures provide the filesystem driver an easy way of referencing data in the BPB for later filesystem use. All we need to do is read in the bootsector, and accessing the data through a PBOOTSECTOR. ðŸ˜€ We read the sector using our floppy disk driver that we developed in the previous chapter. //! Boot sector info PBOOTSECTOR bootsector; //! read boot sector bootsector = (PBOOTSECTOR) flpydsk_read_sector (0); That is all that is needed ðŸ˜€ All of our important information is now in bootsector.bpb . All thats needed is mounting the filesystem... Mounting the filesystem Now that we have our BPB information in memory, we need to prepare the filesystem for use. We start this by first deciding what information we need. Okay.. let see, we will need to total number of sectors on disk. We will also need to know the total number of directory entries. Other helpful information can be for use with the File Allocation Table (FAT) and the Root Directory: typedef struct _MOUNT_INFO { uint32_t numSectors; uint32_t fatOffset; uint32_t numRootEntries; uint32_t rootOffset; uint32_t rootSize; uint32_t fatSize; uint32_t fatEntrySize; }MOUNT_INFO, *PMOUNT_INFO; Okay... Remember that we already have the bootsector stored in our BOOTSECTOR structure? Knowing this, we can simply copy over some of the information from the BPB to our MOUNT_INFO structure. Alright.. Lets locate the location of the first FAT and root directory in a FAT12 formatted disk: Boot Sector Extra Reserved Sectors File Allocation Table 1 File Allocation Table 2 Root Directory (FAT12/FAT16 Only) Data Region containng files and directories. Notice that there are two FATs. The first FAT is right after the boot sector on disk. Because of this, we set fatOffset in MOUNT_INFO to 1, Also note that the Root Directory is right after both FATs. Knowing this, we can come up with a simple calculation to find the starting sector of the root directory. (NumberOfFATs * sectorsPerFAT) + 1 . We need to add 1 for the bootsector. We now have the location of the first FAT and root directory. To find the size of the root directory, all we need is the number of entries in the root directory and the size of each entry. Each directory entry in FAT12 is a specific structure format that is 32 bytes in size. So all we have to do is bootsector->Bpb.NumDirEntries * 32 . This is the number of bytes the directory takes up. We divide it by the bytes per sector to convert it to a sector count. //! store mount info _MountInfo.numSectors = bootsector->Bpb.NumSectors; _MountInfo.fatOffset = 1; _MountInfo.fatSize = bootsector->Bpb.SectorsPerFat; _MountInfo.fatEntrySize = 8; _MountInfo.numRootEntries = bootsector->Bpb.NumDirEntries; _MountInfo.rootOffset = (bootsector->Bpb.NumberOfFats * bootsector->Bpb.SectorsPerFat) + 1; _MountInfo.rootSize = ( bootsector->Bpb.NumDirEntries * 32 ) / bootsector->Bpb.BytesPerSector; That is all that there is to it. We have our FAT12 driver initialized. Easy, huh? We have the important filesystem information in MOUNT_INFO so all thats needed is to parse the directories and load a file. ðŸ˜€ Directory parsing Format (Directory parsing) A directory in FAT12 is composed of 32 byte structures that provide information about a file or subdirectory. Each directory entry has the following format: typedef struct _DIRECTORY { uint8_t Filename[8]; //filename uint8_t Ext[3]; //extension (8.3 filename format) uint8_t Attrib; //file attributes uint8_t Reserved; uint8_t TimeCreatedMs; //creation time uint16_t TimeCreated; uint16_t DateCreated; //creation date uint16_t DateLastAccessed; uint16_t FirstClusterHiBytes; uint16_t LastModTime; //last modification date/time uint16_t LastModDate; uint16_t FirstCluster; //first cluster of file data uint32_t FileSize; //size in bytes } DIRECTORY, *PDIRECTORY; That is all that there is to it ðŸ˜€ This is a directory entry - the information stored in our DIRECTORY structure can be a subdirectory or a file. Filename and Ext containes the file or directories 8.3 format name. Attrib containes the attributes of a file or directory. It has the following values for reference: Read only: 1 Hidden: 2 System: 4 Volume Lable: 8 Subdirectory: 0x10 Archive: 0x20 Device: 0x60 Please note that we will not be using this in the series as it is not needed. However, you can provide support for working and setting file attributes in your own system if you like. All date members in this structure follow a specific bit format: Bits 0-4 : Day (0-31) Bits 5-8 : Month (0-12) Bits 9-15 : Year All time members in this structure follow a specific bit format: Bits 0-4 : Second Bits 5-10 : Minute Bits 11-15 : Hour Because we have no need in modifying or retrieving file or directory date or time information we are not using them in the series. However, I encourage our readers to add the functionality themselves later on it they like. Remember that, for a FAT12 formatted floppy disk, a cluster is the same size as a sector (512 bytes). Because of this, the FirstCluster field in DIRECTORY also points to the first sector of a file. Thus, by reading this sector, you effectively read the first 512 bytes of the file. Now lets parse our directory and find our file... Parsing Remember that a directory containes a list of directory entry structures. Knowing this, parsing the directory to find a file or directory becomes very easy. We begin with loading the root directory. Remember that we retrived the root directory sector from the BPB when we mounted the filesystem and stored it into _MountInfo.rootOffset . Thus, all we need to do is to load the sector, and use a DIRECTORY * to access the directory entries. Then we loop and compare filenames to find a match. We convert the input filename to its DOS 8.3 filename format using ToDosFileName(). For example, turning the input filename of \"Myfile.txt\" to the FAT12 internal format \"MYFILE TXT\". We read in a sector and compare each entry in the sector. You will also notice that we turn the filenames into C strings so we can use a simple strcmp() call to test if filenames match. When we found a match, we fill out our FILE structure and return it. Lets take a look: FILE fsysFatDirectory (const char* DirectoryName) { FILE file; unsigned char* buf; PDIRECTORY directory; //! get 8.3 directory name char DosFileName[11]; ToDosFileName (DirectoryName, DosFileName, 11); DosFileName[11]=0; DirectoryName contains the directory or file name we are wanting to find. We convert the input filename, like \"myfile.txt\" into its DOS 8.3 filesystem format \"MYFILE TXT\" and store it in DosFileName. for (int sector=0; sector<14; sector++) { //! read in sector buf = (unsigned char*) flpydsk_read_sector ( _MountInfo.rootOffset + sector ); //! get directory info directory = (PDIRECTORY) buf; We are reading from the root directory. The root cluster is stored in _MountInfo, which containes information obtained from the Bios Paramater Block (BPB) when the file system was mounted. _MountInfo.rootOffset contains the first cluster of the root directory. The root directory contains, at most, 224 DIRECTORY entries. A DIRECTORY entry is 32 bytes, 224*32=7168 bytes, 7168 bytes / 512 bytes (512 bytes in a cluster) = 14, This means the root directory consists of 14 clusters. Knowing this, rather then loading the entire directory at once, we can load it sector by sector and parse each part of the directory. //! 16 entries per sector for (int i=0; i<16; i++) { //! get current filename char name[11]; memcpy (name, directory->Filename, 11); name[11]=0; //! find a match? if (strcmp (DosFileName, name) == 0) { Knowing that a DIRECTORY entry is 32 bytes, 512 bytes per cluster / 32 bytes = 16, This means there are 16 DIRECTORY entries in one sector. So, we loop through each entry and compare filenames to locate the file or directory that we are looking for. If they match, we can create a new FILE object and return it. file.currentCluster will contain the first cluster of the file for reading later, file.fileLength contains the size of the file, in bytes. directory->Attrib contains the files attributes. We set it based on its DIRECTORY entry attribute. //! found it, set up file info strcpy (file.name, DirectoryName); file.id = 0; file.currentCluster = directory->FirstCluster; file.eof = 0; file.fileLength = directory->FileSize; //! set file type if (directory->Attrib == 0x10) file.flags = FS_DIRECTORY; else file.flags = FS_FILE; //! return file return file; } Almost there... If we have not found the file or directory yet, we just move onto the next DIRECTORY entry. If we never find the file, we set FS_INVALID and return. //! go to next directory directory++; } } //! unable to find file file.flags = FS_INVALID; return file; } Thats it! The above routine works for directories and files in FAT12, By calling it, it will search the root directory for any folder or file name and return its information. SubDirectories (Parsing) While the old version of FAT12 was flat, new versions of this file system supports subdirectories. This allows us to be able to use directories and manage a lot of files more easily. For example, it would be a good idea in a large OS to separate OS-specific files in a system directory, or a user directory containing user profiles. A subdirectory is just an ordinary file with the DIRECTORY flag set. Because of this, we first need to know how to read files so lets look at that now. File Reading Format (File Reading) Okay, so we can now parse directories and locate files. We now need a way to read the file's contents. Remember that, technically, we can already read the first 512 bytes of any file by just the FirstCluster field in the directory entry structure for that file. To read more then one cluster, we have to parse the File Allocation Table (FAT) . Recall that FAT consists of a number of entries containing cluster numbers. The size of these entries depends on the filesystem. FAT12 has 12 bits per entry, FAT16 has 16 bits, FAT32 has 32 bits per entry. Think of the FAT as - not as a linked list, but rather a table of entries that represent the whole physical disk. The first cluster of the disk is represented by the first entry of the FAT. The second cluster is represented by the second entry, and so on. This means there is a one to one relationship between a cluster and a FAT entry. This makes reading and writing files in FAT12 easy. Reading a file To read a file, we just read the current cluster of the file. We try to locate its next cluster on disk by parsing the FAT table. After we find the next cluster, update the \"current cluster\" for the next file read. The cluster to read was set when the file is opened. On the first call to this routine, file->currentCluster is the same as DIRECTORY->FirstCluster . This cluster is an offset into the data area on disk. Lets recall the format of a FAT12 formatted disk and locate our FAT and data area: Boot Sector Extra Reserved Sectors File Allocation Table 1 File Allocation Table 2 Root Directory (FAT12/FAT16 Only) Data Region containng files and directories. Remember that each FAT takes 9 sectors. Because there are two FATs, 9+9=18, We have also concluded that our root directory is 14 sectors in the previous section. 18+14=32, This is the amount of sectors both FATs and the root directory take up. So far our equation is 32 + file->currentCluster . We need to subtract 1 and we have 32 + (file->currentCluster - 1) . This is the sector to read in and containes the file data. void fsysFatRead(PFILE file, unsigned char* Buffer, unsigned int Length) { if (file) { //! starting physical sector unsigned int physSector = 32 + (file->currentCluster - 1); //! read in sector unsigned char* sector = (unsigned char*) flpydsk_read_sector ( physSector ); //! copy block of memory memcpy (Buffer, sector, 512); To read in the next cluster we have to parse the FAT tables. Because a FAT table is 9 sectors, rather then reading all 9 sectors we determin what sector we need to read. We first get a byte offset into where the next cluster will be in. To do this, we multiply the cluster value by the size of a cluster. This gets stored in FAT_Offset . The size of a FAT32 cluster is 4 bytes, so we would mutiply by 4 is we are using FAT32, We would multiply by 2 if we were using FAT16 as that uses 2 bytes per cluster entry. Thats all fine of course, but what about FAT12? FAT12 uses 12 bits per cluster entry. Thats 8 bits (for the 1st byte) and 4 bits (for the 2nd byte. 4 bits is half of 8 bits, so its 0.5) so its 1.5 bits per cluster entry. After this, just divide this byte offset by the size of a sector to obtain the sector of the FAT to read in. The remander is the offset in this sector, which is the cluster to read from the FAT. This is in entryOffset . FAT is defined as uint8_t FAT [SECTOR_SIZE*2] . Notice that we read 2 sectors of our FAT into memory instead of one. Why do this? Knowing a sector size is 512 bytes, 512 bytes * 8 = 4096 bits per sector. 4096 bites / 12 bits (for a FAT entry) and we have 341.3333..etc. This means that an entry will sit between the 1st and 2nd sector. This will cause problems when loading files. Because of this, we have to load an additional sector so the last cluster value of the 1st sector will not be corrupt. unsigned int FAT_Offset = file->currentCluster + (file->currentCluster / 2); //multiply by 1.5 unsigned int FAT_Sector = 1 + (FAT_Offset / SECTOR_SIZE); unsigned int entryOffset = FAT_Offset % SECTOR_SIZE; //! read 1st FAT sector sector = (unsigned char*) flpydsk_read_sector ( FAT_Sector ); memcpy (FAT, sector, 512); //! read 2nd FAT sector sector = (unsigned char*) flpydsk_read_sector ( FAT_Sector + 1 ); memcpy (FAT + SECTOR_SIZE, sector, 512); After the FAT sector has been read, we read in the cluster number. Now we run into a problem. If we read an 8 bit value, we will not be able to read the whole 12 bits of a cluster value. So, we read 16 bits instead using an uint16_t. Of course, now we have the problem of having to much bits of our 12 bit value. Lets take a look closer. Lets say this is our FAT. We will separate our FAT into bytes but mark out the 12 bit entries. (This is taken from [Chapter 6] fix link (OSDev6.html)) Note: Binary numbers seperated in bytes. Each 12 bit FAT cluster entry is displayed. | | 01011101 0111010 01110101 00111101 0011101 0111010 0011110 0011110 | | | | | | | |1st cluster | |3rd cluster-| | |-0 cluster ----| |2nd cluster---| |4th cluster----| Notice all even clusters accopy all of the first byte, but part of the second. Also notice that all odd clusters occopy a part of their first byte, but all of the second! With this in mind, this means if the cluster is even, Mask out the top 4 bits, as it belongs to the next cluster. If the cluster is odd, shift it down 4 bits (to discard the bits used by the first cluster.) Now that we have all of that out of the way, lets finish off this function: //! read entry for next cluster uint16_t nextCluster = *( uint16_t*) &FAT [entryOffset]; //! test if entry is odd or even if( file->currentCluster & 0x0001 ) nextCluster >>= 4; //grab high 12 bits else nextCluster &= 0x0FFF; //grab low 12 bits //! test for end of file if ( nextCluster >= 0xff8) { file->eof = 1; return; } //! test for file corruption if ( nextCluster == 0 ) { file->eof = 1; return; } //! set next cluster file->currentCluster = nextCluster; } } Writing a file [To be completed in the chapter update!] SubDirectories A SubDirectory is a file with the DIRECTORY attribute set. To read from a subdirectory, all we need to do is locate the FAT12 file on disk with that directory name and read it in the same way as with other files using the FAT. After the file is loaded, from the first byte to the last is just an array of DIRECTORY entries. Parse the DIRECTORY entries the same way that we did with the root directory to read this directory ðŸ˜ These will be the files and folders inside of the directory. Lets take a look: FILE fsysFatOpenSubDir (FILE kFile, const char* filename) { FILE file; //! get 8.3 directory name char DosFileName[11]; ToDosFileName (filename, DosFileName, 11); DosFileName[11]=0; filename contains the file or directory that we want to find. kFile is the subdirectory that we want to parse. We convert the input filename, like \"myfile.txt\" into its DOS 8.3 filesystem format \"MYFILE TXT\" and store it in DosFileName . //! read directory while (! kFile.eof ) { //! read directory unsigned char buf[512]; fsysFatRead (&file, buf, 512); //! set directort PDIRECTORY pkDir = (PDIRECTORY) buf; file is our subdirectory that we want to parse. Remember that it is just an ordinary file in FAT12, so we read in a sector of the file. The file consists of an array of DIRECTORY entries. To make the DIRECTORY members easy to access, we use pkDir to point to the sector contents. Now, we search through the directory... //! 16 entries in buffer for (unsigned int i = 0; i < 16; i++) { //! get current filename char name[11]; memcpy (name, pkDir->Filename, 11); name[11]=0; //! match? if (strcmp (name, DosFileName) == 0) { Each DIRECTORY entry is 32 bytes. A sector (also cluster in FAT12) is 512 bytes. 512 bytes / 32 bytes = 16 DIRECTORY entries per sector. So, we loop through all 16 entries to compare names. Once we find a filename matching the one we are searching, we have found the file. //! found it, set up file info strcpy (file.name, filename); file.id = 0; file.currentCluster = pkDir->FirstCluster; file.fileLength = pkDir->FileSize; file.eof = 0; //! set file type if (pkDir->Attrib == 0x10) file.flags = FS_DIRECTORY; else file.flags = FS_FILE; //! return file return file; } When we have found the file, we fill in our FILE structure - first file cluster (so we can read it later on), file size (so we know when EOF is) and its attribute (file or directory). If the file has not been found, we just move onto the next entry. This loop will continue until the end of the file. If no file is found, we set FS_INVALID and return. //! go to next entry pkDir++; } } //! unable to find file file.flags = FS_INVALID; return file; } Notice the simularities between this routine and our FsysFatDirectory routine. Demo Viewing a file in our OS DEMO DOWNLOAD This chapters demo puts everything we covered and impliments a VFS and FAT12 minidriver. It is capable of supporting multiple filesystems, disk devices, subdirectory support, and loading and displaying files. The demo is also capable of displaying large files and impliments a \"press a key to continue\" feature for multi-cluster files. This demo impliments the strchr() ISO C routine in our CRT string.c to help with text parsing. It also upgrades our read command so it is capable of locating and displaying files instead of raw sectors. The Volume Manager is very simplistic in this demo, implimented in fsys.cpp . It manages the registring and unregistring of file systems, and file system abstraction. You can call volOpenFile() to open a file. It defaults to opening a:file.txt but it will also work if you call it to open any file on any directory. Not all file systems support subdirectories. Because of this, we leave subdirectory support to the file system drivers. Instead, the volume manager only handles the drive letter part of a path name. For example, if you call volOpenFile (\"a:\\folder\\file.txt\") , volOpenFile will pass \"\\folder\\file.txt\" to the file system registered on device 'a'. The file system driver is responsible for parsing the directory path name and opening subdirectories and files. In the case of our FAT12 minidriver, this special routine is fsysFatOpen() which is responsible for parsing the direcory path (like \"\\folder\\folder\\file.txt\") and calls its other file system routines for parsing and reading files and directories. Thats it ðŸ˜ This is possibly our last chapter covering FAT12, Because of this I do plan for an update covering writing files and directories on disk a little later. Conclusion This was a fun chapter, huh? We are now able to load files from disk. I know, I know, \"About time!\" ðŸ˜€ We are almost now ready to make the big leap into multitasking and executing programs. Before going multitasking, however, we should cover Loaders. A Loader is responsible for loading and executing a program, and mapping it into an address space. We also need to cover heap management and stack management in address spaces. Because I plan to update the memory management chapter heavily, I might move heap and stack management in a chapter following the memory management chapter. In any case, I will be sure to keep you updated on changes. This does, however, mean that it is almost time for us to dive into multitasking. Afterwords? User mode!"
  },
  "articles/61_unorganised_tutorial/T23.html": {
    "href": "articles/61_unorganised_tutorial/T23.html",
    "title": "User land | BrokenThorn OS Dev Tutorials",
    "keywords": "User land Welcome! In the last chapter we have looked at VFS's and loaded and displayed a text file. We can use this VFS to also load program files that can be executed. This includes drivers, program software, shared, runtime libraries, and more. In this chapter we will take the jump into supporting user land software. We will also be taking a look at System API's and how they work. Lets get started! Protection Levels The Rings of Assembly Language Kernel Land In [Chapter 5] (fix link OSDev5.html) we have took a quick look at the concept of the rings used in assembly language. These rings represent different protection levels. These protection levels are a hardware detail; they are implemented by the hardware. Software running in ring 0 have the most control. They can execute priveldge instructions which allow the software to be able to perform more actions: hardware PIO, MMIO, Processor hardware controls and tables (like CPU cache controls and MMRs, et al.) The list of privileged instructions have been shown in [Chapter 7] (fix link OSDev7.html) however will also be listed here for completness. If any software running in a protection level greater then 0 attempts to execute the above instructions, the processor generates a Protection fault (#PF) exception. Privileged Level Instructions table Instruction Description LGDT Loads an address of a GDT into GDTR LLDT Loads an address of a LDT into LDTR LTR Loads a Task Register into TR MOV Control Register Copy data and store in Control Registers LMSW Load a new Machine Status WORD CLTS Clear Task Switch Flag in Control Register CR0 MOV Debug Register Copy data and store in debug registers INVD Invalidate Cache without writeback INVLPG Invalidate TLB Entry WBINVD Invalidate Cache with writeback HLT Halt Processor RDMSR Read Model Specific Registers (MSR) WRMSR Write Model Specific Registers (MSR) RDPMC Read Performance Monitoring Counter RDTSC Read time Stamp Counter The kernel or executive of an operating system typically resides in ring 0. Because of this, kernel land or kernel mode is any software running in ring 0 . Ring 0 is also known as Supervisor Mode . All of the software that we have written in this series so far has been kernel mode software: kernel and minidrivers. Microkernels and hybrids typically employ a more advanced driver interfacing scheme then what we use in the series that allow proper driver installation and drivers running in user mode, completely separate from the kernel. It is even possible to have a part of the kernel in user mode; it all depends on your design. When the system is first started, the system is running in supervisor mode to allow the BIOS and operating system to start up. User Land Software running in ring 1 through ring 3 have less control of the machine then software running in ring 0. This is for protection of the machine; if there is an error caused by the software running in rings 1 through 3, the processor notifies the system executive or kernel of the problem using a general protection (#GP) exception. Most operating systems employ a 2 mode system, kernel mode and user mode. While the x86 family supports 4 protection modes, these operating systems only use 2 for easier portability across architectures. The design of these operating systems is for kernel mode software to run in ring 0 while user land software run in ring 3. Rings 1 and 2 are not used. Driver software can either operate in ring 0 to access hardware devices, or ring 3 using the provided driver API or System API to communicate with the hardware devices. Because user mode software can not access hardware devices directly, they must notify the operating system in order to complete system tasks. This includes displaying text, obtaining input from user, printing a document, etc. These functions are provided to the user mode software in the form of libraries and APIs. These libraries and APIs communicate with the System API. System API ... you have seen this term before. We will look closer on System APIs in a little bit. For now, lets take a closer look at user mode! Ring -1 Some recent processors have a special protection level that allows a hypervisor ring 0 access. This is sometimes known as \"Ring -1\". Welcome to User Land There are a few steps required to enter user mode. (Come on, you didnt think it would be easy ðŸ˜€ ) Its not that bad though. Step 1: Global Descriptor Table We will be needing to go back to the Global Descriptor Table (GDT) first. The GDT was that big ugly structure that we needed when setting up protected mode for the first time. Recall that the GDT contains a list of 8 byte entries that contains information for the processor. Lets take another look at the GDT entry bit format again: (I have bolded the important parts) Bits 56-63: Bits 24-32 of the base address Bit 55: Granularity 0: None 1: Limit gets multiplied by 4K Bit 54: Segment type 0: 16 bit 1: 32 bit Bit 53: Reserved-Should be zero Bits 52: Reserved for OS use Bits 48-51: Bits 16-19 of the segment limit Bit 47: Segment is in memory (Used with Virtual Memory) Bits 45-46: Descriptor Privilege Level 0: (Ring 0) Highest 1: (Ring 1) 2: (Ring 2) 3: (Ring 3) Lowest Bit 44: Descriptor Bit 0: System Descriptor 1: Code or Data Descriptor Bits 41-43: Descriptor Type Bit 43: Executable segment 0: Data Segment 1: Code Segment Bit 42: Expansion direction (Data segments), conforming (Code Segments) Bit 41: Readable and Writable 0: Read only (Data Segments); Execute only (Code Segments) 1: Read and write (Data Segments); Read and Execute (Code Segments) Bit 40: Access bit (Used with Virtual Memory) Bits 16-39: Bits 0-23 of the Base Address Bits 0-15: Bits 0-15 of the Segment Limit Yikes, okay ... The Descriptor Privilege Level (DPL) bits above represents the priveldge level used for that descriptor. So, by setting those bits to 3, we effectivley make the descriptor a user mode descriptor. So the first step is to create two new descriptors in the GDT - one for user mode data and the other for user mode code. This is done by modifying i86_gdt_initialize to add two new GDT entries for user mode code and data. Lets do that now: //! initialize gdt int i86_gdt_initialize () { //! etc... //! set default user mode code descriptor gdt_set_descriptor (3,0,0xffffffff, I86_GDT_DESC_READWRITE|I86_GDT_DESC_EXEC_CODE|I86_GDT_DESC_CODEDATA| I86_GDT_DESC_MEMORY|I86_GDT_DESC_DPL, I86_GDT_GRAND_4K | I86_GDT_GRAND_32BIT | I86_GDT_GRAND_LIMITHI_MASK); //! set default user mode data descriptor gdt_set_descriptor (4,0,0xffffffff, I86_GDT_DESC_READWRITE|I86_GDT_DESC_CODEDATA|I86_GDT_DESC_MEMORY| I86_GDT_DESC_DPL, I86_GDT_GRAND_4K | I86_GDT_GRAND_32BIT | I86_GDT_GRAND_LIMITHI_MASK); // etc... return 0; } The above code is the same as what we did when creating the other GDT entries, with one change. Notice the I86_GDT_DESC_DPL flag. This will set both DPL bits to 2 which makes them for user mode (ring 3). Please note that none of this is new; all of the above flags were written from an ealier chapter when we covered protected mode. Thats all that is needed! Note that the user mode code descriptor is installed at index 3 in the GDT, while the user mode data descriptor is at index 4. Remember that segment registers contain the offset of the selector it uses. Because each GDT entry is 8 bytes in size, it would be: code selector 0x18 (8 3) and data selector 0x20 (8 4). So in order to use one of these selectors, just copy one of the above segment selectors into the segment register that will be used. DPL The Descriptor Protection Level (DPL) is the protection level of a segment descriptor. For example, our kernels code and data segments DPL are 0 for ring 0 access. RPL The Requested Protection Level (RPL) allows software to override the CPL to select a new protection level. This is what allows software to request changes to other protection levels, such as ring 0 to ring 3. The RPL is stored in bits 0 and 1 of a descriptor selector. Wait, what ? Remember that a segment selector is just an offset into the GDT. So, for example, 0x8 bytes was the offset for our ring 0 code descriptor. 0x10 was the offset of our data selector. 0x8 and 0x10 are segment selectors . GDT entries are all 8 bytes, so the value of a segment selector will always be a multiple of 8: 8, 16, 24, 32 etc. 8, in binary, is 1000. This means, with any value of a segment selector, the low three bits are zero. The RPL is stored in the low two bits of the segment selector. So, if our segment selector is 0x8, the RPL is 0. If its 0xb (0x8 but with first two bits set, binary 1011 instead of 1000) the RPL is 3. This is required; this is how our software can switch to user mode. CPL The Current Protection Level (CPL) is the protection level of the currently executing program. The CPL is stored in bits 0 and 1 of SS and CS. Remember that GDT entries are 8 bytes in size. Because segment registers, in protected mode, contain a segment selector (GDT entry offset), the low three bits are guaranteed to be zero. The low two bits of CS and SS are used to store the CPL of the software. Protection Levels (Step 1) If a software attempts to load a new segment into a segment register, the processor performs checks against the CPL of the software and RPL of the segment that it is trying to load. If the RPL is higher then the CPL, the software can load the segment. If it is not, the processor will raise a General Protection Fault (#GP) . It is important to understand how RPL works, it is required information used when switching to user mode. Step 2: The switch Now we can make the switch to user mode! There are two ways of performing the jump: Using SYSEXIT instruction or with an IRET . Both of these methods have their advantages and disadvantages so lets take a closer look. We will be using IRET in the series for portability purposes. SYSEXIT Instruction This section is planned to be expanded on. IRET / IRETD Instruction A lot of operating systems may employ this method as it is more portable then using SYSEXIT. Larger operating systems might even support this as a back up method in the case SYSEXIT is not avialable. Okay, so how can IRET help us perform the switch? Recall from [Chapter 3] (fix link OSDev5.html) the different methods used when switching modes. IRET is a trap return instruction. When executing an IRET, we can adjust the stack frame so it returns to user mode code. When IRETD is executed, it expects the stack to have the following: SS ESP EFLAGS CS EIP IRETD causes the processor to jump to CS:EIP, which it obtains from the stack. It also sets the EFLAGS register with the value above from the stack. SS:ESP will be set to point to the SS and ESP values that was obtained from the stack. These are automatically pushed on the stack when an INT instruction is executed. Because of this, in the normal case these values would remain untouched. However, we can modify these values to cause IRET to perform a mode switch. Okay, so first is setting the segment selectors. Recall that the low two bits represent the RPL that we want. In our case, we want 3 for user mode. So lets do that now: void enter_usermode () { _asm { cli mov ax, 0x23 ; user mode data selector is 0x20 (GDT entry 3). Also sets RPL to 3 mov ds, ax mov es, ax mov fs, ax mov gs, ax Now we can perform the switch to user mode. This is done by building the stack frame for IRET and issuing the IRET: push 0x23 ; SS, notice it uses same selector as above push esp ; ESP pushfd ; EFLAGS push 0x1b ; CS, user mode code selector is 0x18. With RPL 3 this is 0x1b lea eax, [a] ; EIP first push eax iretd a: add esp, 4 // fix stack } } Notice that the stack frame matches that of what was in the list above. The IRETD instruction will cause 0x1B:a to be called in the above code inside of ring 3. There is a slight problem however. If you try to use the above routine, or switch to user mode in a different way in the kernel, it will cause a Page Fault (PF) exception. This is do to the pages for the kernel being mapped for kernel mode-access only. To fix this, we will either need to enter user mode a different way or map the kernel so user mode software can access it. For now, we are just going to map the kernel so user mode software can access it. This involves updating the vmmngr_initialize() routine and setting the USER bit in the PTEs and PDEs. In a more complex operating system, this approach would not be used. This approach only works if we map kernel pages so they can be accessed by user mode software, which is bad. A more recommended approach is to keep kernel pages mapped for kernel-only access, and have the loader component of your kernel to map user mode pages when loading a user program. A stack and heap allocator would then map a region for program stack and heap to user mode. This current method shares the kernel stack with user land; larger systems should not do this. Entering v8086 Mode These are the same steps involved when setting up v8086 mode. v8086 mode requires a user mode task in order to enter v86 mode. Thus, by doing the above, you can enter v86 mode as well. However, there is one slight modification needed. Recall the format of the EFLAGS register. Bit 17 (VM) is the v8086 Mode Control Flag . Because we push a value for EFLAGS on the stack when performing an IRET, in order to enter v86 mode, just set bit 17 of EFLAGS before pushing it on the stack. This will cause IRET to set the VM bit in the EFLAGS register on return. Thats all that is needed to enter v8086 mode. Notes on design (The switch) The above method presents an easy way to get into user mode, but at a cost: in order for the above method to work, the kernel region must be mapped to allow ring 3 software access to kernel memory. Because of this, while running in ring 3, the software-while will have some limitations do to protected mode, will be able to call kernel routines directly or even trash kernel space. A possible way to resolve the above issues is to keep kernel memory reserved for ring 0 software. The loader component of the kernel can then map the necessary ring 3 regions of memory for the process while loading the program. This will be looked at further in the next chapter when we develop a loader for the OS. Switching back to kernel land Step 1: Setting up the TSS The x86 architecture supports hardware assisted task switching. This means the architecture includes hardware defined structures that allow the processor to select between different tasks. Most modern operating systems do not utilize the hardware task switching support for portability purposes. These operating systems typically employ software task switching methods. Task State Segment (TSS) The TSS structure is quite large: #ifdef _MSC_VER #pragma pack (push, 1) #endif struct tss_entry { uint32_t prevTss; uint32_t esp0; uint32_t ss0; uint32_t esp1; uint32_t ss1; uint32_t esp2; uint32_t ss2; uint32_t cr3; uint32_t eip; uint32_t eflags; uint32_t eax; uint32_t ecx; uint32_t edx; uint32_t ebx; uint32_t esp; uint32_t ebp; uint32_t esi; uint32_t edi; uint32_t es; uint32_t cs; uint32_t ss; uint32_t ds; uint32_t fs; uint32_t gs; uint32_t ldt; uint16_t trap; uint16_t iomap; }; #ifdef _MSC_VER #pragma pack (pop, 1) #endif The TSS is used to store information about the state of the machine prior to a hardware task switch. It has a lot of members, so lets take a look! General Fields: State of LDT,EIP,EFLAGS,CS,DS,ES,FS,GS,SS,EAX,EBX,ECX,EDX,ESP,EBP,ESI,EDI prior to task switch prevTSS - Segment Selector of previous TSS in task list cr3 - PDBR, address of page directory for current task trap Bit 0: 0: Disabled; 1: Raise Debug exception when task switch to task occurs iomap - 16 bit offset from TSS base to I/O permissions and interrupt redirection bit maps esp0,esp1,esp2 - ESP stack pointers for ring 0, 1, and 2 ss0,ss1,ss2 - SS stack segments for ring 0, 1, and 2 Most of these fields are pretty simple. While we are not using hardware assisted task switching, we need to let the processor know how to go back to ring 0. Because of this, we need to set some of the fields in this structure - in particular the ring 0 stack and selector fields. Step 2: Installing the TSS Descriptor Segment A TSS as implied by its name is a segment . Simular to all segments, the TSS requires an entry in the GDT. This allows us to control the TSS: setting if the task is busy or inactive; what software can access it (DPL) and other flags that can be set with descriptors. The Base Address fields must be the base address of the TSS structure that we set up. LTR Instruction The LTR (Load Task Register) instruction is used to load the TSS into TSR register. For example: void flush_tss (uint16_t sel) { _asm ltr [sel] } ax is the segment selector for the TSS. Because the architecture supports hardware task switching, TSR stores the address of the TSS that defines the current task. The Task State Register (TSR) is a register that stores the TSS Selector , TSS Base Address and TSS Limit . Only the TSS Selector can be modified by software however. Installing the TSS In order to install the TSS structure, first install the GDT entry for the TSS. Then select the TSS as the current task by calling flush_tss above. void install_tss (uint32_t idx, uint16_t kernelSS, uint16_t kernelESP) { //! install TSS descriptor uint32_t base = (uint32_t) &TSS; gdt_set_descriptor (idx, base, base + sizeof (tss_entry), I86_GDT_DESC_ACCESS|I86_GDT_DESC_EXEC_CODE|I86_GDT_DESC_DPL|I86_GDT_DESC_MEMORY, 0); //! initialize TSS memset ((void*) &TSS, 0, sizeof (tss_entry)); TSS.ss0 = kernelSS; TSS.esp0 = kernelESP; TSS.cs=0x0b; TSS.ss = 0x13; TSS.es = 0x13; TSS.ds = 0x13; TSS.fs = 0x13; TSS.gs = 0x13; //! flush tss flush_tss (idx * sizeof (gdt_descriptor)); } In the above code, TSS is a global structure definition for our tss_entry structure. We set up the TSSs selector entries to match the previous task (user mode selectors) and ring 0 stack (kernel stack, located at kernelSS:kernelESP). flush_tss installs the TSS into TSR. Additional Instructions There are a few other instructions that can be useful. All of these instructions can be executed by user mode software. VERR Instruction VERR (Verify Segment is Readable) can be used to check if a segment is readable. The processor will set the zero flag (ZF) to 1 if it can be read. This instruction can be executed at any proviledge level. verr [ebx] jz .readable VERW Instruction VERW (Verify Segment is Writable) can be used to check if a segment is writable. The processor will set the zero flag (ZF) to 1 if it can be written. This instruction can be executed at any proviledge level. verw [ebx] jz .readable LSL Instruction This instruction can be used to load the segment limit of a selector into a register. lsl ebx, esp jz .success ARPL Instruction This instruction can be used to adjust the RPL of a selector. It takes the form arpl dest,src , where dest is a memory location or register, src is a register. If the RPL of dest are less then src, the RPL bits of dest are set to the RPL bits of src. For example: arpl ebx, esp System API Abstract A System API provides tools, documentations, and interfaces that allow software to interact with the operating system. Different operating systems may use different termonology but the basic idea is the same. For example, Windows calls this API the \"Native API\". The System API facilitates software interacting with the operating system and device drivers. The System API is the interface between user mode software and kernel mode software. Whenever the software needs system information or to perform a system task, such as creating a file, the software would invoke a system call. A System Call also known as a System Service is a service provided by the operating system. This service is usually a function or routine. Software can invoke system calls in order to perform system tasks. Design SYSENTER / SYSEXIT This section is planned to be expanded on. Software Interrupt Most System APIs are implemented by using a software interrupt. Software can use an instruction, like int 0x21 to call an operating system service. For example, to call the DOS's Terminate function we would do: mov ax, 0x4c00 ; function 0x4c (terminate) return code 0 int 0x21 ; call DOS service In the above code, AH contains a function number. The int 0x21 calls the 0x21 interrupt vector to call DOS. In order for the above to work, the operating system will need to install an ISR for interrupt vector 0x21. The ISR would be a Finity State Machine (FSM) that compares AH and passes control to the correct kernel mode function. And that, dear readers, is the design. Software interrupts are more portable then SYSENTER and SYSEXIT. Because of this, most operating systems provide support for this method (possibly along with other methods.) We will be using this method in the series. Examples System APIs typically consist of hundreds of system calls. This lists some operating systems and what methods they support. The INT numbers are software interrupt vector numbers using the above method. DOS: INT 0x21 Win9x (95,98): INT 0x2F WinNT (2k,XP,Vista,7): INT 0x2E, SYSENTER/SYSEXIT, SYSCALL/SYSRET Over 211 functions Linux: INT 0x80, SYSENTER/SYSEXIT Over 190 functions Basic System API Step 1: System Call Table Most System APIs implement a System Call table that contains all services. This table can be static, dynamic, auto generated, or a combination of the three. Large operating systems typically employ an auto-generated dynamic size table of system calls. This is do to the large number of system services that might be in this table; it would be very tedius to create it by hand. For our purposes, we can just define a system service table in the kernel. It would contain the addresses of different functions that we have in the kernel that would like to be callable: #define MAX_SYSCALL 3 void* _syscalls[] = { DebugPrintf }; Hm, this table is quite small. We will add more to this list in the upcoming chapters, however it wont be too complex. Because DebugPrintf is accessable from user mode (do to the kernel pages being mapped to allow this), and DebugPrintf not using any privedge instruction, the user mode software can technically call this routine directly without any problems. Depending on the design of your operating system or executive software this can cause security and stabability issues. This is why it is typically recommended to keep the kernel pages accessable only from kernel mode. While it adds complexity to the software, the end result might be worth the effort. Step 2: The Service Dispatcher The next step is to create the service dispatcher ISR. Before that, we need to decide on what ISR to use... hm... Ill just follow Linux here and use 0x80. You can use any interrupt vector you like however, a lot of OSs use different vectors. So, lets install the ISR. Remember that ISRs are stored in the IDT managed by the HAL layer. Also recall from [chapter 15] (fix link OSDev15.html) that each IDT descriptor has its own DPL setting. If the DPL of an IDT entery is less then the CPL, a GPF will result. In other words, when we enter user mode, we can only call ISRs with IDT descriptors with DPL 3. Because we want our system interrupt callable from ring 3 software, we must install this ISR with the correct flags. However, do to the current design of the HAL subsystem, this cannot be done by just calling setvect(), as this function does not allow us to set specific flags. To work around this issue, setvect() has been modified with a second paramater to allow optional flags to be set. This uses the C++ default paramater feature to achieve this so no other code needs to be updated. void syscall_init () { //! install interrupt handler! setvect (0x80, syscall_dispatcher, I86_IDT_DESC_RING3); } Thats all there is to it ðŸ˜€ syscall_dispatcher is our ISR for system calls. This ISR will need to determin what system service to call by looking up the function in _syscalls . Usually System APIs use EAX to idenitify function numbers. We are going to do the same here. Thanks to the system service table we defined above, we can use EAX as an index. So, the function to call will be _syscalls [eax] . _declspec(naked) void syscall_dispatcher () { static int idx=0; _asm mov [idx], eax //! bounds check if (idx>=MAX_SYSCALL) _asm iretd //! get service static void* fnct = _syscalls[idx]; Okay, so now we have a pointer to the function to call. However now we a small problem. The above will effectively get a pointer to the service function we want based on the value given by EAX. However we dont know what function it is. We also dont know what to pass to the function nor the amount of paramaters it has. One possible solution is to push all registers on the stack for the function call. Because the services are all C routines, we have to pass the paramaters in the way C functions would expect them. //! and call service _asm { push edi push esi push edx push ecx push ebx call fnct add esp, 20 iretd } } Thats it ðŸ˜€ The add esp, 20 pops the 20 bytes off the stack that we pushed; and notice we return from the ISR with an IRETD instruction. After the system software or executive installs their ISR to their respective interrupt vector, the software can call it by issuing a software interrupt. For example, if we call syscall_init to install our ISR, we can call a system service like this: _asm { xor eax, eax ; function 0, DebugPrintf lea ebx, [stringToPrint] int 0x80 ; call OS } Notes on design (Basic System API) Most operating systems abstract the interrupt vector number and register details behind C interfaces. While calling system services in larger OSs directly is still possible, it is recommended to develop a standard C interface around the system services your system provides to user land software. Large OSs typically wont have a system service for printing a message to the display. Rather it would contain services that can be called from user land software that allows user APIs to interact with kernel mode services, servers, or device drivers. Because of this, large OSs typically contain system APIs consisting of several hundred function calls. Demo Enter into user mode Demo download New and Modified Files This chapter adds a few more files to the series demo. This includes: hal/tss.h hal/tss.cpp Includes TSS routines described in this chapter hal/user.cpp Includes user mode switching routines This chapter also modifies the following files: kernel/mmngr_virtual.cpp vmmngr_initialize has been updated to allow kernel pages to be user accessable hal/hal.h/cpp set_vect() has been modified with an added second paramater hal/gdt.h MAX_DESCRIPTORS has been redefined to 6 for the added GDT entries hal/gdt.cpp Upgraded to include the installation of the user mode descriptors kernel/main.cpp Updated to reflect new changes Conclusion Welcome to user land! Now we have everything that is needed to switch between user land and kernel land. With this, we now have the capability of mapping user mode pages, loading, and running a program in usermode. We dont quite have the capability of returning back to the kernel of the OS in a nice way do to the system not managing tasks. We will look at this in the next chapter."
  },
  "articles/61_unorganised_tutorial/T24.html": {
    "href": "articles/61_unorganised_tutorial/T24.html",
    "title": "Process Management | BrokenThorn OS Dev Tutorials",
    "keywords": "Process Management This chapter details the topics of process management and multitasking. The previous chapters have built a basic monolithic operating system capable of now supporting tasks. A lot of decisions made up to this point in developing the OS was to sacrifice complexity for simplicity; while still providing some detail in the complex designs. I will continue this trend in this chapter; the demonstration presented at the end by no means represents the only way to develop an OS. This chapter will cover the following topics: Processes Threads and tasks Looking inside a process Process management Scheduling Linking Process management - Introduction Process management is the process by which operating systems manage processes, threads, enable processes to share information, protect process resources and allocate system resources to processes that request them in a safe manner. This can be a daunting task to the operating system developer and can be very complex in design. Lets take a closer look at each one of these. Processes and threads We will primarily be discussing processes and threads throughout the rest of this chapter. Process creation implies loading an executable image and creating at least one execution path (thread) to run it. Inter-Process Communication Inter-Process Communication (IPC) is a technique employed by many operating systems to allow communication between processes. This is typically done by message passing: the process would request to send a message to another process to the operating system which would send and queue the message to the other process if it is able to. IPC can be implemented in a number of different ways, the most common being files, pipes, sockets, message passing, signals, semaphores, shared memory, and memory mapped files. Operating systems may implement any or all of these methods of IPC. IPC is heavily used in some hybrid and monolithic kernel designs but is arguably most prominent in micro kernel designs. This chapter primarily focuses on that of process and thread creation and thus will not focus on that of IPC. We may discuss IPC a little later but probably as an addition to this chapter. Process protection Loading multiple processes into the same address space poses a fundamental problem: both processes can read or write each other. The simple solution to this is loading the processes into their own virtual address spaces and mapping them to separate locations in the physical address space. The process can request to create more threads: this is on a per-process bases so all threads share the same address space as the process as you will soon see. Process protection is also employed by mapping processes with the least amount of control that they need: for example, processes that must be in kernel land should be in kernel space, processes that do not need to be in kernel land should be in user space. We will be utilizing both of these in this chapter when creating processes. They will be mapped into user space and in their own virtual address space. This means the process will not be able to access kernel pages (so cannot trash kernel stack or structures) nor can the process trash another process as they are in separate address spaces. Resource allocation Resource allocation means the safe manner of handing system resources (such as files or device handles) to processes that request them. Due to the early state of the series OS, there really is no resources that we need to worry about at this time. As things are needed, though, process resources that have been allocated are typically stored within the process control block . If you are wondering why we need to manage system resource allocation, consider the case in a multi-tasking environment when two processes try to open the same file at the same time and write to it. With that in mind, we will be focusing on the creation of processes and threads in the following sections. We begin by providing a clear definition of what these are and what constitutes a process. Processes A process is an instance of a program, or part of a program, in memory. Processes are executed by the operating system or executive in order to perform complex tasks: such as play a movie or video, play a game, or even run the editor used to write this text in. In essence, one could say a process is a program â€“ but a program could contain multiple processes. For example, a basic program to display a string might be built in its own program file. Loading the program might yield the operating system or executive to load other program files â€“ dynamic loading of shared libraries containing executable code for the process to call and use. All of these program files are a part of the same process; its why a process can have an instance of multiple program files or even multiple instances. Processes may execute in emulated or hardware environments by a central processing unit (CPU) or multiple CPUs or CPU cores. CPUs that support hyper threading or parallel pipeling can also execute multiple instructions from different processes at the same time. This means that the process may not be executed in a sequential manner (one instruction at a time) but may be executed in a number of different ways depending on the environment and hardware configuration. The IA32 CPU family defaults with these features disabled. This means that at computer startup, the CPU will execute all instructions one at a time (although might cache them in an instruction cache buffer ). However if the operating system or executive were to enable these features for a process, the process and system must be designed in a way to be multi-processor safe . This one is an advanced topic however and is very easy to run into errors and thus will be discussed in an advanced chapter. We can break some processes apart into threads and tasks . We will look at these next. Threads and tasks Threads can be defined as a single execution path inside of a process. For example, in the most basic of an example we can have a program that just displays a message and returns: #include <stdio.h> int main (int argc, char** argv) { printf (â€œHello, world!â€); return 0; } In this example, the process has a single thread: it begins at main() and the thread ends when the process terminates. (Do note however that this might not actually be the case: The runtime library that calls main() might contain threads.) Lets look at a multithreaded example: #include <stdio.h> static int _notExit = 0; int thread (void* data) { while (_notExit) { /* do something useful */ } return 0; /* thread terminates returns to runtime which calls TerminateThread */ } int main (int argc, char** argv) { CreateThread (thread); printf (â€œHello, world!â€); return 0; } In this example, CreateThread calls the operating system to set thread() as a new flow of execution . After CreateThread() if called, thread() will be called by the operating system or executive and execution will continue inside of both thread() and main() simultaneously until one of them terminates. Notice that all processes are threads, but threads are not processes. A process can contain a single thread or many threads. Threads inside of a process can access and share the same global variables; although some compilers support thread-local variables as well. Operating systems that support threads are said to be multi-threading capable . Examples of such operating systems include Windows, Linux, and Mac OS. Tasks are synonymous with threads. Tasks represent a task for the operating system or executive to execute. Thus any operating system that supports multithreading effectively supports multitasking . It is important to note though that not all multitasking operating systems supporting multi-threading. What exactly is a process? We have currently defined a process as an instance of a program or a part of a program; lets elaborate on this definition by taking a deeper look inside of a process. Looking inside a process If we were to break apart a process, all we will see at the most fundamental level is code and data. Given ones' experience in programming, this makes sense: All programs are simply instructions instructing the CPU to perform an action or operating on data. It is understandable why programmers tend to separate the â€œdataâ€ part of the program from the â€œcodeâ€ part in order to facilitate program development. .data and .text (for program code) are two of what later became many different types of sections within a program binary. Sections not only help program development but also facilitates standards for how different types of things can be stored within program binaries. We will first discuss program sections and how they can be placed within a process address space . We can then discuss symbolic information , debugging information, export and import tables, and how they can be used. Program sections We have already looked at two sections (or segments ): .data and .text . The program file contains these and other sections. The operating system or executive can load each section in the address space for the process to execute correctly. Sections can also be relocated during load time. This allows the operating system or executive to find the best location for each section if it needs to and update the process accordingly. However, different program file formats support different things so not all program file formats support section relocating. The Portable Executable (PE) file format is the primary program file format used by the Windows operating system. The PE file format supports many different sections for code, data, resource data, symbolic information, manifest data, and more. Each section is stored within the binary file written by the linker or compiler. In order to see how it is stored in the file, we need to take a look at the format of the PE file format. The above is an image of what is inside of the PE executable file. We can load an image into memory and parse the file contents as any other type of binary file so long as the sections do not need to be relocated. This is how the series boot loader is able to load our kernel image: The kernel in the series does not require section relocation so the boot loader can just load the file, locate the entry point in the headers, and call it directly. This is easy to do: /* Get entry point from PE headers */ IMAGE_DOS_HEADER dosHeader = (IMAGE_DOS_HEADER*) imageBase; IMAGE_NT_HEADERS ntHeaders = dosHeader->e_lfanew; IMAGE_OPTIONAL_HEADER optHeader = &ntHeaders->OptionalHeader; void (*EntryPoint) (void) = (void (*EntryPoint) (void) ) optHeader->AddressOfEntryPoint + optHeader->ImageBase; /* Call program entry point */ EntryPoint (); In a similar manner, we could parse the other headers and extract any type of information we want from the file: section information, debugging information, symbolic information, and more. Kernel debuggers and user mode debuggers typically use symbolic and debugging information to facilitate debugging. In other words, you could build your PE image with debugging information (or without); if you build it with you can attach a debugger to it remotely to perform source level debugging. Having different sections inside of the executable files makes it easier for parsing and writing executable files. They provide a consistent location and way to store the data and reference them from headers. For example, in PE files there is a .rscs section that stores the actual resources (string table, bitmap images, program info, cursor, etc.) In order to locate a resource, we just need to parse the directory entry for it at OptionalHeader->DirectoryEnteries [IMAGE_DIRECTORY_ENTRY_RESOURCE] which gives us an RVA (relative pointer) to the resource tree structures that point to the resource data inside of the .rscs. section. The point is that the executable format has a specific format defined by the PE file specification . It has a specific format so there is a standard way to get information from the file. Many compilers such as GCC and CL (Microsoft's compiler) is also capable of programmer-defined sections . In other words, programmers can also define their own section names and put whatever they need into that section. Operating system kernels and executives typically define special sections for different purposes. For example, both Linux and Windows define a special .INIT section containing one time initialization code and data. When initialization completes, the operating system kernel can free the section and re-use it for other things. Common sections There is a set of section names and types that are common to different object files and even architectures. It is important to be able to recognize these sections and what they are used for. They are as follows: .text .data .bss .rodata The .text section is the common section name given to the section that contains program code. This is also known as the code segment . This section might be read only on some systems in order to prevent writing to it; however this prevents self modifying code (which is typically not recommended anyways.) The .data section, as its name suggests, contains static and global data used by the program. It is always writable. The .bss section is a part of the .data section and is typically used for statically allocated data that are initialized to zero. The .bss section is always cleared by the operating system loader so all of the data in it is set to zero. The name â€œ.bssâ€, according to Wikipedia, initially stood for Block Started by Symbol in the United Aircraft Symbolic Assembly Program. The .bss section contains all null variables and so does not take any space in the object files. The .rodata section contains read only statically allocated data. It is typically common in Linux and Unix environments. Notice that there is no section for temporary data. Recall that temporary variables are stored on the stack and thus do not need to be stored in the program file. Custom sections in Microsoft Visual C Microsoft's compiler provides several pragma directives that programmers can use to control where to place data and code in specific sections and making custom sections. These are: alloc_text code_seg const_seg data_seg bss_seg init_seg section The program loader does not need to worry about any special sections that the program has, all it needs to concern itself with is loading them into memory. The program (and thus programmer) has the responsibility. Here is an example of using alloc_text for adding a function to a special section. error_t DECL mmInitialize (SystemBoot* mb) { return SUCCESS; } #pragma alloc_text (â€œ.initâ€, mmInitialize); In the above example, mmInitialize will be added to the section .init . This is a useful tactic used by some operating system kernels and executives. For example, the operating system kernel or executive can add or initialization code and data to a special .init section. Once initialization completes, the operating system can free that section to get some of the memory back. Symbolic information Symbolic information is the symbols that programmers give as names of addresses. For example, when we call a function like printf() how can the compiler and linker know what to do? Lets take a closer look. â€œ printfâ€ is a symbol for a function defined in a library. When we call â€œprintf()â€, the compiler adds the symbol printf to a symbol table managed by the compiler during the build process. Notice that the name of the function is a symbol. In a similar way, static and global variables are also symbols . We can argue that any name we give to an address (like a label in assembly language) is a symbol. Thus a symbol has two things: A name and an address. If we build without linking the library containing the code for printf, the compiler is unable to output the final executable because it will not be able to translate the entire code to machine language. In other words, like an assembler, it cannot do anything with code like the following unless it knows what the function is: call _printf An assembler cannot completely assemble this instruction unless it knows the address of the symbol _printf . The assembler can not know the address if it does not know anything about the symbol. To resolve this, we declare that the symbol is external and the assembler or compiler outputs an object file instead of an executable file. It partially translates the instruction to machine code but in a form like this: 0xe8 _printf This allows us to use another programâ€”a _linkerâ€”_to resolve these symbols. The linker looks at the export symbol tables in the different object files and libraries for the symbol â€œ_printfâ€. If it is found, the linker can get the address of the function code and update the machine code with that address to properly link and output a final executable program. If the symbol is not found, it is unresolved and the linker gives us the famous â€œunresolved external symbolâ€ error. Symbolic information in the executable image can be used by debuggers to display human-readable information (functions and variable) names but at the cost of a bigger program file size. There are different ways to â€œstoreâ€ additional information about a symbol in the symbol name itself. This differs based on the build environment and c alling convention . The standard C calling convention is CDECL which just prepends an underscore to all names. So, for example, if we call â€œprintf()â€; its CDECL symbolic name is â€œ_printfâ€. C++ symbolic names differ between compilers and store a lot more information then just a name (such as return data types and operand types, namespace, classes, template names, etc.) Due to this, C++ symbolic names are said to undergo name-mangling . For example, the function â€œ void h(void) â€ in CL (Microsoft's compiler) translates to the symbolic name**?h@@YAXXZ**. I will not go into the details of the name mangling format here. Notice something interesting here. C symbolic names do not store anything about return data types or operands, but C++ symbolic names due to name mangling do. This is understandable and presents one of the many differences between the languages: With C compilers, you can call functions with different operand types or number of operands without error (although perhaps a warning when it can be detected); C++ compilers do. Export and import tables Symbols in a program library or object file can be exported for use by other libraries or programs. Exported symbols just tell the compiler and linker to add the respective symbol to the export table . Program files and shared libraries (Windows DLL's) may export symbols for use by other programs or debuggers. In a similar way, program files can request to import a symbol for use. This is where we can complete our printf() example above. The Microsoft C Runtime Library is a shared library loaded with the program file. The operating system or executive can tell what DLL's a program file needs to operate by looking at the program import table . By default, CL (Microsoft's compiler) links with the Microsoft C Runtime Library import static library that contains the import table so the symbols are added and the respective DLL is included in the table. The operating system or executive must load all of the shared library files the program requires into memory if not already done so and update the program files Import Address Table (IAT) with the addresses of the functions in these other DLLs. The Microsoft C Runtime Library DLL that gets loaded not only includes the code for _printf but also exports the symbol _printf, so the operating system links them during runtime. (We will discuss that in more detail later.) Thus, when we call â€œprintf()â€ from a program file, this calls a jump table which calls the updated IAT address which calls the function â€œ_printfâ€ in the C runtime library DLL. So far we have covered processes, threads, tasks, and took a look into what program files are and how they work. The goal of this chapter is to be able to load, execute, and manage multiple processes and tasks. Lets look at that next. Process Management - In Detail Process Management is the management of processes in a software system. We have defined a process earlier as a program or a part of a program in memory. To manage processes, then, means managing multiple instances of programs in memory in a collaborated environment. This is typically a requirement in modern operating systems and implemented in the kernel or executive. Operating systems that support a form of process management is considered to be a multitasking operating system. Representation In order to manage a process, an operating system designer needs to determine how to best represent a process given OS design criteria and required system resources. A process consists of the following: Image of the executable in memory (machine code and data); Memory in use by the process and its virtual address space Descriptors used to represent the processes Process state information (registers, stack, attributes, etc.) The operating system is required to manage the processes and allocate system resources in a fair manner to the processes that request them. Lets look at each of these closer. Image of executable in memory Executable programs are stored as files on disk to facilitate program loading and managing. To load a program, an operating system loader loads the file into memory . The loader must also be able to understand the type of file (it must be an executable the operating system can work with) and possibly support features of these file types (like resources and debug information.) The image of the executable in memory is the current representation of the machine code and data of the image and how it appears in memory at any given time. We use the term â€œimageâ€ here to represent a â€œsnapshotâ€ of whats in memory. For example, its like taking a camera looking at a big array of bytes and taking a photo. The array of bytes can be machine code, data, or neither â€“ we don't know nor care. Only the program instructions know. Some data in the program image might be useful though to other programs or even the operating system itself. This is data the program image itself does not usually use; for example, the program file can contain debugging information. A debugger can be then attached to the program and use that information. In short, the operating system needs to be able to load the file from disk into memory somewhere in order to execute it. This can be like just loading the file into memory â€œas-isâ€. The operating system or another program can then get any useful data from the program file that it may need. Memory in use by the process and its Virtual Address Space Processes typically have calls to dynamically allocate memory and use stack space just like the operating system does. The operating system is required to allocate space for a process stack and heap memory for the process to use . For example, the operating system typically allocates a default stack size to all processes. The executable file for the process however can also tell the operating system to allocate a larger stack space if the process needs it . The process heap is different. While the stack is allocated by the operating system before executing a process, the heap is not. Instead, each process has its own heap allocator in user mode. This is implemented in the C Runtime Library (CRT) using the familiar interface of malloc, free, realloc, brk, and sbrk functions. Programs that are linked with the CRT can call these functions to allocate memory. Programs that are not linked with the CRT however must implement their own heap allocator or link with another library that does. The CRT Runtime implements a user mode heap allocator (typically a free list). The C function malloc might call brk, which calls the OS using the System API. The C function brk calls the OS in order to allocate more virtual memory to expand the heap when needed. In short, the user mode heap works like this: The program calls malloc, which might call brk, which calls the OS using the System API to allocate virtual memory for the heap. The malloc and free family of functions implement their own user mode heap allocator. They only call the OS to allocator or free memory from the virtual address space. In preemptive multitasking , all processes have their own virtual address space. This means every process must have their own Page Directory and associated page tables. In order to manage process specific information, we use a process control block (PCB) . Lets look at that next. Descriptors used to represent processes A Process Control Block (PCB) is a data structure used to store the information about a process or task. The PCB contains information such as interrupt descriptor pointers, Page Directory Base Register (PDBR). Protection level, running time, process state, process flags, VM86 flag, priority, and Process ID (PID). PCBs may contain a lot more information â€“ its really OS specific. Operating systems may used a linked list of PCB's to manage processes. When creating a new process, the operating system needs to allocate a new virtual address space, load and map the image, and attach a new PCB structure to the list. The scheduler uses the PCB list in determining what process to execute and to store the current state. Process State Information Process state information includes the entire register state of a process, in-memory state, Input/Output request state of the process at a given time. The process state is stored in the PCB when switching tasks. This is done by the heart of a multitasking operating system: the scheduler. Additionally, the current running state of the process is used to control the execution of processes by the operating system. In the most simple case, a state is either RUNNING or NOT RUNNING. With this model, a process just created as stored in a NOT RUNNING queue and only labeled as RUNNING when it is in execution. The process that is NOT RUNNING may still exist in memory but in a waiting state until either the RUNNING process terminates or is interrupted by a process dispatcher inside of the scheduler. In a three-state process management model, processes may either be RUNNING, READY, or BLOCKED. When a RUNNING process requests access to something that requires the process to wait (such as an I/O request) the operating system may change the process from RUNNING to BLOCKED. When the request can be performed, the process may be moved to either RUNNING or READY states. Processes in the READY state just means the process is ready for execution by the process dispatcher. Processes that are RUNNING are already being executed. The final model is a five state process management model. This model utilizes five states: SUSPEND BLOCKED, BLOCKED, SUSPEND READY, READY, and SUSPENDED. Scheduling The scheduler is the component of an operating system kernel or executive that is responsible for task switching and CPU usage allocation. Operating systems employ scheduling algorithms to determine what task to execute next. Common scheduling algorithms used include but are not limited to First-in First-out, Shortest remaining time, Fixed priority preemptive, round-robin, and a multilevel queue. Possibly the most common algorithm used by both Windows and Linux is a multilevel feedback queue . Basic process management support Now we can implement basic process management support. The goal is simplicity so we will not be implementing an advanced multilevel feedback system with vm86 task support, I/O resource allocations, etc but will focus on a simpler but still efficient scheduler. In order to do this, lets look at the goals of what we must do in order to add support: Load and parse an executable image into memory; Manage a list of PCBs for processes; Support user mode tasks; Support multiple virtual address spaces Allocate stack space for each process; default size can be 4k; Select a scheduling algorithm and implement task switching These are the goals in order to support multitasking. The processes will be user mode processes. Multitasking, however relies on both process management and scheduling . Due to this, we will focus on building the framework to support multitasking but will only allow one process with one thread for this chapter. This will be extended in the next chapter as we implement a scheduler. Process Control Block The PCB structure for our system will be simple: #define PROCESS_STATE_SLEEP 0 #define PROCESS_STATE_ACTIVE 1 #define MAX_THREAD 5 typedef struct _process { int id; int priority; pdirectory* pageDirectory; int state; /* typedef struct _process* next; */ /* thread* threadList; */ thread threads[MAX_THREAD]; /* note: we can add more information, such as the following: -LDT descriptor [if used] -Processor count being used -User and kernel times -Execution options, etc */ }process; We can add more to this structure, but the above is really all we need. Notice that it stores the process ID (PID), priority and virtual address space. The two commented entries are provided for completeness only; in a typical OS they should be linked lists of processes and threads. This, however, requires a kernel heap allocator which we have not written. For simplicity, we will store 5 thread objects in the process as an array. The final thing we need is a way to handle threads. All processes have at most one thread which starts execution at the entry point. typedef struct _thread { process* parent; void* initialStack; void* stackLimit; void* kernelStack; uint32_t priority; int state; trapFrame frame; }thread; The thread structure stores general information about a thread in a process. Note that the structure stores a pointer to the parent process and information about the thread stack, priority, state (if its running or not), and a trap frame. The trap frame stores the current register state of a running thread. typedef struct _trapFrame { uint32_t esp; uint32_t ebp; uint32_t eip; uint32_t edi; uint32_t esi; uint32_t eax; uint32_t ebx; uint32_t ecx; uint32_t edx; uint32_t flags; /* note: we can add more registers to this. For a complete trap frame, you should add: -Debug registers -Segment registers -Error condition [if any] -v86 mode segment registers [if used] */ }trapFrame; We will not be using the trap frame structure much in this chapter since we are not implementing multi-tasking yet. We will, however, be using the trap frame structure more in the next chapter as we develop a scheduler to store the current state of each thread. Virtual Address spaces A complication occurs when we want to support multiple virtual address spaces. Each process address space consist of the entire 4GB address space where the kernel code and data is located at 2GB. When we switch processes, we need to be able to switch address spacesâ€”but only the low 2GBs of the address space (â€œuser landâ€). In other words, lets say a user mode process is running. Somehow we need to be able to call the scheduler in the kernel to be able to switch tasks. Ah, but this means our kernel code needs to be in that same address space! If its not, its an instant crash. To resolve this problem, we have to do just thatâ€”map our kernel code into every process address space. You might be wondering how this can be done. However it might become more clear when we consider that multiple virtual addresses can refer to the same physical frame in memory . In other words, we can map the kernel stack and code into both of the address spaces. Please see the following image. The above image displays two virtual address spaces with the physical address space. Notice how the location of the process stack and code share different locations in physical memory. In other words, they are mapped to the same basic virtual address location to different physical address frames using our virtual memory manager. Lets consider the kernel for a moment. The kernel starts up in an environment with a single address space. It maps itself into its own address space during the initialization process. We need to still be able to map the kernel space into the other process address spaces as well to prevent problems. The kernel is already mapped into its own address space and is located at some place in physical memory. This means the kernel can re-map itself to the other process address spaces as well. In the series kernel, the kernel maps itself from 1MB physical to 3GB virtual. The kernel must map 3GB region of all processes to 1MB physical, then, in order to map itself into each process address space. The kernel and kernel stack must be mapped to the same location in every process address space . Operating systems can also map a portion of the kernel into the process address space rather then the entire kernel. This is quite common in large systems. Address Space Management We need to be able to work with being able to map virtual pages from different address spaces. More specifically, we need to be able to do the following: Create a page table from any page directory Map any physical address to virtual address from any page directory Get the physical address of any virtual mapping from any page directory Create new address spaces The Virtual Memory Manager in the series currently does not support this functionality. We can quickly implement them, though, so lets do so now. Creating a page table To create a page table, all we need to do is to allocate a free frame (recall that a page table consist of 1024 PTEs which is 4096 bytes, the size of a page) and add it to the frame of a PDE in the page directory. V irt >> 22 just allows us to get the directory index from the virtual address. If the PDE at pagedir [directory_index] is 0, then we know that this page table does not exist and so we allocate it using the physical memory manager. If it does exist, no need to allocate. We finish by clearing the page table which effectively sets its pre sent bit to 0 (not present.) int vmmngr_createPageTable (pdirectory* dir, uint32_t virt, uint32_t flags) { pd_entry* pagedir = dir->m_entries; if (pagedir [virt >> 22] == 0) { void* block = pmmngr_alloc_block(); if (!block) return 0; /* Should call debugger */ pagedir [virt >> 22] = ((uint32_t) block) | flags; memset ((uint32_t*) pagedir[virt >> 22], 0, 4096); /* map page table into directory */ vmmngr_mapPhysicalAddress (dir, (uint32_t) block, (uint32_t) block, flags); } return 1; /* success */ } This function allows us to create page tables for any page directory. Mapping physical addresses The next missing functionality is to be able to map physical to virtual addresses for different page directories. This one is easy. void mapPhysicalAddress (pdirectory* dir, uint32_t virt, uint32_t phys, uint32_t flags) { pd_entry* pagedir = dir->m_entries; if (pagedir [virt >> 22] == 0) createPageTable (dir, virt, flags); ((uint32_t*) (pagedir[virt >> 22] & ~0xfff))[virt << 10 >> 10 >> 12] = phys | flags; } This function follows the basic functionality we implemented before in the virtual memory manager. We test for a valid page table, and create one if it is marked not present. The last line performs the mapping. This function allows us to map physical to virtual addresses of any virtual address space. Getting physical addresses The next missing functionality is the reverse of what we did above: obtaining the physical address of any virtual address from a specific address space. void* getPhysicalAddress (pdirectory* dir, uint32_t virt) { pd_entry* pagedir = dir->m_entries; if (pagedir [virt >> 22] == 0) return 0; return (void*) ((uint32_t*) (pagedir[virt >> 22] & ~0xfff))[virt << 10 >> 10 >> 12]; } This function tests for a valid page table at that virtual address (by checking if its present) and returns the physical frame by dereferencing the PDE and PTE and returns the frame. Creating a new address space Each process runs in its own virtual address space. In order to achieve this, we must be able to create multiple address spaces. pdirectory* createAddressSpace () { pdirectory* dir = 0; /* allocate page directory */ dir = (pdirectory*) pmmngr_alloc_block (); if (!dir) return 0; /* clear memory (marks all page tables as not present) */ memset (dir, 0, sizeof (pdirectory)); return dir; } Notice the simplicity of this function: all it does is allocate a block and clears it. This makes sense as a page directory represents an address space and a page directory is 4096 bytes. By clearing, we are effectively setting the present bit to 0 in all the PDE's. When it is time to execute a process we must be able to switch to this new address space that we just created. In other words, we need to be able to load this new page directory into the PDBR. We already implemented this functionality in the PMM. If we just load an empty page directory into the PDBR, however, we will surely triple fault right after. The cause of this is simple: none of our kernel code or stack is mapped into this new address space. To resolve this, we just need to map kernel space. Interestingly, we can just copy the current page directory (stored in the PDBR) into this new address space like the following. memcpy (dst->m_entries, cur->m_entries, sizeof(uint32_t)*1024); This is all that we need to do. We do not need to worry about copying any of the page tables as they were already mapped into the original page directory. The above effectively makes a copy of the address space â€“ the kernel page tables mapped into both address spaces which is what we want. Creating a thread In order to create a thread, we need to first decide what our createThread function needs and what thread creation actually implies. Recall that we defined a thread as a single path of execution. Knowing this, all we need is an entry point function. When the function is completed, it calls the operating system to terminate the thread. This is typically done by the system API (such as the Win32 API) to simplify creating and terminating threads. To create a thread, all that we need to do is allocate a thread structure and add it to the process. We were originally going to implement this functionality for this demo however decided to leave it for chapter 25 where we look at multi-threading. Process creation In order to create a process, we must already have a dedicated loader component for the operating system. The loader component is responsible for loading and parsing executable files, clearing the BSS section, section alignment, and any other thing you might want, such as dynamic loading of dynamic linked libraries. Creating a loader can be a complex task, specifically for a file format as complex as PE. Due to this, I opted to go for a simpler solution for the series so we can focus on the goal of this chapter: process management. In order to crate a process, we must have a clear understanding of what a process is and how it differs from that of a thread. To be specific: Threads each have their own dedicated stack; the process itself does not have one. Each process must have at least one thread. This starts at the entry point of the process. Each process must have their own virtual address space. Threads in a process share the same address space as the process. Each process must be loaded from disk as an executable image. This is typically done using a separate loader component. Due to the series not having a dedicated image loader component, for simplicity we will perform all of these steps in a single function called createProcess . The function follows the following steps. Load the executable file. Create the address space for the process. Create a Process Control Block (PCB). Create the main thread. Map the image into the process virtual address space. This is quite a lot for a single function. Remember, however, that it is better to separate the loader from process creation; later we can move the loading of the executable file to a dedicated loader. For simplicity, the routine assumes the same criteria of the boot loader. That is, the image to be loaded must have sector aligned sections (using the /align:512 flag) and can not be linked with any Microsoft Windows runtime libraries. While I might decide to add this functionality to the demo in the future, this complicates the loading code andâ€”as noted earlierâ€”is typically handled by the loader component anyways. Process Address Space structure At the moment, the kernel for the series OS has a lot of kernel structures loaded below the 1MB mark in identity mapped memory. This includes the kernel stack, initial page directory table and the page tables. The Direct Memory Access Controller (DMAC) memory region may also be located in this region. We must also take into consideration that the kernel also utilizes other memory regions (such as display memory) that are also in this identity mapped region. This was all done for simplicity only. Typical kernels would initialize the kernel stack and initial page tables in kernel memory initially using Position Independent Code (PIC). PIC is also what allows higher half kernels to start when loaded at some other physical base address. This is tricky to do right which is why I decided against it for the series. The result however created a mess: we now have a few kernel structures below 1MB. Rather then moving things around, I decided that reserving 0-4MB for kernel mode only would be the best option. This allows the kernel to continue functioning with no modifications at all and no problems with remapping memory for display output and other basic things. In other words, the address space will look like this: 0x00000000-0x00400000 â€“ Kernel reserved 0x00400000-0x80000000 â€“ User land 0x80000000-0xffffffff â€“ Kernel reserved This means that all processes must have an image base within the region of 4 MB and 2 GB. I will be using 4MB as the base address of all user mode processes. The first 4 MB will remain identity mapped as kernel mode pages (this is already done); and the kernel itself will remain mapped at 3 GB. In short, a ll pages for the process will be mapped as user mode pages between 4 MB and 2 GB. Creating a process With all of that in mind, lets take a look at the function. This is a fairly long routine as it includes some software that is typically done in loaders. For this demo, the software loads and maps the image into the current address space rather then creating a new one; although both are implemented. This was done due to the software only designed to run one process at a time. We will change this in chapter 25 when we cover multitasking. Notice two new functions - vmmngr_createAddressSpace and mapKernelSpace ; these are not currently used in the demo. The first function allocates a new address space (we looked at this earlier in the chapter), the second maps kernel space into a virtual address space. That is, it maps the kernel memory, stack, page directory, and display memory into a new address space. Although these functions are not used, they will be used in the next chapter. The validateImage function just parses the image headers and verifies that it is supported. Finally, although it creates an initial thread structure; it does not support multiple threads. It assumes one thread per process; where only one thread of one process can execute. int createProcess (char* appname) { IMAGE_DOS_HEADER* dosHeader; IMAGE_NT_HEADERS* ntHeaders; FILE file; pdirectory* addressSpace; process* proc; thread* mainThread; unsigned char* memory; uint32_t i; unsigned char buf[512]; * open file */ file = volOpenFile (appname); if (file.flags == FS_INVALID) return 0; if (( file.flags & FS_DIRECTORY ) == FS_DIRECTORY) return 0; /* read 512 bytes into buffer */ volReadFile ( &file, buf, 512); if (! validateImage (buf)) { volCloseFile ( &file ); return 0; } dosHeader = (IMAGE_DOS_HEADER*)buf; ntHeaders = (IMAGE_NT_HEADERS*)(dosHeader->e_lfanew + (uint32_t)buf); /* get process virtual address space */ //addressSpace = vmmngr_createAddressSpace (); addressSpace = vmmngr_get_directory (); if (!addressSpace) { volCloseFile (&file); return 0; } /* map kernel space into process address space. Only needed if creating new address space */ //mapKernelSpace (addressSpace); /* create PCB */ proc = getCurrentProcess(); proc->id = 1; proc->pageDirectory = addressSpace; proc->priority = 1; proc->state = PROCESS_STATE_ACTIVE; proc->threadCount = 1; /* create thread descriptor */ mainThread = &proc->threads[0]; mainThread->kernelStack = 0; mainThread->parent = proc; mainThread->priority = 1; mainThread->state = PROCESS_STATE_ACTIVE; mainThread->initialStack = 0; mainThread->stackLimit = (void*) ((uint32_t) mainThread->initialStack + 4096); mainThread->imageBase = ntHeaders->OptionalHeader.ImageBase; mainThread->imageSize = ntHeaders->OptionalHeader.SizeOfImage; memset (&mainThread->frame, 0, sizeof (trapFrame)); mainThread->frame.eip = ntHeaders->OptionalHeader.AddressOfEntryPoint + ntHeaders->OptionalHeader.ImageBase; mainThread->frame.flags = 0x200; /* copy our 512 block read above and rest of 4k block */ memory = (unsigned char*)pmmngr_alloc_block(); memset (memory, 0, 4096); memcpy (memory, buf, 512); /* load image into memory */ for (i=1; i <= mainThread->imageSize/512; i++) { if (file.eof == 1) break; volReadFile ( &file, memory+512*i, 512); } /* map page into address space */ vmmngr_mapPhysicalAddress (proc->pageDirectory, ntHeaders->OptionalHeader.ImageBase, (uint32_t) memory, I86_PTE_PRESENT|I86_PTE_WRITABLE|I86_PTE_USER); /* load and map rest of image */ i = 1; while (file.eof != 1) { /* allocate new frame */ unsigned char* cur = (unsigned char*)pmmngr_alloc_block(); /* read block */ int curBlock = 0; for (curBlock = 0; curBlock < 8; curBlock++) { if (file.eof == 1) break; volReadFile ( &file, cur+512*curBlock, 512); } /* map page into process address space */ vmmngr_mapPhysicalAddress (proc->pageDirectory, ntHeaders->OptionalHeader.ImageBase + i*4096, (uint32_t) cur, I86_PTE_PRESENT|I86_PTE_WRITABLE|I86_PTE_USER); i++; } /* Create userspace stack (process esp=0x100000) */ void* stack = (void*) (ntHeaders->OptionalHeader.ImageBase + ntHeaders->OptionalHeader.SizeOfImage + PAGE_SIZE); void* stackPhys = (void*) pmmngr_alloc_block (); /* map user process stack space */ vmmngr_mapPhysicalAddress (addressSpace, (uint32_t) stack, (uint32_t) stackPhys, I86_PTE_PRESENT|I86_PTE_WRITABLE|I86_PTE_USER); /* final initialization */ mainThread->initialStack = stack; mainThread->frame.esp = (uint32_t)mainThread->initialStack; mainThread->frame.ebp = mainThread->frame.esp; /* close file and return process ID */ volCloseFile(&file); return proc->id; } Process execution To execute a process, all we have to do is get EIP and ESP from the main thread in the process, drop to user mode, and execute it. We run into a problem though: how do we know what process to execute? Due to us having no scheduler yet, we can only execute one process at a time. This is done using a global process object that stores what process we are currently working with. GetCurrentProcess() returns a pointer to this object. We get ESP and EIP from its main thread, switch to the process address space, and drop to user mode to execute it. Notice that we do not call enter_usermode . This is due to user mode software not being able to access kernel-only pages. If we called it, we will page fault. Instead, we just drop to user mode and execute the program directly using IRETD. void executeProcess () { process* proc = 0; int entryPoint = 0; unsigned int procStack = 0; /* get running process */ proc = getCurrentProcess(); if (proc->id==PROC_INVALID_ID) return; if (!proc->pageDirectory) return; /* get esp and eip of main thread */ entryPoint = proc->threads[0].frame.eip; procStack = proc->threads[0].frame.esp; /* switch to process address space */ __asm cli pmmngr_load_PDBR ((physical_addr)proc->pageDirectory); /* execute process in user mode */ __asm { mov ax, 0x23 ; user mode data selector is 0x20 (GDT entry 3). Also sets RPL to 3 mov ds, ax mov es, ax mov fs, ax mov gs, ax ; ; create stack frame ; push 0x23 ; SS, notice it uses same selector as above push [procStack] ; stack push 0x200 ; EFLAGS push 0x1b ; CS, user mode code selector is 0x18. With RPL 3 this is 0x1b push [entryPoint] ; EIP iretd } } Demo Running a usermode process that uses the system API Demo Download This is an important milestone for any operating system in development; this milestone marks the beginning of interactivity and self hosting system designs. The demo uses the topics we looked at in this chapter, memory management chapter, and the PE loading chapter to implement a proc (process) command that loads an executable image ( Portable Executable format), maps it into its own address space in user land, and interacts with the kernel using the system API through two system calls: DebugPrintf which can be used by the user land process to display strings using the kernel text terminal, and TerminateProcess which is used to terminate the process itself. The system calls are implemented using software interrupts that we looked at in earlier chapters. Project â€œprocâ€ The usermode process we used is called proc . It is built as a 32 bit PE executable image, image base at 4 MB, with 512 byte section alignment. Here is the source for the project for reference. void processEntry () { char* str=\"\\n\\rHello world!\"; __asm { /* display message through kernel terminal */ mov ebx, str mov eax, 0 int 0x80 /* terminate */ mov eax, 1 int 0x80 } for (;;); } Notice the process uses system calls to display the message and to terminate. These system calls are added to our system API implemented in earlier chapters. Int 0x80 function 0 calls DebugPrintf and Int 0x80 function 1 is a new function, TerminateProcess . We can add more system services to improve the functionality of the demo; such as for file reading or input in a similar way. TerminateProcess is responsible for cleaning up process resources and returning execution to the kernel command shell. Recall that when int 0x80 is executed, the CPU traps into kernel mode and restores CS, SS, and ESP to their respective values from the TSS. Thus whenever any of the system calls execute, the CPU is in kernel land running in the same address space. This allows us to call kernel functions directly from TerminateProcess and to call the kernel command shell. extern \"C\" { void TerminateProcess () { process* cur = &_proc; if (cur->id==PROC_INVALID_ID) return; /* release threads */ int i=0; thread* pThread = &cur->threads[i]; /* get physical address of stack */ void* stackFrame = vmmngr_getPhysicalAddress (cur->pageDirectory, (uint32_t) pThread->initialStack); /* unmap and release stack memory */ vmmngr_unmapPhysicalAddress (cur->pageDirectory, (uint32_t) pThread->initialStack); pmmngr_free_block (stackFrame); /* unmap and release image memory */ for (uint32_t page = 0; page < pThread->imageSize/PAGE_SIZE; page++) { uint32_t phys = 0; uint32_t virt = 0; /* get virtual address of page */ virt = pThread->imageBase + (page * PAGE_SIZE); /* get physical address of page */ phys = (uint32_t) vmmngr_getPhysicalAddress (cur->pageDirectory, virt); /* unmap and release page */ vmmngr_unmapPhysicalAddress (cur->pageDirectory, virt); pmmngr_free_block ((void*)phys); } /* restore kernel selectors */ __asm { cli mov eax, 0x10 mov ds, ax mov es, ax mov fs, ax mov gs, ax sti } /* return to kernel command shell */ run (); DebugPrintf (\"\\nExit command recieved; demo halted\"); for (;;); } } // extern \"C\" Bug report There is a reoccurring bug that has been fixed in a few previous demo's but may still be present in others. We plan to upload the fix for all the demo's that it may be present in the future. The bug is in vmmngr_initialize , where some demo's call this function prior to initializing the physical memory manager and those demo's also improperly map kernel space thus may result in page fault or triple fault. It has been resolved (again) in this chapter's demo so please check main.cpp and mmngr_virt.cpp for the updated code. Updated file list sysapi.h - _syscalls has been updated to include DebugPrintf and TerminateProcess. task.h â€“ New. task.cpp â€“ New. main.cpp â€“ Added proc command. Also VMM bug fix. mmngr_virt.h â€“ New address space functions. mmngr_virt.cpp â€“ New address space functions. Also VMM bug fix. image.h â€“ PE image structures and definitions. proc/main.cpp â€“ New. Conclusion In this chapter we have looked at processes, threads, process management, and built basic process management support. We have covered everything needed for executing user mode programs from disk which marks a big milestone for the operating system. In the next chapter we will build on the process management functionality implemented in this chapter to build a scheduler and complete preemptive multitasking support. Resources The following links were referenced to provide more through and accurate information. Please reference them for additional information. http://en.wikipedia.org/wiki/Process_(computing) http://en.wikipedia.org/wiki/Scheduling_(computing)#Scheduling_disciplines http://en.wikipedia.org/wiki/Process_management_(computing) Additional links The following links are additional tutorials or resources related to this topic. They might be helpful as a supplement to the material or even help with providing different designs. If you know of any additional links that might be helpful to add, please let me know. Links may also include some multi-tasking concepts that will not be looked at in depth until the next chapter. http://www.jamesmolloy.co.uk/tutorial_html/9.-Multitasking.html"
  },
  "articles/61_unorganised_tutorial/T25.html": {
    "href": "articles/61_unorganised_tutorial/T25.html",
    "title": "Process Management 2 | BrokenThorn OS Dev Tutorials",
    "keywords": "Process Management 2 Introduction Welcome! In the previous chapter we detailed basic process management topics, including Inter-Process Communication (IPC), protection, resource allocation, Process Control Block (PCB), process execution states, and process address spaces. We have also detailed single tasking support and implementing basic single tasking. This chapter is a continuation of the previous chapter and will go into more detail of the respective topics; with emphasis on multitasking, scheduling, security, and mutual exclusion. In particular, we will cover: Multithreading; Multitasking; Init and Idle Process; Kernel/User Shared Data Space; Mutual exclusion and Semaphores; Introduction to Concurrent programming; Scheduling algorithms; Introducing to the MP Standard. We will assume that you have read the previous chapter and so this chapter will be more advanced; focusing on real world designs and implementations. Like the previous chapter, we will first dive into the theory behind these topics and then present a demo that will implement complete multi-threading in user land processes. Also note that we only provide a brief introduction to the MP standard; we may cover it in more detail in a later article. Implementing MP support requires proper support for the APIC which is an advanced topic. Process State Management We already talked a lot about processes throughout the series so this will just be a review of process states and process creation. In the previous chapter we implemented a function for creating a process. We will be modifying it in the accompanying demo to create a new task for the process so that it can be properly executed. We need to review state management since it ties closely with the scheduling of processes. The state of the process is the current activity employed by the process. At a minimum, the process can be created , executed , ready to be executed, and terminated . Already this gives us four possible states: New . The process is being created. Running . The process is executing. Ready . The process is ready to be executed. Terminated . The process has completed. This is a good start. However we can do better then this. Let's say that we have some process running, and the process sends a request to read a large file from the disk. However, in a system with multiple processes, the disk may be busy handling the request from that process. Our process needs to Wait until the Input/Output Request can be completed. For another example, let's say that we have two processes, but they communicate with each other through signals . A process would need to Wait for a signal to be raised . This would be our fifth state: Wait . The process is waiting to complete an I/O request, exception, or signal. Putting everything together, a process goes through the following states. The above diagram illustrates the current state model. New processes are admitted into the system Ready queue . When the Scheduler dispatcher selects the process to run, the process enters the Run state. From here, the process may take any number of state changes. If an interrupt or exception fires, the Scheduler Dispatcher may need to switch to another process which involves moving our process back into the Ready queue . If, instead our process tries to read from a file, the process will initiate the I/O request and be placed on the Wait queue until the request is completed. When the I/O request is satisfied, the process will be placed back into the Ready queue to be selected by the Scheduler dispatcher again. Finally, at any time while running the process terminates, it will be terminated. Sometimes it might be helpful to suspend a process. This involves taking the process out of memory and storing its state on the disk. This is specifically useful when freeing up system resources and allows other processes with higher priority to run. This requires, at a minimum, two more states: Suspend Ready Suspend Wait Adding these to our previous diagram, we have the following. Processes in the Ready or Wait state may be Suspended depending on the resource demand of the system. There can be many more states that you can add to this depending on your design needs, however for most general purpose operating systems, the above state diagram would suffice. For our purposes, we will only be concerned with the Ready , Run , and Terminated states. However we may also implement the Wait state to properly support the sleep function in the accompanying demo. Concurrent Programming So we looked at process states and state management and process creation. We have also dived deep into a process in memory with the previous chapter. The final topic that we need to dive into is multitasking . The heart of multitasking is the Scheduler dispatcher which we will cover in the next section. The Scheduler dispatcher is responsible for moving processes between states and schedule processes for execution. This is why we covered those first â€“ we will be using them in that section later on. Before moving on to the scheduler however, we need to take a closer look at what happens with multitasking when there are multiple threads of execution . When two threads or processes run concurrently and share some data with each other, it becomes critical to synchronize the activities between the two threads of execution. Concurrency means that the current state of the process is not known. When multiple processes run along side each other and share data with each other, they are said to be running concurrently . Concurrent programming defines the set of techniques used to synchronize access to shared resources between concurrent processes or threads. Critical Section Problem On single core systems, the operating system will allocate a small amount of time for execution for each process. The system switches rapidly between the different processes running concurrently. Processes may be interrupted at any time. In addition, systems that support parallel execution may execute instructions from different processes at the same time. To see the problem of current programming, consider two processes with the following instructions. Process A: mov eax, [count] inc eax mov [count], eax Process B mov ebx, [count] dec ebx mov [count], ebx If we are to execute these processes concurrently, they would be interleaved in some order when the scheduler switches between the two processes. There are many different ways the processes may be interleaved, one way might be: mov eax, [count] inc eax mov ebx, [count] dec ebx mov [count], eax mov [count], ebx If count is shared between the two different processes, you might notice a big problem here. Because there is no control over the order of execution , we cannot insure that the value of count is valid because we may get different results depending on when the scheduler decides to switch between the two processes. The outcome depends on who reads and writes the variable first. What we have is a race condition . To combat the race condition, we need to guard the variable while it is being used by another process. We need to synchronize the two processes in some way. This is a part of the critical section problem . The problem is compounded on systems with multiple processors since the current execution state and current instruction streams are interleaved while executing a single process. The Problem. We need a method to control synchronization of a process that executes concurrently. When a critical section request is made, we must insure that only one processor executes the code within the critical section until it completes. Farther, we must insure that other processes and threads do not execute while we enter the critical section. The Criteria. Mutual Exclusion. When a process is executing in a critical section, no other process is executing in a critical section. Progress . Processes do not wait indefinitely to enter their critical section. Bounded Waiting. The amount of time between making the request to enter its critical section and actually entering it must be bounded. Semaphores Sow how do we implement mutual exclusion ? We need some form of cooperation between the two processes. If process A is operating on a shared resource, and process B needs access to it, we want process B to wait . However, once process A is done with the resource, we want it to signal that Process B can now use that resource . Thus only one process can ever use the shared recourse at any given time. This is mutual exclusion . What we can do is introduce another variable to keep track of whether or not the resource is currently being used or not. This variable is called a lock . We can then use this lock to keep track of the other resource. If the lock is 1, the resource is in use by some other process. If the lock is 0, the resource is free for use. This type of lock has a special name. It is called a mutex . The mutex has only two values and is also called a binary semaphore . Recall what we need to do: we need one process to wait and the other process to signal . These are the basic functions we will be using throughout this chapter. atomic Wait (Semaphore S) { while (S <= 0) Place process on S.Queue and block. S--; } atomic Signal (Semaphore S) { S++; } The mutex is just a * binary semaphore _with values of 0 or 1 only. Semaphores are generalized locks and are not restricted (that is, whereas the mutex only has two values, general semaphores do not.) Also notice the atomic keyword in the above code. This implies that the code will never be interrupted when it is executed. That is, it is guaranteed to run as a block of code on a single processor in the correct order. They are to be treated as a single unit (hence are called atomic operations.) Unfortunately, it isn't quite as simple as what we shown above. Atomic operations are hardware dependent and so we need some assistance from the processor to make it work. More specifically, we need to make use of the LOCK instruction prefix. We will discuss this in more detail later as we implement these primitives into actual code. For now, we believe that it is best to see some examples of using semaphores since they can be difficult when first introduced. It is important to get some practice with using them since you will be using them a lot if you ever plan to completely support multiprocessing. Example: We opened up this section by showing how the instruction flow can get interleaved as we swap between different processes. The problem was that both of the processes can be executed at any time, and because they share a resource, there was no way to verify the integrity of the resource. We can fix that with semaphores. Assuming count is a global variable that is shared by two processes, we can use semaphores to synchronize access to it. Note that signal and wait are atomic operations. Process A: count++; signal (s); Process B: wait (s); count--; signal (s); Spinlocks Mutual exclusion is the first criteria for a solution to the critical section problem. This means that, when one process enters a critical section, no other processes can enter a critical section. To implement this functionality, we need some method of implementing an atomic operation that can guarantee mutual exclusion. One idea is to use a simple variable to act as a lock. If the lock is 1, some process is inside of the critical section. So the first idea is, int lock=0; Process A: while(1) { if (!lock) lock = 1; do_something(); lock=0; } Process B: while(1) { if (!lock) lock = 1; do_something(); lock=0; } Pretty simple. The lock starts at 0, so whatever process runs first will detect this and set the lock. When its done, it releases the lock so the second process can now use it. This would work somewhat, but there is still a big problem. Let's say that process A detects that the lock is 0 but gets interrupted by process B before process A has a chance to set the lock. So process B detects the lock is also 0 and now sets it. So if process B gets interrupted somewhere in do_something , process A will continue executing â€“ as if the lock was still 0! And so both processes can still enter the same critical section (in this example, the critical section is the call to do_something ) at the same time if the processes get interrupted when trying to read and lock the lock variable itself. This seems like a small error, but it can quickly propagate and will happen quite a lot. So the problem here is that we cannot guarantee that accessing and setting the lock can be done without getting interrupted. The operation is not atomic . To be able to visualize what can happen without actual atomic operations, let's say that we have two threads. The first thread displays characters a-z and the second thread displays numbers 0-9. They run concurrently using the scheduler that we develop later on. Here are the threads, Process A: void task_1() { char c='a'; while(1) { DebugPutc(c++); if (c>'z') c='a'; } } Process B: void task_1() { char c='0'; while(1) { DebugPutc(c++); if (c>'9') c='0'; } } As these two tasks run concurrently, the output will become an interleaved mess. The reason is that both processes are reading and writing from shared resources without care. Even if we were to introduce a lock as we discussed above, the output wouldn't be much better. In this example, the shared resources are video memory and the global variables used by DebugPutc which is responsible for cursor positioning and scrolling. As one process reads the current x or y position or prepares to scroll, it may be interrupted and the position and other global variables can be mangled without the first process ever knowing. Sample without semaphores. Notice how the output is a mess. So to fix this, we need something more then a simple lock. Our direction is good â€“ but we need hardware support. If there was a method to make it so that we can test and set a lock variable in one single operation with the guarantee that it will never be interrupted (so it is atomic ) we can finally satisfy the mutual exclusion criteria. One such hardware primitive is the LOCK instruction prefix. This prefix locks the system bus from reads and writes while the instruction is being performed. Because the data bus is locked, it is guaranteed to be atomic. So a simple LOCK XCHG or LOCK BTS can be used when setting and testing a lock variable. For example, inline void acquire(int* lock) { _asm{ mov eax,[lock] a: lock bts [eax], 0 pause jc a } } inline void release(int* lock) { _asm{ mov eax, [lock] mov [eax], 0 } } We can now call these functions from to acquire and release the lock. Process A: void task_1() { char c='a'; while(1) { acquire(lock); DebugPutc(c++); release(lock); if (c>'z') c='a'; } } Process B: void task_2() { char c='a'; while(1) { acquire(lock); DebugPutc(c++); release(lock); if (c>'z') c='a'; } } And we get the desired result. Running Sample with spinlocks. Note how the display is now nicely in order. Classic Concurrency Problems Producer / Consumer Problem (Bounded Buffer Problem) This is the first classic concurrency problem we will look at. Suppose that we have two independent processes, one called the producer and the other called the consumer . Let's also assume that there is a shared buffer being used by both of the processes. The producer is responsible for putting data into the buffer and the consumer is responsible for taking data out. This is the basic setup for the classic Producer/Consumer Problem also known as the Bounded Buffer Problem . The problem is that we need to make sure that the producer does not add data to the buffer if its already full and the consumer does not try to remove data from a buffer that is empty. The problem gets more interesting when there are multiple producers and consumers. Example: This is a solution to the Bounded Buffer problem. This assumes a single producer and consumer running concurrently. Semaphore c = 0; Semaphore s = BUFFER_SIZE; Producer: while (true) { item = produce (); wait(s); write(item); signal(c); } Consumer: while (true) { wait(c); item = read(); signal(s); consume(item); } Readers / Writers Problem The classic R eaders/Writers problem is when an object is shared among many processes such that there are two types of processes â€“ readers and writers . Readers read the shared data but never modify it. Writers can read data and modify it. Many readers may read the data concurrently . Example: There are many different solutions and versions of this problem, this is one of them. Note that we use two semaphores here so that we can allow multiple readers at the same time. Semaphore c = 1; Semaphore s = 1; int count = 0; Writer: while (true) { wait(c); write(); signal(c); } Reader: while(true) { wait(s); count++; if (count == 0) wait(c); signal(s); read(); wait(s); count--; if (count == 0) signal(c); signal(s); } Inter-Process Communication Inter-Process Communication (IPC) is the technique supported by operating systems that permit processes to signal and share data with other running processes. There are many different types of techniques for implementing IPC protocols, we will introduce some of the most commonly used ones here. Pipes Pipes are a basic technique that uses a circular buffer to store the data between a producer and consumer. The producer writes data to the buffer and the consumer reads from it. There can be multiple producers and consumers of the data. There are two types of pipes, anonymous pipes and named pipes. Named pipes are given a name and appear as a file object in the virtual file system. Any process in the system can open named pipes. Anonymous pipes can only be opened by child processes that inherit it from the parent. The operating system must provide functionality for storing the data stream that is shared between the consumers and producers, reading and writing the stream, and blocking processes that attempt to read from the pipe when there is no data to read. The operating system must synchronize the reading and writing using the mutual exclusion techniques that we discussed above. This is usually done using a First-In-First-Out (FIFO) circular buffer and using semaphores to synchronize access to it when reading and writing it. Pipes are file system objects . When you Open a pipe, you will get a File Descriptor pointer back. So you can use the file Read and Write methods to read and write to the pipe as if it were a file. Open file handles are inherited by child processes , and so pipes are also inherited. Pipes can be managed just like file system descriptors. The Process Parameter Block stores a pointer to a Process Handle Table that stored all open references to file descriptors, pipes, and other system objects. They can also be trivial to implement on systems that already support device files . Message Passing The basic idea is simple enough â€“ a producer sends a message and a consumer takes it. There might be additional problems depending on if we want to support synchronized or asynchronous message passing. We also must think about how to store the messages, where they should be managed , the format of the messages, and how to verify that messages are delivered in the expected format to the expected process. So, what exactly is a message ? Messages are whatever the process wants it to be. The consumer and producer must agree on some type of protocol for how to interpret the message. They both need to know the data structure of the message. From the operating system side, the OS does not care about the format of the data â€“ unless its an OS defined message which is typical of microkernels . The operating system needs to implement support to Send and Receive messages at a minimum. Synchronous Message Passing For Synchronous message passing, we need at a minimum two functions. Assuming J and K are process identifiers (PID)'s, send(J, message) receive(K, &message) The producer calls send to post a message. With synchronous message passing, the producer gets put in the suspended queue until J calls receive to get the message. When J calls receive , the operating system can copy the message sent to J directly and resume J . The operating system can then put the producer back on the waiting queue so that it can be executed by the scheduler. Synchronous message passing does not require a message queue since only one (the producer or consumer) will ever be running at the same time (the other would be suspended or waiting .) Asynchronous Message Passing Asynchronous message passing also needs a minimum of two functions, send(J, message) receive(K, &message) The producer calls send to post a message and the consumer calls receive to obtain the message. With asynchronous message passing, the operating system maintains a message queue per process. Producers can send messages at any time and will not be suspended. Messages are copied to the end of the message queue. The consumer can then receive the message from the front of the message queue. The message queue itself is allocated in kernel memory ; a dedicated pointer in the Process Control Block points to the queue. We now have an interesting question. With synchronous message passing , when the process calls receive and there is no process that sent any message, the process gets suspended until another process calls send . With asynchronous message passing , we have two options: We can suspend the process that called receive or, We can have receive return a status code and just continue running the current process. It turns out that the better approach is to offer a few more functions, send(process, message) receive(process, &message) sendrec(process, &message) notify(process, message) Shared Memory When we map the same physical frames into the virtual address spaces of two or more processes, it is shared among those processes. Both processes would be able to read or write to the same pages (depending on the security attributes set when mapping pages. (For example, you can map the physical frames as read/write for process A but as read-only for process B.) Operating systems typically provide support of shared memory through memory mapped files . Under Windows, for example, you would first call CreateFile or OpenFile on a named memory mapped file object followed by MapViewOfFile which maps the region of memory into the process address space and returns a pointer to it. Scheduling The scheduler is responsible for the allocation of system resources. System resources include the CPU, memory, and system devices. There are typically many schedulers, however they tend to fall under three categories: short term , medium term , and long term . Long term schedulers are responsible for admitting processes into the system and terminating them. Medium term schedulers are responsible for suspending and resuming processes. Short term schedulers are responsible for allocating CPU time and dispatching processes. We will be primarily discussing the short term scheduler in this section since it is a core component to implementing a multitasking system. So, our goal here for the demo is to create a short term scheduler . Scheduling Algorithms There are many different algorithms that we can use, some more complicated then others. While we will provide an introduction to the more common algorithms, we will be sticking with the Round Robin approach to keep the demo simple. First Come First Serve In First Come First Serve (FCFS) , jobs are executed as they come. The algorithm is as simple as its name implies; the scheduler selects the first job and lets it run. Then the second. Then the next, and so on. The algorithm cycles through the jobs in the Ready Queue in the order that they came in. New jobs are not started until the previous one terminates. It is not very well suitable for preemptive multitasking. Example: In the following example, P1 arrives at time 0, P2 arrives at time 1, and P3 arrives at time 2. these processes are placed in the Ready queue to be executed. P1 is the first job, so the algorithm selects it to be run. P2 is selected next, but only after P1 is completed. P2 does not get selected until time=5. Process Arrive Run time Service time P1 0 5 0 P2 1 3 5 P3 2 8 8 Shortest Job First In the Shortest Job First (SJF) algorithm, the system must have a way to know the amount of time necessary for each job to execute. The algorithm selects the next job from the Ready Queue to execute that has the smallest time delta. This algorithm suffers from the problem of process starvation . Jobs can be left in the Ready Queue when jobs of smaller time deltas are given priority. Since this example is very similar to the FCFS algorithm discussed above and is almost never implemented in practice due to its requirement of calculating time deltas (your software needs to be an oracle to know beforehand how long processes will execute) we do not think another example is needed. Priority Queue The system can assign each job a priority number . Jobs with higher priority are then selected first. This is the basic idea behind priority scheduling algorithms . How priority is determined is up to the designer. Similarly, how to handle the case when two priority are the same is up to the designer. One idea is to have a default priority and make it user adjustable. When two priorities are the same, we can use FCFS or SJF to decide which one to use. Another idea is to calculate priorities based on a protocol . The protocol could be assigned by a system administrator or calculated using some measurement of system resources and memory constraints. It is more often common to see priorities used alongside other scheduling algorithms as we will see later on. To summarize though, just select the job from the Ready Queue that has the highest priority. Like with SJF , this algorithm suffers from process starvation since processes with higher priorities can starve out processes with lower priorities. Round Robin The system gives each process a time slice to run called a quantum . The system then preempts the currently executing process to allow another process to run. Processes are selected in the order that they appear in the Ready Queue . Because all processes are allowed to run, this algorithm does not starve any processes. The system is responsible for context swapping in order to save and restore the execution state of processes as they are selected to run. We will cover context swapping later when we cover multitasking . Example: Given processes P1, P2, P3 and a time quantum of 5, the Round Robin (RR) algorithm first selects P1 to run. After the quantum time is up, the system preempts P1. P1 is moved to the back of the Ready Queue. The system saves the context of P1. The algorithm selects P2 and the system performs a context switch. P2 can now execute. Process P1 P2 P3 P1 P2 P3 Quantum=5 0 5 10 15 20 25 Multilevel Queue Instead of using one Ready Queue to decide what to run next, why not use multiple ? The idea is that we can get the both worlds of privileged levels and another scheduling algorithm by combining them into a multilevel queue . The basic idea is that we would have multiple queues . And these queues are for different priorities . For example, if you have 5 priority levels, you would have 5 queues . The algorithm would first select a job to run based on priority from the highest priority queue. If the queue has multiple jobs in it, it uses another algorithm (like RR ) to decide what to run. You can also use different scheduling algorithms for the different priority queues. This algorithm has the potential for starving processes however for the same reason priority scheduling does. So we have a great algorithm here, but what can we do to prevent starving processes ? Multilevel Feedback Queue The Multilevel Feedback Queue is a modification of the multilevel queue to prevent process starvation . The problem with the multilevel queue was that, when a process of some priority L is inserted into queue L, we can starve the process by just submitting new jobs where the priority is greater than L. To prevent this, what we can do is change the priority of the process . So we can move processes from one priority queue into another. In our example above, the process with priority L would be moved to a higher priority queue after some time passes. This will continue until the process reaches the highest priority queue. Thus the process is never starved out. We can also lower the priority of jobs by moving them into lower priority queues which might be useful when important system tasks need to run. The difficulty of implementing multilevel feedback queues is determining when processes should be moved. This is the most common algorithm in use by modern operating systems today. Example: The following is an example of a multilevel queue. Here we have three queues, system processes have the highest priority and applications have the lowest priority. Different scheduling algorithms can be used on each of the different queues to select jobs from them. The scheduler selects the highest priority non-empty queue. It then uses another algorithm (such as FCFS or RR) to select a job from that queue. In multilevel feedback queues, the system can move processes between different queues. For example, we can move jobs from L3 then L2 then L1 over time, thereby raising its priority so it can run. Thus no process starvation. Queue Level Priority Queue L1 System Processes L2 Batch Jobs L3 Applications Multitasking We have covered a lot of material throughout this chapter. And at long last, we can finally get to the main focus of this chapter, multitasking . We will be putting everything together into code. We first covered process state management because the scheduler and multitasking component need to able to select and move processes between different states . For example, the scheduler often needs to switch processes from Ready to Running . If you plan to support more advanced paging techniques (such as page swapping algorithms ), you will need to be able to switch processes to and from a Suspended state. The system needs to be able to differentiate between a Suspended process and one that is still in memory awaiting a completion signal. Both processes have a Process Control Block (PCB) and uses system resources, however Suspended processes aren't using memory. We also needed a way to pause processes. We did this by introducing a Wait state. As you can see, state management is a critical component to implementing multitasking. This is why we covered this first. The next thing we looked at was Process Creation . We looked in more detail about how it is used with state management. In Chapter 24 , we implemented a CreateProcess function. Recall, that our function loaded a Portable Executable (PE) image into memory, mapped it into the virtual address space, and executed it in user mode. We will be building off of this function in this section to create a new process, and add it to the Ready queue to be selected by the Scheduler . Then we looked at an introduction to concurrent programming . Topics included the Critical Section problem, Mutual Exclusion , and Semaphores . Concurrency happens when multiple processes and threads run asynchronously . Concurrent programming provides techniques that we can use to synchronize communication between asynchronous processes. Concurrent programming is hard â€“ there is no right way to go about it. If you use concurrency, you can guarantee that your code has bugs â€“ most of which may never surface for years or decades. We introduced concurrent programming since the topic of this chapter is multitasking. Since shared resources tie close to multitasking (typically in the form of shared libraries, signals, and message passing), we included a brief introduction to it here. We then looked at an introduction to Inter-Process Communication (IPC) . IPC plays a critical role in all but the simplest of operating systems. And systems that support IPC with multitasking require the concurrent programming techniques discussed in this chapter. You have already been using a form of IPC through the use of system calls . Finally we covered scheduling algorithms . The Scheduler is the heartbeat of the operating system. It is responsible for selecting processes for running and is a core algorithm in the multitasking system. Now, finally , we will be putting things together as we dive into the world of multitasking operating systems. As you recall, there are three types of multitasking: Preemptive Non-Preemptive Cooperative We will focus on preemptive multitasking. The Plan We will be using the Round Robin (RR) scheduling algorithm. This algorithm requires us to be able to allocate a quantum as a resource to the process being selected. So we'll need a clock . The system has many different types of clocks: Programmable Interval Timer (PIT) Advanced Programmable Interrupt Controller (APIC) timer Real Time Clock (RTC) High Performance Event Timer (HPET) etc. For the purposes of the demo, we will be sticking with the PIT since it has been covered and already supported. So we have our scheduling algorithm and clock that we will be using. In Chapter 24, we introduced the Process Control Block (PCB) and Thread Control Block (TCB) . We will expand the TCB to include information needed to store the current thread state and switch from user mode to kernel mode. typedef struct _thread { uint32_t esp; uint32_t ss; uint32_t kernelEsp; uint32_t kernelSs; struct _process* parent; uint32_t priority; int state; ktime_t sleepTimeDelta; }thread; We will need some lower level stuff to create the task associated with a thread. The stack stores the current register context . We will be storing the register context on the stack pointed to be the esp field in the above structure. The scheduler is responsible for creating tasks, managing tasks, and switching tasks. We will look at each of these in more detail in the following sections. As always, all sample code is used in the demo program at the end of this chapter. The Ready Queue We first need a place to store these tasks. Tasks should be dynamically allocated from a non-paged pool by the kernel memory allocator. However, since the series does not implement a kernel allocator, we are limited to using an array for our implementation. Using a circular queue, we can implement the First-In-First-Out functionality required for Round Robin scheduling. The idea is so that we can move to the next task by simply removing the top element of the queue and pushing it to the back. So the new task would become the top of the queue. thread _readyQueue [THREAD_MAX]; int _queue_last, _queue_first; thread _idleThread; thread* _currentTask; thread _currentThreadLocal; /* clear queue. */ void clear_queue() { _queue_first = 0; _queue_last = 0; } /* insert thread. */ bool queue_insert(thread t) { _readyQueue[_queue_last % THREAD_MAX] = t; _queue_last++; return true; } /* remove thread. */ thread queue_remove() { thread t; t = _readyQueue[_queue_first % THREAD_MAX]; _queue_first++; return t; } /* get top of queue. */ thread queue_get() { return _readyQueue[_queue_first % THREAD_MAX]; } For our example, we only implement a single queue for ready tasks. Tasks can be removed and added at any time by shuffling the queue around. Notice the * currentTask pointer. For Chapter 25, this pointer always points to * currentThreadLocal which stores a local copy of the currently executing thread. Our ISR will use the pointer to save and restore the thread state. We will look at the ISR in the next section. The Interrupt Service Routine (ISR) Alright, so our first task is to somehow get the scheduler called whenever a timer even triggered. Recall that hardware interrupts are raised by the Interrupt Controller, in our case, the legacy Programmable Interrupt Controller (PIC) . There are of course others (such as Advanced PIC (APIC) used with MultiProcessor (MP) and inter-CPU IRQ's) however we supported the legacy PIC interface only for the series in order to keep things simple. The PIC raises a signal to the CPU when a hardware device sends it to the PIC, such as the IR#0 signal sent from the PIT. The PIC then notifies the CPU by raising another signal, in this case the IRQ line on the CPU. What IRQ that gets called depends on how we programmed the PIC. Recall that we programmed the PIC to map IR#0 to ISR 33. What this means is that, whenever the PIT fires, the CPU stops executing the current code, pushes the return cs, eip, and flags on the current stack, and then calls the ISR that we installed in the Interrupt Descriptor Table (IDT) , that is, IDT[33] . In short, we already installed our timer ISR to interrupt vector 33. We did this back when setting up protected mode. It was needed in order for us to enable hardware interrupts. That is fine and all, but what we want to do is override it. We do this through interrupt chaining . We introduced interrupt chaining in an earlier chapter, however we never really put it into practice. Until now, that is. What we need to do is to get the old ISR, install our own. Lets do that now, /* register isr */ old_isr = getvect(32); setvect (32, scheduler_isr, 0x80); Simple enough. We implemented getvect and setvect back when we talked about the IDT . We install it to IDT[32] because that is where the PIT ISR was. So what this does is save it in old_isr and install a new ISR, scheduler_isr . So, with the above in mind, every time the PIT fires, scheduler_isr will be called instead. Now for the hard part â€“ writing the ISR. Consider what the ISR needs to do and when it can be called. The ISR can be called at any time . However, it is always called when a task is running . All we need to do is save the current register state and call the scheduler. Do not forget to send the End-Of-Interrupt (EOI) to the PIC. We will first present the ISR implemented for the demo, and then we will break it piece by piece to cover the details of what its doing below. __declspec(naked) void _cdecl scheduler_isr () { _asm { ; ; clear interrupts and save context. ; cli pushad ; ; if no current task, just return. ; mov eax, [_currentTask] cmp eax, 0 jz interrupt_return ; ; save selectors. ; push ds push es push fs push gs ; ; switch to kernel segments. ; mov ax, 0x10 mov ds, ax mov es, ax mov fs, ax mov gs, ax ; ; save esp. ; mov eax, [_currentTask] mov [eax], esp ; ; call scheduler. ; call scheduler_tick ; ; restore esp. ; mov eax, [_currentTask] mov esp, [eax] ; ; Call tss_set_stack (kernelSS, kernelESP). ; This code will be needed later for user tasks. ; push dword ptr [eax+8] push dword ptr [eax+12] call tss_set_stack add esp, 8 ; ; send EOI and restore context. ; pop gs pop fs pop es pop ds interrupt_return: ; ; test if we need to call old ISR. ; mov eax, old_isr cmp eax, 0 jne chain_interrupt ; ; if old_isr is null, send EOI and return. ; mov al,0x20 out 0x20,al popad iretd ; ; if old_isr is valid, jump to it. This calls ; our PIT timer interrupt handler. ; chain_interrupt: popad jmp old_isr } } The ISR is responsible for saving the current register context and saving the stack pointer of the current task . It then calls the scheduler , and restores the stack pointer from the current task and restores the register context that we saved before . Since everything is restored, the task and continue executing without problems when the ISR returns. The ISR appears more complicated then it actually is. Let's take a closer look at it in pieces. Like all of our other ISR's, the very first thing we do is save the current register state in order to preserve them on the stack. So the ISR begins like this: __declspec(naked) void _cdecl scheduler_isr () { _asm { cli pushad popad iretd } } Since we install the ISR on top of the ISR that was installed by the PIT, we need to be very careful here. This means that our scheduler_isr will be called with every clock tick . When we call setvect to install it, the PIT can fire before we have any tasks in the ready queue . When there are no tasks to run, we just want the ISR to return since there is nothing to do. You might also notice that we disable interrupts but never restore them. This is fine. Currently running tasks enable interrupts through the FLAGS register. Since the FLAGS register is preserved in all cases, when we issue IRETD, FLAGS.IF will enable when we return thereby re-enabling interrupts. Our ISR becomes, __declspec(naked) void _cdecl scheduler_isr () { _asm { cli pushad ; ; if no current task, just return. ; mov eax, [_currentTask] cmp eax, 0 jz interrupt_return ; ; <actual ISR code here> ; interrupt_return: popad iretd } } Finally, we need to keep in mind that the PIT hardware is now calling scheduler_isr , so the PIT driver ISR is never being called. We want to chain the interrupt . This means, if there is an old ISR that was installed before us, we want to give it a chance to run. This is done by jumping (not calling) to it. When calling another ISR, we need to keep in mind that the ISR will either chain another interrupt or issue an End-Of-Interrupt (EOI) command to break the chain . When calling another ISR, we are still technically servicing an interrupt, so don't want to send EOI nor do we need an IRETD. However, when not calling another ISR and giving control back to the original process, we need both. So our ISR now becomes: __declspec(naked) void _cdecl scheduler_isr () { _asm { ; ; clear interrupts and save context. ; cli pushad ; ; if no current task, just return. ; mov eax, [_currentTask] cmp eax, 0 jz interrupt_return ; ; <actual ISR code here> ; interrupt_return: ; ; test if we need to call old ISR. ; mov eax, old_isr cmp eax, 0 jne chain_interrupt ; ; if old_isr is null, send EOI and return. ; mov al,0x20 out 0x20,al popad iretd ; ; if old_isr is valid, jump to it. This calls ; our PIT timer interrupt handler. ; chain_interrupt: popad jmp old_isr } } The actual body of the ISR that performs the actual tasking is the following part: ; save selectors. ; push ds push es push fs push gs ; ; switch to kernel segments. ; mov ax, 0x10 mov ds, ax mov es, ax mov fs, ax mov gs, ax ; ; save esp. ; mov eax, [_currentTask] mov [eax], esp ; ; call scheduler. ; call scheduler_tick ; ; restore esp. ; mov eax, [_currentTask] mov esp, [eax] ; ; Call tss_set_stack (kernelSS, kernelESP). ; This code will be needed later for user tasks. ; push dword ptr [eax+8] push dword ptr [eax+12] call tss_set_stack add esp, 8 ; ; srestore context. ; pop gs pop fs pop es pop ds It first pushes segment registers on the stack. (Recall that we did a PUSHAD before this. And the CPU pushed CS, EIP, and EFLAGS on the stack as well when the ISR was first called.) We store these on the stack so that we can save the current thread register context . The order that these registers are pushed on the stack matches the order that we use later in the stackFrame structure . We then set those segment registers to the kernel mode selectors we set up a long time ago from the Global Descriptor Table (GDT) . We do this because we are not making the assumption that the currently running task is a kernel mode task. If the task is a user mode task, DS, ES, FS, and GS would still be 0x23 rather then 0x10 . We saved the original task selectors on the threads stack, so we can adjust them now. The CPU automatically sets SS and CS for us from the Task State Segment (TSS) when coming from a user mode task, so those would already be set appropriately. We will take a little more closer look at the stacks a little later. Finally, we save the current value of ESP to _currentTask->esp and call scheduler_tick . _ currentTask is assumed by the ISR to always be pointing to whatever the currently running task is. If the scheduler changes tasks, then that new task becomes the new â€œcurrentlyâ€ running task. Even if its a new task, we just restore ESP to that new tasks * currentTask->esp field. Since we initially saved the register context on the new threads stack, we just pop them off back into their respective registers. We also call tss_set_stack that we implemented a long time ago. This is only useful if the task that we are returning to is a user mode task. What we do is set the new tasks kernel stack into TSS by updating it. For the upcoming demo, we will only be running kernel threads, each with only one kernel stack so this does not apply just yet. However, keep in mind that user level threads have two stacks rather then one, since the threads run in both user space and kernel space. We will be expanding on this farther in the next couple of chapters as we dive into address space management and user space. So how do we switch tasks? Consider for a moment what would happen if that * currenTask pointer changes when the scheduler is called. Since the register context and stack pointer of this new task was saved the same way, by simply changing this pointer inside of the scheduler_tick function, the ISR would automatically load the new tasks register context and stack. And so, task switching is as simple as updating that pointer . Switching Tasks So switching tasks just involves updating a pointer. With Round Robin scheduling, we can use a queue to store the running tasks. Since queues already operate in First-In-First-Out order, all we need to do is remove and reinsert the current task to push it back. This greatly simplifies the code. /* schedule next task. */ void dispatch () { /* We do Round Robin here, just remove and insert. Note _currentTask pointer always points to _currentThreadLocal. So just update _currentThreadLocal. */ queue_remove(); queue_insert(_currentThreadLocal); _currentThreadLocal = queue_get(); } /* gets called for each clock tick. */ void scheduler_tick () { /* just run dispatcher. */ dispatch(); } That is all there is to it. The above implements Round Robin scheduling and swaps between the tasks after a certain quantum is up. Tasks are stored in the Ready Queue which was implemented earlier. This only leaves one more thing â€“ task creation. Although the above works for multiple threads, it will not work for threads belonging to different processes. The typical solution is to compare the current threads parent process with the new one. If they belong to the same process, then the dispatcher can simply return. If they belong to different processes, the dispatcher needs to invoke the VMM to switch to the new process address space. To keep the example code simple, we opted to avoid this for this chapter. However, we will be supporting it in the next chapter or two when we cover address space management in greater detail. Task Creation Let's say that our schedule function updates the * currentTask pointer to a different task. So when this function returns back to the ISR, the ISR will set the stack and register context from this new task before issuing IRETD. This works well, but only if the task already has a stack and register context on the stack. So we need to set it up when creating the task in the first time. So we set up a basic stack frame and set the task esp and eip to the stack and entry point function. The stack frame must be one that is expected by our ISR. When we return back to the ISR, it will POP GS, POP FS, POP ES, POP DS first, then does a PUSHA followed by an IRETD. PUSHA pops EAX, EBX, ECX, EDX, ESI, EDI, ESP, and EBP. And IRETD pops EIP, CS, and FLAGS. So this must be our initial stack frame when the task is created. typedef struct _stackFrame { uint32_t gs; uint32_t fs; uint32_t es; uint32_t ds; uint32_t eax; uint32_t ebx; uint32_t ecx; uint32_t edx; uint32_t esi; uint32_t edi; uint32_t esp; uint32_t ebp; uint32_t eip; uint32_t cs; uint32_t flags; }stackFrame; task task_create (uint32_t entry, uint32_t esp) { thread t; stackFrame* frame = ((stackFrame*) esp); frame->flags = 0x202; frame->cs = 8; frame->eip = (uint32_t)entry; frame->ebp = 0; frame->esp = 0; frame->edi = 0; frame->esi = 0; frame->edx = 0; frame->ecx = 0; frame->ebx = 0; frame->eax = 0; frame->ds = 0x10; frame->es = 0x10; frame->fs = 0x10; frame->gs = 0x10; t.esp = (uint32_t) frame; t.ss = 0x10; return t; } This works for most tasks, except one â€“ the initial task . The ISR we created will only work if the currently executing code is within a task. It is yet another chicken and egg problem. To get around this, we need to create a special task object and execute it when we are ready to start multitasking. static thread _idleTask; void task_execute(thread t) { _asm{ mov esp, t.esp pop gs pop fs pop es pop ds popad iretd } } /* initialize scheduler. */ void scheduler_initialize(void) { /* clear ready queue. */ clear_queue(); /* clear process list. */ init_process_list(); /* create idle thread and add it. */ _idleThread = thread_create(idle_task, (uint32_t) create_kernel_stack(), true); /* set current thread to idle task and add it. */ _currentThreadLocal = _idleThread; _currentTask = &_currentThreadLocal; queue_insert(_idleThread); /* register isr */ old_isr = getvect(32); setvect (32, scheduler_isr, 0x80); } /* idle task. */ void idle_task() { while(1) _asm pause; } The above puts everything together. It creates an idle task, adds it to the queue, installs the ISR, and executes the initial task. When the initial task executes, the ISR will be called whenever the PIT fires to call the scheduler to update the current task if needed. Introduction to MP This is a very brief introduction to the Multi-Processor (MP) Specification that is designed to provide a standard interface for starting up the other processors and Inter-Processor Interrupts (IPI) . We consider this an advanced topic since it can quickly escalate the difficulty of concurrent programming. Our scheduler only executes one task at a time, however with MP, we can implement a low level scheduler responsible for scheduling independent CPU's for the tasks and can achieve running multiple tasks at the same time. So what we are presenting here is just a very brief introduction â€“ for anyone wanting to dive more into the MP standard, we recommend checking out the MP specification. Your system must already support the IOAPIC, LAPIC, and ICI which are used by MP. There is symmetric multiprocessing (SMP) and asymmetric multiprocessing (ASP) . In SMP, all of the processors are of the same type whereas in ASP they are not. Most systems only support SMP given that ASP systems are very rare in desktop systems. However, the MP standard is applicable to both and gives itself some room for extendability so it can adopt to more diverse machine types and farther allows the operating systems to adopt and configure itself for different types of systems. When the system first starts up, the hardware selects a Boot-Strap Processor (BSP) to act as the sole processor to start up. The BSP is the first processor to start up and must be the last processor to shut down. The operating system may send a STARTUP IPI from the BSP to another Application Processor (AP) to start it. Other AP's can be started by either the BSP or another AP. The STARTUP IPI (and INIT IPI ) is what the operating system sends to wake the other processors. The operating system must first search for the floating MP Floating Pointer structure in order to detect if the system supports MP. The structure contains the physical address of the MP Configuration Table . The configuration table is read only . It stores the memory mapped address of the Local APIC (LAPC), Processor entries (including the processor LAPIC ID), IOAPIC entries (including IOAPIC base memory mapped address), Buses, and interrupt configuration entries . The operating system must remember the LAPIC ID of the BSP to make sure it is the last one to shut down. To wake another AP, all we need to do is send a INIT IPI through the BSP LAPIC or another AP LAPIC. The memory mapped registers for the LAPIC's are stored in the processor information in the MP configuration table. We then need to send an STARTUP IPI to that AP to start executing. That's really all there is to it. The INIT IPI causes the AP to reset . The STARTUP IPI causes it to start executing at the location you tell it to in real mode. Operating systems must provide a real mode stub routine for configuring the API's in protected or long modes just as you did for the BSP. So that is pretty much all we wanted to cover in this brief introduction to multiprocessor systems. Starting up other processors (or processor cores0 is fairly simple and we encourage experimenting with SMP after implementing your scheduler. We may cover MP in more detail in a later tutorial after covering the APIC. We just wanted to give a little overview and direction for those interested in it now. Demo Download Demo Most of the new code has been covered in the above text, we are just preparing the initial release. Assuming no problems arise during stress tests and final integration, the demo should be released sometime within the next week or two. Demo running in 800x600x32 mode executing three tasks This is our first real graphical demo. The demo runs three tasks concurrently; each task cycles through a select color in video memory while running to visually show that they are executing. We opted to have a graphical demo rather then text based since we believe we can have it more visually appealing yet still simple to do. It is alright if you did not read through the graphics series yet, we will discuss things here. Bochs Graphics Adapter (BGA) To keep the code as simple as possible so we can focus on the primary topic of the chapter, we opted to use BGA under the assumption that the system is configured for ISA. This code is Bochs specific and will not work on real systems. Real systems would require scanning the PCI bus infrastructure which may be a topic in a more advanced chapter. #define VBE_DISPI_IOPORT_INDEX 0x01CE #define VBE_DISPI_IOPORT_DATA 0x01CF #define VBE_DISPI_INDEX_XRES 0x1 #define VBE_DISPI_INDEX_YRES 0x2 #define VBE_DISPI_INDEX_BPP 0x3 #define VBE_DISPI_INDEX_ENABLE 0x4 #define VBE_DISPI_DISABLED 0x00 #define VBE_DISPI_ENABLED 0x01 #define VBE_DISPI_LFB_ENABLED 0x40 void VbeBochsWrite(uint16_t index, uint16_t value) { outportw (VBE_DISPI_IOPORT_INDEX, index); outportw (VBE_DISPI_IOPORT_DATA, value); } void VbeBochsSetMode (uint16_t xres, uint16_t yres, uint16_t bpp) { VbeBochsWrite (VBE_DISPI_INDEX_ENABLE, VBE_DISPI_DISABLED); VbeBochsWrite (VBE_DISPI_INDEX_XRES, xres); VbeBochsWrite (VBE_DISPI_INDEX_YRES, yres); VbeBochsWrite (VBE_DISPI_INDEX_BPP, bpp); VbeBochsWrite (VBE_DISPI_INDEX_ENABLE, VBE_DISPI_ENABLED | VBE_DISPI_LFB_ENABLED); } To set the video mode just involves calling VbeBochsSetMode . We use 800x600x32 in our example since it appears to be well supported. **The Linear Frame Buffer (LFB)**under ISA is at the predefined location 0xe0000000 . However, because we have paging enabled, we need to map the LFB into our virtual address space to use it. We will map it to 0x200000 virtual for the demo. The mapping is done by calculating the size of the LFB in number of pages, and mapping each page by calling our VMM. void* VbeBochsMapLFB () { /* BGA LFB is at LFB_PHYSICAL for ISA systems. */ #define LFB_PHYSICAL 0xE0000000 #define LFB_VIRTUAL 0x200000 /* map LFB into current process address space. */ int pfcount = WIDTH*HEIGHT*BYTES_PER_PIXEL/4096; int c; for (c = 0;c <= pfcount; c++) vmmngr_mapPhysicalAddress (vmmngr_get_directory(),LFB_VIRTUAL + c * 0x1000,LFB_PHYSICAL + c * 0x1000, 3); /* return pointer to LFB. */ return (void*) LFB_VIRTUAL; } With the above function, we can now draw to the LFB by writing to 0x200000. To clean up any possible garbage on the display, we clear it next. Since we need to draw a lot of pixels, we try to optimize the function for 32 bit modes. This function makes the screen white. void fillScreen32 () { uint32_t* lfb = (uint32_t*) LFB_VIRTUAL; for (uint32_t c=0; c<WIDTH*HEIGHT; c++) lfb[c] = 0xffffffff; } In 32 Bits Per Pixel modes, the pixel colors are composed of 8 bits for red, 8 bits for green, and 8 bits for blue. The high 8 bits are ignored for our purposes but is typically used as a transparency value. We use three separate tasks to render the three rectangles and cycle through the intensity of the three colors. Since we are going to render to different locations on display, we won't have to worry about concurrency problems here. Although display memory is shared, each task will render to separate parts. void rect32 (int x, int y, int w, int h, int col) { uint32_t* lfb = (uint32_t*) LFB_VIRTUAL; for (uint32_t k = 0; k < h; k++) for (uint32_t j = 0; j < w; j++) lfb[(j+x) + (k+y) * WIDTH] = col; } void kthread_1() { int col = 0; bool dir = true; while(1) { rect32(200,250,100,100,col << 16); if (dir){ if (col++ == 0xfe) dir=false; }else if (col-- == 1) dir=true; } } void kthread_2 () { int col = 0; bool dir = true; while(1) { rect32(350,250,100,100,col << 8); if (dir){ if (col++ == 0xfe) dir=false; }else if (col-- == 1) dir=true; } } void kthread_3 () { int col = 0; bool dir = true; while(1) { rect32(500,250,100,100,col); if (dir) { if (col++ == 0xfe) dir=false; }else if (col-- == 1) dir=true; } } Thread Stacks Typically a thread has two separate stacks. One for when executing in user mode, and another for when executing in kernel mode. Recall that when a thread is executing in user mode, the CPU switches to a kernel stack by getting the esp0 and ss0 fields of the Task State Segment (TSS) . The scheduler is responsible for updating the TSS to the new threads kernel mode stack. However, for chapter 25, since all threads run in kernel space, the TSS will never be referenced. In other words, the threads in chapter 25 only have one stack â€“ a kernel mode stack . We will be supporting user mode threads within the next two chapters when we cover address space management. We will use our future address space allocator to reserve stack space in user space for each user mode thread. That means threads will have both a user mode and kernel mode stack . The thread uses the kernel mode stack when executing code with **Current Privilege Level (CPL)**of 0. The CPU automatically loads this if the CPL is less then the **Requested Privilege Level (RPL)**from the TSS . In other words, lets say that our user mode thread is running and the PIT fires. The CPU will then set SS=TSS.ss0 and ESP=TSS.esp0 . It will then push the return CS and IP on this new stack and call the ISR. When the ISR is done, it executes IRET to return back to the user mode code and stack. This is why user level threads must have, at a minimum, two separate stacks. The first stack must be mapped in kernel space and the other must be mapped in user space so the program can access it while executing. Kernel level threads only need one stack. Since we don't have an address space allocator, we cannot nicely allocate user mode stacks just yet, so cannot support user level threads (without hacks.) And since we don't have a proper kernel mode allocator yet, we can't nicely support allocation of kernel level stacks either. These will be the topics for the next chapter or two. So what we decided to do for chapter 25 was to reserve space in kernel memory and allocate each 4k block as its own stack. void* create_kernel_stack() { physical_addr p; virtual_addr location; void* ret; /* we are reserving this area for 4k kernel stacks. */ #define KERNEL_STACK_ALLOC_BASE 0xe0000000 /* allocate a 4k frame for the stack. */ p = (physical_addr) pmmngr_alloc_block(); if (!p) return 0; /* next free 4k memory block. */ location = KERNEL_STACK_ALLOC_BASE + _kernel_stack_index * PAGE_SIZE; /* map it into kernel space. */ vmmngr_mapPhysicalAddress (vmmngr_get_directory(), location, p, 3); /* we are returning top of stack. */ ret = (void*) (location + PAGE_SIZE); /* prepare to allocate next 4k if we get called again. */ _kernel_stack_index++; /* and return top of stack. */ return ret; } Back to Sleep You might recall that we implemented a very basic sleep function that we needed in order to delay the read operation of the floppy device. Our implementation simply went into a busy loop in order to waste some time. Now we can adopt it for the threading system. The basic idea is that sleep should pause the thread that called the function. This means we need to adjust the current thread state from READY to BLOCK and force a task switch. The scheduler then needs to keep track of blocked threads to handle them properly. This is typically done via Signals from other operating system components. For example, if a thread is waiting for a device to be ready, it may block. Now the system needs to wait until that thread receives a signal from the driver. Until then, the scheduler should jump to executing other threads. To keep the demo relatively simple, we opted to do things a little differently. All we need to do is change the state of the currently running program and force a task switch (by calling the ISR directly via int 33 .) The scheduler would contain the logic code for checking blocked threads while selecting new threads to run. If the next thread is blocked, we decrement its sleep time delta and awake the thread is the sleep time delta reaches zero. Although we do not use sleep in this demo, the disk driver code relies on it. So now the thread attempting to read from the disk device can properly sleep. Main Program Finally, we will take a look at the main program. In the demo for Chapter 25, we moved the stack into kernel space and readjust it after making a static copy of the boot parameter block that was passed from the boot loader. We then use the services discussed above to set the video mode, initialize the scheduler, and create and add three threads to the ready queue. Since the threads run in kernel space, they only have a kernel stack allocated to them, which we allocate calling create_kernel_stack . We have also completely rewritten the process creation and management code from Chapter 24 to be compatible with the thread system created in Chapter 25. However, it will not be completed until we support the allocation of user mode stacks which we will do in the upcoming chapters. void _cdecl kmain (multiboot_info* bootinfo) { /* store kernel size and copy bootinfo. */ _asm mov word ptr [kernelSize], dx memcpy(&_bootinfo, bootinfo, sizeof(multiboot_info)); /* adjust stack. */ _asm lea esp, dword ptr [_kernel_stack+8096] init (&_bootinfo); /* set video mode and map framebuffer. */ VbeBochsSetMode(WIDTH,HEIGHT,BPP); VbeBochsMapLFB(); fillScreen32 (); /* init scheduler. */ scheduler_initialize (); /* create kernel threads. */ queue_insert (thread_create(kthread_1, (uint32_t) create_kernel_stack(),true)); queue_insert (thread_create(kthread_2, (uint32_t) create_kernel_stack(),true)); queue_insert (thread_create(kthread_3, (uint32_t) create_kernel_stack(),true)); /* execute idle thread. */ execute_idle(); /* this should never get executed. */ for (;;) _asm {cli hlt}; } Conclusion In this chapter we looked at scheduling algorithms, a brief overview of SMP, concurrent programming, and implemented a working preemptive Round Robin scheduler. We have also went through a small introduction to high resolution video modes using Bochs Graphics Adapter (BDA), state management, and an introduction to several IPC techniques."
  },
  "articles/61_unorganised_tutorial/T3.html": {
    "href": "articles/61_unorganised_tutorial/T3.html",
    "title": "T3 - Bootloaders | BrokenThorn OS Dev Tutorials",
    "keywords": "T3 - Bootloaders This page covers topics such as: The booting process - How it works Bootloader Theory Developing a simple bootloader Assembling the bootloader with NASM Using the VFD (Virtual Floppy Drive) software; Creating a floppy image Using PartCopy; Copying our bootloader to the floppy image Using Bochs - Basic Setup and Use; Testing the bootloader The Boot Process Pressing the power button What actually happens when you press the power button? When this button is pressed, the wires connected to the button send an electronic signal to the motherboard. The motherboard simply reroutes this signal to the power supply (PSU). This signal contains a single bit of data. If it is 0, there is, of course, no power (so the computer is off, or the motherboard is dead). If it is a 1 (meaning an active signal), it means that power is being supplied. To better understand this, remember the basics of binary logic in computers. 8 \"bits\" simply represent 8 \"wires\" or \"lines\" where electricity can go. A 0 represents no current, while a 1 represents current within a line. This, along with Logic Gates, is the bases of Digital Logic Electronics, at which computers were built. When the PSU receives this active signal, it begins supplying power to the rest of the system. When the correct amount of power is supplied to all devices, the PSU will be able to continue suppling that power without any major problems. The PSU then sends a signal, called the \"power_good\" signal into the motherboard to the Basic Input Output System (BIOS). BIOS POST When the BIOS receives this \"power_good\" signal, the BIOS begins initializing a process called POST (Power On Self Test). The POST then tests to insure there is good amount of power being supplied, the devices installed (such as keyboard, mouse, USB, serial ports, etc.), and insures the memory is good (By testing for memory corruption). The POST then gives control to the BIOS. The POST loads the BIOS at the end of memory (Might be 0xFFFFF0) and puts a jump instruction at the first byte in memory. The processors Instruction Pointer (CS:IP) is set to 0, and the processor takes control. What does this mean? The processor starts executing instructions at address 0x0. In this case, it is the jump instruction placed by the POST. This jump instruction jumps to 0xFFFFF0 (or wherever the BIOS was loaded), and the processor starts executing the BIOS. The BIOS takes control... The BIOS The Basic Input Output System (BIOS) does several things. It creates an Interrupt Vector Table (IVT), and provides some basic interrupt services. The BIOS then does some more tests to insure there is no hardware problems. The BIOS also supplies a Setup utility. The BIOS then needs to find an OS. Based on the boot order that you set in the BIOS Setup, the BIOS will execute Interrupt (INT) 0x19 to attempt to find a bootable device. If no bootable device is found (INT 0x19 returns), the BIOS goes on to the next device listed in the boot order. If there is no more devices, it will print an error similar to \"No Operating System found\" and halt the system. Interrupts and the Interrupt Vector Table (IVT) An Interrupt is a subroutine that can be executed from many different programs. These interrupts are stored at address 0x0 into a table called the Interrupt Vector Table. A common interrupts, for example, is INT 0x21 used for DOS. Note: There is no DOS! The Only interrupts available are the interrupts set up by the BIOS, and no more! The use of other interrupts will cause the system to execute a nonexistent routine, causing your program to crash. Note: If you switch processor modes, the IVT will not be available. This means absolutely no interrupts--neither software nor hardware, will be available, Not even the BIOS. . For a 32 bit OS, we are going to have to do this. Not yet, though. BIOS Interrupt 0x19 INT 0x19 - SYSTEM: BOOTSTRAP LOADER Reboots the system through a Warm Reboot without clearing memory or restoring the Interrupt Vector Table (IVT). This interrupt is executed by the BIOS. It reads the first sector (Sector 1, Head 0, Track 0) of the first hard disk. Sectors A \"Sector\" simply represents a group of 512 bytes. So, Sector 1 represents the first 512 bytes of a disk. Heads A \"Head\" (or Face) represents the side of the disk. Head 0 is the front side, Head 1 is the back side. Most disks only have 1 side, hence only 1 head (\"Head 1\") Tracks To understand tracks, we should look at a picture: In this picture, This disk could represent a hard disk or floppy disk. Here, we are looking at Head 1 (The front side), and the Sector represents 512 bytes. A Track is a collection of sectors. Note: Remember that 1 sector is 512 bytes, and there are 18 sectors per track on floppy disks. This will be important when loading files. If the disk is bootable, Then the bootsector will be loaded at 0x7C00 , and INT 0x19 will jump to it, thereby giving control to the bootloader. Note: Remember that the bootloader is loaded at 0x7C00. This is important! Note: On some systems, you can also execute a warm boot by putting 0x1234 at address 0x0040:0072, and jumping to 0xFFFF:0. For a cold reboot, store 0x0 instead. Now, our 1337 bootloader is in control! Bootloader Theory We have talked alot about bootloaders. Lets put the important parts together, shall we? So far, bootloaders... *...Are stored with the Master Boot Record (MBR). *...Are in the first sector of the disk. *...Is the size of a single sector (512) bytes. *...Are loaded by the BIOS INT 0x19 at address 0x7C00. As you can imagine, we cannot do a whole lot in 512 bytes. What do we do? In Assembly Language, we can very easily go beyond the 512 byte mark. So, the code could look just fine, but only a part of it will be in memory. For example, consider this: mov ax, 4ch inc bx ; 512 byte mov [var], bx ; 514 byte In Assembly language, execution begins from the top of the file downward. However, remember that, when loading files in memory, we are loading sectors. Each of these sectors is 512 bytes, so it will only copy 512 bytes of the file into memory. If the above code was executed, and only the first sector was loaded in memory, It will only copy up to the 512 byte (The inc bx instruction). So, while the last mov instruction is still on disk, It isnt in memory! . What will the processor do after inc bx then? It will still continue on to the 514 byte. As this was not in memory, It will execute past the end of our file! The end result? A crash. However, it is possible to load the second sector (or more) at a given address and execute it. Then the rest of the file will be in memory, and everything will work just fine. This approach will work, but it will be hard hacked. The most common approach is keeping the bootloader at 512 bytes in size, searching, loading, and executing a second stage bootloader. We will look more into this later. Hardware Exceptions Hardware Exceptions are just like Software Exceptions, however the processor will execute them rather then software. There are times when one must stop all exceptions for happening. For example, when switching computer modes, the entire Interrupt Vector Table is not available, so any interrupt-hardware or software, will cause your system to crash . More on this later. CLI and STI Instructions You can use the STI and CLI instructions to enable and disable all interrupts. Most systems do not allow these instructions for applications as it can cause big problems (Although systems can emulate them). cli ; clear interrupts ; do something... sti ; enable interrupts--we're in the clear! Double Fault Hardware Exception If the processor finds a problem during execution (Such as an invalid instruction, division by 0, etc.) It executes a Second Fault Exception Handler (Double Fault), Which is Interrupt 0x8. We will be looking a Double Faults later. If the processor still cannot continue after a double fault, it will execute a Triple Fault . Triple Fault We seen this term before, haven't we? A CPU that \"Triple Faults\" simply means the system hard reboots. In early stages, such as the bootloader, whenever there is a bug in your code, the system will triple fault. This indicates a problem in your code. Developing a simple Bootloader Yippee! drum rolls The moment we have been waiting for! :) Lets take another look at our list: Are stored with the Master Boot Record (MBR). Are in the first sector of the disk. Is the size of a single sector (512) bytes. Are loaded by the BIOS INT 0x19 at address 0x7C00. Open up any ordinary text editor (I am using Visual Studio 2005), but Notepad will suffice. Here's the bootloader (Boot1.asm) ... ;********************************************* ; Boot1.asm ; - A Simple Bootloader ; ; Operating Systems Development Tutorial ;********************************************* org 0x7c00 ; We are loaded by BIOS at 0x7C00 bits 16 ; We are still in 16 bit Real Mode Start: cli ; Clear all Interrupts hlt ; halt the system times 510 - ($-$) db 0 ; We have to be 512 bytes. Clear the rest of the bytes with 0 dw 0xAA55 ; Boot Signature Some of this should not come to much of a surprise. Lets analyze line by line: org 0x7c00 ; We are loaded by BIOS at 0x7C00 Remember: The BIOS loads us at 0x7C00. The above code tells NASM to insure all addresses are relative to 0x7C00. This means, the first instruction will be at 0x7C00. bits 16 ; We are still in 16 bit Real Mode Remember tutorial two? In that tutorial, I explained how the x86 family is backward compatible with the old DOS systems. Because the old DOS systems were 16 bit, All x86 compatible computers boot into 16 bit mode . This means: We are limited to 1 MB (+64k) of memory. We will need to switch the computer into a 32 bit mode. We will do this later. times 510 - ($-$) db 0 ; We have to be 512 bytes. Clear the rest of the bytes with 0 I wish this was more documented. In NASM, the dollar operator ($) represents the address of the current line. $$ represents the address of the first instruction (Should be 0x7C00). So, $-$$ returns the number of bytes from the current line to the start (In this case, the size of the program). dw 0xAA55 ; Boot Signature This needs some explanation. Remember that the BIOS INT 0x19 searches for a bootable disk. How does it know if the disk is bootable? The boot signature. If the 511 byte is 0xAA and the 512 byte is 0x55, INT 0x19 will load and execute the bootloader. Because the boot signature must be the last two bytes in the bootsector, We use the times keyword to calculate the size different to fill in up to the 510th byte, rather then the 512th byte. Assembling with NASM NASM is a command line assembler, and hence must be executed either through command line or a batch script. To assemble Boot1.asm do this: nasm -f bin Boot1.asm -o Boot1.bin The -f option is used to tell NASM what type of output to generate. In this case, it is a binary program. -o option is used to give your generated file a different output name. In this case, its Boot1.bin After assembling, you should have an exact 512 byte file named \"Boot1.bin\". Note: For some reason, Windows Explorer limits displaying file sizes to 1 KB. Just see the properties of the file, and it should say 512 bytes. How to use VFD (Virtual Floppy Drive) We will use VFD to create a virtual floppy image to copy our OS to. This will explain how to use it. Open vfdwin.exe. Under the Driver tab, Click the Start button. This starts the driver. Click either the Drive0 or Drive1 tab. Click Open You should see this: Insure Media Type is a standard 3.5\" 1.44 MB floppy, and disk type is in RAM. Also, insure Write Protect is disabled. Click \"Create\". Go to My Computer (On your computer ðŸ˜‰ ) and you should see a new floppy drive. To format the disk, right click the drive and go to Properties. Under the VFD Tab will be a format option. PartCopy - Copying to the Bootsector Great... Now that we have our boot loader ready, how do we copy it to our disk? As you probably know, Windows will not allow us to directly copy it to the first sector of a disk. Because of this, we need to use a command to do it. In the first tutorial we have looked at one of these commands: debug . If you have decided to use this command, you can skip this section on partcopy . PartCopy is a command line program. It uses the following synthax: partcopy file first_byte last_byte drive PartCopy can be used for more then just copying files. It can be used for copying certain bytes to and from sectors. Thinking of its format (Shown above) is a safe method. Because you have an emulated floppy drive, you can refrence the drive name by letter (Like A:). To copy our bootloader, this will work: partcopy Boot1.bin 0 200 -f0 f0 represents Floppy Disk 0. You can change between f0, f1, etc based on what drive your floppy disk is in. Boot1.bin is our file to copy. This copies from the first byte (0x0) of the file to the last byte (0x200, which is 512 decimal). Notice that partcopy only accepts hexadecimal numbers. Warning Remember using this program can cause parmenant disk curruption if you are not carefull. The above command line commands will only work for floppy disks. Do not attempt to try on hard disks! Bochs: Testing the bootloader Bochs is a 32 bit PC emulator. We are going to use Bochs for debugging and testing. Bochs uses a configuation file that describes the hardware to emulate. For example, this is the configuation file I am using: # ROM and VGA BIOS images --------------------------------------------- romimage: file=BIOS-bochs-latest, address=0xf0000 vgaromimage: VGABIOS-lgpl-latest # boot from floppy using our disk image ------------------------------- floppya: 1_44=a:, status=inserted # Boot from drive A # logging and reporting ----------------------------------------------- log: OSDev.log # All errors and info logs will output to OSDev.log error: action=report info: action=report The configuation file uses # for comments. It will attempt to boot from whatever floppy disk image (Like the one we created in VFD) in drive A. The ROM BIOS and VGA BIOS images come with Bochs, so you dont need to worry about that. Locating the BIOS ROM A lot of the lines in the configuation file are very simple. There is however one line that we need to look at here however: romimage: file=BIOS-bochs-latest, address=0xf0000 This line tells Bochs where to place the BIOS in its memory (Virtual RAM). Remember that BIOS sizes may differ? Also remember that the BIOS must end at the end of the first megabyte (0xFFFFF) in memory? Because of this, you may need to change this line to reposition the Bios. This can be done by getting the size of the Bios image (It should be named BIOS-bochs-latest in your Bochs directory). Get the size in bytes. After this, simply subtract 0xFFFFF - size of bochs file (in bytes). This will be the new Bios address, so update the address on this line to move the Bios to its new location. You may or may not need to do this step. If you get an error from Bochs telling you that the Bios must end at 0xFFFFF, then you do need to complete this step and it should work. How to use Bochs To use Bochs: Execute bochs.exe Select option 2 (Read options form); hit enter. Type in the configuation files name (The one we created above); hit enter. You will be back to the main menu. Select option 5: Begin Simulation, and hit enter. A new window will open, and this is what you should see: If Bochs just quits or restarts ...Then you have just experenced a Triple Fault. Go back to the code and try to find where the problem is at. If you need any help, feel free to contact me. If the Window appears, but does nothing Congrats! That is our cli and hlt instructions haulting the system, so we know our bootloader is being executed."
  },
  "articles/61_unorganised_tutorial/T3-6.html": {
    "href": "articles/61_unorganised_tutorial/T3-6.html",
    "title": "Bootloaders | BrokenThorn OS Dev Tutorials",
    "keywords": "Bootloaders"
  },
  "articles/61_unorganised_tutorial/T4.html": {
    "href": "articles/61_unorganised_tutorial/T4.html",
    "title": "Bootloaders 2 | BrokenThorn OS Dev Tutorials",
    "keywords": "Bootloaders 2 In this page, we will expand on our bootloader. We will cover: BIOS Parameter Block and the MBR Processor Modes Interrupts - Printing text and more Segment:offset Addressing Mode Note From here on out, our bootloader has full control of the entire system. What this means, is simply that everything relies on us writing the code. Everything now is up to us! In short: There will be a lot more code coming up. Ready? Processor Modes Well, well...Where have we heard this term before? Lets see... In every single tutorial! And yet, we have not really talked much about it. Understanding the different processor modes will be very important to us. Why is this? In the previous 2 tutorials, we talked about how and why the x86 family boots up in a 16 bit environment. We want to develop a 32 bit operating system (OS), so we will need to switch the processor from its 16 bit mode into a 32 bit mode. There are more then two modes. Lets go over each one, shall we? Real Mode As you know, the x86 processor boots into a 16 bit environment. What is this mode? (Hint: Its not Real Mode) ... Okay, it is :) What is so real abut real mode, anyway? Real Mode... Uses the native segment:offset memory model . Is limited to 1 MB (+64k) of memory. No Virtual Memory or Memory Protection . Some of these are fairly easy. Others require some explanation though. One thing to note is that, all of the above indirectly or directly relates to memory. Lets take a closer look, shall we? Segment:offset Memory Mode - History Lets go Back In Time(tm) again, and look at Tutorial 2. The concept of Memory and use of Operating Systems dated back since the 1950s. These computers were not personal computers, but instead large mainframe computers. Remember that, back then, all computers had very large and bulky hardware devices. Through time (Looking back at Tutorial 2), you can see not only advances in Operating Systems, but computers as well. As computer popularity gained, so did its demand. When computers were 8 bit, many wanted 16. When the 16 bit era came, Microsoft was already thinking 32 bit. As soon as the 32 bit area came, 64 bit was already mainstream. Okay, the last one isn't true :) but, 128 bit is on its way. The primary problem is the computer industry moves to fast. When Intel was designing the 8086 Processor, the processor used 16 bit registers, and could only access up to 64 KB of memory. The problem, however, was that a lot of software required more memory then this. The 8086 was being designed the same time the 8088 was. The 8088, however, was going to be Intel's \"next generation\" processor, except it was taking longer then expected. To challenge the other companies, Intel quickly wanted to develop and release a processor, the 8086, to hold off until the 8088 was released. The problem here is that, software demanded more memory then 64 KB, and Intel's processor, the 8086, was to challenge their competitors who is already building 16 bit processors, until the 8088 was released. Intel needed a strategy. The designers of the 8086 proposed a solution. This solution will allow the 8086 to stay 16 bit, while being able to access up to 1 MB of memory. They agreed, and Intel approved. The segment:offset memory scheme was born. To understand the segment:offset scheme, lets break it down and look at segments and offsets first. Segments A Segment is simply a part of a whole. In our case, A segment is a section of memory. Yep--That's basically all it is. Imagine dividing memory into sections. These sections represent segments. The x86 Family of processors uses 4 primary registers that store the beginning location of a segment. Its like a base address --It provides the start of a segment. Normally, a segment may be 64 KB in size, and are freely movable. Remember that segments simply represents a section in memory. In this case, if the segment base address is 0, then this represents the segment between byte 0 and 64 KB. The registers are CS, DS, ES, and SS . These registers store the base address for the segments. We will take a closer look at them after we look at addressing with this mode. Offsets An offset is a number that is added to a base number. For example, if the base number is 3: Offset = base number (3) + the offset number Offset 2 is 3+2 = 5 Offset 4 is 3+4 = 7 Okay, so how does this relate to us? Well, in segment:offset addressing, we add the Base Address (Remember that a segment represents a base address) with the offset address! Pretty simple, huh? Now, lets put it all together. Segment:offset Addressing In Segment:offset Addressing, we simply add the offset address with the segment address. However, in the previous section, I mentioned that each segment address in Real Mode is 16 bits in size. This means we also have to multiply our segment by 16(decimal), and then we add the offset. So, here's our current formula: Absolute (Exact) Memory Address = (Segment Address * 16(decimal)) + Offset That's all there is to it ðŸ˜ Segment:offset Conventions Segment and offset addresses are usually separated by a colon (:). They are usually of the form Segment : Offset . For example: 07C0:0000 < 07C0 is the segment, and 0 is the offset We can convert the above to the absolute address 0x7C00 by using our formula: base address = base address * segment size (16) + offset 07C0:0000 = 07C0 * 16 (decimal) + 0 = 07C00 + 0 = 0x7C00 Segment:offset Problems Segment:offset is quite unique. By changing the segment and offset values, you can find different segment:offset pairs will yield the same absolute address. Why? Because they both refer to the same memory location! For example, all of the below addresses refer to our bootloader at 0x7C00: 0007:7B90 0008:7B80 0009:7B70 000A:7B60 000B:7B50 000C:7B40 0047:7790 0048:7780 0049:7770 004A:7760 004B:7750 004C:7740 0077:7490 0078:7480 0079:7470 007A:7460 007B:7450 007C:7440 01FF:5C10 0200:5C00 0201:5BF0 0202:5BE0 0203:5BD0 0204:5BC0 07BB:0050 07BC:0040 07BD:0030 07BE:0020 07BF:0010 07C0:0000 These are only a few. Technically, there is exactly 4,096 different combinations of segment:offset that can refer to the same byte in memory -- This is for each byte in memory! What if we have two segment addresses that are within 64 KB? Remember that the size of a segment (and offset) are 16 bits. And the segment addresses refer only to the base of a segment. This is what an Overlapped Segment is: Imagine layers on top of layers that lay over other segments. This could cause problems. This means, in Real Mode, you can access every byte in memory, over 4,000 different ways, being able to overlap segments that could potentially corrupt that area of memory without you knowing. This is what is meant by Real Mode not having any Memory Protection . The registers the x86 use for segment referencing are as follows: CS (Code Segment) - Stores base segment address for code DS (Data Segment) - Stores base segment address for data ES (Extra Segment) - Stores base segment address for anything SS (Stack Segment) - Stores base segment address for the stack Wow, Real Mode has a lot of problems. What will protect little old us from it? Protected Mode Protected Mode (PMode) is a term you heard a lot, and will here a lot more. PMode allows Memory Protection through the use of a Descriptor Tables that describe your memory layout. PMode is a 32 bit processor modes, so it also allows you to use 32 bit registers, and access up to 4 GB of RAM . A huge improvement over Real Mode. We will be using PMode. And yes, before you ask, Windows is a PMode OS. :) PMode is a bit tricky to set up and to fully understand how it works. We will discuss more about PMode later. Unreal Mode It is possible to switch from processor modes whenever you want. The term \"Unreal Mode\" is a pun that represents Real Mode with the address space (4 GB limit) of PMode. To enable Unreal Mode, simply switch the processor from Real Mode into PMode, and back again after loading a new Descriptor . Descriptor Tables can be quite confusing. I will talk about them in detail when we talk more about Protected Mode (PMode). Virtual 8086 Mode Virtual 8086 Mode (v86 Mode) is a Mode that represents Protected Mode with a 16 bit Real Mode emulated environment. This might seem kind of strange, don't you think? v86 can be useful, however. All BIOS interrupts are only available in real mode! v86 Mode provides a way of executing BIOS interrupts from within PMode. More on this later. Switching processor modes We wont cover the code to switch processor modes just yet. Instead, I want to take a step back and explain some important concepts. The only two built in actual modes are Real Mode and Protected Mode. In other words, the other modes, Unreal Mode and v86 Mode, are built from these two modes. Remember that Unreal Mode is in Real Mode, but uses the Protected Mode (PMode) Addressing system. And, Virtual 8086 Mode is in PMode, but uses Real Mode to execute 16 bit code. As you can see, both v86 and Unreal mode are simply based off of Real Mode and Protected Modes. Because of this, it might be hard to understand how these modes work without an understanding of PMode. We will take a closer look at PMode, Unreal Mode, and v86 Mode soon, so don't worry :) There is some important things to remember about PMode however: Absolutely no interrupts will be available. You will need to write them yourself. The use of any interrupt--hardware or software will cause a Triple Fault Once you switch into PMode, the slightest mistake will cause a Triple Fault. Be careful. PMode requires the use of Descriptor Tables , such as the GDT, LDT, and IDT s. PMode gives you access to 4 GB of Memory, With Memory Protection Segment:offset Addressing is used along with Linear Addressing Access and use of 32 bit registers We will cover PMode in a lot more detail later. Expanding the bootloader Wow, we went over a lot so far, didn't we? We went over basic theory of Protected Mode, Unreal Mode, and v86 Mode. We covered Real Mode in depth though. Why? Because, remember that the computer boots in a 16 bit environment for backward compatibility with DOS. This 16 bit environment is Real Mode . So, yes-When our bootloader is executed, we are in Real Mode. Wait! This means we can use BIOS Interrupts, right? Yep :) This includes VGA Video interrupts, and any other interrupt mapped directly from hardware :) Useful Routines and BIOS Interrupts OEM Parameter Block The OEM Parameter Block stores the Windows MBR and Boot Record information. Its primary purpose is to describe the filesystem on the disk. We will not describe this table until we look at filesystems. However, we can go no further without it. This will also fix the \"Not formatted\" message from Windows. For now, think of this table as a simple necessity. I will explain it in detail later when we talk about File Systems, and loading Files off disk. Here is the bootloader with the table: ;********************************************* ; Boot1.asm ; - A Simple Bootloader ; ; Operating Systems Development Tutorial ;********************************************* bits 16 ; We are still in 16 bit Real Mode org 0x7c00 ; We are loaded by BIOS at 0x7C00 start: jmp loader ; jump over OEM block ;*************************************************; ; OEM Parameter block ;*************************************************; TIMES 0Bh-$+start DB 0 bpbBytesPerSector: DW 512 bpbSectorsPerCluster: DB 1 bpbReservedSectors: DW 1 bpbNumberOfFATs: DB 2 bpbRootEntries: DW 224 bpbTotalSectors: DW 2880 bpbMedia: DB 0xF0 bpbSectorsPerFAT: DW 9 bpbSectorsPerTrack: DW 18 bpbHeadsPerCylinder: DW 2 bpbHiddenSectors: DD 0 bpbTotalSectorsBig: DD 0 bsDriveNumber: DB 0 bsUnused: DB 0 bsExtBootSignature: DB 0x29 bsSerialNumber: DD 0xa0a1a2a3 bsVolumeLabel: DB \"MOS FLOPPY \" bsFileSystem: DB \"FAT12 \" ;*************************************************; ; Bootloader Entry Point ;*************************************************; loader: cli ; Clear all Interrupts hlt ; halt the system times 510 - ($-$) db 0 ; We have to be 512 bytes. Clear the rest of the bytes with 0 dw 0xAA55 ; Boot Signature Printing Text - Interrupt 0x10 Function 0x0E You an use INT 0x10 for video interrupts. Remember, however, that only basic interrupts will work. INT 0x10 - VIDEO TELETYPE OUTPUT AH = 0x0E AL = Character to write BH - Page Number (Should be 0) BL = Foreground color (Graphics Modes Only) For example: xor bx, bx ; A faster method of clearing BX to 0 mov ah, 0x0e mov al, 'A' int 0x10 This will print the character 'A' on the screen. Printing Strings - Interrupt 0x10 Function 0x0E Using the same interrupt, we can easily print out a 0 terminated string: msg db \"Welcome to My Operating System!\", 0 ;*************************************** ; Prints a string ; DS=>SI: 0 terminated string ;*************************************** Print: lodsb or al, al ; al=current character jz PrintDone ; null terminator found mov ah, 0eh ; get next character int 10h jmp Print PrintDone: ret ;*************************************************; ; Bootloader Entry Point ;*************************************************; loader: ; Error Fix 1 ------------------------------------------ xor ax, ax ; Setup segments to insure they are 0\\. Remember that mov ds, ax ; we have ORG 0x7c00\\. This means all addresses are based mov es, ax ; from 0x7c00:0\\. Because the data segments are within the same ; code segment, null em. mov si, msg call Print cli ; Clear all Interrupts hlt ; halt the system times 510 - ($-$) db 0 ; We have to be 512 bytes. Clear the rest of the bytes with 0 dw 0xAA55 ; Boot Signature Getting amount of RAM This is too easy: INT 0x12 - BIOS GET MEMORY SIZE Returns: AX = Kilobytes of contiguous memory starting from absolute address 0x0. Here's an example: xor ax, ax int 0x12 ; Now AX = Amount of KB in system recorded by BIOS Wow... That was hard, wasn't it? ðŸ˜ Actually, it can be very hard to do in Protected Mode (PMode) as you will not have any interrupts available. Note The amount of memory actually returned from the BIOS might not be accurate! We will look at some other methods later. Demo ;********************************************* ; Boot1.asm ; - A Simple Bootloader ; ; Operating Systems Development Tutorial ;********************************************* bits 16 ; We are still in 16 bit Real Mode org 0x7c00 ; We are loaded by BIOS at 0x7C00 start: jmp loader ; jump over OEM block ;*************************************************; ; OEM Parameter block ;*************************************************; TIMES 0Bh-$+start DB 0 bpbBytesPerSector: DW 512 bpbSectorsPerCluster: DB 1 bpbReservedSectors: DW 1 bpbNumberOfFATs: DB 2 bpbRootEntries: DW 224 bpbTotalSectors: DW 2880 bpbMedia: DB 0xF0 bpbSectorsPerFAT: DW 9 bpbSectorsPerTrack: DW 18 bpbHeadsPerCylinder: DW 2 bpbHiddenSectors: DD 0 bpbTotalSectorsBig: DD 0 bsDriveNumber: DB 0 bsUnused: DB 0 bsExtBootSignature: DB 0x29 bsSerialNumber: DD 0xa0a1a2a3 bsVolumeLabel: DB \"MOS FLOPPY \" bsFileSystem: DB \"FAT12 \" ;*************************************************; ; Bootloader Entry Point ;*************************************************; loader: cli ; Clear all Interrupts hlt ; halt the system times 510 - ($-$) db 0 ; We have to be 512 bytes. Clear the rest of the bytes with 0 dw 0xAA55 ; Boot Signature msg db \"Welcome to My Operating System!\", 0 ;*************************************** ; Prints a string ; DS=>SI: 0 terminated string ;*************************************** Print: lodsb or al, al ; al=current character jz PrintDone ; null terminator found mov ah, 0eh ; get next character int 10h jmp Print PrintDone: ret ;*************************************************; ; Bootloader Entry Point ;*************************************************; loader: ; Error Fix 1 ------------------------------------------ xor ax, ax ; Setup segments to insure they are 0\\. Remember that mov ds, ax ; we have ORG 0x7c00\\. This means all addresses are based mov es, ax ; from 0x7c00:0\\. Because the data segments are within the same ; code segment, null em. mov si, msg call Print cli ; Clear all Interrupts hlt ; halt the system times 510 - ($-$) db 0 ; We have to be 512 bytes. Clear the rest of the bytes with 0 dw 0xAA55 ; Boot Signature Conclusion Give yourself a pat on the back for making this far. ðŸ˜ This tutorial was a nasty one. I had to find a very good way of explaining segment:offset addressing and the processor modes without going into to much depth. I think I did well ðŸ˜ We talked about the different processor modes--Real Mode, Protected Mode, Unreal Mode, and v86. We looked at Real Mode in depth because we will be in that mode when developing the bootloader. We also went over segment:offset addressing. This might be a refresher course for some of our DOS programmers out there. We also looked at some BIOS interrupts, and ended with a complete example. In the next tutorial, we are going to decipher that ugly OEM Parameter Block that we added. We are also going to take a look at basic File System theory, and loading sectors off disk."
  },
  "articles/61_unorganised_tutorial/T5.html": {
    "href": "articles/61_unorganised_tutorial/T5.html",
    "title": "Bootloaders 3 | BrokenThorn OS Dev Tutorials",
    "keywords": "Bootloaders 3 Here, we are going to take a look at: the different \"Rings\" that describe differences between Application Programming and Systems Programming. single stage and multi stage bootloaders, and pros and cons of each. BIOS Interrupt 0x13 , the OEM Parameter Block , and Reading, loading, and executing a program . This program will be our Second Stage Bootloader . Our Second Stage Bootloader will then set the 32 bit envirement, and prepare to load our C Kernel . The Rings of Assembly Language In Assembly Language, you might here the term \"Ring 0 program\", or \"This program is running in Ring 3\". Understanding the different rings (and what they are) can be usefull in OS Development. Rings - Theory Okay, so what is a ring? A \"Ring\", in Assembly Language, represents the level of protection and control the program has over the system. There are 4 rings: Ring 0, Ring 1, Ring 2, and Ring 3. Ring 0 programs have absolute control over everything within a system, while ring 3 has less control. The smaller the ring number, the more control (and less level of protection), the software has. A Ring is more then a concept--it is built into the processor architecture. When the computer boots up, even when your Bootloader executes, the processor is in Ring 0. Most applications, such as DOS applications, run in Ring 3. This means Operating Systems, as running in Ring 0, have far more control over everything then normal Ring 3 applications. Switching Rings Because Rings are part of the processor architecture, the processor changes states whenever it needs to. It may change when... A directed instruction executes a program at a different ring level, such as a far jump, far call, far return, etc. A trap instruction, such as INT, SYSCALL, SYSENTER Exceptions We will cover Exception Handling later, as well as the SYSCALL and SYSENTER instructions. Multi Stage Bootloaders Single Stage Bootloaders Remember that bootloaders, and bootsectors, are only 512 bytes in size. If the bootloader, within that same 512 bytes, executed the kernel directly, it is called a Single Stage Bootloader . The problem with this, however, is that of its size. There is so little room to do alot within those 512 bytes. It will be very difficault to set up, load and execute a 32 bit kernel within a 16 bit bootloader. This does not include error handling code. This includes code for: GDT, IDT, A20, PMode, Loading and finding 32 bit kernel, executing kernel, and error handling. Fitting all of this code within 512 bytes is impossible. Because of this, Single stage bootloaders have to load and execute a 16 bit kernel . Because of this problem, most bootloaders are Multi Stage Loaders. Single and Multi Stage Bootloaders A Multi Stage Bootloader consists of a single 512 byte bootloader (The Single Stage Loader), however it just loads and executes another loader - A Second Stage Bootloader. the Second Stage Bootloader is normally 16 bit, however it will include all of the code (listed in the previous section), and more. It will be able to load and execute a 32 bit Kernel. The reason this works is because the only 512 byte limitation is the bootloader. As long as the bootloader loads all of the sectors for the Second Stage loader in good manner, the Second Stage Loader has no limitation in size. This makes things much easier to set up for the Kernel. We will be using a 2 Stage Bootloader. Loading Sectors Off Disk Remember that Bootloaders are limited to 512 bytes. Because of this, there is not a whole lot we can do. As stated in the previous section, we are going to be using a 2 Stage Bootloader. This means, we will need our Bootloader to load and execute our Stage 2 program -- The Kernel Loader. If you wanted to, The Stage 2 loader is the place to include your own \"Choose your Operating System\" and \"Advanced Options\" menu ðŸ˜ Come on, I know you want one. ðŸ˜ BIOS Interrupt (INT) 0x13 Function 0 - Reset Floppy Disk The BIOS Interrupt 0x13 is used for disk access. You can use INT 0x13, Function 0 to reset the floppy drive. What this means is, wherever the Floppy Controller is reading from, it will immediately go to the first Sector on disk. INT 0x13/AH=0x0 - DISK : RESET DISK SYSTEM AH = 0x0 DL = Drive to Reset Returns: AH = Status Code CF (Carry Flag) is clear if success, it is set if failure Here is a complete example. This resets the floppy drive, and will try again if there is an error: .Reset: mov ah, 0 ; reset floppy disk function mov dl, 0 ; drive 0 is floppy drive int 0x13 ; call BIOS jc .Reset ; If Carry Flag (CF) is set, there was an error. Try resetting again Why is this interrupt important to us? Before reading any sectors, we have to insure we begin from sector 0. We dont know what sector the floppy controller is reading from. This is bad, as it can change from any time you reboot. Reseting the disk to sector 0 will insure you are reading the same sectors each time. BIOS Interrupt (INT) 0x13 Function 0x02 - Reading Sectors INT 0x13/AH=0x02 - DISK : READ SECTOR(S) INTO MEMORY AH = 0x02 AL = Number of sectors to read CH = Low eight bits of cylinder number CL = Sector Number (Bits 0-5). Bits 6-7 are for hard disks only DH = Head Number DL = Drive Number (Bit 7 set for hard disks) ES:BX = Buffer to read sectors to Returns: AH = Status Code AL = Number of sectors read CF = set if failure, cleared is successfull Okay, This is alot to think about. Some of this is fairly easy, others should be explained more. Lets take a look closer, shall we? CH = Low eight bits of cylinder number What is a Cylinder ? A cylinder is a group of tracks (with the same radius) on the disk. To better understand this, lets look at a picture: Looking at the above picture, remember: Each Track is useually divided into 512 byte sectors. On floppies, there are 18 sectors per track. A Cylinder is a group of tracks with the same radius (The Red tracks in the picture above are one cylinder) Floppy Disks have two heads (Displayed in the picture) There is 2880 Sectors total. What does this mean for us? The Cylinder number basically represents a track number on a single disk. In the case of a floppy disk, It represents the Track to read from. In summary, there are 512 bytes per sector, 18 sectors per track, and 80 tracks per side. CL = Sector Number (Bits 0-5). Bits 6-7 are for hard disks only This is the first sector to begin reading from. Remember: There is only 18 sectors per track. This means that this value can only be between 0 and 17. You have to increase the current track number, and insure the sector number is correctly set to read the correct sector. If this value is greater then 18, The Floppy Controller will generate an exception, because the sector does not exist. Because there is no handler for it, The CPU will generate a second fault exception, which will ultimately lead to a Triple Fault . DH = Head Number Remember that some floppys have two heads , or sides, to them. Head 0 is on the front side, where sector 0 is. Because of this, We are going to be reading from Head 0. If this value is greater then 2, The Floppy Controller will generate an exception, because the head does not exist. Because there is no handler for it, The CPU will generate a second fault exception, which will ultimately lead to a Triple Fault. DL = Drive Number (Bit 7 set for hard disks) ES:BX = Buffer to read sectors to What is a Drive Number? Its simply a number that, of course, represents a drive. Drive Number 0 useually represents a floppy drive . Drive Number 1 is useually for 5-1/4\" Floppy drives. Because we are on a floppy, we want to read from the floppy disk. So, the drive number to read from is 0. ES:BX stores the segment:offset base address to read the sectors into. Remember that the Base Address represents the starting address. With this all in mind, lets try to read a sector. Reading and loading a sector To read a sector from disk, first reset the floppy drive, and just read: .Reset: mov ah, 0 ; reset floppy disk function mov dl, 0 ; drive 0 is floppy drive int 0x13 ; call BIOS jc .Reset ; If Carry Flag (CF) is set, there was an error. Try resetting again mov ax, 0x1000 ; we are going to read sector to into address 0x1000:0 mov es, ax xor bx, bx .Read: mov ah, 0x02 ; function 2 mov al, 1 ; read 1 sector mov ch, 1 ; we are reading the second sector past us, so its still on track 1 mov cl, 2 ; sector to read (The second sector) mov dh, 0 ; head number mov dl, 0 ; drive number. Remember Drive 0 is floppy drive. int 0x13 ; call BIOS - Read the sector jc .Read ; Error, so try again jmp 0x1000:0x0 ; jump to execute the sector! Note If there is a problem reading the sectors, and you try to jump to it to execute it, The CPU will exeute whatever instructions at that address, weather or not the sector was loaded. This useually means the CPU will run into either an invalid/unkown instruction, or the end of memory, both will result in a Triple Fault. The above code only reads and executes a raw sector, which is kind of pointless to our needs. For one**,We currently have PartCopy set up to copy only 512 bytes**, which means: Where and how are we going to create a raw sector? Also, it is impossible for us to give this Raw Sector a \"filename\" because it does not exist. Its just a raw sector. Finally, We currently have the bootloader setup for a FAT12 File System. Windows will attempt to read certain tables ( File Allocation Tables ) from Sector 2 and 3. However, with a Raw Sector, these tables are nonexistant, so Windows will take garbage values (as if it was the table). The result? When reading the floppy disk from Windows, you will see files and directories with currupt names, and enormous sizes (Have you ever seen a 2.5 Gigabyte file on a 3.14 MB Floppy? I have ðŸ˜) Of course, We Will need to load sectors this way . Before we do, however, we have to find the Starting Sector, Number of sectors, base address, etc . of a file in order to load it properly. This is the bases of loading files off disk. We will look at this next. Navigating The FAT12 FileSystem OEM Parameter Block - Detail In the previous artical, we dumped an ugly table in our code. What was it? Oh yeah... bpbBytesPerSector: DW 512 bpbSectorsPerCluster: DB 1 bpbReservedSectors: DW 1 bpbNumberOfFATs: DB 2 bpbRootEntries: DW 224 bpbTotalSectors: DW 2880 bpbMedia: DB 0xF0 bpbSectorsPerFAT: DW 9 bpbSectorsPerTrack: DW 18 bpbHeadsPerCylinder: DW 2 bpbHiddenSectors: DD 0 bpbTotalSectorsBig: DD 0 bsDriveNumber: DB 0 bsUnused: DB 0 bsExtBootSignature: DB 0x29 bsSerialNumber: DD 0xa0a1a2a3 bsVolumeLabel: DB \"MOS FLOPPY \" bsFileSystem: DB \"FAT12 \" Alot of this is pretty simple. Lets analyze this in some detail: bpbBytesPerSector: DW 512 bpbSectorsPerCluster: DB 1 bpbBytesPerSector indicates the number of bytes that represents a sector. This must be a power of 2. Normally for floppy disks, it is 512 bytes. bpbSectorsPerCluster indicates the number of sectors per cluster . In our case, we want one sectorper cluster. bpbReservedSectors: DW 1 bpbNumberOfFATs: DB 2 A Reserved Sector is the number of sectors not included in FAT12. ie, not part of the Root Directory . In our case, The Bootsector , which contains our bootloader, will not be part of this directory. Because of this, bpbReservedSectors should be 1. This also means that the reserved sectors (Our bootloader) will not contain a File Allocation Table. bpbNumberOfFATs rpresents the number of File Allocation Tables (FATs) on the disk. The FAT12 File System always has 2 FATs. Normally, you would need to create these FAT tables. However, Because we are using VFD, **We can have Windows/VFD to create these tables for us when it formats the disk. Note: These tables will also be written to by Windows/VFD when you add or delete entrys. ie, when you add a new file or directory.** bpbRootEntries: DW 224 bpbTotalSectors: DW 2880 Floppy Disks have a maximum of 224 directories within its Root Directory . Also, R emember that there are 2,880 sectors in a floppy disk. bpbMedia: DB 0xF0 bpbSectorsPerFAT: DW 9 The Media Descriptor Byte (bpbMedia) is a byte code that contains information about the disk. This byte is a Bit Pattern: Bits 0: Sides/Heads = 0 if it is single sided, 1 if its double sided Bits 1: Size = 0 if it has 9 sectors per FAT, 1 if it has 8. Bits 2: Density = 0 if it has 80 tracks, 1 if it is 40 tracks. Bits 3: Type = 0 if its a fixed disk (Such as hard drive), 1 if removable (Such as floppy drive) Bits 4 to 7 are unused, and always 1. 0xF0 = 11110000 binary. This means it is a single sided, 9 sectors per FAT, 80 tracks, and is a movable disk . Look at bpbSectorsPerFAT and you will see that it is also 9. bpbSectorsPerTrack: DW 18 bpbHeadsPerCylinder: DW 2 Remember: from the previous tutorials/ There is 18 sectors per track. bpbHeadsPerCylinder simply represents that there are 2 heads that represents a cylinder. (If you dont know what a Cylinder is, please read the section \"BIOS Interrupt (INT) 0x13\" on Reading Sectors.) bpbHiddenSectors: DD 0 This represents the number of sectors from the start of the physical disk and the start of the volume. bpbTotalSectorsBig: DD 0 bsDriveNumber: DB 0 Remember that the floppy drive is Drive 0? bsUnused: DB 0 bsExtBootSignature: DB 0x29 The Boot Signiture represents the type and version of this BIOS Parameter Block (This OEM Table) is. The values are: 0x28 and 0x29 indicate this is a MS/PC-DOS version 4.0 Bios Parameter Block (BPB) We have 0x29, so this is the version we are using. bsSerialNumber: DD 0xa0a1a2a3 bsVolumeLabel: DB \"MOS FLOPPY \" bsFileSystem: DB \"FAT12 \" The serial number is assigned by the utility that formats it. The serial number is unique to that particular floppy disk, and no two serial numbers should be identical. Microsoft, PC, and DR-DOS base the Seral number off of the current time and date like this: Low 16 bits = ((seconds + month) << 8) + (hundredths + day_of_month) High 16 bits = (hours << 8) + minutes + year Because the serial number is overwritten, we could put whatever we want in it--it doesnt matter. The Volume Label is a string to indicate what is on the disk. Some OSs display this as its name. Note Volume Label string Must be 11 bytes. No more, and no less. The Filesystem string is used for the same purpose, and no more. Note The Filesystem string must be 8 bytes, no more and no less. Demo Wow, thats alot of stuff, huh? The following is the bootloader I developed in this tutorial, that puts everything together. Please note: This demo will not work as is . It was originally intended for demonstration purposes only, and is not buildable in its current state. I plan to update this tutorial and make the demo buildable sometime during the next revision of the series. ;********************************************* ; Boot1.asm ; - A Simple Bootloader ; ; Operating Systems Development Tutorial ;********************************************* bits 16 ; We are still in 16 bit Real Mode org 0x7c00 ; We are loaded by BIOS at 0x7C00 start: jmp loader ; jump over OEM block ;*************************************************; ; OEM Parameter block / BIOS Parameter Block ;*************************************************; TIMES 0Bh-$+start DB 0 bpbBytesPerSector: DW 512 bpbSectorsPerCluster: DB 1 bpbReservedSectors: DW 1 bpbNumberOfFATs: DB 2 bpbRootEntries: DW 224 bpbTotalSectors: DW 2880 bpbMedia: DB 0xF0 bpbSectorsPerFAT: DW 9 bpbSectorsPerTrack: DW 18 bpbHeadsPerCylinder: DW 2 bpbHiddenSectors: DD 0 bpbTotalSectorsBig: DD 0 bsDriveNumber: DB 0 bsUnused: DB 0 bsExtBootSignature: DB 0x29 bsSerialNumber: DD 0xa0a1a2a3 bsVolumeLabel: DB \"MOS FLOPPY \" bsFileSystem: DB \"FAT12 \" ;*************************************** ; Prints a string ; DS=>SI: 0 terminated string ;*************************************** Print: lodsb ; load next byte from string from SI to AL or al, al ; Does AL=0? jz PrintDone ; Yep, null terminator found-bail out mov ah, 0eh ; Nope-Print the character int 10h jmp Print ; Repeat until null terminator found PrintDone: ret ; we are done, so return ;*************************************************; ; Bootloader Entry Point ;*************************************************; loader: .Reset: mov ah, 0 ; reset floppy disk function mov dl, 0 ; drive 0 is floppy drive int 0x13 ; call BIOS jc .Reset ; If Carry Flag (CF) is set, there was an error. Try resetting again mov ax, 0x1000 ; we are going to read sector to into address 0x1000:0 mov es, ax xor bx, bx mov ah, 0x02 ; read floppy sector function mov al, 1 ; read 1 sector mov ch, 1 ; we are reading the second sector past us, so its still on track 1 mov cl, 2 ; sector to read (The second sector) mov dh, 0 ; head number mov dl, 0 ; drive number. Remember Drive 0 is floppy drive. int 0x13 ; call BIOS - Read the sector jmp 0x1000:0x0 ; jump to execute the sector! times 510 - ($-$$) db 0 ; We have to be 512 bytes. Clear the rest of the bytes with 0 dw 0xAA55 ; Boot Signiture ; End of sector 1, beginning of sector 2 --------------------------------- org 0x1000 ; This sector is loaded at 0x1000:0 by the bootsector cli ; just halt the system hlt Conclusion We went in alot of detail about disk reading and the BIOS Parameter Block (BPB). We even developed a simple demo that combined everything together. We also have taken a look at the different rings in assembly language, and learned that our OS is at Ring 0, which differenates it then most other programs. This allows us to use more special privedged instructions that application programs dont have. Now, we have everything we need to find and load our second stage loader! We will learn everything about FAT12, and load the second stage in the next tutorial. I cant wait! ðŸ˜ Until next time,"
  },
  "articles/61_unorganised_tutorial/T6.html": {
    "href": "articles/61_unorganised_tutorial/T6.html",
    "title": "Bootloaders 4 | BrokenThorn OS Dev Tutorials",
    "keywords": "Bootloaders 4 In this page, we are going to use everything we learned to parse the FAT12 file system, and load our second stage loader by name, This tutorial is going to have a lot of code in it. I will do my best to explain everything in detail. Also, this tutorial will have some math in it as well. cli and hlt You might be curious at why I end all of my demo programs with the instructions \"cli\" and \"hlt\". Its actually pretty simple. If there is no way of stopping the program in some manner, the CPU will just go beyond your program and execute random instructions. This will, ultimately, end in a Triple Fault. The reason I clear interrupts (cli) as because the interrupts will execute (hence the system is not halted) even when I wanted to. This can cause problems. So, just having a hlt instruction (without cli ) can Triple Fault the CPU. Because of this, I always end all of my demos with cli and hlt. Filesystems - Theory Yippee! Its time to talk about filesystems ðŸ˜ A File System is nothing more then a specification. It helps create the concept of a \"file\" on a disk. A file is a group of data that has represents something. This data can be anything we want it to be. It all depends on how we interpreted the data. As you know, a sector is 512 bytes in size. A file is stored across these sectors on disk. If the file exceeds 512 bytes, we have to give it more sectors. Because not all files are evenly 512 bytes in size, we will need to fill in the rest of the bytes (That the file doesn't use). Kind of like what we did for our bootloader. If a file spans across several sectors, we call these sectors a Cluster in the FAT file systems. For example, our kernel will most likely span a lot of sectors. To load our kernel, we will need to load the cluster (The sectors) from where it is located. If a file spans across different sectors (Not contiguous) across different clusters, it is said to be Fragmented . We will need to collect the different parts of the file. There are a lot of different kinds of file systems. Some are widely use (Like FAT12, FAT16, FAT32, NTFS, ext (Linux), HFS (Used in older MACs); other filesystems are only used by specific companies for in house use (Like the GFS - Google File System). a lot of OS developers also create there on versions of the FAT file systems (or even something completely new). These are usually not as good as the most common filesystems though (Like FAT and NTFS). Okay, so we know a little about file systems now. We are going to be using FAT12 for its simplicity. If we decide, we can always use a different one. ðŸ˜ FAT12 Filesystem - Theory FAT12 is the first FAT (File Allocation Table) Filesystem released in 1977, and used in Microsoft Disk BASIC. FAT12, as being an older filesystem generally released for floppy disks, had a number of limitations. FAT12 has no support for hierarchical directories. This means there is only one directory- The Root Directory . Cluster Addresses were only 12 bits long, which limits the maximum number of clusters to 4096 The Filenames are stored in the FAT as a 12 bit identifier. The Cluster Addresses represent the starting clusters of the files. Because of the limited cluster size, The maximum number of files possible is 4,077 The Disk Size is stored only as a 16 bit count of sectors, limiting it to 32 MiB in size FAT12 uses the value \"0x01\" to identify partitions These are some big limitations. Why do we want FAT12 then? FAT16 has support for directories, and over 64,000 files as it uses a 16 bit cluster (file) address, as apposed to FAT12. However, FAT16 and FAT12 are very similar. To make things simple, we are going to use FAT12. We might spruce things up with FAT16 (or even use FAT32) later ðŸ˜ (FAT32 is quite different then FAT 12/16, so we might use FAT16 later.) FAT12 Filesystem - Disk Storage To understand more about FAT12, and how it works, it is better to look at the structure of a typical formatted disk. |FAT12 FS Sectors| |---| |Boot Sector| |Extra Reserved Sectors| |File Allocation Table 1| |File Allocation Table 2| |Root Directory (FAT12/FAT16 Only)| |Data Region containing files and directories| This is a typical formatted FAT12 disk, from the bootsector to the very last sector on disk. Understanding this structure will be important when loading and searching for our file. Note that there are 2 FATs on a disk. It is located right after the reserved sectors (or the bootloader, if there is none) . Also note: The Root Directory is right after all of the FATs . This means... if we add up the number of sectors per FAT, and the reserved sectors, we can get the first sector to the Root Directory. By searching the Root Directory for a simple string (our filename), we can effectively find the exact sector of the file on disk ðŸ˜ Lets look closer... Boot Sector This section contains the BIOS Parameter Block and the bootloader. Yep--Ours. The BIOS Parameter Block contains information tat help describe our disk. Extra Reserved Sectors Remember the bpbReservedSectors member of our BPB? Any extra reserved sectors are stored here, right after the bootsector. File Allocation Tables (FATs) Remember that a cluster represents a series of contiguous sectors on disk. the size of each cluster is normally 2 KB to 32 KiB. The file pieces are linked (from one cluster to another using a common data structure, such as a Linked List . There are two FATs. However, one is just a copy of the first one for data recovery purposes. It usually isn't used. The File Allocation Table (FAT) is a list of entries that map to each of these clusters. They help identify important information to aid in storing data to these clusters. Each entry is a 12 bit value that represents a cluster. The FAT is a linked list-like structure with these entries that helps identify what clusters are in use . To better understand this lets look at the possible values: Value marks free cluster : 0x00 Value marks Reserved cluster : 0x01 This cluster is in use--the value represents next cluster : 0x002 through 0xFEF Reserved values : 0xFF0 through 0xFF6 Value marks bad clusters : 0xFF7 Value marks this cluster as the last in the file : 0xFF8 through 0xFFF A FAT is just an array of these values--that's all. When we find the starting sector form the Root Directory, we can look through the FAT to find which clusters to load. How? We simply check the value. If the value is between 0x02 and 0xfef, this value represents the next cluster to load for the file. Lets look at this in a deeper way. A cluster , as you know, represents a series of sectors. We define the amount of sectors it represents from the BIOS Parameter Block: bpbBytesPerSector: DW 512 bpbSectorsPerCluster: DB 1 In our case, each cluster is 1 sector. When we get the first sector of Stage 2 (We get this from the root directory), we use this sector as the starting cluster number in the FAT. Once we find the starting cluster, we just reference the FAT to determine the cluster (The FAT is just an array of 32 bit numbers. We just compare this number with the list above to determine what to do with it.) The Root Directory Table Now, THIS will be important to us ðŸ˜ The root directory is a table of 32 byte values that represent information regarding file and directories. This 32 byte value uses the format: Bytes 0-7 : DOS File name (Padded with spaces) Bytes 8-10 : DOS File extension (Padded with spaces) Bytes 11 : File attributes. This is a bit pattern: Bit 0 : Read Only Bit 1 : Hidden Bit 2 : System Bit 3 : Volume Label Bit 4 : This is a subdirectory Bit 5 : Archive Bit 6 : Device (Internal use) Bit 6 : Unused Bytes 12 : Unused Bytes 13 : Create time in ms Bytes 14-15 : Created time, using the following format: Bit 0-4 : Seconds (0-29) Bit 5-10 : Minutes (0-59) Bit 11-15 : Hours (0-23) Bytes 16-17 : Created year in the following format: Bit 0-4 : Year (0=1980; 127=2107 Bit 5-8 : Month (1=January; 12=December) Bit 9-15 : Hours (0-23) Bytes 18-19 : Last access date (Uses same format as above) Bytes 20-21 : EA Index (Used in OS/2 and NT, don't worry about it) Bytes 22-23 : Last Modified time (See byte 14-15 for format) Bytes 24-25 : Last modified date (See bytes 16-17 for format) Bytes 26-27 : First Cluster Bytes 28-32 : File Size I bolded the important parts--everything else is just junk Microsoft added that we can add to when we create a FAT12 driver, much later. Wait a sec! Remember that DOS filenames are limited to 11 bytes? This is why: Bytes 0-7 : DOS File name (Padded with spaces) Bytes 8-10 : DOS File extension (Padded with spaces) 0 through 10, hmm... that's 11 bytes. Having a filename less then 11 bytes will miss up the data entry (The 32 byte entry table displayed above). This, of course, is bad ðŸ˜ Because of this, we have to pad the filenames with characters, and insure it is 11 bytes. Remember in a previous tutorial I explained how their are internal and external filenames? The filename structure I explained is the internal filename. As it is limited to 11 bytes, the filename \"Stage2.sys\" has to become \"STAGE2 SYS\" ; (Note the padding!) Searching and reading FAT12 - Theory Okay, after reading all of the above, you are probably tired of me saying \"FAT12\" ðŸ˜ Anyhow ... How is this information useful to us? We are going to be referencing the BIOS Parameter Block (BPB) a lot. Here is the BPB that we created from the previous tutorials for reference: bpbBytesPerSector: DW 512 bpbSectorsPerCluster: DB 1 bpbReservedSectors: DW 1 bpbNumberOfFATs: DB 2 bpbRootEntries: DW 224 bpbTotalSectors: DW 2880 bpbMedia: DB 0xF0 bpbSectorsPerFAT: DW 9 bpbSectorsPerTrack: DW 18 bpbHeadsPerCylinder: DW 2 bpbHiddenSectors: DD 0 bpbTotalSectorsBig: DD 0 bsDriveNumber: DB 0 bsUnused: DB 0 bsExtBootSignature: DB 0x29 bsSerialNumber: DD 0xa0a1a2a3 bsVolumeLabel: DB \"MOS FLOPPY \" bsFileSystem: DB \"FAT12 \" Please see the previous tutorial for a detailed explanation of each member. What we are trying to do is to load a second stage loader. Lets look at what we need to do in detail: Beginning with a filename The first thing to do is to create a good filename. Remember: The Filenames must be exactly 11 bytes to insure we don't corrupt the root directory. I am using \"STAGE2.SYS\", for my second stage. You can look at an example of its internal filename in the above section. Creating Stage 2 Okay, Stage2 is a separate program then the bootloader. Our Stage2 will be very similar to a DOS COM program, sound cool? All Stage2 does right now is print a message and halt. Everything you have already seen from the bootloader: ; Note: Here, we are executed like a normal ; COM program, but we are still in Ring 0. ; We will use this loader to set up 32 bit ; mode and basic exception handling ; This loaded program will be our 32 bit Kernel. ; We do not have the limitation of 512 bytes here, ; so we can add anything we want here! org 0x0 ; offset to 0, we will set segments later bits 16 ; we are still in real mode ; we are loaded at linear address 0x10000 jmp main ; jump to main ;*************************************************; ; Prints a string ; DS=>SI: 0 terminated string ;************************************************; Print: lodsb ; load next byte from string from SI to AL or al, al ; Does AL=0? jz PrintDone ; Yep, null terminator found-bail out mov ah, 0eh ; Nope-Print the character int 10h jmp Print ; Repeat until null terminator found PrintDone: ret ; we are done, so return ;*************************************************; ; Second Stage Loader Entry Point ;************************************************; main: cli ; clear interrupts push cs ; Insure DS=CS pop ds mov si, Msg call Print cli ; clear interrupts to prevent triple faults hlt ; halt the system ;*************************************************; ; Data Section ;************************************************; Msg db \"Preparing to load operating system...\",13,10,0 To assemble with NASM, just assemble it as a binary program (COM programs are binary), and copy it into the floppy disk image. For example: nasm -f bin Stage2.asm -o STAGE2.SYS copy STAGE2.SYS A:\\STAGE2.SYS Step 1: Loading the Root Directory Table Now its time to load Stage2.sys! We will be referencing the Root directory table a lot here, along with the BIOS parameter block for disk information. Step 1: Get size of root directory Okay, first we need to get the size of the root directory. To get the size, just multiply the number of entries in the root directory. Seems simple enough ðŸ˜ In Windows, whenever you add a file or directory to a FAT12 formatted disk, Windows automatically adds the file information to the root directory, so we don't need to worry about it. This makes things much simpler. Dividing the number of root entries by bytes per sector will tell us how many sectors the root entry uses. Here is an example: mov ax, 0x0020 ; 32 byte directory entry mul WORD [bpbRootEntries] ; number of root entries div WORD [bpbBytesPerSector] ; get sectors used by root directory Remember that the root directory table is a table of 32 byte values (entries) that represent the file information. Yippee--Okay, we know how much sectors to load in for the root directory. Now, lets find the starting sector to load from ðŸ˜ Step 2: Get start of root directory This is another easy one. First, lets look at a FAT12 formatted disk again: FAT12 FS Sectors Boot Sector Extra Reserved Sectors File Allocation Table 1 File Allocation Table 2 Root Directory (FAT12/FAT16 Only) Data Region containing files and directories Okay, note that the Root Directory is located directly after both FATs and reserved sectors . In other words, just add the FATs + reserved sectors, and you found the root directory! For example... mov al, [bpbNumberOfFATs] ; Get number of FATs (Usually 2) mul [bpbSectorsPerFAT] ; number of FATs * sectors per FAT; get number of sectors add ax, [bpbReservedSectors] ; add reserved sectors ; Now, AX = starting sector of root directory Pretty easy, huh? Now, we just read the sector to some location in memory: mov bx, 0x0200 ; load root directory to 7c00:0x0200 call ReadSectors Root Directory - Complete example This example code is taken directly from the bootloader a the end of the tutorial. It loads the root directory: LOAD_ROOT: ; compute size of root directory and store in \"cx\" xor cx, cx xor dx, dx mov ax, 0x0020 ; 32 byte directory entry mul WORD [bpbRootEntries] ; total size of directory div WORD [bpbBytesPerSector] ; sectors used by directory xchg ax, cx ; compute location of root directory and store in \"ax\" mov al, BYTE [bpbNumberOfFATs] ; number of FATs mul WORD [bpbSectorsPerFAT] ; sectors used by FATs add ax, WORD [bpbReservedSectors] ; adjust for bootsector mov WORD [datasector], ax ; base of root directory add WORD [datasector], cx ; read root directory into memory (7C00:0200) mov bx, 0x0200 ; copy root dir above bootcode call ReadSectors Step 2: Find Stage 2 Okay, now the root directory table is loaded. Looking at the above code, we loaded it to 0x200. Now, to find our file. Lets look back at the 32 byte root directory table again (Section Root Directory Table . Remember the first 11 bytes represent the filename . Also remember that, because each root directory entry is 32 bytes, Every 32 bytes will be the start of the next entry - Pointing us back to the first 11 bytes of the next entry. Hence, all we need to do is compare filenames, and jump to the next entry (32bytes), and test again until we reach the end of the sector. For example... ; browse root directory for binary image mov cx, [bpbRootEntries] ; the number of entries. If we reach 0, file doesn't exist mov di, 0x0200 ; Root directory was loaded here .LOOP: push cx mov cx, 11 ; eleven character name mov si, ImageName ; compare the 11 bytes with the name of our file push di rep cmpsb ; test for entry match pop di je LOAD_FAT ; they match, so begin loading FAT pop cx add di, 32 ; they don't match, so go to next entry (32 bytes) loop .LOOP jmp FAILURE ; no more entries left, file doesn't exist :( On to the next step... Step 3: Loading FAT Step 1: Get start cluster Okay, so the root directory is loaded and we found the files entry. How do we get its starting cluster? Bytes 26-27 : First Cluster Bytes 28-32 : File Size This should look familiar ðŸ˜ To get the starting cluster, just reference byte 26 in the file entry: mov dx, [di + 0x001A] ; di contains starting address of entry. Just reference byte 26 (0x1A) of entry ; Yippee--dx now stores the starting cluster number The starting cluster will be important to us when loading the file. Step 2: Get size of FAT Lets look at the BIOS parameter block again. More specifically... bpbNumberOfFATs: DB 2 bpbSectorsPerFAT: DW 9 Okay, so how do we find out how many sectors there are in both FATs? Just multiply sectors per FAT by the number of sectors ðŸ˜ Seems simple, ...but... xor ax, ax mov al, [bpbNumberOfFATs] ; number of FATs mul WORD [bpbSectorsPerFAT] ; multiply by number of sectors per FAT ; ax = number of sectors the FATs use! No, never mind, it is simple ^^ Step 3: Load the FAT Now that we know how many sectors to read. Just, um... read it ðŸ˜ mov bx, 0x0200 ; address to load to call ReadSectors ; load the FAT table Yes! Now with the FAT stuff out of the way (Not completely!), load in stage 2! FAT - Complete example Here is the complete code taken directly from the bootloader: LOAD_FAT: ; save starting cluster of boot image mov si, msgCRLF call Print mov dx, WORD [di + 0x001A] mov WORD [cluster], dx ; file's first cluster ; compute size of FAT and store in \"cx\" xor ax, ax mov al, BYTE [bpbNumberOfFATs] ; number of FATs mul WORD [bpbSectorsPerFAT] ; sectors used by FATs mov cx, ax ; compute location of FAT and store in \"ax\" mov ax, WORD [bpbReservedSectors] ; adjust for bootsector ; read FAT into memory (7C00:0200) mov bx, 0x0200 ; copy FAT above bootcode call ReadSectors LBA and CHS In loading the image, all we need to do is load each cluster by referencing the FAT. There is one little problem we haven't discussed yet though. Okay, We have a cluster number from the FAT. But, How do we use it? The problem is that this cluster represents a linear address, while, in order to load sectors, we will need a segment/track/head address. (Interrupt 0x13) There are two ways to access a disk. Either through Cylinder/Head/Sector (CHS) addressing or Logical Block Addressing (LBA) . The LBA represents an indexed location on disk. The first block being 0, then 1, and so on. LBA simply represents sectors are sequentially numbered with LBA 0. Cant get more basic then that. You will need to know how to convert between LBA and CHS. Converting CHS to LBA The formula to convert CHS to LBA: LBA = (cluster - 2 ) * sectors per cluster That is simple enough. ðŸ˜ here's an example: sub ax, 0x0002 ; subtract 2 from cluster number xor cx, cx mov cl, BYTE [bpbSectorsPerCluster] ; get sectors per cluster mul cx ; multiply Converting LBA to CHS This is a little bit more complex, but still is relatively easy: absolute sector = (LBA % sectors per track) + 1 absolute head = (LBA / sectors per track) % number of heads absolute track = LBA / (sectors per track * number of heads) here's an example... LBACHS: xor dx, dx ; prepare dx:ax for operation div WORD [bpbSectorsPerTrack] ; divide by sectors per track inc dl ; add 1 (absolute sector formula) mov BYTE [absoluteSector], dl ; these forumlae are very similar ... xor dx, dx ; prepare dx:ax for operation div WORD [bpbHeadsPerCylinder] ; mod by number of heads (Absolue head formula) mov BYTE [absoluteHead], dl ; everything else was already done from the first formula mov BYTE [absoluteTrack], al ; not much else to do ðŸ˜ ret Not to hard, I hope ðŸ˜ Load the cluster Okay, in loading Stage 2, we first need to reference the cluster from the FAT. Pretty simple. Then, convert the cluster number to LBA so we can read it in: mov ax, [cluster] ; cluster to read pop bx ; buffer to read into call ClusterLBA ; convert cluster to LBA xor cx, cx mov cl, [bpbSectorsPerCluster] ; sectors to read call ReadSectors ; read in cluster push bx Get next cluster This is tricky. Okay, remember each cluster number in the FAT entry is 12 bits . This is a problem. If we read in 1 byte, we are only copying a part of the cluster number! . Because of this, we have to read a WORD (2 byte) value. Yet, then again, we run into a problem. Copying 2 bytes (from a 12 bit value) means that we will copy a part of the next cluster entry . For example, imagine this is your FAT: Note: Binary numbers separated in bytes. Each 12 bit FAT cluster entry is displayed. | | 01011101 0111010 01110101 00111101 0011101 0111010 0011110 0011110 | | | | | | | |1st cluster | |3rd cluster-| | |-0 cluster ----| |2nd cluster---| |4th cluster----| Notice all even clusters occupy all of the first byte, but part of the second. Also notice that all odd clusters occupy a part of their first byte, but all of the second! Okay, so what we need to do is to read a 2byte (word) value from the FAT (This is our cluster). If the cluster is even, Mask out the top 4 bits, as it belongs to the next cluster. If it is odd, shift it down 4 bits (to discard the bits used by the first cluster.) For example... ; compute next cluster mov ax, WORD [cluster] ; identify current cluster from FAT ; is the cluster odd or even? Just divide it by 2 and test! mov cx, ax ; copy current cluster mov dx, ax ; copy current cluster shr dx, 0x0001 ; divide by two add cx, dx ; sum for (3/2) mov bx, 0x0200 ; location of FAT in memory add bx, cx ; index into FAT mov dx, WORD [bx] ; read two bytes from FAT test ax, 0x0001 jnz .ODD_CLUSTER ; Remember that each entry in the FAT is a 12 but value. If it represents ; a cluster (0x002 through 0xFEF) then we only want to get those 12 bits ; that represent the next cluster .EVEN_CLUSTER: and dx, 0000111111111111b ; take low twelve bits jmp .DONE .ODD_CLUSTER: shr dx, 0x0004 ; take high twelve bits .DONE: mov WORD [cluster], dx ; store new cluster cmp dx, 0x0FF0 ; test for end of file jb LOAD_IMAGE ; we are not done yet--go to next cluster Demo The first shot contains the bootloader loading Stage 2 successfully. Stage 2 prints the loading operating system message. The second shot displays an error message when it cannot find the file (within the root directory). This demo contains most of the code in this lesson, 2 source files, 2 directories, and 2 batch programs. The first directory contains the stage 1 program -- our bootloader, the second directory contains our stage 2 program - STAGE2.SYS. DEMO DOWNLOAD HERE"
  },
  "articles/61_unorganised_tutorial/T7.html": {
    "href": "articles/61_unorganised_tutorial/T7.html",
    "title": "Computer Systems Architecture | BrokenThorn OS Dev Tutorials",
    "keywords": "Computer Systems Architecture We are going to first look at the x86 architecture in detail. This will be important to us, especially in protected mode, and understanding how protected mode works. We are going to cover every single thing of how the computer works and operates down to the bit level. To understand how this fits in with the BIOS during bootup, you have to remember that you can \"start\" other processors. The BIOS does just this with the main processor, and we can do the same to support multi processor systems. We will cover: The 80x86 Registers System Organization The System Bus Real Mode Memory Map How an instruction executes Software Ports In some ways, this is like a system architecture tutorial. However, we are going to look at the architecture from an OS development point of view. Also, We will cover every single thing within the architecture. Understanding the basic concepts will make understanding Protected Mode in a lot more detail. In the next tutorial, we are going to use everything we learn here to switch into protected mode. let's have some fun, shall we...? The World of Protected Mode We all heard this term before, haven't we? Protected Mode (PMode) is an operation mode available from the 80286 and later processors. PMode was primarily designed to increase the stability of the systems. As you know from the previous tutorials, Real Mode has some big problems. For one, we can write a byte anywhere we want. This can overwrite code or data, that may be used by software ports, the processor, or even ourselves. And yet, we can do this in over 4,000 different ways--both directly and indirectly! Real Mode has no Memory Protection . All data and code are dumped into a single all purpose use memory block. In Real Mode, you are limited to 16 bit registers. Because of this, you are limited to 1 MB of memory. No support for hardware level Memory Protection or Multitasking . Quite possibly the biggest problem, was that there is no such thing as \"rings\". All programs execute at Ring 0 level, as every program has full control over the system. This means, in a single tasking environment, a single instruction (such as cli/hlt ) can crash the entire OS if you are not careful. a lot of this should sound familiar from when we covered Real Mode in depth. Protected Mode fixes all of these problems. Protected Mode: Has Memory Protection Has hardware support for Virtual Memory and Task State Switching (TSS) Hardware support for interrupting programs and executing another 4 Operating Modes: Ring 0, Ring 1, Ring 2, Ring 3 Access to 32 bit registers Access to up to 4 GB of memory We covered the Rings of Assembly Language in a previous tutorial. Remember that we are in Ring 0, while normal applications are in Ring 3 (Usually). We have access to special instructions and registers that normal applications do not. In this tutorial, we are going to be using the LGDT instruction, along with a far jump using our own defined segment, and the use of the processor control registers. None of this is available in normal programs. Understanding the system architecture and how the processor works will help us understand this a lot better. System Architecture The x86 family of computers follow the Van Neumann Architecture . The Van Neumann Architecture is a design specification that states a typical computer system has three main components: Central Processing Unit (CPU) Memory Input/output (IO) For example: There are a couple of important things to note. As you know, the CPU fetches data and instructions from memory. The Memory Controller is responsible for calculating the exact RAM chip and memory cell that it resides in. Because of this, The CPU communicates with the Memory Controller. Also, notice the \"I/O Devices\". They are connected to the system bus. All I/O Ports are mapped to a given memory location. This allows us to use the IN and OUT instructions. The hardware devices can access memory through the System Bus. It also allows us to notify a device when something is happening. For example, if we write a byte to a memory location for a hardware device controller to read, the processor can signal the device that there are data at that address. It does this through the Control Bus part of the entire System Bus . This is basically how software interacts with hardware devices. We will go into much more detail later as this is the only way to communicate to devices in protected mode, hence this is important. We will cover everything in detail first. Then, we will combine them and learn how they all work together, by watching an instruction get executed at the hardware level. From here, we will talk about I/O Ports, and how software interacts with hardware. As you have experience with x86 Assembly, Some or even a lot of this should be familiar. However, we are going to cover a lot of things most assembly books don't cover in detail. More specifically, things specific to Ring 0 programs. The System Bus The System Bus is also known as the Front Side Bus that connects the CPU to the Northbridge on a motherboard. The System Bus is a combination of the Data Bus , Address Bus , and Control Bus . Each electronic line on this bus represents a single bit . The voltage level used to represent a \"zero\" and \"one\" is based off Standard Transistor-Transistor Logic (TTL) Levels. We don't need to know this though. TTL is a part of Digital Logic Electronics , at which computers are built. As you know, the System Bus is made up of 3 buses. let's look at them in detail, shall we? Data Bus The data bus is the series of electronic lines that which data can be carried over. The size of the data bus is 16 lines/bits, 32 lines/bits, or 64 lines/bits. Note the direct relationship between an electronic line and a single bit. This means, A 32 bit processor has and uses a 32 bit data bus. This means, it can handle a 4 byte piece of data simultaneously. Knowing this, we can watch the data sizes in our programs, and help increase speed. How? The processor will need to pad 1,2,4,8, and 16 bit data to the size of the data bus with 0's. Larger pieces of data will need to be broken (and padded) so the processor can send the bytes correctly over the data bus. Sending a piece of data that is the size of the data bus will be faster because no extra processing is done. For example, let's say we have a 64 bit data type, but a 32 bit data bus. In the first Clock Cycle , only the first 32 bits are sent through the data bus to the Memory Controller. In the second Clock Cycle , the processor references the last 32 bits. Note: Notice that, the larger the data type, the more clock cycles it will take! Generally, the terms \"32 bit processor\", \"16 bit processor\", etc. generally refers to the size of the data bus. So, a \"32 bit processor\" uses a 32 bit data bus. Address Bus Whenever the processor or an I/O device needs to reference memory, it places its address on the Address Bus. Okay, we all know that a Memory Address represents a location in memory. This is an abstraction though. A \"Memory Address\" is just a number used by the Memory Controller. That's it. The Memory Controller takes the number from this bus, and interprets it as a memory location. Knowing the size of each RAM chip The Memory Controller could easily reference the exact RAM chip and byte offset in it. Beginning with Memory Cell 0 , the Memory Controller interprets this offset as the Address that we want . The Address Bus is connected to the processor through the Control Unit (CU) , and the I/O Controller . The Control Unit is inside the processor, so we will look at that later. The I/O Controller controls the interface to hardware devices. We will look at that later. Just like with the Data Bus, Each Electronic line represents a single bit. Because there are only two unique values in a bit, There is exactly 2^n unique address that a CPU can access. Therefore, The number of bits/lines in the Address Bus represents the maximum memory the CPU can access. In the 8080 through 80186 processor each had 20 line/bit address busses . The 80286 and 80386 has 24 lines/bits, and the 80386+ has 32 lines/bits. Remember that the entire x86 family is designed to be portable with all older processors. This is why it starts in Real Mode. Their processor architectures were limited to 1 MB because they only had access to 20 address lines -- line 0 through line 19. This is important to us, Because this limitation still applies to us! What we need to do is Enable access through the 20th address line. This will allow our OS to access more then 4 GB of memory. More on this later. Control Bus Okay, we could place data on the Data Bus, and reference memory addresses using the Address Bus. But, how do we know what to do with this data? Are we reading it from memory? Or we writing the data? The Control Bus is a series of lines/bits that represent what a device is trying to do. For example, the processor would set the READ bit or WRITE bit to let the Memory Controller know it wants to read or write the data in the Data Bus from the memory location stored in the Address Bus. The Control Bus also allows the processor to signal a device. This lets a device that we need its attention. For example, perhaps we need the device to read from the memory location from the Address Bus? This will let the device know of what we need. This is important in I/O Software ports. Of course, remember the system bus is not directly connected to hardware devices. Instead, it is connected to a central controller-- The I/O Controller , which, in turn, signals the devices. That's all there is to the system bus. It is the pathway for accessing and reading memory from the processor (Through its Control Unit (CU) ) and the I/O devices ( Through the I/O Controller ) to the Memory Controller , which is responsible for calculating the exact RAM chip and finding the memory cell we want to access. \"Controller\" ... You will hear me say this term a lot. I will explain why later. Memory Controller The Memory Controller is the primary interface between the System Bus (aka, Front Side Bus(FSB) ) on the motherboard to the physical RAM chips. We seen the term Controller before, haven't we? What exactly is a controller? Controllers A Controller provides basic hardware control functionality. It also provides the basic interface between hardware and software. This is important to us. Remember that in protected mode, we will not have any interrupts available to us . In the bootloader, we used several interrupts to communicate with the hardware. Using these interrupts in protected mode will cause a Triple Fault. Yikes--so what are we to do? We will need to communicate to the hardware directly. We do this through the controllers. (We will talk more about how controllers work later when we cover the I/O Subsystem). The Memory Controller The Memory Controller provides a way of reading and writing memory locations through software. The Memory Controller is also responsible for the constant refreshing of the RAM chips to insure they retain the information. Memory Controllers a Multiplexer and Demultiplexer circuits to select the exact RAM chip, and location that references the address in the Address Bus. Double Data Rate (DDR) Controller A DDR Controller is used to refresh DDR SDRAM, which uses the System Clock pulse to allow reading and writing memory. Dual Channel Controller A Dual Channel Controller are used where DRAM devices are separated into two small busses, allowing reading and writing two memory locations at once. This helps increasing speed when accessing RAM. Memory Controller Conclusion The Memory Controller takes the address we put into the Address Bus. This is good and all, but how do we tell the Memory Controller to read or write memory? And where does it get its data from? When reading memory, The processor sets the Read bit in the Control Bus . similarly, The processor sets the Write bit when writing memory on the Control Bus . Remember that the Control Bus allows the processor to control how other devices use the bus. The data the Memory Controller uses is inside the Data Bus. The Address to use is in the Address Bus. Reading Memory When reading memory, The Processor places the absolute address to read from on the Address Bus. The processor then sets the READ control line. The Memory Controller now has control. The controller converts the absolute address into a physical RAM location using its Multiplexer circuit, and places the data into the Data Bus. It then resets the READ bit to 0, and sets the READY bit. The processor now knows the data is now in the data bus. It copies this data, and executes the rest of the instruction...perhaps store it in BX? Writing Memory The process of writing memory is similar. First, the processor places the memory address into the Address Bus. It then places the data to write into the Data Bus. Then, it sets the WRITE bit in the Control Bus. This lets the Memory Controller know to write the data in the Data Bus to the Absolute address in the Address Bus. When done, the Memory Controller resets the WRITE bit, and sets the READY bit on the Control Bus. Memory Read-Write Conclusion We do not communicate directly with the Memory Controller through software, but instead, we communicate indirectly with it. Whenever we read or write memory, we are using the Memory Controller. This is the interface between our software and the Memory Controller / RAM Chip Hardware. Yippee--let's take a look at the I/O Subsystem now, shall we? Oh wait! What about that 1337 Multiplexer circuit? That is a physical electronic circuit in the Memory Controller. To understand how it works, one has to know Digital Logic Electronics . Because this is irrelevant to us, we are not going to cover it here. If you would like to know more, Google! I/O Subsystem The I/O Subsystem simply represents Port I/O . This is the basic system that provides the interface between software and hardware controllers. let's look closer... Ports A Port simply provides an interface between two devices. There are two types of ports: Hardware Ports and Software Ports . Hardware Ports A Hardware Port provides the interface between two physical devices. This port is usually a connection device of sorts. This includes, but is not limited to: Serial Ports, Parallel ports, PS/2 Ports, 1394, FireWire, USB Ports, etc. These ports are usually on the sides/back/or front of a typical computer system. Okay... um, if you want to see a port, just follow any line that connects to your computer. Please, for the sake of Jeeves, Don't ask me what these do--you have got to already now! Seriously! In typical electronics, the pins in these ports carry signals that represent different things depending on the hardware device. These pins represent, just like the system bus--wait for it... Bits! Each pin represents a single bit. Yep--that's it. Two general classifications for Hardware Ports include \"Male\" and \"Female\" ports. Male ports are connections where the pins emerge from the connector. Female ports are the opposite of this. Hardware ports are accessed through Controllers. More on this later... Software Ports THIS will be very important to us. This is our interface to the hardware. A Software Port is a number. That's it. This number represents a hardware controller... Kind of. You may know that several port numbers could represent the same controller. The reason? Memory Mapped I/O . The basic idea is that we communicate to hardware by specifying certain memory addresses. The port number represents this address. ... Once more, kind of. The meaning of the addresses could represent a specific register in a device, or a control register. We will look more closer later. Memory Mapping On the x86 Architecture, the processor uses specific memory locations to represent certain things. For example, The address 0xA000:0 represents the start of VRAM in the video card. By writing bytes to this location, you effectively change what is currently in video memory, and effectively, what is displayed on screen. Other memory addresses can represent something else--let's say, a register perhaps for the Floppy Drive Controller (FDC)? Understanding what addresses are what is critical, and very important to us. x86 Real Mode Memory Map General x86 Real Mode Memory Map: |Memory Locations|Used for| |---|---| |0x00000000 - 0x000003FF| Real Mode Interrupt Vector Table| |0x00000400 - 0x000004FF| BIOS Data Area| |0x00000500 - 0x00007BFF| Unused| |0x00007C00 - 0x00007DFF| Our Bootloader| |0x00007E00 - 0x0009FFFF| Unused| |0x000A0000 - 0x000BFFFF| Video RAM (VRAM) Memory| |0x000B0000 - 0x000B7777| Monochrome Video Memory| |0x000B8000 - 0x000BFFFF| Color Video Memory| |0x000C0000 - 0x000C7FFF| Video ROM BIOS| |0x000C8000 - 0x000EFFFF| BIOS Shadow Area| |0x000F0000 - 0x000FFFFF| System BIOS| Note: It is possible to remap all of the above devices to use different regions of memory. This is what the BIOS POST does to map the devices to the table above. Okay, this is cool and all. Because these addresses represent different things, by reading (or writing) to specific addresses, we get obtain (or change) information with ease from different parts of the computer. For example, remember when we talked about INT 0x19 ? We referenced that writing the value 0x1234 at 0x0040:0x0072, and jumping to 0xFFFF:0, we effectively warm reboot the computer. (similar to Windows ctrl+alt+del.) Remembering the conversion between segment:offset addressing mode and absolute addressing, we can convert 0x0040:0x0072 to the absolute address 0x000000472 , a byte within the BIOS data area. Another example is text output. But writing two bytes into 0x000B8000 , we can effectively change what is in text mode memory. Because this is constantly refreshed when displayed, it effectively displays the character on screen. Cool? let's go back to port mapping, shall we? We will look back at this table a lot more later. Port Mapping - Memory Mapped I/O A \"Port Address\" is a special number that each Controller listens to. When booting, the ROM BIOS assigns different numbers to these controller devices. It starts the primary processor, loads the BIOS program at 0xFFFF:0 ( Remember this? Compare this with the table in the previous section ). The ROM BIOS Assigns these numbers to different controllers, so controllers have a way to identify themselves. This allows the BIOS to set up the Interrupt Vector Table, which communicates to the hardware using this special number. The processor uses the same system bus when working with I/O Controllers. The processor puts the special port number into the Address Bus , as if it was reading memory. It also sets the READ or WRITE lines on the control bus as well. This is cool, but there's a problem: How does the processor differentiate between writing memory and accessing a controller? The processor sets another line on the control bus--An I/O ACCESS line. If this line is set, The I/O Controllers from within the I/O Subsystem watches the Address Bus. If the Address Bus corresponds to a number that is assigned to the device, that device takes the value from the data bus and acts upon it. The Memory Controller ignores any request if this line is set. So, if the port number has not been assigned, absolutely nothing happens. No controller acts on it, and the Memory Controller ignores it. let's take a look at these port addresses. This is very important! This is the only way of communicating with hardware in protected mode! : Default x86 Port Address Assignments Default x86 Port Address Assignments Address Range First QWORD Second QWORD Third QWORD Fourth QWORD 0x000-0x00F DMA Controller Channels 0-3 0x010-0x01F System Use 0x020-0x02F Interrupt Controller 1 System Use 0x030-0x03F System Use 0x040-0x04F System Timers System Use 0x050-0x05F System Use 0x060-0x06F Keyboard/PS2 Mode (Port 0x60) Speaker (0x61) Keyboard/PS2 Mouse (0x64) System Use 0x070-0x07F RTC/CMOS/NMI (0x70, 0x71) DMA Controller Channels 0-3 0x080-0x08F DMA Page Register 0-2 (0x81 - 0x83) DMA Page Register 3 (0x87) DMA Page Register 4-6 (0x89-0x8B) DMA Page Register 7 (0x8F) 0x090-0x09F System Use 0x0A0-0x0AF Interrupt Controller 2 (0xA0-0xA1) System Use 0x0B0-0x0BF System Use 0x0C0-0x0CF DMA Controller Channels 4-7 (0x0C0-0x0DF), bytes 1-16 0x0D0-0x0DF DMA Controller Channels 4-7 (0x0C0-0x0DF), bytes 16-32 0x0E0-0x0EF System Use 0x0F0-0x0FF Floating Point Unit (FPU/NPU/Mah Copprocessor) 0x100-0x10F System Use 0x110-0x11F System Use 0x120-0x12F System Use 0x130-0x13F SCSI Host Adapter (0x130-0x14F), bytes 1-16 0x140-0x14F SCSI Host Adapter (0x130-0x14F), bytes 17-32 SCSI Host Adapter (0x140-0x15F), bytes 1-16 0x150-0x15F SCSI Host Adapter (0x140-0x15F), bytes 17-32 0x160-0x16F System Use Quaternary IDE Controller, master slave 0x170-0x17F Secondary IDE Controller, Master drive System Use 0x180-0x18F System Use 0x190-0x19F System Use 0x1A0-0x1AF System Use 0x1B0-0x1BF System Use 0x1C0-0x1CF System Use 0x1D0-0x1DF System Use 0x1E0-0x1EF System Use Tertiary IDE Controller, master slave 0x1F0-0x1FF Primary IDE Controller, master slave System Use 0x200-0x20F Joystick Port System Use 0x210-0x21F System Use 0x220-0x22F Sound Card Non-NE2000 Network Card System Use 0x230-0x23F SCSI Host Adapter (0x220-0x23F), bytes 17-32) 0x240-0x24F Sound Card Non-NE2000 Network Card System Use NE2000 Network Card (0x240-0x25F) Bytes 1-16 0x250-0x25F NE2000 Network Card (0x240-0x25F) Bytes 17-32 0x260-0x26F Sound Card Non-NE2000 Network Card System Use NE2000 Network Card (0x240-0x27F) Bytes 1-16 0x270-0x27F System Use Plug and Play System Devices LPT2 - Second Parallel Port System Use LPT3 - Third Parallel Port (Monochrome Systems) NE2000 Network Card (0x260-0x27F) Bytes 17-32 0x280-0x28F Sound Card Non NE2000 Network Card System Use NE2000 Network Card (0x280-0x29F) Bytes 1-16 0x290-0x29F NE2000 Network Card (0x280-0x29F) Bytes 17-32 0x2A0-0x2AF Non NE2000 Network Card System Use NE2000 Network Card (0x280-0x29F) Bytes 1-16 0x2B0-0x2BF NE2000 Network Card (0x280-0x29F) Bytes 17-32 0x2C0-0x2CF System Use 0x2D0-0x2DF System Use 0x2E0-0x2EF System Use COM4 - Fourth Serial Port 0x2F0-0x2FF System Use COM2 - Second Serial Port 0x300-0x30F Sound Card / MIDI Port System Use Non NE2000 Network Card System Use NE2000 Network Card (0x300-0x31F) Bytes 1-16 0x310-0x31F NE2000 Network Card (0x300-0x32F) Bytes 17-32 0x320-0x32F Sound Card / MIDI Port (0x330, 0x331) System Use NE2000 Network Card (0x300-0x31F) Bytes 17-32 SCSI Host Adapter (0x330-0x34F) Bytes 1-16 0x330-0x33F Sound Card / MIDI Port System Use Non NE2000 Network Card System Use NE2000 Network Card (0x300-0x31F) Bytes 1-16 0x340-0x34F SCSI Host Adapter (0x330-0x34F) Bytes 17-32 SCSI Host Adapter (0x340-0x35F) Bytes 1-16 Non NE2000 Network Card System Use NE2000 Network Card (0x340-0x35F) Bytes 1-16 0x350-0x35F SCSI Host Adapter (0x340-0x35F) Bytes 17-32 NE2000 Network Card (0x300-0x31F) Bytes 1-16 0x360-0x36F Tape Accelerator Card (0x360) System Use Quaternary IDE Controller (Slave Drive)(0x36E-0x36F) Non NE2000 Network Card System Use NE2000 Network Card (0x300-0x31F) Bytes 1-16 0x370-0x37F Tape Accelerator Card (0x370) Secondary IDE Controller (Slave Drive) LPT1 - First Parallel Port (Color systems) System Use LPT2 - Second Parallel Port (Monochrome Systems) NE2000 Network Card (0x360-0x37F) Bytes 1-16 0x380-0x38F System Use Sound Card (FM Synthesizer) System Use 0x390-0x39F System Use 0x3A0-0x3AF System Use 0x3B0-0x3BF VGA/Monochrome Video LPT1 - First Parallel Port (Monochrome Systems) 0x3C0-0x3CF VGA/CGA Video 0x3D0-0x3DF VGA/CGA Video 0x3E0-0x3EF Tape Accelerator Card (0x370) System Use COM3 - Third Serial Port System Use Tertiary IDE Controller (Slave Drive)(0x3EE-0x3EF) 0x3F0-0x3FF Floppy Disk Controller COM1 - First Serial Port Tape Accelerator Card (0x3F0) Primary IDE Controller (Slave Drive)(0x3F6-0x3F7) System Use This table is not complete, and hopefully has no errors in it. I will add to this table as time goes on, and more devices are developed. All of these memory ranges are used by certain controllers--as the above table displays. The exact meaning of a port address depends on the controller. It could represent a control register, state register virtually anything. This is unfortunate. I highly recommend to print out a copy of the above table. We will need to reference it every time we are communicating with hardware. I will update (at the beginning of the tutorial), if I have updated the table. That way, you can print out the table again, insuring everyone has the latest copy. With all of this in mind, let's put it all together... IN and OUT Instructions The x86 processor has two instructions used for port I/O. They are IN and OUT . These instructions tell the processor that we want to communicate to a device. This insures the processor sets the I/O DEVICE line on the control bus. let's have a complete example, and try to see if we can read from the keyboard controllers input buffer. let's see... Looking at our trusty Port table above, we can see the Keyboard Controller is in port addresses 0x60 through 0x6F . The table displays that the first QWORD and second QWORD (Starting from port address 0x60) is for the keyboard and PS/2 Mouse. The last two QWORDS are for system use, so we will ignore it. Okay, so our keyboard controller is mapped to ports 0x60 through, technically, port 0x68. This is cool, but what does it mean to us? This is device specific, remember? For our keyboard, Port 0x60 is a control register, Port 0x64 is a status register. Remember from before--I said we would here these terms a lot more, and in different contexts. If bit 1 in the status register is set, data is inside the input buffer. So, lessee... If we set the CONTROL register to READ, we can copy the contents of the input buffer somewhere... WaitLoop: in al, 64h ; Get status register value and al, 10b ; Test bit 1 of status register jz WaitLoop ; If status register bit not set, no data in buffer in al, 60h ; Its set--Get the byte from the buffer (Port 0x60), ; and store it This, right here, is the bases of hardware programming and device drivers. In an IN instruction, the processor places the port address--like 0x64--into the Address Bus, and sets the I/O DEVICE line in the control bus, followed by the READ line. The device that has been assigned to 0x60 by the ROM BIOS-- In this case, the Status Register in the keyboard Controller, knows its a read operation because the READ line is set. So, it copies data from some location inside the keyboard registers onto the Data Bus, resets the READ and I/O DEVICE lines on the control bus, and sets the READY line. Now, the processor has the data from the Data Bus that was read. An OUT instruction is similar. The processor copies the byte to be written into the Data Bus (Zero extending it to the Data Bus Width). Then, it sets the WRITE and I/O DEVICE lines on the control bus. It then copies the port address--let's say--0x60, into the Address Bus. Because the I/O DEVICE Line is set, it is a signal that tells all controllers to watch the address bus. If the number on the address bus corresponds with there assigned number, the device acts on that data. In our case--The Keyboard Controller. The Keyboard controller knows its a WRITE operation because the WRITE line is set in the control bus. So, it copies the value on the data bus into its Control Register--which was assigned port address 0x60. The Keyboard Controller the resets the WRITE and I/O DEVICE line, sets the READY line on the control bus, and the processor is back in control. Port mapping and Port I/O are very important. It is our only way of communicating with hardware in protected mode. Remember: Interrupts are not available until we write them. To write them, along with any hardware routine--such as input and output, requires us to write drivers. All of this requires direct hardware access. If you don't feel comfortable with this, practice a little first, and reread this section. If you have any questions, let me know. The Processor Special Instructions Most 80x86 instructions can be executed by any program. However, there are some instructions that only Kernel-level software can access. Because of this, some of these instructions may not be familiar to our readers. We will require the use of most of these instructions, so understanding them is important. Privileged Level (Ring 0) Instructions Instruction Description LGDT Loads an address of a GDT into GDTR LLDT Loads an address of a LDT into LDTR LTR Loads a Task Register into TR MOV Control Register Copy data and store in Control Registers LMSW Load a new Machine Status WORD CLTS Clear Task Switch Flag in Control Register CR0 MOV Debug Register Copy data and store in debug registers INVD Invalidate Cache without writeback INVLPG Invalidate TLB Entry WBINVD Invalidate Cache with writeback HLT Halt Processor RDMSR Read Model Specific Registers (MSR) WRMSR Write Model Specific Registers (MSR) RDPMC Read Performance Monitoring Counter RDTSC Read time Stamp Counter Executing any of the above instructions by any other program that does not have Kernel mode access (Ring 0) will generate a General Protection Fault , or a Triple Fault . Do not worry if you do not understand these instructions. I will cover each of them throughout the series as we need them. 80x86 Registers The x86 processor has a lot of different registers for storing its current state. Most applications only have access to the general, segment, and eflags . Other registers are specific to Ring 0 programs, such as our Kernel. The x86 family has the following registers: RAX (EAX(AX/AH/AL)), RBX (EBX(BX/BH/BL)), RCX (ECX(CX/CH/CL)), RDX (EDX(DX/DH/DL)), CS,SS,ES,DS,FS,GS, RSI (ESI (SI)), RDI (EDI (DI)), RBP (EBP (BP)). RSP (ESP (SP)), RIP (EIP (IP)), RFLAGS (EFLAGS (FLAGS)), DR0, DR1, DR2, DR3, DR4, DR5, DR6, DR7, TR1, TR2, TR3, TR4, TR5, TR6, TR7, CR0, CR1, CR2, CR3, CR4, CR8, ST, mm0, mm1, mm2, mm3, mm4, mm5, mm6, mm7, xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, GDTR, LDTR, IDTR, MSR, and TR . All of these registers are stored in a special area of memory inside the processor called a Register File . Please see the Processor Architecture section for more information. Other registers include, but may not be in the Register File , include: PC, IR, vector registers, and Hardware Registers. a lot of these registers are only available to real mode ring 0 programs. And for very good reasons, too. Most of these registers effect a lot of states within the processor. Incorrectly setting them can easily triple fault the CPU. Other cases, might cause the CPU to malfunction. (Most notably, the use of TR4,TR5,TR6,TR7) Some of the other registers are internal to the CPU , and cannot be accessed through normal means. One would need to reprogram the processor itself in order to access them. Most notably, IR, the vector registers. We will need to know some of these special registers, so let's take a look closer, shall we? Note: Think of the CPU as any normal device that we need to communicate with. The concept of Control Registers (and registers themselves) will be important later on when we talk to other devices. Also, please note that some registers are undocumented. Because of this, there may be more registers then those listed. If you know of any, please Let me know , so that I can add them. ðŸ˜ General Purpose Registers These are 32 bit registers that can be used for almost any purpose. Each of these registers have a special purpose as well, however. EAX - Accumulator Register. Primary purpose: Math calculations EBX - Base Address Register. Primary purpose: Indirectly access memory through a base address. ECX - Counter Register. Primary purpose: Use in counting and looping. EDX - Data Register. Primary purpose: um... store data. Yep, that's about it ðŸ˜ Each of these 32 bit registers has two parts. The High order word and low order word . The high order word is the upper 16 bits. The low order word is the lower 16 bits. On 64 bit processors, these registers are 64 bits wide, and or named RAX, RBX, RCX, RDX . The lower 32 bits is the 32 bit EAX register. The upper 16 bits does not have a special name associated with them. However, The lower 16 bits do. These names have an appended 'H' (for higher 8 bits in low word), or an appended 'L' for lower 8 bits. For example, in RAX, we have: +--- AH ----+--- AL ---+ | | | +-------------------------------------------------------------+ | | | | +-------------------------------------------------------------+ | | | | +--------EAX lower 32 bits------------------| -- Available only on 32 bit processors. | | |------------------ RAX Complete 64 bits----------------------| -- Available only on 64 bit processors. What does this mean? AH and AL are a part of AX, which, in turn, is a part of EAX. Thus, modifying any of these names effectively modifies the same register - EAX. This, in turns, modifies RAX, on 64 bit machines. The above is also true with BX, CX, and DX. General purpose registers can be used within any program, from Ring 0 to Ring 4. Because they are basic assembly language, I will assume you already know how they work. Segment Registers The segment registers modify the current segment addresses in real mode. They are all 16 bit. CS - Segment address of code segment DS - Segment address of data segment ES - Segment address of extra segment SS - Segment address of stack segment FS - Far Segment address GS - General Purpose Register Remember: Real Mode uses the segment:offset memory addressing model. The segment address is stored within a segment register. Another register, such as BP, SP, or BX can store the offset address. It is usually referenced like: DS:SI , where DS contains the segment address, and SI contains the offset address. Segment registers can be used within any program, from Ring 0 to Ring 4. Because they are basic assembly language, I will assume you already know how they work. Index Registers The x86 uses several registers that help when access memory. SI - Source Index DI - Destination Index BP - Base Pointer SP - Stack Pointer Each of these registers store a 16 bit base address (that may be used as an offset address as well.) On 32 bit processors, these registers are 32 bits and have the names ESI, EDI, EBP, and ESP . On 64 bit processors, each register is 64 bits in size, and have the names RSI, RDI, RBP, and RSP . The 16 bit registers are a subset of the 32 bit registers, which is a subset of the 64 bit registers; the same way with RAX. The Stack Pointer is automatically incremented and decremented a certain amount of bytes whenever certain instructions are encountered. Such instructions include push , pop instructions, ret/iret, call, syscall** etc. The C Programming Language, in fact most languages, use the stack regularly. We will need to insure we set the stack up at a good address to insure C works properly. Also, remember: The stack grows downward ! Instruction Pointer / Program Counter The Instruction Pointer (IP) register stores the current offset address of the currently executing instruction. Remember: This is an offset address, Not an absolute address! The Instruction Pointer (IP) is sometimes also called the Program Counter (PC). On 32 bit machines, IP is 32 bits in size and uses the name EIP . On 64 bit machines, IP is 64 bits in size, and uses the name RIP . Instruction Register This is an internal processor register that cannot be accessed through normal means. It is stored within the Control Unit (CU) of the processor inside the Instruction Cache . It stores the current instruction that is being translated to Microinstructions for use internally by the processor. Please see Processor Architecture for more information. EFlags Register The EFLAGS register is the x86 Processor Status Register. It is used to determine the um.. current status. We have actually used this a lot already so far. A simple example: jc, jnc, jb, jnb Instruction Most instructions manipulate the EFLAGS register so that you can test for conditions (Like if the value was lower or higher then another). EFLAGS is composed of the FLAGS register. similarity, RFLAGS is composed of EFLAGS and FLAGS . i.e.: +---------- EFLAGS (32 Bits) ------+ | | +-FLAGS(16 bits)-+ | | | | ==================================================================== < Register Bits | | +------------------------- RFLAGS (64 Bits) -----------------------+ | | Bit 0 Bit 63 FLAGS Register Status Bits table Bit Number Abbrivation Description 0 CF Carry Flag - Status bit 1 Reserved PF CF Parity Flag 3 Reserved 4 AF Adjust Flag - Status bit 5 Reserved 6 ZF Zero Flag - Status bit 7 SF Sign Flag - Status bit 8 TF Trap Flag (Single Step) - System Flag 9 IF Interrupt Enabled Flag - System Flag 10 DF Direction Flag - Control Flag 11 OF Overflow Flag - Status bit Dec-13 IOPL I/O Priviledge Level (286+ Only) - Control Flag 14 NT Nested Task Flag (286+ Only) - Control Flag 15 Reserved EFLAGS Register Status Bits table Bit Number Abbrivation Description 16 RF Resume Flag (386+ Only) - Control Flag 17 VM v8086 Mode Flag (386+ Only) - Control Flag 18 AC Alignment Check (486SX+ Only) - Control Flag 19 VIF Virtual Interrupt Flag (Pentium+ Only) - Control Flag 20 VIP Virtual Interrupt Pending (Pentium+ Only) - Control Flag 21 ID Identification (Pentium+ Only) - Control Flag 22-31 Reserved RFLAGS Register Status Bits table Bit Number Abbrivation Description 32-63 Reserved The IO Privilege Level (IOPL) controls the current ring level required to use certain instructions. For example, the CLI, STI, IN and OUT instructions will only execute if the current Privilege Level is equal, or greater, then the IOPL. If not, a General Protection Fault (GPF) will be generated by the processor. Most operating systems set the IOPF to 0 or 1. This means that only Kernel level software can use these instructions. This is a very good thing. After all, if an application issues a CLI, it can effectively stop the Kernel from running. For most operations, we only need to use the FLAGS register. Notice that the last 32 bits of the RFLAGS register is null, null, non existent, there for viewing pleasure. So, um... yeah. For speed purposes, of course, but a lot of bytes being wasted... ...yeah. Because of the size of this table, I recommend printing it out for reference later. Test Registers The x86 family uses some registers for testing purposes. Many of these registers are undocumented. On the x86 series, these registers are TR4,TR5,TR6,TR7 . TR6 is the most commonly used for command testing, and TR7 for a test data register. One can use the MOV instruction to access them. There are only available in Ring 0 for both PMode and real mode. Any other attempt will cause a General Protection Fault (GPF) leading to a Triple Fault. Debug Registers These registers are used for program debugging. They are DR0,DR1,DR2,DR3,DR4,DR5,DR6,DR7 . Just like the test registers, they can be accessed using the MOV instruction, and only in Ring 0. Any other attempt will cause a General Protection Fault (GPF) leading to a Triple Fault. Breakpoint Registers The registers DR0, DR1, DR2, DR3 store an Absolute Address of a breakpoint condition. If Paging is enabled, the address will be converted to its Absolute address. These breakpoint conditions are further defined in DR7. Debug Control Register DR7 is a 32 bit register that uses a bit pattern to identify the current debugging task. Here it is: Bit 0...7 - Enable the four debug registers (See below) Bit 8...14 - ? Bit 15...23 - When the breakpoints will trigger. Each 2 bits represents a single Debug Register. This can be one of the following: 00 - Break on execution 01 - Break on data write 10 - Break on IO read or write. No hardware currently supports this. 11 - Break on data read or write Bit 24...31 - Defines how large of memory to watch. Each 2 bits represents a single Debug Register. This can be one of the following: 00 - One bytes 01 - Two bytes 10 - Eight bytes 11 - Four bytes The Debug Registers uses two methods to enable. This is Local and Global levels. If you are using different Tasks such as in Paging , all Local debug changes only effect that task. The processor automatically clears all local changes when switching between tasks. Global tasks, however, are not. In Bits 0...7 in the above list: Bit 0: Enable local DR0 register Bit 1: Enable global DR0 register Bit 2: Enable local DR1 register Bit 3: Enable global DR1 register Bit 4: Enable local DR2 register Bit 5: Enable global DR2 register Bit 6: Enable local DR3 register Bit 7: Enable global DR3 register Debug Status Register This is used by debuggers to determine what happened when the error occured. When the processor runs into an enabled exception error, it sets the low 4 bits of this register and executes the Exception Handler. Warning: The debug status register, DR6, is never cleared. If you have the program continue, insure you clear this register! Model Specific Register This is a special control register that provides special processor specific features that may not be on others. As these are system level, Only Ring 0 programs can access this register. Because these registers are specific to each processor, the actual register may change. The x86 has two special instructions that are used to access this register: RDMSR - Read from MSR WRMSR - Write from MSR The registers are very processor specific. Because of this, it is wise to use the CPUID instruction before using them. To access a given register, one must pass the instructions an Address which represents the register you want access to. Through the years, Intel has used some MSRs that are not machine specific. These MSRs are common within the x86 architecture. Model Specific Registers (MSRs) table Register Address Register Name IA-32 Processor Family 0x0 IA32_PS_MC_ADDR Pentium Processors 0x1 IA32_PS_MC_TYPE Pentium 4 Processors 0x6 IA32_PS_MONITOR_FILTER_SIZE Pentium Processors 0x10 IA32_TIME_STAMP_COUNTER Pentium Processors 0x17 IA32_PLATFORM_ID P6 Processors 0x1B IA32_APIC_BASE P6 Processors 0x3A IA32_FEATURE_CONTROL Pentium 4 / Processor 673 0x79 IA32_BIOS_UPDT_TRIG P6 Processors 0x8B IA32_BIOS_SIGN_ID P6 Processors 0x9B IA32_SMM_MONITOR_CTL Pentium 4 / Processor 672 0xC1 IA32_PMC0 Intel Core Duo 0xC2 IA32_PMC1 Intel Core Duo 0xE7 IA32_MPERF Intel Core Duo 0xE8 IA32_APERF Intel Core Duo 0xFE IA32_MTRRCAP P6 Processors 0x174 IA32_SYSENTER_CS P6 Processors 0x175 IA32_SYSENTER_ESP P6 Processors 0x176 IA32_SYSENTER_IP P6 Processors There are a lot more MSR's then those that are listed. Please see Appendix B from the Intel Development Manuals for the complete list. I'm not sure what MSRs we will be referencing as the Series is still in development. I will add onto this list as needed. RDMSR Instruction This instruction loads the MSR specified by CX into EDX:EAX. This instruction is a privileged instruction, and can only be executed at Ring 0 (Kernel Level). A General Protection Fault, or Triple Fault will occur if a nonprivileged application attempts to execute this instruction, or the value in CS does not represent a valid MSR Address. This instruction does not effect any flags. Here is an example of using this instruction (You will see this again later in the tutorials): ; This reads from the IA32_SYSENTER_CS MSR mov cx, 0x174 ; Register 0x174: IA32_SYSENTER_CS rdmsr ; Read in the MSR ; Now EDX:EAX contains the lower and upper 32 bits of the 64 bit register Cool, huh? WRMSR Instruction This instruction writes to the MSR specified by CX the 64 bit value stored in EDX:EAX. This instruction is a privileged instruction, and can only be executed at Ring 0 (Kernel Level). A General Protection Fault, or Triple Fault will occur if a nonprivileged application attempts to execute this instruction, or the value in CS does not represent a valid MSR Address. This instruction does not effect any flags. Here is an example of how it is used: ; This writes to the IA32_SYSENTER_CS MSR mov cx, 0x174 ; Register 0x174: IA32_SYSENTER_CS wrmsr ; Write EDX:EAX into the MSR Control Registers THIS is going to be important to us. The control registers allow us to change the behavior of the processor. They are: CR0, CR1, CR2, CR3, CR4 . CR0 Control Register CR0 is the primary control register. It is 32 bits, which are defined as follows: Bit 0 (PE) : Puts the system into protected mode Bit 1 (MP) : Monitor Coprocessor Flag This controls the operation of the WAIT instruction. Bit 2 (EM) : Emulate Flag . When set, coprocessor instructions will generate an exception Bit 3 (TS) : Task Switched Flag This will be set when the processor switches to another task . Bit 4 (ET) : Extension Type Flag. This tells us what type of coprocessor is installed. 0 - 80287 is installed 1 - 80387 is installed. Bit 5 (NE): Numeric Error 0 - Enable standard error reporting 1 - Enable internal x87 FPU error reporting Bits 6-15 : Unused Bit 16 (WP): Write Protect Bit 17: Unused Bit 18 (AM): Alignment Mask 0 - Alignment Check Disable 1 - Alignment Check Enabled (Also requires AC flag set in EFLAGS and ring 3) Bits 19-28: Unused Bit 29 (NW): Not Write-Through Bit 30 (CD): Cache Disable Bit 31 (PG) : Enables Memory Paging. 0 - Disable 1 - Enabled and use CR3 register Wow... a lot of new stuff, huh? let's look at Bit 0-- Puts system in protected mode. This means, By setting Bit 0 in the CR0 register, we effectively enter protected mode. For example: mov ax, cr0 ; get value in CR0 or ax, 1 ; set bit 0--enter protected mode mov cr0, ax ; Bit 0 now set, we are in 32 bit mode! Wow! Its that easy!! Not quite ðŸ˜ If you dump this code into our bootloader, its almost guaranteed to Triple Fault. Protected mode uses a different memory addressing system then real mode. Also, Remember that PMode has no interrupts . A single timer interrupt will triple fault. Also, because we use a different addressing model, CS is invalid . We would need to update CS to go into 32 bit code. And yet, We didn't set privilege levels for the memory map. We will go more into detail later. CR1 Control Register : Reserved by Intel, do not use. CR2 Control Register : Page Fault Linear Address. If a Page Fault Exception occurs, CR2 contains the address that was attempted accessed CR3 Control Register : Used when the PG bit in CR0 is set. Last 20 bits Contains the Page Directory Base Register (PDBR) CR4 Control Register : Used in protected mode to control operations, such as v8086 mode, enabling I/O breakpoints, Page size extension and machine check exceptions. I don't know if we will use any of these flags or not. I decided to include it here for completeness sake. Don't worry to much if you don't understand what these are. Bit 0 (VME) : Enables Virtual 8086 Mode Extensions Bit 1 (PVI) : Enables Protected Mode Virtual Interrupts Bit 2 (TSD) : Time Stamp Enable 0 - RDTSC instruction can be used in any privilege level 1 - RDTSC instruction can only be used in ring 0 Bit 3 (DE) : Enable Debugging Extensions Bit 4 (PSE) : Page Size Extension 0 - Page size is 4KB 1 - Page size is 4MB. With PAE, it is 2MB. Bit 5 (PAE) : Physical Address Extension Bits 6 (MCE) : Machine Check Exception Bits 7 (PGE) : Page Global Enable Bits 8 (PCE) : Performance Monitoring Counter Enable 0 - RDPMC instruction can be used in any privilege level 1 - RDPMC instruction can only be used in ring 0 Bits 9 (OSFXSR) : OS Support for FXSAVE and FXSTOR instructions (SSE) Bits 10 (OSXMMEXCPT) : OS Support for unmasked SIMD FPU exceptions Bits 11-12 : Unused Bits 13 (VMXE) : VMX Enable CR8 Control Register Provides Read and Write access to the Task Priority Register (TPR) PMode Segmentation Registers The x86 family uses several registers to store the current linear address of each Segment Descriptor . More on this later. These registers are: GDTR - Global Descriptor Table Register IDTR - Interrupt Descriptor Table Register GDTR - Local Descriptor Table Register TR - Task Register We will take a look closer at these registers in the next section. Processor Architecture Throughout this series, you will notice a lot of similarities between the processor and microcontrollers. That is, Microcontrollers have registers, and execute instructions similar to the processor. The CPU itself is nothing more then a specialized controller chip . We will look at the boot process again a little later, but from a very low level perspective. This will answer a lot of questions regarding how the BIOS POST actually starts, and how it executes the POST, starts the primary processor, and load the BIOS. We have covered the what , but we have not covered the how yet. Note: This section is fairly technical. If you do not understand everything, do not worry, as we do not need to understand everything. I am including this section for completeness sake; to dive into the main component required in any computer system, and the one that is responsible for executing our code. How does it execute our given code? What is so special about machine language? All of this will be answered here. Later on when we dive into the Kernel and Device Driver development, you will learn that understanding the basic hardware controller components themselves can not only be a great learning experience, but sometimes a necessity in understanding how to program that controller. Breaking apart a processor We will be looking at the Pentium III processor here for explanation purposes. let's open up and disect this processor into it's individual components first: a lot of things in the processor, huh? Notice how complex this is. We are not going to learn much from this picture alone, so let's look at each component. L2: Level 2 Cache CLK: Clock PIC: Programmable Interrupt Controller EBL: Front Bus Logic BBL: Back Bus Logic IEU: Integer Execution Unit FEU: Floating Point Execution Unit MOB: Memory Order Buffer MIU / MMU: Memory Interface Unit / Memory Management Unit DCU: Data Cache Unit IFU: Instruction Fetch Unit ID: Instruction Decoder ROB: Re-Order Buffer MS: Microinstruction Sequencer BTB: Branch Target Buffer BAC: Branch Allocator Buffer RAT: Register Alias Table SIMD: Packed floating point DTLB: Data TLB RS: Reservation Station PMH: Page Miss Handler PFU: Pre-Fetch Unit TAP: Test Access Port I plan on adding to this section. How instructions execute Okay, Remember that the IP Register contains the offset address of the currently executing instruction. CS contains the segment address. Okay, so what exactly happens when the processor needs to execute an instruction? It first calculates the absolute address that it needs to read from. Remember that in the segment:offset model, the absolute address = segment * 16 + offset . Or, essentially, absolute address = CS * 16 + IP . The processor copies this address into the Address Bus. Remember that the address bytes is just a series of electronic lines, each representing a single bit. This bit pattern represents the binary form of the absolute address of the next instruction. After this, the processor enables the \"Read Memory\" line (By setting its bit to 1). This tells the Memory Controller that we need to read from memory. The Memory Controller takes control. The Memory Controller copies the address from the Address Bus, and calculates its exact location in a particular RAM chip. The Memory Controller references this location, and copies it into the Data Bus. It does this because the \"Read Memory\" line is set on the Control Bus. The Memory Controller resets the Control Bus, so the processor knows its done executing. The processor takes the value(s) within the Data Bus, and uses its Digital Logic gates to \"execute\" it. This \"value\" is just a binary representation of a machine instruction, encoded as a series of electronic pulses. let's say, the instruction is mov ax, 0x4c00 The value 0xB8004C will be on the data bus for the processor. 0xB8004C is what is known as an operation code (OPCode) . Every instruction has an opcode associated with it. For the i86 architecture, our instruction would evaluate to the opcode 0xB8004C. We can convert this number to binary and can see the pattern as electronic lines, where a 1 means the line is high (active), and a 0 means the line is low: 101110000000000001001100 The processor follows a series of discrete instructions hard built into the digital logic circuit of the CPU. These instructions tells the processor how to encode a series of bits. All x86 processors will encode this bit pattern as our mov ax, 0x4c00 instruction. Do to the increasing complexity of instructions, most newer processors actually follow their own internal instruction sets. This is not new to processors--a lot of microcontrollers may use multiple internal instruction sets to decrease the complexity of the electronics. Normally these are Macrocode and Microcode . Macrocode is an abstract set of instructions the processor uses to decode an instruction into microcode. Macrocode is normally written in a special macro language developed by the electronic engineers stored on a ROM chip inside of the controller and compiled in a macro assembler. The macro assembler assembles the macrocode into an even lower level language, which is the language of the controller: Microcode. Microcode is a very low level language developed by the electronic engineers. Microcode is used by the controller or processor to decode an instruction...such as our 0xB8004C (mov ax, 0x4c00) instruction. Using its Arithmetic Logic Unit (ALU) the CPU can get a number - 0x4C00. And copy it into AX (A simple bit copy). This example demonstrates how everything comes together. How the CPU uses the system bus, and relies on the memory controller to decode the memory location, and follow the Control Bus . This is an important concept. Software Ports rely on the Memory Controller in a similar fashion. Protected Mode - Theory Okay...So why did we talk about architecture? The unfortunate truth is that in protected mode, there is no interrupts. So lessee... No interrupts. No System calls. No Standard Library. No nothing. Everything we do, we have to do ourselves. Because of this, there is no helping hand to guide us. One mistake can either crash your system, or even destroy your hardware if you are not careful. Not only floppy disks, but hard disks, external (and internal ) devices, etc. Understanding the system architecture will help us understand everything a lot better, to insure we don't make too many mistakes. Also, it gives us an introduction to direct hardware programming-- because this is the only thing we can do. You might be thinking: Wait--What about the uber-1337 C Kernel you promised us!? Well...Remember that C is a low level language, in a way. Through inline assembly, we could create an interface to the hardware. And C, just like C++, only produces x86 machine instructions that could be executed directly by the processor. Just remember, however, that there is no standard library. And, that you are programming in a very low level environment, even if you are using a high level language. We will go over this when we start the Kernel. Conclusion We want over a lot -Memory Mapping, Port Mapping, the x86 Port Addresses, All x86 registers, The x86 Memory Map, System Architecture, IN/OUT keywords and how they execute, and how instructions execute-step by step. We also have taken a look at basic hardware programming--in which we will be doing a lot."
  },
  "articles/61_unorganised_tutorial/T7-11.html": {
    "href": "articles/61_unorganised_tutorial/T7-11.html",
    "title": "Bootloader stage 2 | BrokenThorn OS Dev Tutorials",
    "keywords": "Bootloader stage 2"
  },
  "articles/61_unorganised_tutorial/T8.html": {
    "href": "articles/61_unorganised_tutorial/T8.html",
    "title": "Protected Mode | BrokenThorn OS Dev Tutorials",
    "keywords": "Protected Mode We covered a lot so far throughout this series. We looked at bootloaders, system architecture, file systems, and real mode addressing in depth. This is cool--but we have yet to look at the 32 bit world. And, are we not building a 32bit OS? In this tutorial, we are going to make the jump-- Welcome to the 32 bit world! Granted, we are not done with the 16 bit world just yet, however it will be much easier to get entering protected mode done now. So, lets get started then! This tutorial covers: Protected Mode Theory Protected Mode Addressing Entering Protected Mode Global Descriptor Table (GDT) Ready? stdio.inc To make things more object oriented, I have moved all input/output routines into a stdio.inc file. Please, Do not associate this with the C standard stdio.lib library. They have almost nothing in common. We will start work on the standard library while working on the Kernel. Anyways... Here's the file: ;************************************************* ; stdio.inc ; -Input/Output routines ; ; OS Development Series ;************************************************* %ifndef __STDIO_INC_67343546FDCC56AAB872_INCLUDED__ %define __STDIO_INC_67343546FDCC56AAB872_INCLUDED__ ;************************************************; ; Puts16 () ; -Prints a null terminated string ; DS=>SI: 0 terminated string ;************************************************; bits 16 Puts16: pusha ; save registers .Loop1: lodsb ; load next byte from string from SI to AL or al, al ; Does AL=0? jz Puts16Done ; Yep, null terminator found-bail out mov ah, 0eh ; Nope-Print the character int 10h ; invoke BIOS jmp .Loop1 ; Repeat until null terminator found Puts16Done: popa ; restore registers ret ; we are done, so return %endif ;__STDIO_INC_67343546FDCC56AAB872_INCLUDED__ For those who do not know--*.INC files are Include files. We will add more to this file as needed. I'm not going to explain the puts16 function--It's the exact same routine we used in the bootloader, just with an added pusha/popa. Welcome to Stage 2 The bootloader is small. Way to small to do anything usefully. Remember that the bootloader is limited to 512 bytes. No more, No less. Seriously--our code to load Stage 2 was almost 512 bytes already! Its simply way to small. This is why we want the bootloader to just load another program. Because of the FAT12 file system, our second program can be of almost any amount of sectors. Because of this, there is no 512 byte limitation. This is great for us. This, our readers, is Stage 2. The Stage 2 bootloader will set everything up for the kernel. This is similar to NTLDR (NT Loader), in Windows. In fact, I am naming the program KRNLDR (Kernel Loader). Stage 2 will be responsible for loading our kernel, hence KRNLDR.SYS. KRNLDR -- Our Stage 2 bootloader, will do several things. It can: Enable and go into protected mode Retrieve BIOS information Load and execute the kernel Provide advance boot options (Such as Safe Mode, for example) Through configuration files, you can have KRNLDR boot from multiple operating system kernels Enable the 20th address line for access up to 4 GB of memory Provide basic interrupt handling ...And more. It also sets up the environment for a high level language, like C. In fact, a lot of times the Stage 2 loader is a mixture of C and x86 assembly. As you can imagine--Writing the stage 2 bootloader can be a large project itself. And yet, its nearly impossible to develop an advanced bootloader without an already working Kernel. Because of this, we are only going to worry about the important details-- bolded above. When we get a working kernel, we may come back to the bootloader. We are going to look at entering protected mode first. I'm sure a lot of you are itching to get into the 32 bit world--I know I am! World of Protected Mode Yippie!! Its finally time! You have heard me say \"protected mode\" a lot--and we have described it in some detail before. As you know, protected mode is supposed to offer memory protection. By defining how the memory is used, we can insure certain memory locations cannot be modified, or executed as code. The 80x86 processor maps the memory regions based off the Global Descriptor Table (GDT). . The processor will generate a General Protection Fault (GPF) exception if you do not follow the GDT. Because we have not set up interrupt handlers, this will result in a triple fault. Lets take a closer look, shall we? Descriptor Tables A Descriptor Table defines or map something--in our case, memory, and how the memory is used. There are three types of descriptor tables: Global Descriptor Table (GDT), Local Descriptor Table (LDT), and Interrupt Descriptor Table (IDT); each base address is stored in the GDTR, LDTR, and IDTR x86 processor registers. Because they use special registers, they require special instructions. Note: Some of these instructions are specific to Ring 0 kernel level programs. If a general Ring 3 program attempts to use them, a General Protection Fault (GPF) exception will occur. In our case, because we are not handling interrupts yet, a triple fault will occur. Global Descriptor Table THIS will be important to us--and you will see it both in the bootloader and Kernel. The Global Descriptor Table (GDT) defines the global memory map. It defines what memory can be executed (The Code Descriptor ), and what area contains data ( Data Descriptor ). Remember that a descriptor defines properties--i.e., it describes something. In the case of the GDT, it describes starting and base addresses, segment limits, and even virtual memory. This will be more clear when we see it all in action, don't worry :) The GDT usually has three descriptors--a Null descriptor (Contains all zeros), a Code Descriptor , and a Data Descriptor . Okay.....So, what is a \"Descriptor\"? For the GDT, a \"Descriptor\" is an 8 byte QWORD value that describes properties for the descriptor. They are of the format: Bits 56-63: Bits 24-32 of the base address Bit 55: Granularity 0: None 1: Limit gets multiplied by 4K Bit 54: Segment type 0: 16 bit 1: 32 bit Bit 53: Reserved-Should be zero Bits 52: Reserved for OS use Bits 48-51: Bits 16-19 of the segment limit Bit 47 Segment is in memory (Used with Virtual Memory) Bits 45-46: Descriptor Privilege Level 0: (Ring 0) Highest 3: (Ring 3) Lowest Bit 44: Descriptor Bit 0: System Descriptor 1: Code or Data Descripto Bits 41-43: Descriptor Type Bit 43: Executable segment 0: Data Segment 1: Code Segment Bit 42: Expansion direction (Data segments), conforming (Code Segments) Bit 41: Readable and Writable 0: Read only (Data Segments); Execute only (Code Segments) 1: Read and write (Data Segments); Read and Execute (Code Segments) Bit 40: Access bit (Used with Virtual Memory) Bits 16-39: Bits 0-23 of the Base Address Bits 0-15: Bits 0-15 of the Segment Limit ...Pretty ugly, huh? Basically, by building up a bit pattern, the 8 byte bit pattern will describe various properties of the descriptor. Each descriptor defines properties for its memory segment. To make things simple, lets build a table that defines a code and data descriptors with read and write permissions from the first byte to byte 0xFFFFFFFF in memory. This just means we could read or write any location in memory. We are first going to look at a GDT: ; This is the beginning of the GDT. Because of this, its offset is 0. ; null descriptor dd 0 ; null descriptor--just fill 8 bytes with zero dd 0 ; Notice that each descriptor is exactly 8 bytes in size. THIS IS IMPORTANT. ; Because of this, the code descriptor has offset 0x8. ; code descriptor: ; code descriptor. Right after null descriptor dw 0FFFFh ; limit low dw 0 ; base low db 0 ; base middle db 10011010b ; access db 11001111b ; granularity db 0 ; base high ; Because each descriptor is 8 bytes in size, the Data descriptor is ; at offset 0x10 from the beginning of the GDT, or 16 (decimal) bytes from start. ; data descriptor: ; data descriptor dw 0FFFFh ; limit low (Same as code) dw 0 ; base low db 0 ; base middle db 10010010b ; access db 11001111b ; granularity db 0 ; base high That's it. The infamous GDT. This GDT contains three descriptors--each 8 bytes in size. A null descriptor, code, and data descriptors. Each bit in each descriptor corresponds directly with that represented in the above bit table (Shown above the code). Lets break each down into its bits to see what's going on. The null descriptor is all zeros, so we will focus on the other two. Breaking the code selector down Lets look at it again: ; code descriptor: ; code descriptor. Right after null descriptor dw 0FFFFh ; limit low dw 0 ; base low db 0 ; base middle db 10011010b ; access db 11001111b ; granularity db 0 ; base high Remember that, in assembly language, each declared byte, word, dword, qword, instruction, whatever is literally right after each other. In the above, 0xffff is, of course, two bytes filled with ones. We can easily break this up into its binary form because most of it is already done: 11111111 11111111 00000000 00000000 00000000 10011010 11001111 00000000 Remember (From the above bit table), that Bits 0-15 (The first two bytes) represents the segment limit. This just means, we cannot use an address greater then 0xffff (Which is in the first 2 bytes) within a segment. Doing so will cause a GPF. Bits 16-39 (The next three bytes) represent Bits 0-23 of the Base Address (The starting address of the segment). In our case, its 0x0. Because the base address is 0x0, and the limit address is 0xFFFF, the code selector can access every byte from 0x0 through 0xFFFF . Cool? The next byte (Byte 6) is where the interesting stuff happens. Lets break it bit by bit--literally: db 10011010b ; access Bit 0 (Bit 40 in GDT): Access bit (Used with Virtual Memory). Because we don't use virtual memory (Yet, anyway), we will ignore it. Hence, it is 0 Bit 1 (Bit 41 in GDT): is the readable/writable bit. Its set (for code selector), so we can read and execute data in the segment (From 0x0 through 0xFFFF) as code Bit 2 (Bit 42 in GDT): is the \"expansion direction\" bit. We will look more at this later. For now, ignore it. Bit 3 (Bit 43 in GDT): tells the processor this is a code or data descriptor. (It is set, so we have a code descriptor) Bit 4 (Bit 44 in GDT): Represents this as a \"system\" or \"code/data\" descriptor. This is a code selector, so the bit is set to 1. Bits 5-6 (Bits 45-46 in GDT): is the privilege level (i.e., Ring 0 or Ring 3). We are in ring 0, so both bits are 0. Bit 7 (Bit 47 in GDT): Used to indicate the segment is in memory (Used with virtual memory). Set to zero for now, since we are not using virtual memory yet The access byte is very important! We will need to define different descriptors in order to execute Ring 3 applications and software. We will look at this alot more closer when we start getting into the Kernel. Putting this together, this byte indicates: This is a readable and writable segment, we are a code descriptor, at Ring 0. Lets look at the next bytes: db 11001111b ; granularity db 0 ; base high Bit 0-3 (Bits 48-51 in GDT): Represents bits 16-19 of the segment limit. So, lessee... 1111b is equal to 0xf. Remember that, in the first two bytes if this descriptor, we set 0xffff as the first 15 bites. Grouping the low and high bits, it means we can access up to 0xFFFFF . Cool? It gets better... By enabling the 20th address line, we can access up to 4 GB of memory using this descriptor. We will look closer at this later... Bit 4 (Bit 52 in GDT): Reserved for our OS's use--we could do whatever we want here. Its set to 0. Bit 5 (Bit 53 in GDT): Reserved for something. Future options, maybe? Who knows. Set to 0. Bit 6 (Bit 54 in GDT): is the segment type (16 or 32 bit). Lessee.... we want 32 bits, don't we? After all-we are building a 32 bit OS! So, yeah--Set to 1. Bit 7 (Bit 55 in GDT): Granularity. By setting to 1, each segment will be bounded by 4KB. The last byte is bits 24-32 of the base (Starting) address--which, of course is 0. That's all there is to it! The Data Descriptor Okay then--go back up to the GDT that we made, and compare the code and data selectors: They are exactly the same, except for one single bit. Bit 43. Looking back at the above, you can see why: It is set if its a code selector, not set if its a data selector. Conclusion (GDT) This is the most comprehensive GDT description I have ever seen (and written!) That's a good thing though, right? Okay, Okay--I know, the GDT is ugly. Loading it for use is very easy though--so it has benefits! Actually, all you need to do is load the address of a pointer. This GDT pointer stores the size of the GDT ( Minus one! ), and the beginning address of the GDT. For example: toc: dw end_of_gdt - gdt_data - 1 ; limit (Size of GDT) dd gdt_data ; base of GDT gdt_data is the beginning of the GDT. end_of_gdt is, of course, a label at the end of the GDT. Notice the size of this pointer, and note its format. The GDT pointer must follow this format. Not doing so will cause unpredictable results--Most likely a triple fault. The processor uses a special register-- GDTR , that stores the data within the base GDT pointer. To load the GDT into the GDTR register, we will need a special instruction... LGDT (Load GDT). It is very easy to use: lgdt [toc] ; load GDT into GDTR This is not a joke--it really is that simple. Not much times do you actually get nice breaks like this one is OS Dev. Brace it while it lasts! Local Descriptor Table The Local Descriptor Table (LDT) is a smaller form of the GDT defined for specialized uses. It does not define the entire memory map of the system, but instead, only up to 8,191 memory segments. We will go into this more later, as it does not have to do with protected mode. Cool? Interrupt Descriptor Table THIS will be important. Not yet, though. The Interrupt Descriptor Table (IDT) defines the Interrupt Vector Table (IVT). It always resides from address 0x0 to 0x3ff. The first 32 vectors are reserved for hardware exceptions generated by the processor. For example, a General Protection Fault , or a Double Fault Exception . This allows us to trap processor errors without triple faulting. More on this later, though. The other interrupt vectors are mapped through a Programmable Interrupt Controller chip on the motherboard. We will need to program this chip directly while in protected mode. More on this later... PMode Memory Addressing Remember that PMode (Protected Mode) uses a different addressing scheme then real mode. Real mode uses the Segment:offset memory model, However PMode uses the Descriptor:Offset model. This means, in order to access memory in PMode, we have to go through the correct descriptor in the GDT. The descriptor is stored in CS. This allows us to indirectly reference memory within the current descriptor. For example, if we need to read from a memory location, we do not need to describe what descriptor to use; it will use the one currently in CS. So, this will work: mov bx, byte [0x1000] This is great, but sometimes we need to reference a specific descriptor. For example, Real Mode does not use a GDT, While PMode requires it. Because of this, when entering protected mode, We need to select what descriptor to use to continue execution in protected mode. After all, because Real Mode does not know what a GDT is, there is no guarantee that CS will contain the correct descriptor in CS, so we need to set it. To do this, we need to set the descriptor directly: jmp 0x8:Stage2 You will see this code again. Remember that the first number is the descriptor (Remember PMode uses Descriptor:Address memory model?) You might be curious at where the 0x8 came from. Please look back at the above GDT. Remember that each descriptor is 8 bytes in size . Because our Code descriptor is 8 bytes from the start of the GDT, we need to offset 0x8 bytes in the GDT. Understanding this memory model is very important in understanding how protected mode works. Entering Protected Mode To enter protected mode is fairly simple. At the same time, it can be a complete pain. To enter protected mode, we have to load a new GDT which describes permission levels when accessing memory. We then need to actually switch the processor into protected mode, and jump into the 32 bit world. Sounds easy, don't you think? The problem is the details. One little mistake can triple fault the CPU . In other words, watch out! Step 1: Load the Global Descriptor Table Remember that the GDT describes how we can access memory. If we do not set a GDT, the default GDT will be used (Which is set by the BIOS--Not the ROM BIOS). As you can imagine, this is by no means standard among BIOS's. And, if we do not watch the limitations of the GDT (i.e....if we access the code selector as data), the processor will generate a General Protection Fault (GPF). Because no interrupt handler is set, the processor will also generate a second fault exception--which will lead to a triple fault. Anywho...Basically, all we need to do is create the table. For example: ; Offset 0 in GDT: Descriptor code=0 gdt_data: dd 0 ; null descriptor dd 0 ; Offset 0x8 bytes from start of GDT: Descriptor code therefore is 8 ; gdt code: ; code descriptor dw 0FFFFh ; limit low dw 0 ; base low db 0 ; base middle db 10011010b ; access db 11001111b ; granularity db 0 ; base high ; Offset 16 bytes (0x10) from start of GDT. Descriptor code therefore is 0x10. ; gdt data: ; data descriptor dw 0FFFFh ; limit low (Same as code) dw 0 ; base low db 0 ; base middle db 10010010b ; access db 11001111b ; granularity db 0 ; base high ;...Other descriptors begin at offset 0x18\\. Remember that each descriptor is 8 bytes in size? ; Add other descriptors for Ring 3 applications, stack, whatever here... end_of_gdt: toc: dw end_of_gdt - gdt_data - 1 ; limit (Size of GDT) dd gdt_data ; base of GDT This will do for now. Notice toc . This is the pointer to the table. The first word in the pointer is the size of the GDT - 1. The second dword is the actual address of the GDT. This pointer must follow this format. Do NOT forget to subtract the 1! We use a special Ring 0-only instruction - LGDT to load the GDT (Based on this pointer), into the GDTR register. Its a single, simple, one line instruction: cli ; make sure to clear interrupts first! lgdt [toc] ; load GDT into GDTR sti That's it! Simple, huh? Now... Onto protected mode! Um...Oh yeah! Here's Gdt.inc to hide all the ugly GDT stuff: ;************************************************* ; Gdt.inc ; -GDT Routines ; ; OS Development Series ;************************************************* %ifndef __GDT_INC_67343546FDCC56AAB872_INCLUDED__ %define __GDT_INC_67343546FDCC56AAB872_INCLUDED__ bits 16 ;******************************************* ; InstallGDT() ; - Install our GDT ;******************************************* InstallGDT: cli ; clear interrupts pusha ; save registers lgdt [toc] ; load GDT into GDTR sti ; enable interrupts popa ; restore registers ret ; All done! ;******************************************* ; Global Descriptor Table (GDT) ;******************************************* gdt_data: dd 0 ; null descriptor dd 0 ; gdt code: ; code descriptor dw 0FFFFh ; limit low dw 0 ; base low db 0 ; base middle db 10011010b ; access db 11001111b ; granularity db 0 ; base high ; gdt data: ; data descriptor dw 0FFFFh ; limit low (Same as code) dw 0 ; base low db 0 ; base middle db 10010010b ; access db 11001111b ; granularity db 0 ; base high end_of_gdt: toc: dw end_of_gdt - gdt_data - 1 ; limit (Size of GDT) dd gdt_data ; base of GDT %endif ;__GDT_INC_67343546FDCC56AAB872_INCLUDED__ Step 2: Entering Protected Mode Remember that bit table of the CR0 register? What was it? Oh yeah... Bit 0 (PE) : Puts the system into protected mode Bit 1 (MP) : Monitor Coprocessor Flag This controls the operation of the WAIT instruction. Bit 2 (EM) : Emulate Flag . When set, coprocessor instructions will generate an exception Bit 3 (TS) : Task Switched Flag This will be set when the processor switches to another task . Bit 4 (ET) : ExtensionType Flag. This tells us what type of coprocessor is installed. 0 - 80287 is installed 1 - 80387 is installed. Bit 5 : Unused. Bit 6 (PG) : Enables Memory Paging. The important bit is bit 0. By setting bit 0, the processor continues execution in a 32 bit state. That is, Setting bit 0 enables protected mode. Here is an example: mov eax, cr0 ; set bit 0 in CR0-go to PMode or eax, 1 mov cr0, eax That's it! If bit 0 is set, Bochs Emulator will know that you are in protected mode (PMode). Remember: The code is still 16 bit until you specify bits 32 . As long as you code is in 16bit, you can use segment:offset memory model. Warning! Insure interrupts are DISABLED before going into the 32 bit code! If it is enabled, the processor will triple fault. (Remember that we cannot access the IVT from PMode?) After entering protected mode, we run into an immediate problem. Remember that, in Real Mode, we used the Segment:offset memory model? However, Protected Mode relies on the Descriptor:Address memory model. Also, remember that Real Mode does not know what a GDT is, while in PMode, the use of it is Required , because of its addressing mode. Because of this, in real mode, CS still contains the last segment address used, Not the descriptor to use . Remember that PMode uses CS to store the current code descriptor? So, in order to fix CS (So that it is set to our code descriptor) we need to far jump , using our code descriptor. Because our code descriptor is 0x8 (8 bytes offset from start of GDT), just jump like so: jmp 08h:Stage3 ; far jump to fix CS. Remember, code selector is 0x8! Also, once in PMode, we have to reset all of the segments (As they are incorrect) to their correct descriptor numbers. mov ax, 0x10 ; set data segments to data selector (0x10) mov ds, ax mov ss, ax mov es, ax Remember that our data descriptor was 16 (0x10) bytes from the start of the GDT? You might be curious at why all of the references inside the GDT (to select the descriptor) are offsets. Offsets of what? Remember the GDT pointer that we loaded in via the LGDT instruction? The processor bases all offset address off of the base address that we set the GDT pointer to point to. Here's the entire Stage 2 bootloader in its entirety: bits 16 ; Remember the memory map-- 0x500 through 0x7bff is unused above the BIOS data area. ; We are loaded at 0x500 (0x50:0) org 0x500 jmp main ; go to start ;******************************************************* ; Preprocessor directives ;******************************************************* %include \"stdio.inc\" ; basic i/o routines %include \"Gdt.inc\" ; Gdt routines ;******************************************************* ; Data Section ;******************************************************* LoadingMsg db \"Preparing to load operating system...\", 0x0D, 0x0A, 0x00 ;******************************************************* ; STAGE 2 ENTRY POINT ; ; -Store BIOS information ; -Load Kernel ; -Install GDT; go into protected mode (PMode) ; -Jump to Stage 3 ;******************************************************* main: ;-------------------------------; ; Setup segments and stack ; ;-------------------------------; cli ; clear interrupts xor ax, ax ; null segments mov ds, ax mov es, ax mov ax, 0x9000 ; stack begins at 0x9000-0xffff mov ss, ax mov sp, 0xFFFF sti ; enable interrupts ;-------------------------------; ; Print loading message ; ;-------------------------------; mov si, LoadingMsg call Puts16 ;-------------------------------; ; Install our GDT ; ;-------------------------------; call InstallGDT ; install our GDT ;-------------------------------; ; Go into pmode ; ;-------------------------------; cli ; clear interrupts mov eax, cr0 ; set bit 0 in cr0--enter PMode or eax, 1 mov cr0, eax jmp 08h:Stage3 ; far jump to fix CS. Remember that the code selector is 0x8! ; Note: Do NOT re-enable interrupts! Doing so will triple fault! ; We will fix this in Stage 3. ;****************************************************** ; ENTRY POINT FOR STAGE 3 ;****************************************************** bits 32 ; Welcome to the 32 bit world! Stage3: ;-------------------------------; ; Set registers ; ;-------------------------------; mov ax, 0x10 ; set data segments to data selector (0x10) mov ds, ax mov ss, ax mov es, ax mov esp, 90000h ; stack begins from 90000h ;******************************************************* ; Stop execution ;******************************************************* STOP: cli hlt Conclusion I'm excited, are you? We went over a lot in this tutorial. We talked about the GDT, descriptor tables, and getting into protected mode. Welcome to the 32 bit world! This is great for us. Most compilers only generate 32 bit code, so protected mode is necessary. Now, we would be able to execute the 32 bit programs written from almost any language - C or assembly. We are not done with the 16 bit world yet though. In the next tutorial, we are going to get BIOS information, and loading the kernel through FAT12. This also means, of course, we will create a small little stub kernel. Cool, huh?"
  },
  "articles/61_unorganised_tutorial/T9.html": {
    "href": "articles/61_unorganised_tutorial/T9.html",
    "title": "Enabling A20 | BrokenThorn OS Dev Tutorials",
    "keywords": "Enabling A20 we have looked at how to switch the processor into a 32 bit mode. We also learned how we can access up to 4 GB of memory. This is great--but, how ? Also, remember that the PC boots into real mode, which has the limitation of 16 bit registers. And, hence, 16 bit segment addressing. This limits the amount of memory you can access in real mode. Because of this, we still cannot access even up to 1 GB of memory yet. Heck, we cannot even go passed the 1 MB barrier yet! What to do? We have to enable the 20th address line. This will require direct hardware programming, so we will talk about that as well. So, This is what's on the menu: Direct Hardware Programming - Theory Direct Hardware Programming and Controllers Keyboard Controller Programming - Basics Enabling A20 Pizza ðŸ˜ Do to the use of high level languages, like C, being able to access more then 1 MB of memory can be critical. Because of this, enabling A20 (Address line 20) will be important! Note: Remember that we cannot access over 1 MB yet! Doing so will cause a triple fault. Also, because we are going to go over direct hardware programming, this tutorial will be a little more complicated then previous ones. Don't worry - You will get more experience with direct hardware programming later when we develop device drivers for the Kernel. Ready? Get Ready For those who have been with me this far, I am certain you know how hard OS development is. However, we have not touched anything close to hard. All of the concepts listed here is still very basic, and yet quite advanced. However: Things are only going to get much more harder. Every single controller must be programmed a special way in order to work correctly. For example, to write (or read) a hard drive, you must first determine if it is an IDE or SCSI drive. Then, you have to determine the drive number it is, and program it using either the IDE Controller or SCSI Controller , which control the IDE and SCSI connections, respectively. Both of these controllers are different. To add more complexity, a \"Sector\" might not be 512 bytes. Hence, \"Reading and writing sectors\" is vague. Then comes memory management and fragmentation. This is where Paging , Virtual Address Space , and the Memory Management Unit (MMU) comes into play. Reading and writing any drive is very different then any other drive. This is even true at the bootsector level. The typical format and file system is different between media, so code that boots from a FAT12 floppy will Not work to boot a CDFS Filesystem CD ROM. By Abstracting hardware specific (And low level code), we can make most of the code, however, work for these devices. When we say \"Write a file to hard drive\", we normally don't want to define what a \"file\" is, because we shouldn't. We shouldn't have to worry about what controller to read to/from, nor the exact location on disk. This is why abstraction is very important! Everything here is primarily for protected mode (i.e., it is 32 bit code), although it will work in real mode as well. Because of this, remember the rule of protected mode: No interrupts are available! The use of any interrupt will cause a triple fault ...Hence, you are Completely on your own. Kernel Debugging Debugging is an art form. It provides a way of trapping problems, and fixing errors through software before they become serious. Kernel Debugging relates to debugging kernel-level Ring 0 programs. This is never an easy task. Debuggers in High Level Languages Most debuggers in languages, like C and C++, provide a way of displaying variable and routine names, and their values, locations, etc during runtime. The problem? We don't have any symbolic names yet in any of our programs. We are still working at the Binary level. What this means is that we need a debugger that could work and display memory directly. Bochs has a debugger just for us. Bochs Debugger Bochs comes with a debugger called bochsdbg.exe . When you launch it, you will be given the same startup screen from Bochs.exe. Load your configuration file, and start the emulation. Bochs debugger and display window will now appear, and you should see the line: [0x000ffff0] f000:fff0 (unk. ctxt): jmp f000:e05b ; ea5be000f0 < bochs:1> _ In the second line, bochs tells you the number of commands sent to it (In this case, this is the first command, so a 1 is displayed). You can type your commons here. The first line is the important line. It tells you the current instruction, absolute address, and seg:offset address. It also gives you the machine language Operation Code (Opcode) equivalent. HELP command The help command gives you a list of available commands. BREAK command The b (break) command allows you to set breakpoints at addresses in memory. For example, if we are trying to debug our OS, we need to start at the bootloader (07c00:0). However, Bochs Debugger starts where the BIOS is at. Because of this, we will need to set a breakpoint to 0x7c00:0, and continue execution until that breakpoint is reached: // BIOS is at 0xea5be000f0 [0x000ffff0] f000:fff0 (unk. ctxt): jmp f000:e05b < bochs:1> b 0x7c00 // Sets the breakpoint to 0x7c00:0 < bochs:2> c // Continue execution < 0> Breakpoint 1, 0x7c00 in ?? < > // Our breakpoint is hit Next at t=834339 // We are now at our bootloaders first instruction < 0> [0x00007c00] 0000:7c00 (unk. ctxt): jmp 7cb5 ; e9b200/DIV> The above tells us that our main() function in our bootloader is at 0x7cb5. This makes since because, remember that the OEM Parameter Block is between this jump instruction, and the start of main(). Knowing that the bootloader loads stage 2 at 0x500, lets break to it: < bochs:3> b 0x500 < bochs:4> c < 0> Breakpoint 2, 0x500 in ?? < > Next at t=934606 <0> [0x000000500] 0050:0000 (ink. ctxt): jmp 00a0 ; e99d00 < bochs:5> _ Now, we are at the beginning of stage 2, and could follow the debugger with our assembly file! Cool, huh? Best of all, you can see the window dynamically update to display the output of your system. Single Step The s (Single Step) command is used to walk through one instruction at a time: < bochs:6> s Next at t=934607 <0> [0x0000005a0] 0050:00a0 (ink. ctxt): cli ; fa < bochs:7> s Next at t=934608 <0> [0x0000005a1] 0050:00a1 (ink. ctxt): xor AX, AX ; 31c0 < bochs:8> _ dump_cpu This command displays the current value of all cpu registers, including RFLAGS, General Purpose, Test, Debug, Control, and Segment registers. It also includes GDTR, IDTR, LDTR, TR, and EIP. print_stack This displays the current values of the stack. This is critical considering that we use the stack very often. There are more commands then this, however these are the most useful. Learning how to use the debugger is very important, especially in the early stages like we are in now. Direct Hardware Programming - Theory This is where things start getting very hard in operating system development. \"Direct hardware programming\" simply refers to communicating directly (and controlling) individual chips. As long as these chips are programmable (In some way), we can control them. In [Tutorial 7] (fix link), we took a very detailed look at how the system works. We also talked about how software ports work, port mapping, the IN and OUT instructions, and I gave a huge table with common port mappings on x86 architectures. Remember that, whenever the processor receives an IN or OUT instruction, It enables the I/O Access Line on the Control Bus , which, of course, is part of the System Bus , in the Motherboards North Bridge . Because the system bus is connected to both the Memory Controller and I/O Controller , both controllers listen for specific addresses and activated lines in the control bus. If the I/O Access line is set electricity runs through it--which means it is active (1), The I/O controller takes the address. The I/O Controller then gives the port address to every other device, and awaits a signal from a controller chip (meaning that it belongs to some device--so give whatever data to that device). If no controller chip responds, and the port address is set back, it is ignored. This is how port mapping works. (Please see [Tutorial 7] (fix link) for more detail.) Also, remember that a single controller chip may be assigned a range of port addresses. Port addresses are assigned by the BIOS POST, even before the BIOS is loaded and executed. Why? A lot of devices need different types of information. Some ports may represent \"registers\", while others may be \"data\" or \"ready\" ports. It's ugly, I know. But it gets worse. On different systems, port addresses may vary widely. Because x86 architectures are backwards compatible, basic devices (Such as keyboards and mice) are usually always the same address. More complex devices, however, may not be. Direct Hardware Programming and Controllers To better understand how everything works, lets look at controllers. After all, we will be talking to them a lot--especially in protected mode. Many PCs are based off of the early Intel 8042 Microcontroller chip . This controller chip is either embedded as an IC (Integrated Circuit) chip, or directly in the motherboard. It is usually located in the South Bridge . This microcontroller communicates through a cord connecting to your keyboard, to another microcontroller chip in your keyboard. When you press a key on the keyboard, It presses down on a rubber dome setting beneath the key itself. On the underside of the rubber dome is a conductive contact that, when pressed down, comes in contact with two conductive contacts on the keyboard circuit. Because of this, current can flow through. Each key is connected by a pair of electrical lines. As each signal changes (Depending on weather keys are pressed), a make code is generated (From the series of lines). This make code is sent to the microcontroller chip inside of the keyboard, and sent through the cord connecting to the computer hardware port. It is sent through as a series of on and off electrical pulses. Depending on the clock cycles, each pulse can be converted to a series of bits representing a bit pattern. We are on the motherboard. This series of bits goes through the south bridge as electrical signals, all the way to the 8042 microcontroller. This microcontroller decodes the make code into a scan code, and stores it within an internal register. That is, our buffer. The internal registers can be an EEPROM chip, or similar, so we can electrically overwrite the data whenever we want. When booting, the BIOS POST assigns each device (Through the I/O Controller) port addresses. It does this by querying the devices. In the usual case, the BIOS POST sets this internal register at port address 0x60. This means, Whenever we reference port 0x60, we are requesting to read from this internal register. You know the rest of the story regarding port mapping, and IN/ OUT instructions, so lets read from that register: in al, 0x60 ; get byte from 8042 microcontroller input register As you can probably guess, The 8042 Microcontroller is the Keyboard Controller . By communicating with the various of registers with the chip, we can read input from the keyboard, map scan codes, even several other things: Like enabling A20. You might be wondering why you have to communicate to the keyboard controller to enable A20. We will look at this next. Gate A20 - Theory Finally we cover A20. I know, I know...Most of this tutorial so far covers other topics that are not directly related to A20. However, I wanted to start with the basics of direct hardware programming first before going into A20..as enabling A20 requires it, along with any microcontroller programming. Enabling the A20 line may require programming the keyboard microcontroller. Because of this, I will cover a little bit about programming the keyboard controller but will not go into keyboard programming just yet. A little history When IBM designed the IBM PC AT machines, it used their newer Intel 80286 microprocessor , which was not entirely compatible with previous x86 microprocessors when in real mode. The problem? The older x86 processors did not have address lines A20 through A31. They did not have an address bus that size yet. Any programs that go beyond the first 1 MB would appear to wrap around. While it worked back then, the 80286's address space required 32 address lines. However, if all 32 lines are accessible, we get the wrapping problem again. To fix this problem, Intel put a logic gate on the 20th address line between the processor and system bus. This logic gate got named Gate A20 , as it can be enabled and disabled. For older programs, it an be disabled for programs that rely on the wrap around, and enabled for newer programs. When booting, the BIOS enables A20 when counting and testing memory, and then disables it again before giving our operating system control. There are a lot of ways to enable A20. By enabling the A20 gate, we have access to all 32 lines on the address bus, and hence, can reference 32 bit addresses, or up to 0xFFFFFFFF - 4 GB of memory. The Gate A20 is an electronic OR gate that was originally connected to the P21 electrical line of the 8042 microcontroller (The keyboard controller). This gate is an output line that is treated as Bit 1 of the output port data. We can send a command to receive this data and even modify it. By setting this bit, and writing the output line data we can have the microcontroller set the OR gate thus enabling the A20 line. We can either do this ourselves directly or indirectly. We will look more in the next section. During bootup, the BIOS enables the A20 line to test the memory. After the memory test, the BIOS disables the A20 line to retain compatibility with older processors. Because of this, by default, the A20 line is disabled for our operating system. There can be several different ways to re-enable gate A20 depending on the motherboard configuration. Because of this, I will cover several different more common methods to enable A20. Lets look at this next. ðŸ˜‰ Gate A20 - Enabling Remember that there are a lot of different ways to enable A20. If you are wanting to just get your system working, all you need to do is use a method that works for you. If portability is a requirement, you may be required to use a mixture of methods. Method 1: System Control Port A This is a very fast, yet less portable method of enabling the A20 address line. Sone systems, including MCA and EISA we can control A20 from the system control port I/O 0x92. The exact details and functions of port 0x92 vary greatly by manufacturer. There are several bits that are commonly used though: Bit 0 - Setting to 1 causes a fast reset (Used to switch back to real mode) Bit 1 - 0: disable A20; 1: enable A20 Bit 2 - Manufacturer defined Bit 3 - power on password bytes (CMOS bytes 0x38-0x3f or 0x36-0x3f). 0: accessible, 1: inaccessible Bits 4-5 - Manufacturer defined Bits 6-7 - 00: HDD activity LED off; any other value is \"on\" Here is an example that enables A20 using this method: mov al, 2 ; set bit 2 (enable a20) out 0x92, al Notice there is a lot of other things we can do with this port: mov al, 1 ; set bit 1 (fast reset) out 0x92, al This method seems to work with Bochs as well. Warning While this is one of the easier methods, I have seen this method conflict with some other hardware devices. It would normally cause the system to halt. If you want to use this method (and it works for you), I would stick with using it, but please keep this in mind. Other Ports I feel that I should mention that some systems allow the use of other I/O ports to enable and disable A20. The most common of these are I/O port 0xEE. If I/O port 0xEE (\"FAST A20 GATE\") is enabled on these systems, reading from this port enables A20, and writing to it disables A20. A similar effect occurs for port 0xEF (\"FAST CPU RESET\") as well for resetting the system. Other systems may use different ports (i.e.; AT&T 6300+ needs a write of 0x90 to I/O port 0x3f20 to enable A20, and a write of 0 to disable A20). There are also rumors of systems that exist that use bit 2 of I/O port 0x65 or bit 0 of I/O port 0x1f8 for enabling and disabling A20 (0: disable, 1: enable). As you can see, there are a lot of headaches when it comes to working with A20. The only way to be sure is with your motherboard manufacturer. Method 2: Bios A lot of Bioses make interrupts available for enabling and disabling A20. Bochs Support It seems some versions of Bochs recognizes these methods but it may not be supported on some versions of Bochs. INT 0x15 Function 2400 - Disable A20 This function disables the A20 gate. It is very easy to use: mov ax, 0x2400 int 0x15 Returns:CF = clear if success AH = 0 CF = set on error AH = status (01=keyboard controller is in secure mode, 0x86=function not supported) INT 0x15 Function 2401 - Enable A20 This function enables the A20 gate. mov ax, 0x2401 int 0x15 Returns:CF = clear if success AH = 0 CF = set on error AH = status (01=keyboard controller is in secure mode, 0x86=function not supported) INT 0x15 Function 2402 - A20 Status This function returns the current status of the A20 gate. mov ax, 0x2402 int 0x15 Returns:CF = clear if success AH = status (01: keyboard controller is in secure mode; 0x86: function not supported) AL = current state (00: disabled, 01: enabled) CX = set to 0xffff is keyboard controller is no ready in 0xc000 read attempts CF = set on error INT 0x15 Function 2403 - Query A20 support This function is used to query the system for A20 support. mov ax, 0x2403 int 0x15 Returns:CF = clear if success AH = status (01: keyboard controller is in secure mode; 0x86: function not supported) BX = status. BX contains a bit pattern: Bit 0 - 1 if supported on keyboard controller Bit 1 - 1 if supported on bit 1 of I/O port 0x92 Bits 2-14 - Reserved Bit 15 - 1 if additional data is available. Method 3: Keyboard Controller This is probably the most common method of enabling A20. Its quite easy, but requires some knowledge of programming the keyboard microcontroller. This will be the method I will be using as it seems it is also the most portable. Because this requires some knowledge of programming the keyboard microcontroller, we should look at that a little bit first. This is also the reason why I wanted to cover hardware programming first. This will be our first glimpse into direct hardware programming, and what it is all about. Don't worry, it's not too bad ðŸ˜‰ It can get quite complex at times though ðŸ˜ 8043 Keyboard Controller - Port Mapping Remember that -- in order for us to communicate with this controller, we must know what I/O ports the controller uses. This controller has the following port mapping: PORT MAPPING table Port Read/Write Description 0x60 Read Read Input Buffer 0x60 Write Write Output Buffer 0x64 Read Read Status Register 0x64 Write Send Command to controller We send commands to this controller by writing the command byte to I/O Port 0x64. If the command accepts a parameter, this parameter is sent to port 0x60. Likewise, any results returned by the command may be read from port 0x60. We must note that the keyboard controller itself is quite slow. Because our code will be executing faster then the keyboard controller, we must provide a way to wait for the controller to be ready before we continue on. This is usually done by querying for the controllers status. If this seems confusing, don't worry--everything will be clear soon enough. 8043 Keyboard Controller Status Register Okay, how do we get the status of the controller? Looking at the table above, we can see that we must read from I/O port 0x64. The value read from this register is an 8 bit value that follows a specific format. Here it is... Bit 0: Output Buffer Status 0: Output buffer empty, don't read yet 1: Output buffer full, please read me ðŸ˜ Bit 1: Input Buffer Status 0: Input buffer empty, can be written 1: Input buffer full, don't write yet Bit 2: System flag 0: Set after power on reset 1: Set after successful completion of the keyboard controllers self-test (Basic Assurance Test, BAT) Bit 3: Command Data 0: Last write to input buffer was data (via port 0x60) 1: Last write to input buffer was a command (via port 0x64) Bit 4: Keyboard Locked 0: Locked 1: Not locked Bit 5: Auxiliary Output buffer full PS/2 Systems: 0: Determines if read from port 0x60 is valid If valid, 0=Keyboard data 1: Mouse data, only if you can read from port 0x60 AT Systems: 0: OK flag 1: Timeout on transmission from keyboard controller to keyboard. This may indicate no keyboard is present. Bit 6: Timeout 0: OK flag 1: Timeout PS/2: General Timeout AT: Timeout on transmission from keyboard to keyboard controller. Possibly parity error (In which case both bits 6 and 7 are set) Bit 7: Parity error 0: OK flag, no error 1: Parity error with last byte As you can see, there is a lot going on here! The important bits are bolded above--they will tell us if the controllers output or input buffers are full or not. Here is an example. Lets say we send a command to the controller. This is placed in the controllers input buffer. So, as long as this buffer is still full, we know our command is still being performed. Here is what our code might look like: wait_input: in al,0x64 ; read status register test al,2 ; test bit 2 (Input buffer status) jnz wait_input ; jump if its not 0 (not empty) to continue waiting We will be needing to do this for both the input and output buffers. Now that we are able to wait for the controller, we must be able to actually tell the controller what we need it to do. This is done through command bytes. Lets take a look! 8043 Keyboard Controller Command Register Looking back at the I/O port table, we can tell that we need to write to I/O Port 0x64 to send commands to the controller. The keyboard controller has a lot of commands. Because this is not a tutorial on keyboard programming, I will not list them all here. However, I will list the more important ones: KEYBOARD CONTROLLER COMMANDS Table Keyboard Command Description 0x20 Read Keyboard Controller Command Byte 0x60 Write Keyboard Controller Command Byte 0xAA Self Test 0xAB Interface Test 0xAD Disable Keyboard 0xAE Enable Keyboard 0xC0 Read Input Port 0xD0 Read Output Port 0xD1 Write Output Port 0xDD Enable A20 Address Line 0xDF Disable A20 Address Line 0xE0 Read Test Inputs 0xFE System Reset Mouse CONTROLLER COMMANDS Table Mouse Command Description 0xA7 Disable Mouse Port 0xA8 Enable Mouse Port 0xA9 Test Mouse Port 0xD4 Write to mouse Again, please take note there are a lot more commands then this. We will look at them all later, don't worry ðŸ˜ Method 3.1: Enabling A20 through keyboard controller Notice the command bytes 0xDD and 0xDF in the above table. This is one way to enable A20 using the keyboard controller: ; Method 3.1: Enables A20 through keyboard controller mov al, 0xdd ; command 0xdd: enable a20 out 0x64, al ; send command to controller Not all keyboard controllers support this function. If it works, I would stick with it for its simplicity ðŸ˜‰ Method 3.2: Enabling A20 through Output Port Yet another method of enabling A20 is through the keyboard controllers output port. To do this, we need to use commands D0 and D1 to read and write the output port (Please see the Keyboard Controller Commands table again for reference.) This method is a little bit more complex then the other methods, but it is not too bad. Basically, we can disable the keyboard and read the output port from the controller. The 8042 contains thee ports: One is input, the other is output. Oh right... The third is for testing. These \"ports\" are just the hardware pins on the microcontroller. To keep things simple (And because this isn't a keyboard programming tutorial), we will just look at the output port for now. Okay... read from the output port, simply send the... erm ...read output port command (0xD0) to the controller: (Please see the keyboard controller commands table for reference) ; read output port into al mov al,0xD0 out 0x64,al Now we have gotten the output port data. Great, but that isn't very useful, is it? Well, actually the output port data follows ..yet again.. a specific bit format. Lets take a look... Bit 0: System Reset 0: Reset computer 1: Normal operation Bit 1: A20 0: Disabled 1: Enabled Bit 2-3: Undefined Bit 4: Input buffer full Bit 5: Output Buffer Empty Bit 6: Keyboard Clock 0: High-Z 1: Pull Clock Low Bit 6: Keyboard Data 0: High-Z 1: Pull Data Low Most of these bits we do not want to change. Setting bit 0 to 1 resets the computer; setting bit 1 enables gate A20. You should OR this value to set the bit to insure none of the other bits get touched. After setting the bit, just write the value back (Command byte 0xD1). The commands used to read and write the output port use the input and output buffers of the controller for its data. This means, if we read the output port, the data read will be in the controllers input buffer register. Looking back at the I/O port table, this means to get the data we read from I/O port 0x60. Lets look at an example. During any read or write operation, we will want to wait for the controller to be ready. wait_input waits for the input buffer to be empty, while wait_output waits for the output buffer to be empty. ; send read output port command mov al,0xD0 out 0x64,al call wait_output ; read input buffer and store on stack. This is the data read from the output port in al,0x60 push eax call wait_input ; send write output port command mov al,0xD1 out 0x64,al call wait_input ; pop the output port data from stack and set bit 1 (A20) to enable pop eax or al,2 ; 2 = 10 binary out 0x60,al ; write the data to the output port. ; This is done through the output buffer That's all there is to it! ðŸ˜ This method is a bit more complex then the other methods, but it is also the most portable. Cautions to look out for Because of it's emulation, most of these do not apply with Bochs, but to real hardware instead. Controller executes the wrong command If the controller executes the wrong command, it will usually do something you don't want. Like, perhaps, read data from a port instead of write data, which may corrupt your data. For example, using in al, 0x61 instead of in al, 0x60 , which will read from a different register in the keyboard microcontroller, instead of the status register (Port 0x60). Unknown Controller Command Most controllers ignore commands it does not know, and just discards it (Clears it's command register, if any.) Some controllers may malfunction, however. Please see the \"Malfunction\" section for more information. Controller Malfunctions This happens rarely, but is possible. Two notable instances are both with the Pentium processor, including the infamous FDIV and foof bugs. The FDIV bug was an internal CPU design flaw, in which the FPU inside the processor gives incorrect results. The foof problem is more series. When the processor is given the command bytes 0xf0 0x0f 0xc7 0xc8, which is an example of an Halt and Catch Fire (HCF) instruction. (An Undocumented Instruction ). Most of these instructions may lock up the processor itself, forcing the user to hard reboot. Others may cause unusual side effects from the use of these instructions. One should consider these problems that may happen. It does happen, and controllers are no exception. (Remember that we send instruction bytes to individual ports? For example, Port 0x64--The Command Register in the Keyboard Controller). Most of these malfunctions can easily be considered \"Design Flaws\" of the device, though. Physical Hardware damage Although also rare, it is possible to inflict hardware damage through software. An easy example is the floppy drive. You have to control the floppy drive motor directly through the Floppy Drive Controller (FDC) . Forgetting to send the command to stop the motor can cause the floppy drive to wear out and break. Be careful! Triple Fault The microcontroller may signal the primary processor that there is a problem via the Control Bus, in which case the processor signals an exception, which will, of course, reboot the computer. Controller problems in Bochs If there is a controller problem, Bochs will provoke a Triple fault, and log the information (The problem) into the log. For example, if you try to send an unknown command (Such as 0) to the keyboard controller: mov al, 0x00 ; some random command out 0x64, al ; try to send command to controller Bochs will provoke a triple fault, and log the information: [KBD ] unsupported IO write to keyboard port 64, value = 0 \"KBD\" represents that the log was written by the keyboard controller device. Demo All of the A20 code is in A20.inc . I wrote several different routines that uses different methods of enabling A20. So if one method fails, try using another method. Do to the increase in complexity, I have decided to have this demo downloadable. The current Stage2.asm has not changed that much either. Because the demo does not display anything new, there is not a new picture to display. Download the latest demo (*.ZIP: 8KB) Here . Conclusion Remember: This is the only way of communicating with hardware in protected mode! Good bye interrupts. Good bye BIOS. Good bye everything--we are now completely on our own. Right now, you can probably start appreciating Windows a little more ðŸ˜ After all, they all had to start at our level. Don't worry if you do not understand everything yet--It is complicated, I know. When we get to our Kernel, we are going to have an entire tutorial dedicated to programming the keyboard microcontroller, and writing a driver for it."
  },
  "articles/61_unorganised_tutorial/Z1.html": {
    "href": "articles/61_unorganised_tutorial/Z1.html",
    "title": "File Formats | BrokenThorn OS Dev Tutorials",
    "keywords": "File Formats"
  },
  "articles/61_unorganised_tutorial/Z1a.html": {
    "href": "articles/61_unorganised_tutorial/Z1a.html",
    "title": "Portable Executable (PE) | BrokenThorn OS Dev Tutorials",
    "keywords": "Portable Executable (PE) Welcome! Yey, this is going to be a long one. This chapter is going to cover an advanced topic - the PE executable file format. We will be looking at covering PE resources, dynamic linking, and more. This chapter is also planned for an update to include more information to make the information as complete as possible. Most of what is included in this chapter is for information purposes only and are only included both for completness and in case any of our readers would like to provide support for them. Also please note that a lot of the information provided can also be found in the official PE specification. After this chapter, we will have everything we need to develop a loader and support a single tasking environment. Lets get started! File Format Abstract The Portable Executable (PE) file format is the standard executable file format used in several operating systems, including Windows and Windows-like OSs, such as ReactOS. It is also the standard file format used with booting on Extensable Firmware Interface (EFI) machines. The PE executable file format is a complex format, supporting relocations, symbol tables, resources, dynamic binding, and more. Terms VA (Virtual Address) A Virtual Address (VA) is a linear address in the Virtual Address Space (VAS) of the current program. All addresses in the PE executable format are virtual addresses. These addresses are 32 bit linear addresses. RVA (Relative Virtual Address) A Relative Virtual Address (RVA) is a VA that is relative to the base address of the executable program. The PE executable format uses RVAs in a lot of areas, so it is important to know what RVAs are and how to obtain linear addresses from them. RVAs are just offsets from the base address, thats all. So to obtain its linear address, just add the RVA to the base: Linear address = Base address + RVA This one is important as we will need to perform this calculation in a lot of areas when parsing. Sections and the Section Table Sections Advanced executable file formats typically use program sections to simplify the linking process and provide structure to the software. Sections simplifies the linking process by providing a standard method for instructions and data to be stored within the executable image or object file. A section typically has a name associated with what elements are inside of the section. For example, .data is a common section name that contains variable, uninitialized data. Other section names have historical backgrounds. For example, .text is a typical name of a section containing executable or object code. .bss is typically used for global, program-wide initialized data. Using the C++ toolchain, for an example, variables defined in the global namespace or as static are stored in .bss . The resulting bytecode generated after compilation is stored in .text . The PE executable file format typically includes one or more of the following section names: .text .data .bss .arch .edata .idata .pdata .rdata .reloc .rsrc .sbss .sdata .srdata .xdata Section Table Program files and object files contain multiple sections. The base location of each section, and the name of that section, is typically stored in a section table . In some implimentations, a section table can be a simple linked list of structures or a hash table - different implimentations exist. Symbols and the Symbol Table Symbols While programming in C++, you most likley have encountered the unfamous Undefined symbol linker errors (or in some implimentations of C, warnings. Thats right, fully compiling and linking without error ahem old MSVC). This happens do to calling a function or referencing a variable by name whose definition could not be resolved during the linking stage. Functions and variables are referred to as symbols by the linker. A symbol contains the name, and information about what it is: such as a data type and value, for example. During compiling, the compilier must keep track of these symbols to insure that the final program can be linked. If a symbol is used that is not defined in the current translation unit , but is an EXTERN symbol, the compilier will need to mark it as an EXTERN symbol when writing the symbols to the object file. If, during the linking stage, a symbol marked EXTERN still has no value associated with it (the symbol has no definition), the linker issues the above error. Symbols are what allows programmers to define variables or functions across modules, translation units, or libraries. There can only be one symbol with the same name through the entire program, and any libraries that it links with. Because of this, and the high probability of naming collisions with the use of high level languages, variable and function names typically have name mangling applied. This, of course, does not apply to assembly language. The name mangling applied depends on multiple factors, and differ between toolchains. Lets take a look. Here are some C function declarations, and their mangled symbolic name on the right. The number in the mangled name is the number of bytes for the paramaters. void _cdecl function (int i); -> _function void _stdcall function(int i); -> _function@4 void _fastcall function(int i); -> @function@4 Notice that functions with the _cdecl call convention only have an underscore prepended. This allows C functions to be easily defined using assembly language, and allows C code to easily call those functions. There isnt any standard for C++ name mangling. Some compiliers might produce a symbolic name like **?h@@YAXH@Z**, while others can produce __7h__Fi or W?h$n(i)v for the same function of void h(int) . This makes it impractical to use with assembly language. It is still possible, however. Symbol table Simular to the section table there exists a symbol table . The symbol table allows a way for the software to look up symbolic names and information about the symbol, such as if its an exported symbol, its data type, properties, etc. Symbol tables are typically a linked list of information or implimented in hash tables. Structure Abstract (Structure) We have taken a look at the structure of the PE executable format in our MSVC++ chapter. When we load a PE executable in memory, that memory would contain an exact copy of our loaded file. This means the first byte within the first structure of the PE file format is actually located at the first byte from where the file was loaded in memory. For example, if we load a PE file to 1MB, the in-memory footprint might look like this: The above image should look famailier to our readers who have read the MSVC chapter. Looking at the above image, if the PE file was loaded to 1MB, then the first on-disk structure, IMAGE_DOS_HEADER, begins at that location in memory, followed by the rest of the structures in the file (including padding). The above image is also an oversimplification - it does not, by any means, show the complete PE file format. The structure of the PE file format is fairly large, composed of a lot of structures and tables. Here is the complete format: IMAGE_DOS_HEADER structure (Important) STUB program IMAGE_FILE_HEADER structure [COFF Header] (Important) IMAGE_OPTIONAL_HEADER structure (Important) Segment Table Resource Table Resident Name Table Module Reference Table Imported Names Table Entry Table Non Resident Name Table Segments Data Info The above table lists the complete file format - from beginning to end. Items marked important are required to know how to parse in order to just execute the program. All of the other information if provided for information purposes only. The only important members in IMAGE_OPTIONAL_HEADER structure are the member that contains the address of the entry point, and image base address. We will cover parsing each section of this file in detail in the upcoming sections. We will also introduce the other structures used when parsing tables and directories as well. IMAGE_DOS_HEADER structure IMAGE_DOS_HEADER is the first structure of the PE file. It contains global information about the program file and how to load it. Most of the information contained in this structure were more relivant to DOS software, and are only supported for backward compatability. The structure follows the format: typedef struct _IMAGE_DOS_HEADER { // DOS .EXE header uint16_t e_magic; // must contain \"MZ\" uint16_t e_cblp; // number of bytes on the last page of the file uint16_t e_cp; // number of pages in file uint16_t e_crlc; // relocations uint16_t e_cparhdr; // size of the header in paragraphs uint16_t e_minalloc; // minimum and maximum paragraphs to allocate uint16_t e_maxalloc; uint16_t e_ss; // initial SS:SP to set by Loader uint16_t e_sp; uint16_t e_csum; // checksum uint16_t e_ip; // initial CS:IP uint16_t e_cs; uint16_t e_lfarlc; // address of relocation table uint16_t e_ovno; // overlay number uint16_t e_res[4]; // resevered uint16_t e_oemid; // OEM id uint16_t e_oeminfo; // OEM info uint16_t e_res2[10]; // reserved uint32_t e_lfanew; // address of new EXE header } IMAGE_DOS_HEADER, *PIMAGE_DOS_HEADER; Alright, a lot of interesting things in this structure. The initial CS:IP and initial SS:SP members should be ignored as the operating system normally allocates a stack space and code descriptor value for CS. These members were more prominent during the DOS area and software requiring v8086 mode. STUB Program Okay then! Lets look back up at the PE file image structure again (The above picture.) Notice how a DOS stub program is right after the IMAGE_DOS_HEADER structure. This is a useful program, actually. This is the program that displays \"This program cannot be run in DOS Mode\", if you try to execute a Windows program from within DOS. We can change the stub program by using the /STUB linker option: /stub=myprog.exe When DOS attempts to load the executable, it will parse the IMAGE_DOS_HEADER structure and attempt to execute the DOS stub program because it is a valid DOS program. When running under the Win32 subsystem, the Windows loader will ignore the stub program. IMAGE_NT_HEADERS Following the STUB program is a structure, IMAGE_NT_HEADERS that contains the format of the PE header structures. Here is the structure: typedef struct _IMAGE_NT_HEADERS { DWORD Signature; IMAGE_FILE_HEADER FileHeader; IMAGE_OPTIONAL_HEADER OptionalHeader; } IMAGE_NT_HEADERS, *PIMAGE_NT_HEADERS; The signiture must match with \"PE\\0\\0\", where \\0\\0 are null characaters. The IMAGE_FILE_HEADER contains additional information used by the loader and the complete size of the IMAGE_OPTIONAL_HEADER structure. The IMAGE_OPTIONAL_HEADER is the largest and most important structure in the file. It also does not have a defined size. In order to locate this structure, the OS loader must use the e_lfanew member of IMAGE_DOS_HEADER. e_lfanew is an RVA to this structure in memory, so in order to locate this structure, the loader needs to perform the following: IMAGE_DOS_HEADER* pFile = (IMAGE_DOS_HEADER*) imageBase; IMAGE_NT_HEADERS* pHeaders = (IMAGE_NT_HEADERS*) (pFile->e_lfanew + imageBase); This assumes imageBase referres to the location where the program file was loaded into memory. Because older operating systems, such as DOS are not aware of this member of the header, it will be ignored by these OSs. This structure contains the format for the other two header structures. Lets look at the first of these structures. IMAGE_FILE_HEADER The IMAGE_FILE_HEADER is the Common Object File Format (COFF) header structure. It follows the following format: typedef struct _IMAGE_FILE_HEADER { USHORT Machine; USHORT NumberOfSections; // Number of sections in section table ULONG TimeDateStamp; // Date and time of program link ULONG PointerToSymbolTable; // RVA of symbol table ULONG NumberOfSymbols; // Number of symbols in table USHORT SizeOfOptionalHeader; // Size of IMAGE_OPTIONAL_HEADER in bytes USHORT Characteristics; } IMAGE_FILE_HEADER, *PIMAGE_FILE_HEADER; This structure isnt too complex. Most of the above is only useful for debuggers (symbol table parsing). SizeOfOptionalHeader is important - because IMAGE_OPTIONAL_HEADER does not have a defined size, this member lets you know the size of the structure. Machine can be one of the following values: 0x014c for x86 machines 0x0200 for x64 machines 0x8664 for AMD64 machines In the usual case, it should be 0x014c as we are developing for the x86 architecture. Characteristics is composed of bit flags that can be bitwise-ORd by the linker to let the loader know different properties of the type of executable image this is. Heres the format: Bit 0 : If set, image has no relocation information Bit 1 : If set, File is executable Bit 2 : If set, image has no COFF line numbers Bit 3 : If set, image has no COFF symbol table entries Bit 4 : If set, trim the working set for image. (Windows memory management specific. Obsolete) Bit 5 : If set, loader assumes executable can handle >2GB VAs Bit 6 : If set, loader assumes image supports 32 bit words Bit 7 : If set, image has no debug information Bit 8 : If set, image wont run directly from network drive (Windows specific) Bit 9 : If set, image is treated as a SYSTEM file Bit 10 : If set, image is treated as a DLL file Bit 11 : If set, image will only run on single-processor machines Bit 12 : If set, big-endian. obsolete flag The Windows headers use defined constants, such as IMAGE_FILE_RELOCS_STRIPPED and IMAGE_FILE_EXECUTABLE_IMAGE that can be used when setting these flags. As you can see, most of this structure is for information only for the loader on how to load the image. But wait! What about resources, symbol tables, debug info ... where is this at? Ah, behold the reason why IMAGE_OPTIONAL_HEADER does not have a defined size. Lets take a look! IMAGE_OPTIONAL_HEADER Ugh, here we go. This is the most complex structure in the file. The good news is that you probably have seen this structure before: struct _IMAGE_OPTIONAL_HEADER { USHORT Magic; // not-so-magical number UCHAR MajorLinkerVersion; // linker version UCHAR MinorLinkerVersion; ULONG SizeOfCode; // size of .text in bytes ULONG SizeOfInitializedData; // size of .bss (and others) in bytes ULONG SizeOfUninitializedData; // size of .data,.sdata etc in bytes ULONG AddressOfEntryPoint; // RVA of entry point ULONG BaseOfCode; // base of .text ULONG BaseOfData; // base of .data ULONG ImageBase; // image base VA ULONG SectionAlignment; // file section alignment ULONG FileAlignment; // file alignment USHORT MajorOperatingSystemVersion; // Windows specific. OS version required to run image USHORT MinorOperatingSystemVersion; USHORT MajorImageVersion; // version of program USHORT MinorImageVersion; USHORT MajorSubsystemVersion; // Windows specific. Version of SubSystem USHORT MinorSubsystemVersion; ULONG Reserved1; ULONG SizeOfImage; // size of image in bytes ULONG SizeOfHeaders; // size of headers (and stub program) in bytes ULONG CheckSum; // checksum USHORT Subsystem; // Windows specific. subsystem type USHORT DllCharacteristics; // DLL properties ULONG SizeOfStackReserve; // size of stack, in bytes ULONG SizeOfStackCommit; // size of stack to commit ULONG SizeOfHeapReserve; // size of heap, in bytes ULONG SizeOfHeapCommit; // size of heap to commit ULONG LoaderFlags; // no longer used ULONG NumberOfRvaAndSizes; // number of DataDirectory entries IMAGE_DATA_DIRECTORY DataDirectory[IMAGE_NUMBEROF_DIRECTORY_ENTRIES]; } IMAGE_OPTIONAL_HEADER, *PIMAGE_OPTIONAL_HEADER; First, take a look at that last member, DataDirectory . The constant, IMAGE_NUMBEROF_DIRECTORY_ENTRIES can, and has, changed through the years. This is that member that could change the size of this structure. We will look closer at that member a little later though as thats where all the fun stuff is at. You might be interested in why this is called an \"optional\" header even though its clearly not optional. This is due to it being optional for COFF object files. While its not optional for executable images, it is for object files :) magic can be one of the following: 0x10b: 32bit executable image 0x20b: 64bit executable image 0x107: ROM image In the usual case, it should be 0x10b . A lot of the members in this structure really arent that complex. The subsystem member is Windows-specific. It tells Windows what subsystem the program requires in order to execute properly. It can be one of the following values (posted here for completness only) 0: Unknown 1: Native SubSystem 2: GUI SubSystem 3: CUI SubSystem 5: OS/2 CUI SubSystem 7: POSIX CUI SubSystem 9: Windows CE GUI SubSystem 10: EFI 11: EFI Boot Driver 12: EFI Runtime Driver 13: EFI ROM 14: XBox 16: Boot application The DllCharacteristics member contains bit flags that gives the loader information about the DLL. It follows the following format: Bit 0-3 : reserved Bit 4 : If set, DLL is relocatable Bit 5 : If set, force code integrity checks Bit 6 : If set, image is Data Execution Prevention (DEP) compatable Bit 7 : If set, image should not be isolated Bit 8 : If set, image does not use Structured Exception Handling (SEH) Bit 9 : If set, image wont be binded Bit 10 : reserved Bit 11 : If set, image is a Windows Driver Model (WDM) driver Bit 12 : reserved Bit 13 : image is terminal server aware AddressOfEntryPoint is an important one. This member contains the RVA of the entry point function of the image (for DLLs this can be null as DLLs dont need entry points.) This is what our bootloader uses to call our entry point function in our kernel. Thats about all there is to it. You might be interested in what those other members are - for .text , .data , .bss etc. There is also that nasty looking DataDirectory member that we havnt looked at. We will look at those members closly later on. For now, lets look at executing a program! Executing a program At this stage, if all that you would like to do is execute a program , all of the information has been provided. After loading a program, all that the loader needs to do is locate the AddressOfEntryPoint member from the optional header, and call that address. Remember that this is an RVA, meaning the loader needs to add this address to the ImageBase to obtain the linear address to the entry point function. Here is an example: //! loadedProgram is where the image was loaded to IMAGE_DOS_HEADER* pImage = (IMAGE_DOS_HEADER*) loadedProgram; //! go to NT HEADERS IMAGE_NT_HEADERS* pHeaders = (IMAGE_NT_HEADERS*)(loadedProgram + pImage->e_lfanew); //! get image base and entry point address from optional header int base = pHeaders->OptionalHeader.ImageBase; int entryPoint = pHeaders->OptionalHeader.AddressOfEntryPoint; //! entry point function is at base+entryPoint void (*entryFunction) () = (entryPoint + base); //! call program entry point entryFunction(); Thats all that is needed to execute a PE executable :) Data Directories Abstract (Data Directories) Resources, symbol tables, debugging information, import, export tables etc are accessable from that nifty DataDirectory member of the optional header. This member is an array of IMAGE_DATA_DIRECTORY 's that can be used to access other structures containing this information. IMAGE_DATA_DIRECTORY has the format: typedef struct _IMAGE_DATA_DIRECTORY { DWORD VirtualAddress; // RVA of table DWORD Size; // size of table } IMAGE_DATA_DIRECTORY, *PIMAGE_DATA_DIRECTORY; Remember that DataDirectory is an array of IMAGE_DATA_DIRECTORY 's. Each entry in this array allows us to access the different data that we want to access. Here are the index entries: 0: Export directory 1: Import directory 2: Resource directory 3: Exception directory 4: Security directory 5: Base relocation table 6: Debug directory 7: Description string 8: Machine value (MIPS GP) 9: TLS directory 10: Load configuation directory 14: COM+ data directory For example, if you need to read the export table, reference DataDirectory[0] . If you want to read a resource, reference DataDirectory[2].VirtualAddress : Each of these sections contains their own structures that are required to parse the specific data. Lets take a look at some of the more useful ones. Reading the export table The export table contains all functions exported from libraries or DLLs, including their function addresses within that DLL, their names, and ordinal number. The Win32 API function GetProcAddress() works by parsing the modules export table by ordinal number or name and returning the address from it. This is one way reading the export table can be useful. To parse the export table, you need to first get the export directory structure. This is done by getting DataDirectory[0] . PIMAGE_DATA_DIRECTORY DataDirectory = &OptionalHeader->DataDirectory [0]; PIMAGE_EXPORT_DIRECTORY exportDirectory = (PIMAGE_EXPORT_DIRECTORY) (DataDirectory->VirtualAddress + ImageBase); Remember that VirtualAddress in the IMAGE_DATA_DIRECTORY structure is an RVA, so must be added to the image base. Now exportDirectory points to this nice structure: typedef struct _IMAGE_EXPORT_DIRECTORY { uint32_t Characteristics; uint32_t TimeDateStamp; uint16_t MajorVersion; uint16_t MinorVersion; uint32_t Name; uint32_t Base; uint32_t NumberOfFunctions; uint32_t NumberOfNames; uint32_t** AddressOfFunctions; uint32_t** AddressOfNames; uint16_t** AddressOfNameOrdinal; } IMAGE_EXPORT_DIRECTORY,*PIMAGE_EXPORT_DIRECTORY; This one is an easy one. AddressOfFunctions is an RVA that points to an array of function addresses. The function addresses, however are also RVAs. AddressOfNames is a pointer to a list of function names. All of these addresses are RVAs however so must be added to the image base in order to properly obtain the function name and address. AddressOfNameOrdinal is an RVA to a list of ordinals. The ordinals, being just numbers representing the exported functions and not addresses, arent RVAs. To properly parse the export table must be done in a loop. For example: PDWORD FunctionNameAddressArray = ((DWORD)ExportDirectory->AddressOfNames) + ((PBYTE)imageBase); PWORD FunctionOrdinalAddressArray = (DWORD)ExportDirectory->AddressOfNameOrdinal + (PBYTE)imageBase; PDWORD FunctionAddressArray = (DWORD)ExportDirectory->AddressOfFunctions + (PBYTE)imageBase; //! search for function in exports table for ( i = 0; i < ExportDirectory->NumberOfFunctions; i++ ) { LPSTR FunctionName = FunctionNameAddressArray [i] + (PBYTE)imageBase; if (strcmp (FunctionName, funct) == 0) { WORD Ordinal = FunctionOrdinalAddressArray [i]; DWORD FunctionAddress = FunctionAddressArray [Ordinal]; return (PBYTE) (FunctionAddress + (PBYTE)imageBase); } } This can be used to impliment GetProcAddress() which can be useful in supporting DLLs. Reading the import table So... reading the export table wasnt hard enough, huh? Reading the import table isnt too hard, but is a little more involved then the export table. Ok, ok, whats the use for reading the import table? Its not so much the reading, but the writing . By writing entries into a programs inport table, you can allow function calls across libraries and DLLs without the need of a GetProcAddress() call. Windows performs this with delayed loaded DLLs and system DLLs. In order to read the import table, you need to locate the import directory structure. This is at DataDirectory[1] : PIMAGE_DATA_DIRECTORY DataDirectory = &OptionalHeader->DataDirectory [1]; PIMAGE_IMPORT_DESCRIPTOR importDirectory = (PIMAGE_IMPORT_DESCRIPTOR) (DataDirectory->VirtualAddress + ImageBase); It is important to note that importDirectory points to an array of descriptor entries. Each of these entries represents a module that was imported, such as an import DLL. Lets take a look at this structure: typedef struct _IMAGE_IMPORT_DESCRIPTOR { union { uint32_t Characteristics; // 0 for terminating null import descriptor uint32_t OriginalFirstThunk; // RVA to INT }; uint32_t TimeDateStamp; // Time/Date of module, or other properties (see below) uint32_t ForwarderChain; // Forwarder chain ID uint32_t Name; // Module name uint32_t FirstThunk; // RVA to IAT (if bound this IAT has actual addresses) } IMAGE_IMPORT_DESCRIPTOR; typedef IMAGE_IMPORT_DESCRIPTOR *PIMAGE_IMPORT_DESCRIPTOR; Its important to note that Name, OriginalFirstThunk and FirstThunk are RVAs. This means you will need to add the addresses (these are pointers) to the image base in order to properly parse the data. Name is an RVA that points to the imported module name, such as kernel32.dll . It is null terminated. Remember that we are working with an array of import descriptors? How can we tell how many import descriptors that is in this array? The array ends with a null IMAGE_IMPORT_DESCRIPTOR, so an easy way to loop through each entry is this: IMAGE_IMPORT_DESCRIPTOR* lpImportDesc; while (! lpImportDesc->FirstThunk) { //! work with lpImportDesc here lpImportDesc++; // move to next entry } TimeDateStamp can be either the proper time/date or one of the following values: 0: module not bound -1: image is bound. Real time/date stamp stored ForwarderChain is only used when supporting DLL Forward Referencing , which allows calls across DLLs to be forwarded to other DLLs. For example, some calls in Windows kernel32.dll are forwarded to other DLLs. FirstThunk points to the IAT, OriginalFirstThunk points to an array of structures representing all imported functions. This is the Import Name Table (INT) . Both of these members are RVAs. Thunk? right, Im sure you know another structure is coming up. Lets take a look: typedef struct _IMAGE_THUNK_DATA { union { uint32_t* Function; // address of imported function uint32_t Ordinal; // ordinal value of function PIMAGE_IMPORT_BY_NAME AddressOfData; // RVA of imported name DWORD ForwarderStringl // RVA to forwarder string } u1; } IMAGE_THUNK_DATA, *PIMAGE_THUNK_DATA; OriginalFirstThunk are RVAs that point to an array of IMAGE_THUNK_DATA structures. Ugh, yey, another structure. This one is a small one though: typedef struct _IMAGE_IMPORT_BY_NAME { uint16_t Hint; // Possible ordinal number to use uint8_t Name[1]; // Name of function, null terminated } IMAGE_IMPORT_BY_NAME, *PIMAGE_IMPORT_BY_NAME; Thats all there is to it. The first paramater can be 0, but it just hints the loader what ordinal number the function might be using. Name is an array of characters representing the name of the function. Heres the deal: The IAT is just a list of addresses representing functions. What functions? The functions within this IMAGE_THUNK_DATA array. Look back at that IMAGE_THUNK_DATA structure and notice that its just an union representing a function name. This is the Import Name Table (INT) . For example, lets say we want to get the current address of the function thats in IMAGE_THUNK_DATA[3]. Its address will be the 3rd dword in the IAT, which can be read using IMAGE_IMPORT_DESCRIPTOR->FirstThunk . So, lets try to obtain the function name and address: unsigned int count=0; while (lpThunk->u1.Function) { //! get the function name char* lpFunctionName = (char*)((uint8_t*)imageBase + (uint32_t)lpThunk->u1.AddressOfData.Name); //! go into the IAT to get this functions address uint32_t* addr = (uint32_t*)((uint8_t*)imageBase + lpImportDesc->FirstThunk) + count; // lpFunctionName now points to the null terminated function name // addr now points to the address of this function count++; lpThunk++; } Image binding This is where things get interesting. The IAT can be filled with the addresses of the imported functions either during runtime or building time. A bounded image is an image that has its IAT bounded to the functions during build time. An unbounded image is an image whose IAT is filled in by the OS loader during loading time. If the image is bounded, you can do the following to call a function in an external DLL: __declspec (dllimport) void function (); function (); // calls myDll:function() If the image is not bounded, the IAT contains junk. It is then the responsbility of the OS loader to update the IAT in order for the above code to work. This can be performed by reading the export table of the loaded DLL module (calling GetProcAddress(), and overwriting the IAT entry of that import function. Overwriting the IAT can be done by following the above - when you get the functions IAT entry, just overwrite it :) This method can also be useful for installing hooks in DLLs and other modules. Supporting resources Introduction Have you ever wondered how the Windows kernel can display an image and work with an XML configuation file without loading anything from disk? Have you ever worked with adding resources but wondered if it was possible to support them in an OS? The answer is a \"yes, of course!\" Parsing resources is a bit more complex then the other directory types, however. Like the other sections, there is a base IMAGE_RESOURCE_DIRECTORY structure that can be obtained from the DataDirectory member of the optional header: PIMAGE_DATA_DIRECTORY DataDirectory = &OptionalHeader->DataDirectory [2]; PIMAGE_RESOURCE_DIRECTORY resourceDirectory = (PIMAGE_RESOURCE_DIRECTORY) (DataDirectory->VirtualAddress + ImageBase); Notice the pattern with how to access these sections? Oh, right, onto the new structure: typedef struct _IMAGE_RESOURCE_DIRECTORY { uint32_t Characteristics; uint32_t TimeDateStamp; uint16_t MajorVersion; uint16_t MinorVersion; uint16_t NumberOfNamedEntries; uint16_t NumberOfIdEntries; IMAGE_RESOURCE_DIRECTORY_ENTRY DirectoryEntries[1]; } IMAGE_RESOURCE_DIRECTORY, *PIMAGE_RESOURCE_DIRECTORY; This structure doesnt have much of any interesting fields, except the last three. If you have worked with Win32 resources, you might know that resources can be idenitified by ID or name. Two of the members in this structure will let us know the number of these entries, and the total amount of entries (NumberOfNamedEntries + NumberOfIdEntries), which is useful in looping through all of the entries. As you can probably guess, the entries are in the DirectoryEntries array. DirectoryEntries consists of an array of IMAGE_RESOURCE_DIRECTORY_ENTRY structures, which follow the format: typedef struct _IMAGE_RESOURCE_DIRECTORY_ENTRY { union { struct { DWORD NameOffset:31; DWORD NameIsString:1; }; DWORD Name; WORD Id; }; union { DWORD OffsetToData; struct { DWORD OffsetToDirectory:31; DWORD DataIsDirectory:1; }; }; } IMAGE_RESOURCE_DIRECTORY_ENTRY, *PIMAGE_RESOURCE_DIRECTORY_ENTRY; Alright, this is an ugly structure. This structure represents a single resource, or resource directory. Resource directory structure resource or resource directory? Lets stop for a moment. ( grabs a cup of coffee ) ok, it is important to know that resources are stored as a tree . This tree is structured like this: Root directory Resource group 1 Directory Resource 1 Resource 2 Resource group 2 Directory Resource 1 Resource 2 Resource group 3 Directory Resource 1 Resource 2 ...etc... There are a number of different resource groups which let us know the type of resources are in this group. Here are the group IDs: 1 - Cursor 2 - Bitmap 3 - Icon 4 - Menu 5 - Dialog 6 - String 7 - Font directory 8 - Font 9 - Accelerator 10 - RcData 11 - Message table 16 - Version 17 - DlgInclude/li> 19 - Plug and Play 20 - VXD 21 - Animated Cursor 22 - Animated Icon 23 - HTML 24 - Manifest In order to locate a resource, you will need to traverse this tree. The good news is that this isnt hard if you assume there is only 3 layers in the tree. First, lets look at looping through all of the entries in a resource directory: //! get first entry in directory IMAGE_RESOURCE_DIRECTORY_ENTRY* lpResourceEntry = lpResourceDir->DirectoryEntries; //! loop through all entries int entries = lpResourceDir->NumberOfIdEntries + lpResourceDir->NumberOfNamedEntries; while (entries-- != 0) { //! look for bitmap resource (id=2) if (lpResourceEntry->Id == 2) { //! see below } lpResourceEntry++; } This is simple enough, huh? The Id member of IMAGE_RESOURCE_DIRECTORY_ENTRY is used to store the group ID. If we were looking for a bitmap, it would be in the bitmap group of the root directory, so look for the entry with ID=2. Because IMAGE_RESOURCE_DIRECTORY_ENTRY represents both resource entries and directories, how can we tell what it is? Why, the DataIsDirectory member of course: If this member is set, its a directory. Ah, but if its a directory, how can you read the directory? Lets take a look: if (lpResourceEntry->DataIsDirectory) { lpResourceEntry = lpResourceEntry->OffsetToDirectory; lpResourceEntry += startOfResourceSection; } This one isnt to bad. If the entry is a directory, the above obtains the offset to the new directory from the OffsetToDirectory and adds it to .. what? the startOfResourceSection !? Thats right... this is an offset, but not an RVA. I know ... Why Microsoft, Why!? The start of the resource section is actually the address of the first member of the IMAGE_RESOURCE_DIRECTORY_ENTRY array. So by adding this address to the offset obtained from OffsetToDirectory you can obtain the pointer to the IMAGE_RESOURCE_DIRECTORY structure for this directory. Yes, then the whole process of reading those directory entries begins :) If you are in the process of parsing the directory for your specific resource, just loop through all of the resource entries in the directory. If the resourceEntry ID field matches that of the resource ID you are trying to find (program specific ID here), then you have found the resource data. The resource data is stored in a ... zomg! structure! It can be obtained from the OffsetToData member of the directory entry structure. Simular to the OffsetToDirectory member, this too is an offset from the start of the resource section. Once you obtained the pointer, you can extract the resource data. Lets take a look at that structure: typedef struct _IMAGE_RESOURCE_DATA_ENTRY { uint32_t OffsetToData; uint32_t Size; uint32_t CodePage; uint32_t Reserved; } IMAGE_RESOURCE_DATA_ENTRY, *PIMAGE_RESOURCE_DATA_ENTRY; Thats it! OffsetToData is an RVA to the real resource data, and Size is the size of that data, in bytes. For example, if we were looking for a bitmap resource, OffsetToData would be the RVA pointing to the bitmaps BITMAPINFOHEADER structure, which can be handled by any bitmap loader. Conclusion Thats all for this chapter. There are some planned updates to including covering additional sections (debug data and COMDATS) as well. There is no demo for this chapter - it is primarily released for anyone that is interested in the internal workings of the PE executable file format and working with it. For the main series, we might only be loading and executing the program, so all of the other information is provided for completeness only. All code provided in text for demenstration has been tested (slightly modified) to work. In the upcoming chapters, we will be using the PE executable file format and building a loader for supporting user mode programs. After that, on to multitasking!"
  },
  "articles/61_unorganised_tutorial/Z2.html": {
    "href": "articles/61_unorganised_tutorial/Z2.html",
    "title": "Microcontrollers | BrokenThorn OS Dev Tutorials",
    "keywords": "Microcontrollers"
  },
  "articles/61_unorganised_tutorial/Z2a.html": {
    "href": "articles/61_unorganised_tutorial/Z2a.html",
    "title": "8259A PIC Microcontroller | BrokenThorn OS Dev Tutorials",
    "keywords": "8259A PIC Microcontroller 8259A PIC Microcontrollers with all pins labeled. This tutorial covers a very important topic: The Programmable Interrupt Controller . We will need to initialize this microcontroller by mapping it to our IRQ's. This will be needed when setting up interrupts, and handling interrupt requests. This is our first controller tutorial. All of these controller tutorials go very deep in each device, while building a workable interface to handling them. Remember that, as we are in protected mode, we have nothing to guide us. One wrong move can cause unpredictable results. As we have no helping hand, we have to communicate with each controller directly. Because of this, we have emphasized hardware programming concepts all throughout this series so our readers have more experience and better understanding of hardware level programming. This tutorial puts everything we learned to the test. I will do my best to keep things simple. the 8259A Microcontroller , Also known as the Programmable Interrupt Controller (PIC) . Get Ready This is our first of many microcontroller programming tutorials. We will cover nearly every asset of each microcontroller as we cover them. The main series will reference these tutorials on an as needed bases to help cover what we need these controllers for. This tutorial is fairly complicated. We will cover the 8259A Microcontroller from both hardware and software perspectives, and understand exactly how it connects and interacts with the PC. We will also cover every command, register, and part of this microcontroller. History To do - We plan on adding this section soon Because the 8259A PIC handles hardware interrupts, we should first have a basic understanding of what interrupts are, and how they work. Interrupts An Interrupt is an external asynchronous signal requiring a need for attention by software or hardware. It allows a way of interrupting the current task so that we can execute something more important. Not to hard. Interrupts provide a way to help trap problems, such as divide by zeros. If the processor find a problem with the currently executing code, it provides the processor alternative code to execute to fix that problem. Other interrupts may be used to provide a way to service software as routines. These interrupts can be called by any software from within the system. This is used a lot for System API's, which provide a way for ring 3 applications to execute ring 0 level routines. Interrupts provide a lot of use, especially as a way of receiving information from hardware that may change its state at asynchronous times. Interrupt Types There are two types of interrupts: Software Interrupts and Hardware Interrupts . Software Interrupts Software Interrupts are interrupts implemented and triggered in software. Normally, the processor's instruction set will provide an instruction to service software interrupts. For the x86 architectures, these are normally INT imm , and INT 3 . It also uses IRET and IRETD instructions. For example, here we generate an interrupt through a software instruction: int 3 ; generates interrupt 3 These instructions may be used to generate software interrupts and execute Interrupt Routines (IR)'s through software. We will not cover software interrupts here. The 8259A PIC Microcontroller only services hardware interrupts. Software interrupts will be covered in another tutorial. Hardware Interrupts A hardware interrupt is an interrupt triggered by a hardware device. Normally, these are hardware devices that require attention. The hardware Interrupt handler will be required to service this hardware request. Spurious Interrupt : This is a hardware interrupt generated by electrical interference in the interrupt line, or faulty hardware. We do NOT want this! Interrupt Modes There are several modes and classes of interrupts that we will need to cover. In programming the PIC, we will need to choose a mode. Note: This section may require some knowledge of the 8259A PIC hardware pin layout. this is discussed in the next section. Level Triggered A Level Triggered interrupt is determined to happen when the Interrupt Request (IR) line on the PIC has current (1). A device sends a signal (Setting this line to active), and keeps it at that state until the interrupt is serviced. Level Triggered interrupt lines may be shared by multiple interrupts if the circuit is designed to handle it. This mode is the preferred mode because of how the lines are shared. When an IR line is active, the CPU searches through all of the devices sharing the same line until it finds what device is activating the signal. After finding the device, the CPU rechecks all of the devices again to insure there are no other devices that also need service. A problem with this approach is, if there is an interrupt with higher priority that needs to be serviced, all other interrupts will be permanently blocked until the other interrupts are serviced. After all, only one line can be active at a given time. Edge Triggered Edged Triggered interrupts are determined to happen when the Interrupt Request (IR) line on the PIC has current (1). A device sends a signal (Setting this line to active) through a single pulse, and returns the line to its previous state. Edged Triggered interrupt lines may be shared by multiple interrupts if the circuit is designed to handle it. If the pulse is too short to be detected, then it will not be detected. As these are only pulses of current that signals interrupt requests, Edged triggered mode does not have the same problems that Level triggered does with shared IRQ lines. Of course, we still run into the possibility of an interrupt being missed, as it is just a single pulse of current being sent through the IRQ line. This has caused early computer lockups of the CPU. However, through recent times, these lockups have decreased through time. Hybrid Both of these modes have their pros and cons. a lot of systems implement a hybrid of both of them. More specifically, Most systems check for both Edge triggered and Level triggered interrupts on the Non Maskable Interrupt (NMI) pin on the CPU. The purpose of this is that the NMI pin is used to signal major problems with the system that can cause big problems, or entire system malfunctions, possibly hardware damage. The Non Maskable Interrupt is just that -- It cannot be disabled or masked off by any device. This insures, along with having a hybrid setup, that if the NMI pin is set, the system can die peacefully without big problems. Message Signaled These types of hardware interrupts do not use a physical interrupt line. Instead, they rely on another medium, such as the system bus, to send messages over. These types of interrupts cause the device to only send a pulse of current over the medium, similar to edge triggered interrupts. These types of systems may use a special interrupt line on its control bus indicating a message signaled interrupt number. As these numbers are sent over the medium as a series of bits, they do not have the limitations of the other interrupt types, which are limited to a single interrupt line. As such, they can manage as much interrupts as the underlaying system allows. These types of interrupts also support sharing of interrupt vectors. PCI Express uses these types of interrupts a lot. Thats all Okay, a lot of info here ðŸ˜€ The 8259A only has support for Level triggered and Edge triggered interrupts. Because of this, Those should be your primary focus when working with the 8259A Microcontrollers. Interrupt Vector Table The Interrupt Vector Table (IVT) is a list of Interrupt Vectors . There are 256 Interrupts in the IVT. Interrupt Routines (IR) An Interrupt Routine (IR) is a special function used to handle an Interrupt Request (IRQ) . When the processor executes an interrupt instruction , such as INT , it executes the Interrupt Routine (IR) at that location within the Interrupt Vector Table (IVT) . This means, it simply executes a routine that we define. Not to hard, huh? This special routine determines the Interrupt Function to execute normally based off of the value in the AX register. This allows us to define multiple functions in an interrupt call. Such as, the DOS INT 21h function 0x4c00. Remember: Executing an interrupt simply executes an interrupt routine that you created. For example, the instruction INT 2 will execute the IR at index 2 in the IVT. Cool? IVT Map The IVT is located in the first 1024 bytes of physical memory, from addresses 0x0 through 0x3FF. Each entry inside of the IVT is 4 bytes, in the following format: Byte 0: Offset Low Address of the Interrupt Routine (IR) Byte 1: Offset High Address of the IR Byte 2: Segment Low Address of the IR Byte 3: Segment High Address of the IR Notice that each entry in the IVT simply contain the address of the IR to call. This allows us to create a simple function anywhere in memory (Our IR). As long as the IVT contains the addresses of our functions, everything will work fine. Okay, Lets take a look at the IVT. The first few interrupts are reserved, and stay the same. x86 Interrupt Vector Table (IVT) Base Address Interrupt Number Description 0x000 0 Divide by 0 0x004 1 Single step (Debugger) 0x008 2 Non Maskable Interrupt (NMI) Pin 0x00C 3 Breakpoint (Debugger) 0x010 4 Overflow 0x014 5 Bounds check 0x018 6 Undefined Operation Code (OPCode) instruction 0x01C 7 No coprocessor 0x020 8 Double Fault 0x024 9 Coprocessor Segment Overrun 0x028 10 Invalid Task State Segment (TSS) 0x02C 11 Segment Not Present 0x030 12 Stack Segment Overrun 0x034 13 General Protection Fault (GPF) 0x038 14 Page Fault 0x03C 15 Unassigned 0x040 16 Coprocessor error 0x044 17 Alignment Check (486+ Only) 0x048 18 Machine Check (Pentium/586+ Only) 0x05C 19-31 Reserved exceptions 0x068 - 0x3FF 32-255 Interrupts free for software use Not to hard. Each of these interrupts are located at a base address within the IVT. Interrupt Handling in Protected Mode (PMode) Protected Mode requires each IVT entry to point to an interrupt routine (IR) defined within an Interrupt Descriptor Table (IDT) . The IDT will be explained further in another tutorial, as it is not directly related to this tutorial. The IDT is an array of Interrupt Descriptors , that describe the base address of the Interrupt Routine (IR) to execute, that contains extra information about it's protection level, segment information, etc. PMode uses a Global Descriptor Table (GDT) that defines the memory map that is being used. Most of the interrupt routines will be inside of a code descriptor, mapped by the GDT. This is why the IDT is required in PMode. Do not worry if you do not understand this right now. For now, just think of it as an array of 256 function pointers, mapped exactly like that of the IVT (It normally is, anyways.) Hardware Interrupts (Detailed) There are two types of interrupts, those generated by software (Usually by an instruction, such as INT, INT 3, BOUND, INTO ), and an interrupt generated by hardware. Hardware interrupts are very important for PC's. It allows other hardware devices to signal the CPU that something is about to happen. For example, a keystroke on the keyboard, or a single clock tick on the internal timer, for example. We will need to map what Interrupt Request (IRQ) to generate when these interrupts happen. This way, we have a way to track these hardware changes. Lets take a look at these hardware interrupts. x86 Hardware Interrupts 8259A Input pin Interrupt Number Description IRQ0 0x08 Timer IRQ1 0x09 Keyboard IRQ2 0x0A Cascade for 8259A Slave controller IRQ3 0x0B Serial port 2 IRQ4 0x0C Serial port 1 IRQ5 0x0D AT systems: Parallel Port 2. PS/2 systems: reserved IRQ6 0x0E Diskette drive IRQ7 0x0F Parallel Port 1 IRQ8/IRQ0 0x70 CMOS Real time clock IRQ9/IRQ1 0x71 CGA vertical retrace IRQ10/IRQ2 0x72 Reserved IRQ11/IRQ3 0x73 Reserved IRQ12/IRQ4 0x74 AT systems: reserved. PS/2: auxiliary device IRQ13/IRQ5 0x75 FPU IRQ14/IRQ6 0x76 Hard disk controller IRQ15/IRQ7 0x77 Reserved You do not need to worry to much about each device just yet. The 8259A Pins will be described in detail within the next section. The Interrupt Numbers listed in this table are the default DOS interrupt requests (IRQ) to execute when these events trigger. In most cases, we will need to recreate a new interrupt table. As such, most operating systems need to remap the interrupts the PIC's use to insure they call the proper IRQ within their IVT. This is done for us by the BIOS for the real mode IVT. We will cover how to do this later in this tutorial as well. 8259 Programmable Interrupt Controller The 8259 Microcontroller familiy is a set of Programmable Interrupt Controller (PIC) Integrated Circuits (ICs) . Look back again at Tutorial 7 ... Under the Processor Architecture section, Notice that the processor has it's own internal PIC Microcontroller. This is very important to note. Do to limitations in the circuit design, a PIC only supports 8 IRQ's . This is a big limitation. As additional devices were created, IBM quickly realized that this limitation is very bad. Because of this, Most motherboards contain a secondary (Slave) PIC microcontroller to work with the primary PIC inside the processor. Today, this is very common. A single PIC can be \"cascaded\" (capable of working with) another PIC. This makes it possible to support more IRQ's with additional PICs. The More PIC's supported, the more IRQ's can be handled. They can be cascaded to support up to 64 IRQ's. Cool? Remember: Most computers have 2 PIC's, 1 inside the processor, and 1 on the motherboard. Some systems may not have this. Remember: Each PIC can only support up to 8 IRQ's. Remember: Each PIC can communicate with each other, allowing up to 64 IRQ's depending on the number of PIC's. Not to hard ðŸ˜€ 8259 Hardware Understanding how microcontrollers work at the hardware level will help in understanding how the software side of things work. Remember that the PIC's are only used during a hardware interrupt. 8259A Microcontroller At the top of this tutorial, there is an image of an actual 8259 Dual Inline Package (DIP) , with all of the electronic pins labeled. To make things more understandable, we are going to represent the controller using a simpler graphic. The only pins these graphics do not display that the 8259 has are GND (Ground) and Vcc (Input Voltage). You can see these pins labeled in the picture on the top of this tutorial. Lets first look at what we are going to be programming: That's it. The 8259A Programmable Interrupt Controller. Each of the lines in the above image displays each of the controllers electronic pins. These electronic pins are the connections between the controller and the rest of the system. This is the chip that we will need to program in order to handle IRQ's within an operating system. Let's look at this closer at each pin. I bolded the important pins. WR Pin: This pin connects to a write strobe signal (One of 8 on a Pentium) RD Pin: This connects to the IOCR (Input Output Control Routine) signal. INT Pin: Connects to the INTR pin on the microprocessor. INTA Pin: Connects to the INTA pin on the microprocessor. A0 Pin: Selects different Command WORDS CS Pin: Enables the chip for programming and control. SP/EN Pin: Slave program (SP) / Enable Buffer (EN). Slave Program (1=Master, 0=Slave) Enable Buffer (Controls data bus transceivers when in buffered mode) CAS0, CAS1, CAS2 Pins: Used to output from master to slave PIC controllers in cascaded systems. D0 - D7 Pins: 8 bit Data connector pins. There are a couple of important pins here. Pins D0-D7 provide a way for an external device to communicate with the PIC. This is like a small data bus--It provides a way to send data over to the PIC, like...An interrupt number, perhaps? Remember that we can connect PIC's together. This allows us to provide support for up to 64 IR numbers. In other words--64 hardware interrupts. CAS0, CAS1, and CAS2 pins provide a way to send signals between these PIC's. Look at the INT and INTA pins. Remember from the Processor Perspective section that the processors' own INT and INTA pins connect to these pins on the PIC. Remember that, when about to execute an interrupt, the processor clears the Interrupt (IF) and Trap flags (TF) from the FLAGS register, which disables the INTR pin. The PIC's INT pin connects to the processors' INTR pin. This means that the processor, essentially, disables the PIC's INT pin when executing an interrupt. With this, the pins IR0-IR7 can be streamed to other PIC's. These 8 pins represent the 8 bit interrupt number to be executed. Notice that this, as being an 8 bit value, provides a way to allow up to 256 hardware interrupts. these lines provide a way to send the interrupt number to another PIC controller, so that controller could handle it instead. The important thing to note is that We can combine multiple PIC's to support more interrupt routine numbers. The IR lines connect to another PIC's data lines to transfer data over. As there are only 8 lines (8 bits), we can only connect up to 8 PIC's together, providing support for up to 64 interrupt numbers. Okay... a lot of stuff here, huh? We have described how the processor connects to the primary PIC, and how the PIC's can combine with other PIC's to create a chain of PIC's. This is great, but completely useless. How does an interrupt execute through hardware? What makes this controller \"programmable\"? How can we program the PIC to work for our needs? Programming the PIC revolves around the use of sending Command Bytes through the 8 bit data line that the PIC's have. This 8 bit command byte follows specific formats that describe what the PIC is to do. We will need to know these commands in order to program the PICs. We w8ill cover this later. Lets take a closer look at how the PIC works. This will help in better understanding of the 8259A pins, and how interrupt signals are sent. 8259A Connections Note: This section may require some knowledge in Digital Logic Electronics. Okay... So far we have looked at the 8259A PIC pins. Lets try to look at these pins from another perspective, and see what it looks like within a typical computer. Connecting the PICs to the processor First, remember when I said that most computers today have 2 8259A PICs? This is only half true. Remember from the Processor Architecture that the primary PIC is integrated into the processor. There is a reason for this, as you will soon see. To make things simple, lets imagine the system we are on actually have 2 PIC controllers, both directly on the motherboard (None of them are integrated with the processor.) Looking at this graphically, this is what we might see: Okay... There is a lot going on here. This displays a part of the IO Subsystem and ISA bus, and how the 8259A controllers connect to the system bus through the common 16L8. Do not worry at all if you do not understand this, as digital logic electronics is not a prerequisite for this series ;) This image is also missing more details as well. Nonetheless, it displays the basic links and connections between the components. Looking at the above image, there are a few important notes.**Notice how the slave controller connects to the primary controller.** Notice that only the primary PIC needs direct connection with the processor. Because of this tight integration, modern computers usually have the primary PIC integrated directly inside of the processor to eliminate this dependency. Also notice how the CAS0-CAS2 pins directly connect to the second PIC. This allows the primary PIC to send commands to the secondary PIC. And, as we all know, the IR lines connect to other controllers that control that line. For example, Hardware Interrupt 0 represents a timer interrupt. The 8254 Programmable Interval Timer (PIT) Controller will send a signal through the IR0 line to the primary PIC, as it is directly connected to it. This signal will either be a current that stays active until the interrupt has been serviced, or may be a single pulse that is held for a certain time. We can control what we want the PIC to watch for. This is described in more detail later. So...There you have it ðŸ˜€ The infamous 8259A PIC Microcontroller. How hardware interrupts execute On the underside of all microprocessors contain connectors. These can be flat, or in the form of pins, that connects to the motherboard. Two of these pins are the INTR and NMI pins. With this, there is another pin for acknowledges the completion of the interrupt - INTA. Software interrupts are handled differently then hardware interrupts. Both of these types of interrupts are inside of the Interrupt Vector Table located at address 0 through 0x3ff in memory. Remember: Only hardware interrupts are handled through the Programmable Interrupt Controller. The interrupt is generated When a device controller needs to generate an interrupt, it needs to signal the PIC somehow. Lets say, for purposes of discussion, that this device is the timer, which uses interrupt line 0. The timer controller signals the PIC by activating the IR0 line. This changes its state from a 0 (No power) to a 1 (Power is going through the line.) The PIC sets the bit representing the IRQ inside of the Interrupt Request Register (IRR) . In this example, bit 0 will be set to 1. The PIC examines the Interrupt Mask Register (IMR) to see if the interrupt can be serviced. If the interrupt can be serviced, the PIC determines if there are any higher priority interrupts waiting to be serviced. If there is, the interrupt request is ignored until the higher priority interrupts are serviced. If the interrupt can be serviced, and there are no higher priority interrupts, the PIC continues to the next step. The PIC signals the processor through the INTA pin to inform the processor an interrupt has been fired. The processor now knows that an interrupt has been fired. The processor acknowledges the interrupt The CPU completes execution of the current instruction. The CPU examines the Interrupt Flag (IF) within RFLAGS . If IF is set, the CPU acknowledges the interrupt request through the INTR pin back to the PIC. If IF is cleared, the interrupt request is ignored. The PIC receives the acknowledgment signal through INTR. The PIC places the interrupt vector number into the D0-D7 pins. This interrupt vector number is obtained from the Initialization Control Word (ICW) 2 during initialization of the PIC. We will cover this later. The PIC also places the IRQ number into D0-D7 The PIC sets the correct bit inside of the In Service Register (ISR) . In this case, it is bit 0. This indicates that Interrupt 0 is currently being serviced. Now the processor has the IRQ number and the interrupt vector number to execute. Interruption The processor interrupts the current process. It pushes EFLAGS, CS, and EIP on the stack. The processor uses the interrupt vector number (given by the PIC). In real mode, the CPU offsets into the IVT. In Protected Mode, The Processor offsets into the IDT. Real Mode: The CPU offsets into the correct entry into the IVT The CPU loads the base address of the interrupt to call into CS:IP The interrupt takes control. Protected Mode: The CPU uses the loaded IDT to offset into The selector field of the gate descriptor is loaded into the CS segment selector. The offset field of the gate descriptor is loaded into EIP. If paging is enabled, this address is translated from a linear address to a physical address. Now, the CPU will perform architecture specific security checks on the current state. The interrupt routine can now take control from gate descriptor + CS:EIP. The Interrupt Service Routine Now the ISR is executing to handle the hardware interrupt. It can perform whatever action needed to service the specific device. For example, reading or writing data to/from the device, reading status registers, sending commands, et al. During this time, all interrupts are masked out by the Interrupt Mask Register (IMR) . In other words, this disables all hardware interrupts until a request has been made to end the interrupt. this requires an End of Interrupt (EOI) command to be sent to the PIC. After the EOI signal has been sent to the PIC through the Primary PIC's Command Register , The PIC clears the appropriate bit in the In Service Register (IRR) , and is now ready to service new interrupts. the interrupt service routine then performs a IRETD instruction, popping EFLAGS, CS, and EIP registers, which were pushed by the processor when the interrupt was fired. This transfers control back to the initial task. 8259A Registers The 8259A has several internal registers, similar to the processor. Command Register This is a write only register that is used to send commands to the microcontroller. There are a lot of different commands that you can send. Some commands are used to read from other registers, while other command are used to initialize and sending data, such as End of Interrupt (EOI). We will cover these commands later. Status register This is a read only register that can be accessed to determine the status of the PIC. Interrupt Request Register (IRR) This register specifies which interrupts are pending acknowledgment. Note: This register is internal, and cannot be accessed directly. Interrupt Request Register Table Bit Number IRQ Number (Primary controller) IRQ Number (Slave controller) 0 IRQ0 IRQ8 1 IRQ1 IRQ9 2 IRQ2 IRQ10 3 IRQ3 IRQ11 4 IRQ4 IRQ12 5 IRQ5 IRQ13 6 IRQ6 IRQ14 7 IRQ7 IRQ15 If a bit is set, the interrupt has been signaled by a device, and the PIC has signaled the CPU, but is awaiting acknowledgment from the CPU to go ahead with the interrupt. In-Service Register (ISR) This register specifies which interrupts have already been acknowledged, but are awaiting for the End of Interrupt (EOI) signal. The EOI signal is very important as it determines the end of an interrupt. Note: We will need to send the EOI signal upon completion of the interrupt to let the 8259A acknowledge the interrupt. Not doing so will result in undefined behavior or malfunction. More on this later. Note: This register is internal, and cannot be accessed directly. In Service Register Table Bit Number IRQ Number (Primary controller) IRQ Number (Slave controller) 0 IRQ0 IRQ8 1 IRQ1 IRQ9 2 IRQ2 IRQ10 3 IRQ3 IRQ11 4 IRQ4 IRQ12 5 IRQ5 IRQ13 6 IRQ6 IRQ14 7 IRQ7 IRQ15 If a bit is set, the current IRQ has been acknowledged by the CPU to go ahead and begin executing. The PIC uses this register to determine what IRQ is currently being executed. Interrupt Mask Register (IMR) This specifies what interrupts are to be ignored, and not acknowledged. this allows us to focus on executing certain, more important interrupts before executing the interrupts specified in this register. This is an 8 bit register, where each bit determines if an interrupt is disabled or not. If the bit is 0, it is enabled. If it is a 1, the interrupt device is disabled. Interrupt Mask Register Table Bit Number IRQ Number (Primary controller) IRQ Number (Slave controller) 0 IRQ0 IRQ8 1 IRQ1 IRQ9 2 IRQ2 IRQ10 3 IRQ3 IRQ11 4 IRQ4 IRQ12 5 IRQ5 IRQ13 6 IRQ6 IRQ14 7 IRQ7 IRQ15 This is an important register, as it allows us to enable and disable interrupts from certain devices. Each of these IRQ's represent the device listed in the x86 Hardware Interrupts table shown above. For example, lets say we want to enable COM1 (Serial Port 1). Looking at the x86 Hardware Interrupt Table, we can see that this is mapped to IRQ 4. So, in order to enable COM1 interrupts, all we need to do is set the IRQ4 bit for the primary PIC's Interrupt Mask Register. This register is mapped to the software port number 0x21 (We will cover this later.) So, all we need to do is set the bit by writing to this port location. in al, 0x21 ; read in the primary PIC Interrupt Mask Register (IMR) and al, 0xEF ; 0xEF =11101111b. This sets the IRQ4 bit (Bit 5) in AL out 0x21, al ; write the value back into IMR Too cool for school ðŸ˜ When a hardware interrupt occurs, The 8259A Masks out all other interrupts until it receives an End of Interrupt (EOI) signal. We will need to send the EOI upon completion of the interrupt. We will look at this later. 8259A Software Port Mappings Like all hardware controllers, the BIOS POST maps each controller to use a specific region of software ports. Because of this, in order to communicate with the PIC controllers, we need to use software ports. 8259A Software Port Map Port Address Description 0x20 Primary PIC Command and Status Register 0x21 Primary PIC Interrupt Mask Register and Data Register 0xA0 Secondary (Slave) PIC Command and Status Register 0xA1 Secondary (Slave) PIC Interrupt Mask Register and Data Register Notice the Primary PIC's Interrupt Mask Register is mapped to Port 0x21. We have seen this before, haven't we? The Command Register and Status Register are to different registers that share the same port number. The command register is write only, while the status register is read only. This is an important difference, as the PIC determines what register to access depending on weather the write or read lines are set. We will need to be able to write to these ports to communicate with individual device registers and control the PICs. Lets now take a look at the commands for the PIC. 8259A Commands Setting up the PIC is fairly complex. It is done through a series of Command Words , which are a bit pattern that contains various of states used for initialization and operation. This might seem a little complex, but it is not to hard. Because of this, lets first look at how to initialize the PIC controllers for our use, followed by operating and controlling the PICs. Initialization Control Words (ICW) The purpose of initializing the PIC is to remap the PIC's IRQ numbers to our own. this insures the proper IRQ is generated when a hardware interrupt happens. In order to initialize the PIC, we must send a command byte (Known as an Initialization Control Word (ICW) ) to the primary PIC Command Register. This is ICW 1 . There can be up to 4 Initialization Control Words. These are not required, but are often needed. Lets take a look at them. Note: If there are multiple PICs in the system that are to be cascaded with each other, we must send the ICW's to both of the PICs! ICW 1 This is the primary control word used to initialize the PIC. this is a 7 bit value that must be put in the primary PIC command register. This is the format: ICW 1 table Bit Number Value Description 0 IC4 If set(1), the PIC expects to receive IC4 during initialization. 1 SNGL If set(1), only one PIC in system. If cleared, PIC is cascaded with slave PICs, and ICW3 must be sent to controller. 2 ADI If set (1), CALL address interval is 4, else 8. This is usually ignored by x86, and is default to 0 3 LTIM If set (1), Operate in Level Triggered Mode. If Not set (0), Operate in Edge Triggered Mode 4 1 Initialization bit. Set 1 if PIC is to be initialized 5 0 MCS-80/85: Interrupt Vector Address. x86 Architecture: Must be 0 6 0 MCS-80/85: Interrupt Vector Address. x86 Architecture: Must be 0 7 0 MCS-80/85: Interrupt Vector Address. x86 Architecture: Must be 0 As you can see, there is a lot going on here. We have seen some of these before. This is not as hard as it seems, as most of these bits are not used on the x86 platform. To initialize the primary PIC, all we need to do is create the initial ICW and set the appropriate bits. So, lessee... Bit 0 - Set to 1 so we can sent ICW 4 Bit 1 - PIC cascading bit. x86 architectures have 2 PICs, so we need the primary PIC cascaded with the slave. Keep it 0 Bit 2 - CALL address interval. Ignored by x86 and kept at 8, so keep it 0 Bit 3 - Edge triggered/Level triggered mode bit. By default, we are in edge triggered, so leave it 0 Bit 4 - Initialization bit. Set to 1 Bits 5...7 - Unused on x86, set to 0. Looking at the above, the final bit pattern becomes 00010001 , or 0x11. So, to initialize the PIC, send 0x11 to the primary PIC controller register, mapped to port 0x20... ; Setup to initialize the primary PIC. Send ICW 1 mov al, 0x11 out 0x20, al ; Remember that we have 2 PICs. Because we are cascading with this second PIC, send ICW 1 to second PIC command register out 0xA0, al ; slave PIC command register Because we have enabled cascading, we need to send ICW 3 to the controller as well. Also, because we have set bit 0, we must also send ICW 4. More on those later. For now, lets take a look at ICW 2. ICW 2 This control word is used to map the base address of the IVT of which the PIC are to use. This is important! ICW 2 table Bit Number Value Description 0-2 A8/A9/A10 Address bits A8-A10 for IVT when in MCS-80/85 mode. 3-7 A11(T3)/A12(T4)/A13(T5)/A14(T6)/A15(T7) Address bits A11-A15 for IVT when in MCS-80/85 mode. In 80x86 mode, specifies the interrupt vector address. May be set to 0 in x86 mode. During initialization, we need to send ICW 2 to the PICs to tell them where the base address of the IRQ's to use. If an ICW1 was sent to the PICs (With the initialization bit set), you must send ICW2 next. Not doing so can result in undefined results. Most likley the incorrect interrupt handler will be executed. Unlike ICW 1, which is placed into the PIC's data registers, ICW 2 is sent to the data Registers, as software ports 0x21 for the primary PIC, and port 0xA1 for the secondary PIC. (Please see the 8259A Software Port Map table for a complete listing of PIC software ports). Okay, so assuming we have just sent an ICW 1 to both PICs (Please see the above section), lets send an ICW 2 to both PICs. This will map a base IRQ address to both PICs. This is very simple, but we must be careful at where we map the PICs to. Remember that the first 31 interrupts (0x0-0x1F) are reserved (Please see the above x86 Interrupt Vector Table (IVT) table). As such, we have to insure we do not use any of these IRQ numbers. Instead, lets map them to IRQs 32-47, right after these reserved interrupts. the first 8 IRQ's are handled by the primary PIC, so we map the primary PIC to the base address of 0x20 (32 decimal), and the secondary PIC at 0x28 (40 decimal). Remember there are 8 IRQ's for each PIC. ; send ICW 2 to primary PIC mov al, 0x20 ; Primary PIC handled IRQ 0..7. IRQ 0 is now mapped to interrupt number 0x20 out 0x21, al ; send ICW 2 to secondary controller mov al, 0x28 ; Secondary PIC handles IRQ's 8..15. IRQ 8 is now mapped to use interrupt 0x28 out 0xA1, al That is simple, huh? Onto the next one! ICW 3 This is an important command word. It is used to let the PICs know what IRQ lines to use when communicating with each other. ICW 3 - Primary PIC table Bit Number Value Description 0-7 S0-S7 Specifies what Interrupt Request (IRQ) is connected to slave PIC ICW 3 - Secondary PIC table Bit Number Value Description 0-2 ID0 IRQ number the master PIC uses to connect to (In binary notation) 3-7 0 Reserved, must be 0 We must send an ICW 3 whenever we enable cascading within ICW 1. this allows us to set which IRQ to use to communicate with each other. Remember that the 8259A Microcontroller relies on the IR0-IR7 pins to connect to other PIC devices. With this, it uses the CAS0-CAS2 pins to communicate with each other. We need to let each PIC know about each other and how they are connected. We do this by sending the ICW 3 to both PICs containing which IRQ line to use for both the master and associated PICs. Remember: The 80x86 architecture uses IRQ line 2 to connect the master PIC to the slave PIC. Knowing this, and remembering that we need to write this to the data registers for both PICs, we need to follow the formats shown above. Note that, in the ICW 3 for the primary PIC, Each bit represents an interrupt request. That is... IRQ Lines for ICW 3 (Primary PIC) Bit Number IRQ Line 0 IR0 1 IR1 2 IR2 3 IR3 4 IR4 5 IR5 6 IR6 7 IR7 Notice that IRQ 2 is Bit 2 within ICW 3 . So, in order to set IRQ 2, we need to set bit 2 (Which is at 0100 binary, or 0x4). Here is an example of sending ICW 3 to the primary PIC: ; Send ICW 3 to primary PIC mov al, 0x4 ; 0x4 = 0100 Second bit (IR Line 2) out 0x21, al ; write to data register of primary PIC To send this to the secondary PIC, we must remember that we must send this in binary notation . Please refer to the table above. Note that only Bits 0...2 are used to represent the IRQ line. By using binary notation, we can refer to the 8 IRQ lines to choose from: IRQ Lines for ICW 3 (Secondary PIC) Binary IRQ Line 000 IR0 001 IR1 010 IR2 011 IR3 100 IR4 101 IR5 110 IR6 111 IR7 Simple enough. Notice that this just follows a binary<->decimal conversion in the above table. Because we are connected by IRQ line 2, we need to use bit 1 (Shown above). Here is a complete example, that sends a ICW 2 to both primary and secondary PIC controllers: ; Send ICW 3 to primary PIC mov al, 0x4 ; 0x04 =0100, second bit (IR line 2) out 0x21, al ; write to data register of primary PIC ; Send ICW 3 to secondary PIC mov al, 0x2 ; 010=IR line 2 out 0xA1, al ; write to data register of secondary PIC That's all there is to it ðŸ˜‹ Okay, so now both PICs are connected to use IR line 2 to communicate with each other. We have also set a base interrupt number for both PICs to use. This is great, but we are not done yet. Remember that, when building up ICW 1, if bit 0 is set, the PIC will be expecting us to send it ICW 4. As such, we need to send ICW 4, the final ICW, to the PICs. ICW 4 This is the final initialization control word. This controls how everything is to operate. Initialization Control Word (ICW) 4 Bit Number Value Description 0 uPM If set (1), it is in 80x86 mode. Cleared if MCS-80/86 mode 1 AEOI If set, on the last interrupt acknowledge pulse, controller automatically performs End of Interrupt (EOI) operation 2 M/S Only use if BUF is set. If set (1), selects buffer master. Cleared if buffer slave. 3 BUF If set, controller operates in buffered mode 4 SFNM Special Fully Nested Mode. Used in systems with a large amount of cascaded controllers. 5-7 0 Reserved, must be 0 This is a pretty powerful function. Bits 5..7 are always 0, so lets focus on the other bits and pieces (pun intended ;) ) The PIC was originally designed to be a generic microcontroller, even before the 80x86 existed. As such, it contains a lot of different operation modes designed for different systems. one of these modes is the Special Fully Nested Mode . The x86 family does not support this mode, so you can safely set bit 4 to 0. Bit 3 is used for buffered mode. For now, set this to 0. We will cover modes of operation later. Bit 2 is only used when bit 3 is set, so set this to 0. With this, Bit 1 is rarely used either. As such, we only need to set bit 0, which enables the PIC for 80x86 mode. Simple enough. So, to send ICW 4, all we need to do is this: mov al, 1 ; bit 0 enables 80x86 mode ; send ICW 4 to both primary and secondary PICs out 0x21, al out 0xA1, al This is probably the easiest code snippet in this tutorial. Brace it while it lasts! ðŸ˜€ Initializing the PIC - Putting it together Believe it or not, but we have already went over this. In initializing the PIC, all we need to do is send the correct ICW's to the PIC. Lets put everything from the previous section together to initialize the PIC for better understanding of how everything is put together: ;************************************************************************ ; Map the 8259A PIC to use interrupts 32-47 within our interrupt table ;************************************************************************ %define ICW_1 0x11 ; 00010001 binary. Enables initialization mode and we are sending ICW 4 %define PIC_1_CTRL 0x20 ; Primary PIC control register %define PIC_2_CTRL 0xA0 ; Secondary PIC control register %define PIC_1_DATA 0x21 ; Primary PIC data register %define PIC_2_DATA 0xA1 ; Secondary PIC data register %define IRQ_0 0x20 ; IRQs 0-7 mapped to use interrupts 0x20-0x27 %define IRQ_8 0x28 ; IRQs 8-15 mapped to use interrupts 0x28-0x36 MapPIC: ; Send ICW 1 - Begin initialization ------------------------- ; Setup to initialize the primary PIC. Send ICW 1 mov al, ICW_1 out PIC_1_CTRL, al ; Send ICW 2 - Map IRQ base interrupt numbers --------------- ; Remember that we have 2 PICs. Because we are cascading with this second PIC, send ICW 1 to second PIC command register out PIC_2_CTRL, al ; send ICW 2 to primary PIC mov al, IRQ_0 out PIC_1_DATA, al ; send ICW 2 to secondary controller mov al, IRQ_8 out PIC_2_DATA, al ; Send ICW 3 - Set the IR line to connect both PICs --------- ; Send ICW 3 to primary PIC mov al, 0x4 ; 0x04 =0100, second bit (IR line 2) out PIC_1_DATA, al ; write to data register of primary PIC ; Send ICW 3 to secondary PIC mov al, 0x2 ; 010=IR line 2 out PIC_2_DATA, al ; write to data register of secondary PIC ; Send ICW 4 - Set x86 mode -------------------------------- mov al, 1 ; bit 0 enables 80x86 mode ; send ICW 4 to both primary and secondary PICs out PIC_1_DATA, al out PIC_2_DATA, al ; All done. Null out the data registers mov al, 0 out PIC_1_DATA, al out PIC_2_DATA, al That was not that hard, was it? We covered everything in this code. Now the PIC is initialized. Whenever a hardware interrupt occurs, it will call our interrupts 32 - 47 that we have previously defined somewhere within the Interrupt Vector Table (IVT). This allows us to track hardware interrupts. Cool, huh? Operation Command Words (OCW) Yippee! Now that the ugly initialization stuff is out of the way, we can finally focus on standard controlling and operation of the PIC. This is done by writing and reading from various registers through Operation Control Words (OCW)'s . OCW 1 OCW 1 represents the value inside of the Interrupt Mask register (IMR) . To obtain the current OCW 1, all you need to do is read from the IMR. Remember that the IMR is mapped to the same port that the status register is at. Because the status register is read only, the PIC can determine what register to access based off if this is a read or write operation. We have looked at the IMR register above when we covered the PIC registers. OCW 2 This is the primary control word used to control the PIC. Let's take a look... Operation Command Word (OCW) 2 Bit Number Value Description 0-2 L0/L1/L2 Interrupt level upon which the controller must react 3-4 0 Reserved, must be 0 5 EOI End of Interrupt (EOI) request 6 SL Selection 7 R Rotation option Okay then! Bits 0-2 represents the interrupt level for the current interrupt. Bits 3-4 are reserved. Bits 5-7 are the interesting bits. Let's take a look at each combination for these bits. OCW2 Commands R Bit SL Bit EOI Bit Description 0 0 0 Rotate in Automatic EOI mode (CLEAR) 0 0 1 Non specific EOI command 0 1 0 No operation 0 1 1 Specific EOI command 1 0 0 Rotate in Automatic EOI mode (SET) 1 0 1 Rotate on non-specific EOI 1 1 0 Set priority command 1 1 1 Rotate on specific EOI Okay...This table, in its current state, is confusing, don't you think? a lot of the above commands are fairly advanced. Let's take a look at what we can do. Sending End of Interrupt (EOI) As you know, when a hardware interrupt triggers, all other interrupts are masked off inside of the Interrupt Mask Register until an EOI signal is sent to the primary controller. This means, we must send an EOI to ensure all hardware interrupts are enabled at the end of our Interrupt Routine (IR) . Looking at the above table, we can send a non specific EOI command to signal EOI to the controller. Because the EOI bit is bit 5 within the OCW 2, all we need to do is set bit 5 (100000 binary = 0x20): ; send EOI to primary PIC mov al, 0x20 ; set bit 4 of OCW 2 out 0x20, al ; write to primary PIC command register"
  },
  "articles/61_unorganised_tutorial/Z2b.html": {
    "href": "articles/61_unorganised_tutorial/Z2b.html",
    "title": "8253 Programmable Interval Timer | BrokenThorn OS Dev Tutorials",
    "keywords": "8253 Programmable Interval Timer 8253 PIT Microcontroller with all pins labled: Note This tutorial may require some knowledge of hardware interrupt handling and the 8259 Programmable Interrupt Controller (PIC). Please see [this tutorial] (fix link) for information on them. This tutorial will cover everything you ever wanted to know about system timing and programming the Intel 8253 Programmable Interval Timer (PIT) . The 8253 PIT has had a long history, and has played an important part in nearly every x86 PC. It is the \"System clock\", and is responsible for many very important functions within the PC. This erm.. \"chip\" is no longer distributed as an independent chip (as a Dual Inline Package (DIP) to be more precise), but rather integrated into the motherboards southbridge chipset. Everything about the 8253 still remains, however. Because of this, its input and output facilities, hardware, and the way we program the 8253 remains the same. Because there is not of any difference (besides speed) between this and the older DIPs, we will be looking at the older 8253 DIP to help keeping things simple. The picture at the beginning of this tutorial displays what we will be looking at and programming. Lets have some fun ðŸ˜‰ Programmable Interval Timers A Programmable Interval Timer (PIT) is a counter which triggers an interrupts when they reach their programmed count. The 8253 and 8254 microcontrollers are PITs avialble for the i86 architectures used as timer for i86-compatable systems. These PICs include three timers that are used for different putposes. The first timer is useually used as the System Clock . Timer 2 was used for RAM refreshing, and timer 3 is connected to the PC speaker. We will see all of the connections a little later, so we won't go into much detail now. Instead, lets take a closer look at one of these famous PITs... The 8253 Microcontroller. 8253 Hardware Before looking at the software side of things, it will be helpful to learn more about what we are actually programming. Because of this, we will look at the 8253 hardware first, and learn how it works and is connected to the rest of the PC. We will also be looking at internal registers, pin layout, command words, and more that will be needed for the software side of things. 8253 Hardware: Description The 8253 PIT has a simple interface, and is not that hard to program. Yep--There is the chip that we will program. Here is the complete pin layout. We will be refrencing these pins throughout this tutorial, so it is important to know what they are. D0...D7: 8 bit data lines. This is connected to the data bus so we can read and send commands. CLK 0, CLK 1, CLK 2: Clock input pins. There are 3 pins for 3 separate counters OUT 0, OUT 1, OUT 2: Output data line. There are 3 pins for 3 separate counters **GATE 0, GATE 1, GATE 2:**Gate data line. There are 3 pins for 3 separate counters GND: Ground Vcc: Input voltage WR: Write enable. When this line is active, lets the 8253 that we are writing data RD: Read enable. When this line is active, lets the 8253 that we are reading data CS: Chip select signal A0, A1: Address lines. Used to determin what register we are accessing. Not to bad. There are a couple of important pins here that we need to look at. The D0-D7 pins connect to the systems data bus . These pins carry our data when we are sending or reading data to the controller. Vcc and GND complete the circuit (Voltage input, Ground output.) The WR pin tells the controller that we are writing (expect input on the data pins.) When the signal in this pin is \"low\", we are currently sending data. The RD pin is very simular in this manner, but it tells the controller we are reading data instead. The CS pin is a special pin that determins what the controller should do with the RD and WR pins. If the CS pin is \"low\", the controller will respond to the RD and WR pins. If CS is not, they are ignored. WR and RD connect to the Systems Control Bus . The CS pin connects to the systems Address Bus for port i/o operations. The A0 and A1 pins are connected to the Systems Address Bus , and are used to determin what register we are accessing. These, in conjunction with WR and RD allows the controller to determin if are reading to or from a register. Notice that there are three groups of the CLK, OUT, and GATE pins. Yes, there is indeed a reason for this: The 8253/8254 microcontrollers contain 3 independent timers. Lets look closer on how this works... 8253 Hardware: Counters The 8253 consists of three counters: Counter 0, Counter 1, and Counter 2. Each counter has 2 input pins: CLK (Clock Input) and GATE , and one pin for output-- OUT . As there are three counters, they are used for different purposes within the system. Each counter are 16 bit down counters. Typical computers connect the first timer's OUT pin to a Programmable Interrupt Controller (PIC) to generate an interrupt for every clock tick. This is useually used as the System Timer . The second counter was used for generating a timing signal to the Memory Controller to refresh DRAM memory. The third counter is used to generate tones to the PC speaker. As you can probably guess, the PIT uses the OUT pins to signal these devices when its counter reaches 0. When the PIT's counter reaches 0, it simply wraps around and starts again. CLK is the clock input for the timer. It may be used with the GATE pin depending on the current mode of operation. The following table describes the operation depending on if the current in GATE is low, rising, or high. GATE Input pin operations Table Mode Low or going low Rising High 0 Disables Counting - Enables Counting 1 - Initiates Counting and resets OUT after next CLK - 2 Disables Counting, Sets OUT to high Reloads counter and initiates counting Enables Counting 3 Disables Counting, Sets OUT to high Initiates Counting Enables Counting 4 Disables Counting - Enables Counting 5 - Initiates Counting - The 8253 Counters are also known as Channels. Knowing that the 8253/8254 PITs contain three channels, lets look at each of them more closer... Channel 0 Channel 0 is connected to the 8259 PIC to generate an Interrupt Request (IRQ) . The PITs OUT pin connects to the PIC's IR0 pin. Typically the BIOS configures this channel with a count of 65536, which gives an output frequency of 18.2065 Hz. This fires IRQ 0 every 54.9254 ms. The is the primary timer used on almost all x86 machines. the clock rate (Signalled through Counter 0's CLK pin) is at 1193181.6666... Hz, one third of the NTSC subcarrier frequency. This was required do to backward compatability with the older CGA PC's. Channel 0 is typically programmed in most systems to act as the System Clock . This is made possible do to channel 0's OUT pin indirectly connecting to the PIC's IR0 line. Depending on the mode that we set it in, we can set the timer to a good frequency, and have it enable the PIC's IR0 line at a constant rate. Afterwords, reseting itself and starting over again. Because the PIC is used to handle hardware interrupts , we will need to first reprogram the PIC . Because it is connected to the interrupt with the lowest number (IR0), it also has the highest priority over all other hardware interrupts. Its lowest frequency rate is normally used for computers running the old DOS systems (Are there any left?) at about 18.2 Hz. Its highest frequency rate is a little over a megahertz. In real mode operating systems, the BIOS normally increments the number of times IRQ0 is fired to 0000:046C, which can be read by any running program. Channel 1 Many video cards and the BIOS may reprogram the second channel for their own uses. This channel was originally used for generating a timing pulse signal to signal the memory controller to refresh the DRAM memory. In modern times, this is no longer needed as the refresh is done by the memory controller. Because of this, there is no guarantee at what devices may use this counter. Channel 2 This channel is connected to the PC Speaker to generate sounds. the PC speaker is normally meant to produce a square wave with two levels of output. However, it is possible to go between the two true defined sound square levels. This is called Pulse-Width Modulation (PWM) . We can set up this channel by programming it for mode 3, and setting a frequency rate for the tone. We can also program the PC Speaker directly. Looking back at [Tutorial 7] (fix link OSDev7.html), we can see that the PC speaker is mapped to port 0x61. This port defines how the speaker will operate: Bit 0: If set (1), the state of the speaker follows bit 1 Bit 1: If set (1), the speaker uses the PIT, If not set (0), the speaker disables its connection to the PIT If bit 0 is set, the rest of the byte contains a pattern of bits representing the frequency of the tone. We can generate up to 8 bit sounds from the speaker, which is kind of cool, but tricky to do. You should also notice that we can disable devices from using the PIT. At startup, the BIOS configures the speaker to use the PIT channel 2, running in mode 3. It is recommended to keep the speaker to use the PIT do to timing problems that you will run into. Here is an example: ; disables the speaker, and stop using channel 2 mov dx, 0x61 out dx, 0 ; generates tone from speaker out dx, 11111101b Conclusion (counters) Once a counter is set up, it will remain that way until it is changed by another control word. There is some cool things we can do with these counters, huh? Because channel 1 is not used anymore, we cannot assume it is safe and use it ourselves. Because of this, it is recommended to stick to channel's 0 and 2. We can use channel 0 to fire off our interrupt handler. Our interrupt handler can increment a counter used by our kernel. This special little counter variable, plays a very important role in the system: The System Timer. We will see all of this soon, don't worry ;) Alright...So, we looked at pin configurations, and the three timers used by different devices for..err...timing. Whats next? When programming these timers, we have to initialize them. Remember that each channel supports 6 different modes. Some of these modes are very useful. Other modes are not. Lets take a look at each of these modes for better understanding of them. Please note that this gets a little detailed, but I am sure you already knew or were expecting that ðŸ˜ 8253 Channel Modes Remember that each counter can be programmed in 1 of 6 modes. This is done by sending an Initialization Control Word (ICW) to the controller. We will look at the format of this command word later. For now, lets look at each mode. Mode 0: Interrupt on Terminal Count In this mode, the counter will be programmed to an initil COUNT value and afterwords counts down at a rate to the input clock frequency (The CLK signal). When COUNT is equal to 0, and after the Control Word is written, the counter enables its OUT pin (by setting its line high) to signal the device it is connected to. Counting starts one clock cycle after the COUNT is programmed. The OUT line remains high until the counter is reloaded with a new value or the same value or until another control word is written to the controller. What this mode basically does is allow us to set a timer that counts down to 0. After which, we will need to reload a new count number to it, or a new control word to re-initialize the counter. Mode 1: Hardware Triggered One-Shot In this mode, the counter is programmed to give an output pulse every certain number of clock pusles. The OUT line is set to high as soon as a Control Word is written. After COUNT is written, the counter waits until the rising edge of the GATE input. If the trigger occurs during the pulse output, the 8253 will be retriggered again. One clock cycle after the rising edge of GATE is detected, OUT will become and remain low until COUNT reaches 0. OUT will then be set high until the next trigger and wait again until the rising edge of the GATE input is detected. Mode 2: Rate Generator This mode configures the counter to be a \"divide by n\" counter, which is commonly used to generate a real-time system clock. The counter is programmed to an initial COUNT value. Counting starts at the next clock cycle. OUT remains high until COUNT reaches 1. Afterwords, OUT will be set low for one clock pulse. OUT is then set back high, and COUNT is reset back to its initial value. This process repeats until a new control word is sent to the controller. The time between the high pulses depends on the current value in COUNT , and is calculated using the following formula: COUNT = input (Hz) / Frequency of output COUNT never reaches 0. It only ranges from n to 1, where n is the initial COUNT value. Okay, lets stop for a moment. Remember that Counter 0 is connected to the PIC? Counter 0's OUT line indirectly connects to the PIC's IR0 line . Knowing that, when the IR0 line is low, the PIC will call the IRQ 0 handler defined by us. If we set the counter to Mode 2, we can set up the timer to fire off our interrupt at a constant rate. All we need to do is determine what the COUNT value should be based off of the above formula. This is used very often in setting up the System Timer for the operating system. After all, IRQ 0 is now being called for every clock tick at a frequency rate that we defined. Yes, Mode 2 is an important mode, indeed. Mode 3: Square Wave Generator This mode is quite similar to Mode 2. However, OUT will be high for half of the period, and low for the other half. If COUNT is odd, OUT will be high for (n+1)/2 counts. If COUNT is even, OUT will be low for (n-1)/2 counts. Everything else is the same from Mode 2. We will need to use the formula from Mode 2 to set up the initial COUNT value. If the speaker is configured to use the PIT, the channel that it uses typically should be set to use this mode. Mode 4: Software Triggered Strobe The counter is programmed to an initial COUNT value. Counting starts at the next clock cycle. OUT remains high until COUNT reaches 0. The counter will then set OUT low for one clock cycle. Afterwords, it resets OUT to high again. Mode 5: Hardware Triggered Strobe The counter is programmed to an initial COUNT value. OUT remains high until the controller detects the rising edge of the GATE input. When this happens, the counting starts. When COUNT reaches 0, OUT goes low for one clock cycle. Afterwords, OUT is set high again. This cycle repeats when the controller detects the next rising edge of GATE . 8253 Registers The 8253 contains a few registers that we can access. Most of these registers are very simular to each other, so I will just put them in the same table for clarity. This table displays each register and their functionality when the corresponding lines on the 8253 are active. Notice how the RD and WR lines determine the read and write operation. Also notice how the A0 and A1 lines determin what register we are accessing. Looking at the port table from [Tutorial 7] (Fix link), we can see that the System Timer is mapped by the BIOS to use ports 0x40-0x4F. Each port address is a byte in size. 8253 PIT Internal Registers Table Register Name Port Address RD line WR line A0 line A1 line Function Counter 0 0x40 1 0 0 0 Load Counter 0 Counter 0 0x40 0 1 0 0 Reads Counter 0 Counter 1 0x41 1 0 0 1 Load Counter 1 Counter 1 0x41 0 1 0 1 Reads Counter 1 Counter 2 0x42 1 0 1 0 Load Counter 2 Counter 2 0x42 0 1 1 0 Reads Counter 2 Control Word 0x43 1 0 1 1 Write Control Word NA 0 1 1 1 No Operation All other port addresses from 0x44-0x4f are undefined. The system will activate the correct lines depending on the operation we are performing. When setting the counter registers, we need to first let the controller know how we are going to load it. This is done by first setting up the control word. Lets take a look closer at these registers... Counter Registers Each counter register holds the COUNT value used by the PIT to count down from. They are all 16-bit registers. When writing or reading from these registers, you must first send a control word to the PIT. You might wonder why we cannot just do it directly. There is a reason for this, and it has to do with the size of the data. The PIT only has 8 data lines (Pins D0-D7). However, the counter registers are all 16 bits, not 8. Because of this, how does the PIT know what data you are writing to its counter register? How does it know what byte within the counter registers 16 bits are you setting? It doesn't. Sending a command word allows you to let the PIT know to expect incoming data, and what to do with it. We will look at that next. Control Word Register THIS will be important to us. This is an important register used to determin and set the operation modes for the controller. This is accessed by enabling the RD, A0, and A1 lines. This register can only be written to, not read from. The control word register uses a simple format. At first I was thinking of using a table here, but it may be easier in a list format so here it is: Bit 0: (BCP) Binary Counter 0: Binary 1: Binary Coded Decimal (BCD) Bit 1-3: (M0, M1, M2) Operating Mode. See above sections for a description of each. 000: Mode 0: Interrupt or Terminal Count 001: Mode 1: Programmable one-shot 010: Mode 2: Rate Generator 011: Mode 3: Square Wave Generator 100: Mode 4: Software Triggered Strobe 101: Mode 5: Hardware Triggered Strobe 110: Undefined; Don't use 111: Undefined; Don't use Bits 4-5: (RL0, RL1) Read/Load Mode. We are going to read or send data to a counter register 00: Counter value is latched into an internal control register at the time of the I/O write operation. 01: Read or Load Least Significant Byte (LSB) only 10: Read or Load Most Significant Byte (MSB) only 11: Read or Load LSB first then MSB Bits 6-7: (SC0-SC1) Select Counter. See above sections for a description of each. 00: Counter 0 01: Counter 1 10: Counter 2 11: Illegal value Alright, then! bit of stuff going on here, don't you think? So...All we need to do is build up the control word by writing to the control word register to initialize the controller, right? Of course! Sort of... Basically, we want to initialize a counter for a specific purpose. So, we have to build up the control word to set up the counter, the counters counting mode and operating mode. THEN, we initialize the counter itself. Remember that, once initialized, the counter can carry on itself (depending on its mode), so we only need to do this once. Lets give an example and put everything together, shall we? Lets pretend we already have a PIC initialized and interrupt 0 handler. We want to set up a timer to fire off IRQ 0 every 100Hz (once every 10 milliseconds). We know that channel 0 of the PIT is connected to the PIC's IR0 line, so we can program channel 0 to do this. ; COUNT = input hz / frequency mov dx, 1193180 / 100 ; 100hz, or 10 milliseconds ; FIRST send the command word to the PIT. Sets binary counting, ; Mode 3, Read or Load LSB first then MSB, Channel 0 mov al, 110110b out 0x43, al ; Now we can write to channel 0. Because we set the \"Load LSB first then MSB\" bit, that is ; the way we send it mov ax, dx out 0x40, al ;LSB xchg ah, al out 0x40, al ;MSB Notice how we set up the control word first, THEN write to the counter 0 register. Is that it!?? Yep. The above will program counter 0 to fire IRQ0 every 10 milliseconds. Conclusion The 8253 and 8254 PIT's are very usefull little chips. They can be used in alot of different devices, and used for alot of different purposes. For our needs, we can both have a nice signaled output via the PC speaker and a system timer that is a very important aspect on all modern system software. We have even looked at another way of working with the speaker directly, and even disable its connection to the PIT, which has advantages and disadvantags. It is up to the system software designer to decide and outweight the pros and cons of the different and unlimited possibilities when developing their system. We have looked at the PIT in depth, pin configuations, and their connections on a standard x86-based PC motherboard. The PIT itself is useually integrated with the motherboard's southbridge in modern computers. Tutorial 16: Kernel: Timing and Exception Handling puts everything from the [8259A PIC] (OSDevPic.html fix link) and this tutorial together. It impliments and creates interfaces for both devices. Mabey even a little bit more..."
  },
  "articles/61_unorganised_tutorial/Z3.html": {
    "href": "articles/61_unorganised_tutorial/Z3.html",
    "title": "Graphics | BrokenThorn OS Dev Tutorials",
    "keywords": "Graphics"
  },
  "articles/61_unorganised_tutorial/Z3a.html": {
    "href": "articles/61_unorganised_tutorial/Z3a.html",
    "title": "Graphics 1 | BrokenThorn OS Dev Tutorials",
    "keywords": "Graphics 1 Welcome! Wait, what? Graphics already? Thats right, we will start developing an ultra-cool GUI for the OS! ðŸ˜€ Okay, not really, but its a start in that direction. This chapter is the first of a miniseries of chapters covering graphics programming. I plan to cover Vesa VBE, Video BIOS, and direct hardware programming for the VGA and, possibly, some SVGA concepts. I also plan on covering graphics concepts and rendering, including 2d vector rendering and images. Who knows; mabye a little 3d a little later. Excited? A lot of cool material coming up in this mini series spinoff of the OS Development Series! However, before we can dive into the wonderful world of computer graphics, we have to set up a ground rule. There are a lot of ways that we can work with computer graphics, and a lot of directions that we can take. Computer graphics are a complicated topic: It cannot be covered in one chapter. Well, it can. It would just be one .. very, very long chapter. Because of this, I decided to do this in stages. The first chapter covers working with graphics in real or v86 modes. We use the system BIOS interrupts and cover basic graphics concepts. The second chapter we will dive into Video BIOS Extensions (VBE) and Super VGA. The third chapter, will be the first chapter of a smaller miniseries covering direct hardware programming of the graphics pipeline: VGA and mabye some Super VGA topics. So for this chapter, lets get started with working with real mode graphics using the real mode Video BIOS... Basic Concepts Abstract Computer Graphics (CG) does not need an introduction. It has revolutionized the computer, animation, and video game industries. The field of computer graphics encompasses the development, creation, and continuation of the ability of producing graphical effects on computer displays. From 1D graphics, 2D, 3D, and even 4D graphics simulation software. History The computer graphics industry started to emerge from early projects like the Whirlwind in the 1960's. The Whirlwind was the first computer that used video display output and helped introduce the Cathode Ray Tube (CRT) technology. Whirlwind eventually led to the development of the SAGE (Air Force Semi Automatic Ground Environment) computer system. The ealiest known version of the CRT was created by Ferdinand Braun in 1897 known as the Braun tube . The Special Interest Group on GRAPHics and Interactive Techniques (SIGGRAPH) , is governed by the Association for Computing Machinery (ACM) SIGGRAPH group. Originally started in 1969 by Andy van Dam, the group hosts the SIGGRAPH conferences around the world. These conferences are attended by thousands of professionals from companies from the engineering, graphics, motion picture, and video game industries. As graphics hardware advanced the ability of creating more powerful graphics designs emerged. As other display technologies emerges, such as Liquid Crystal Display (LCD) , The use of the CRT technology started to decline. Video Display Terminals (VDT) , also known as a Video Display unit (VDU) are early display terminals. Cathode ray tube (CRT) Abstract (CRT) A CRT is a vacuum tube which consists of electron guns and a phosphor target. The entire front area of the tube is scanned repetitibely in a pattern called a raster . The image is produced by changing the intensity of the three electron beams: one for red, green, and blue color components at a given point on display. These electron beams first travel through a Shadow Mask layer before hitting the phosphor coated screen. Problems CRT monitors can emit a small amount of X-Ray radiation. Also, do to the constant rescanning of the display, at low refresh rates (below 60Hz) flicker may be seen. CRTs may also contain some toxic phosphore. Because of this the United States Environmental Protection Agency (EPA) created a rule that CRTs must be bought to a proper recycling facility. Finally, do to the CRT containing a vaccum of glass, if the outer glass is damaged, the CRT may implode. This may cause the glass to shatter outward at dangerous speeds. Modern CRTs have certain measures in place to prevent the shattering of the CRT. It is possible to control the frequency of the CRT using software. At higher frequency rates, it is possible to make the CRT operate faster then its intended use increasing the possibility of imploding the CRT. Because of this, it is very important to be careful when working with the CRT Controller (CRTC) . Modern CRTs have protections in place to prevent this, however. VGA Abstract (VGA) The Video Graphics Array (VGA) is an anolog computer display standard marketed in 1987 by IBM. It is called an \"Array\" because it was originally developed as a single chip, replacing dozens of logic chips in a Industry Standard Architecture (ISA) board that the MDA, CGA, and EGA used. Because this was all on a single ISA board, it was very easy to connect it to the motherboard. The VGA consists of the video buffer, video DAC, CRT Controller, Sequencer unit, Graphics Controller, and an Attribute Controller. We will cover all of these components in more detail in later chapters. Video Buffer The Video Buffer is a segment of memory mapped as Video Memory. We can change what region of memory is mapped to video memory. At startup, the BIOS maps it to 0xA0000., which means that video memory is mapped to 0xA0000. (Remember the Real Mode Address Map from Tutorial 7?) We will cover memory mapping a little later in this chapter in more detail. Video DAC The Video Digital to Analog Converter (DAC) contains the color palette that is used to convert the video data into an analog video signal that is sent to the display. This signal indicates the red, green, and blue intensities in analog form. We will go into more detail later, so don't worry if you do not understand this yet. CRT Controller This controller generates horizontal and vertical synchronization signal timings, addressing for the video buffer, cursor and underline timings. We will go into more detail later when we cover the VGA hardware. Sequencer The Sequencer generates basic memory timings for video memory and the character clock for controlling regenerative buffer fetches. It allows the system to access memory during active display intervals. Once more, we will not cover this in detail yet. Graphics Controller This is the interface between video memory and the attribute controller , and between video memory and the CPU. During active display times, memory data is sent from the video buffer (Video Memory) and sent to the Attribute Controller. In Graphics Modes, this data is converted from parallel to a serial bit plane data before being sent. In text modes, Just the parallel data is sent. Don't worry if you do not understand these yet. I do not plan on going into much detail here. We will cover everything in detail later when we talk about developing a video driver. For now, just remember that: The Graphics Controller refreshes the display from the parallel data from video memory. This is automatic based on the active display times. This simply means, that By writing to video memory (Default mapped to 0xA0000) we effectivly write to video display, depending on the current mode. This is important when printing characters. Remember that it is possible to change the address range used by the Graphics Cotroller. When initializing, the BIOS does just this to map video memory to 0xA0000. Video Modes A \"Video Mode\" is a specification of display. That is, it describes how Video Memory is refrenced, and how this data is displayed by the video adapter. The VGA supports two types of modes: APA Graphics, and Text. APA Graphics All Points Addressable (APA) is a display mode, that, on a video monitor, dot matrix, or any device that consists of a pixel array, where every cell can be refrenced individually. In the case of video display, where every cell represents a \"pixel\", where every pixel can be manipulated directly. Because of this, almost all graphic modes use this method. By modifying this pixel buffer, we effectivly modify individual pixels on screen. Pixel : A \"Pixel\" is the smallest unit that can be represented on a display. On a display, it represents the smallest unit of color. That is, basically, a single dot. The size of each pixel depends heavily on the current resolution and video mode. Text Modes A Text Mode is a display mode where the content on the screen is internally represented in terms of characters rather then pixels, as with APA. A Video Controller implimenting text mode uses two buffers: A character map representing the pixels for each individual character to be displayed, and a buffer that represents what characters are in each cell. By changing the character map buffer, we effectivly change the characters themselves, allowing us to create a new character set. By changing the Screen Buffer, which represents what characters are in each cell, we effectivly change what characters are displayed on screen. Some text modes also allow attributes, which may provide a character color, or even blinking, underlined, inversed, brightened, etc. MDA, CGA, EGA Remember that VGA is based off of MDA, CGA, and EGA. VGA also supports alot of the modes these adapters do. Understanding these modes will help in better understanding VGA. MDA Back before I was born (Seriously ðŸ˜€) in 1981, IBM developed a standard video display card for the PC. They were the Monochrome Display Adapter (MDA), and Monochrome Display and Printer Adapter (MDPA). The MDA did not have any graphics mode of any kind. It only had a single text mode, (Mode 7) which could display 80 columns by 25 lines of high resolution text characters. This display adapter was a common standard used in older PC's. CGA In 1981, IBM also developed the Color Graphics Adapter (CGA), coinsidered the first color display standard for PC's. The CGA only supported a Color Palette of 16 colors, because it was limited to 4 bytes per pixel. CGA supported two text modes and two graphics modes, including: 40x25 characters (16 color) text mode 18x25 characters (16 color) text mode 320x200 pixels (4 colors) graphics modes 640x200 pixels (Monochrome) graphics mode It is possible to treak the display adapter in creating and discovering new, \"undocumented\" video modes. More on this later. EGA Introduced in 1984 by IBM, The Enhanced Graphics Adapter (EGA) produced a display of 16 colors at a resolution up to 640x350 pixels. Remember that the VGA adapters are backward compatible, simular to the 80x86 microprocessor family. Because of this, and to insure backward compatibility, the BIOS starts up in Mode 7 (Originally from the MDA), which supports 80 columns, by 25 lines. This is important to us, because this is the mode we are in! Video Memory Memory Mapped I/O (MMIO) If you know what Memory Mapped I/O is, you can skip this part. The processor can work with reading from RAM and ROM devices. In applications programming, this is something you never see. This is made possible with MMIO devices. Memory Mapped I/O allows a hardware device to map its own RAM or ROM into your processors physical address space. This allows the processor to be able to access hardware RAM or ROM in different ways by just using a pointer to that location in the address space. This is made possible because MMIO devices uses the same physical address and data bus that the processor and system memory uses. It is important to remember, however, that Memory Mapped I/O is a mapping to the physical address space of the processor, not actual computer memory. In some architectures, it is possible to bank switch , or provide a method to switch between either using the MMIO device mapping or the system memory \"hidden\" behind it, while on others it is not. What this means for us is that we cannot access the actual system memory addresses that are \"hidden\" by the MMIO device. For example, CMOS RAM memory is mapped into the physical address space at address 0x400. This is different then main system memory; accessing 0x400 with a pointer will access the CMOS RAM memory always do to MMIO. It is not possible to access this location in system memory in the i86 architecture. MMIO devices allows us to have more control over the hardware - it allows high resolution video displays with limited system memory, it allows us to obtain information from a device that is kept current by a battery (CMOS RAM) that would have altherwise been lost if in system memory. Another example of an MMIO device is the system BIOS ROM itself. MMIO is what allows the processor to execute the BIOS from ROM as it is mapped to the systems physical address space. Cool, huh? You might be wondering what this has to do with graphics. Video memory is RAM that is mapped into the physical address space. Video memory is managed by the video display device which uses MMIO to do this. How MMIO memory is managed and worked with is up to the device ; it is not always nice and linear. Different graphics modes require different ways that you have to work with this memory, so understanding that it is an MMIO device is important. An interesting fact about MMIO address space regions is that, with paging they can be mapped to any virtual address and accessed from that address. This means you can map, for example, video memory, to any virtual address you want and access video memory using that virtual address. This, of course, has to do with the way pages are mapped to frames in the physical address space. Also remember that MMIO memory is not in system memory . Computer system memory does not need to be greater then the size of the MMIO address that you are trying to access. For example, if your system only has 2GB of system memory, you can still access the MMIO device if it has RAM mapped to the physical address space at 0xFC000000 without error. See this text right here? Thats right, me; I am in your computer... residing in Video RAM (VRAM). VRAM is Video Memory, also known as the video framebuffer . It containes all of the pixels that you see before you, and more. Standard VGA Video memory is stored inside of the video device; usually a video card or onboard video adapter. Standard VGA cards have 256 KB of VRAM. It is not uncommon however to see SVGA+ cards to have much more video memory however. After all, they have to be able to store all of the pixels in the high resolution video modes somehow, right? Remember the memory map from [chapter 7] (fix link)? We can see the Standard VGA memory resides in 0x000A0000 - 0x000BFFFF . 0xBFFFF - 0xA0000 = 0xA0000, which is 655360 bytes, or 640 KB. It is important to remember that video memory is mapped in the PCs address space at this location. What this means is by writing here, you are writing to video memory that is located in the video adapter. This is a form of Memory Mapped I/O . When accessing video memory, you typically access it using a \"window\" into the real video RAM. This is typically: 0xA0000 - EGA/VGA graphics modes (64 KB) 0xB0000 - Monochrome text mode (32 KB) 0xB8000 - Color text mode and CGA (32 KB) Because different modes uses different address mappings, it is possible to combine a monochome display adapter and color adapter on the same machine. This allows a computer with a dual monitor setup to be able to run without issues. Of course, this is just standard VGA. Super VGA Super VGA and other display adapters typically do things differently. It is not uncommon to see a Super VGA or higher resolution display adapter to have VRAM mapped to a high address range. While they will usually support the Standard VGA memory mapped range, they can use other memory ranges as well to help with high resolution video modes or to provide additional functionality. For example, my NVideo GeForce 7600 GT has 4 memory ranges that it can use: 0xA0000 - 0x000BFFFFF (Look familier?), 0xFC000000 - 0xFCFFFFFF, 0xD0000000 - 0xDFFFFFFF, and 0xFD000000 - 0xFDFFFFFF. This can be different on your system. Linear Frame Buffer (LFB) If it is possible to map the entire video memory of the current display into the physical address space, it is possible to set it up to act like a linear frame buffer. A linear frame buffer is just a packed-pixel frame buffer that allows you to be able to read or write to it in linear fashion. For example, buffer[0] is the first element of the buffer, buffer[1] is the second - there is nothing special. Well, actually there is. Standard VGA does not support LFB modes. Remember Mode 0x13 above? That is the only Standard VGA video mode that creates the effect of a linear frame buffer. This might be a little confusing. After all, how \"else\" can you read or write to video memory if its not in linear fashion? This has to do with Standard VGA being a planer device. We will talk about that after the next section, Bank Switching Super VGA and higher resolution video modes can also provide a way of using a \"window\" into the full video memory that is on the adapter. For example, notice above that, for graphics modes, we are limited to a 64KB region between 0xA0000 - 0xB0000 . If this was a \"window\", and we can \"move\" this 64K window around, we can access a much larger video memory area. For example: This is known as Bank Switching . A \"Bank\" is a window into the larger video memory. The size of the window is typically 64K do to standard VGA only having a graphics region of 64K. Planer Memory Okay, it gets a little tricky here. Standard VGA modes operate in planer memory mode. This is the VGAs native memory model. The above is an example of Mode 12h's planer memory format. Mode 12h has 4 bits per pixel. To draw a pixel, you have to set or unset the bit in the plane. To better understand this, imagine you have a 64k block of video memory. Imagine it as a flat sheet of paper and put three more behind it. Each sheet of paper is a 64k \"plane\" that shares this same 64k area of memory. Each plane holds a little bit of information about the pixel that it is used for. Dont worry to much about understanding planer memory and how it works, we wont be needing it in this chapter. It will be important when we cover VGA and Mode 12h in more detail however. Because we are using Mode 0x13, which hides the details of working with planer memory, we wont need it now. Odd / Even Memory Addressing Odd / Even Memory Addressing uses the Planer Memory model and is used in all text modes . All even addresses work with planes 0 or 2 and odd addresses work with planes 1 or 3. For example: Memory Address Plane Offset in plane 0 Plane 0 Offset 0 1 Plane 1 Offset 0 2 Plane 0 Offset 2 3 Plane 1 Offset 2 Remember what it is like writing to video memory in text modes? unsigned char* vmem = 0xb8000; vmem[0] = 'a'; // plane 0 [character plane] offset 0 vmem[1] = 0x7; // plane 1 [attribute plane] offset 0 vmem[2] = 'b'; // plane 0 [character plane] offset 2 vmem[3] = 0x7; // plane 1 [attribute plane] offset 2 In text modes, plane 0 is used to store character codes and plane 1 stores the attribute bytes. Plane 2 stores the font data. If you overwrite plane 2 when writing to video memory, you will overwrite the font installed at boot time by the BIOS. This means that, if you write over plane 2 in graphics mode, and go back to text mode, the BIOS text output routines will not work as expected as the font data is corrupt. If you would like to go back to text mode, you will either need to store your own font or backup the default font and write it back to plane 2 before using any text output routines again. Because we are not using the planer memory model in this chapter, we wont be using the Odd/Even addressing model in this chapter. Color Palette A Palette is like a look-up table. A Color Palette is a look-up table for colors. For example, we can store a list of the actual color information in a table. We can then use another table of indices into that table: Index Table Color Palette 0 red(0), green(0), blue(0) 1 red(0), green(0), blue(1) 2 red(0), green(1), blue(0) In the above example, we can reference whatever color we want by just using the index. That saves storage space greatly because after the look up table (The color palette) is created, any time that we want to refer to a color we just use the index. For example, in a video mode that uses a color palette, video memory acts as the index buffer. So, to draw a pixel using the palette that we created above, just write the index of the color that you would like to use: unsigned char* p = 0xa0000; p[0] = 0; // black pixel p[1] = 1; // blue pixel p[2] = 2; // green pixel In the VGA, the Color Palette is handled by the hardware. We can control and change the colors in the palette however way we want. However, because working with the palette requires VGA hardware programming, we will not cover it too much here. Dont worry, we will cover it when we get into VGA hardware. Palette Animation Okay, lets take a step back for a moment. Look at the above example again. Notice that the video display will determin what the color is of a pixel by an index. What if, lets say, that the index 1 in the color palette (Like in the above example) changes to a different color? Looking at the above example, index 1 in the color palette is a bright blue color. So, if we are in a palette video mode, any time we write a \"1\" to someplace in video memory, it will be that bright blue color. This means a simple memset (vidmem, 1, VIDMEM_SIZE) will effectively clear video display to this color. Cool, huh? Knowing that the video display determins what color to display for an index is inside of the Color Palette table, we can change what the color is for any palette entry. This allows us to change the colors on screen by just updating the colors in the palette in some way. This is known as Palette Animation . Palette Animation can create alot of really nice looking and cool effects, such as fire animation, icy effects, etc. Mode 0x13 Abstract (Mode 0x13) Video Mode 0x13 is a standard IBM VGA BIOS mode number for a 256 color 320x200 resolution. It uses a 256 color palette , did not have square pixels , and allowed access to the Video Memory as a Packed-Pixel Framebuffer . What this means is that it allowed access to video memory as if it was a linear buffer: Just get a pointer to video memory. pointer[0] = pixel 1, pointer[1] = pixel 2, and so on, assuming pointer is an unsigned char* . This is made possible by specific hardware register settings (The video mode \"configuation\") - Standard VGA does not, by itself, provide access to video memory like this. The important thing here is that video modes define the resolution, how video memory is accessed, and hardware configuation setup for the operation of that mode. Do not worry if you do not understand everything here; we will go into detail when we cover the VGA hardware in a later chapter. Because video Mode 0x13 is easy to work with (and fast) I decided to use it for the duration of this chapter. Some other modes require experience with the VGA hardware which I am wanting to avoid in this chapter do to its complexity. Dont worry though, I plan on covering some (Like Mode 12h, 640x480x4 color) later on. Video Mode 0x13 was used alot in the DOS era for video games do to its simplicity to program and speed. It is a video configuation for a 320 width, 200 height pixel resolution with a 256 color palette. It is a planer video memory mode but acts as a Linear Frame Buffer (LFB) which makes it easy to program. Color Palette (Mode 0x13) Mode 0x13 has a color palette of 256 colors. Video memory in Mode 0x13 only stores the palette index; the video device will determin what color to render from the installed palette color table. By default, the color table is this: Here is an example, looking at the above we can see the first color (0) is black, color 1 is blue, color 2 is green, etc. We can write these colors to video display by using these indices in the above lookup table: unsigned char* p = 0xa0000; *p = 0; //black pixel *(p++) = 1; // blue pixel *(p++) = 4; // red pixel *(p++) = 255; //white pixel Compare the above code to the table above and notice how the indices match with the colors in the palette. Changing the palette It is possible to change the palette to whatever colors that you would like. However there is not any easy BIOS interrupt for it (Not without using VBE anyways.) Most of the interrupt calls are used to set or get individual or all palette registers which are inside of the VGA Digital to Analog Converter (DAC) . This requires some knowledge of the VGA hardware which I am wanting to avoid this chapter for simplicity (Dont worry, I am planning on covering that soon!) Because of this, I decided to wait on covering palette changing (And mabye palette animations) in a future chapter. The Video BIOS Interface The VGA Video BIOS Interface is a set of video interrupts (Software interrupt 0x10). Because these are BIOS interrupts, they can only be used in real or v86 modes. Setting the video mode INT 0x10 Function 0 You can set the video mode by calling BIOS interrupt 0x10 function 0: Input AH = 0 AL = video mode Output AL = video mode flag (Phoenix, AMI BIOS) AL = CRT Controller (CRTC) mode byte (Phoenix 386 BIOS v1.10) You will see the CRTC alot more in the future as it is one of the controllers that you will need to program if you plan to directly program the video hardware. This interrupt can set any text or video mode. For example, the following switches to 320x200x8 bit [mode 0x13]: Please remember that all code samples can be found in the demo. mode13h: mov ah, 0 mov al, 0x13 int 0x10 ret</pre> Easy, huh? The above is all that is needed to get you in a graphics mode. Sure, it will only work in real or v86 mode, but it is as easy as you can get. Dont worry if you do not understand video modes yet; we will cover them a little later. Getting the video mode INT 0x10 Function 0xF You can get the video mode by calling BIOS interrupt 0x10 function 0xF: Input AH = 0xF Output AH = number of character columns AL = display mode number BH = active page This interrupt is an easy one and can be used to obtain the current video or text mode. Dont worry about the \"active page\" part yet. Dont worry if you do not understand video modes yet; we will cover them a little later. getMode: mov ah, 0xf int 0x10 ret Other Video BIOS Interrupts INT 0x10 Function 0xB/BH=1 You can set the palette by calling Video BIOS INT 0x10 function 0xB: Input AH = 0xB BH = 1 BL = Palette ID 00h background, green, red, and brown/yellow 01h background, cyan, magenta, and white This interrupt may not be supported on all systems. INT 0x10 Function 0xC You can write a pixel to the display using this interrupt. Input AH = 0xC BH = Page number AL = Pixel color if bit 7 set, value is XOR'ed onto screen except in 256-color modes CX = column DX = row Output AL = pixel color This interrupt can only be used in graphics modes. INT 0x10 Function 0xD You can read the pixel by calling Video BIOS INT 0x10 function 0xB: Input AH = 0xC BH = Page number CX = column DX = row This interrupt will only work on graphics modes. Primitives Plotting your first pixel \"The secret to making any video game is the ability to change the color of a pixel.\" - Teej We have covered alot in this chapter and have yet to draw a pixel on screen. Whats up with that? I decided to close this chapter with the basics of most basic graphics primitives - rendering a pixel to the screen. Because we are working in Mode 0x13, remember that it acts like a linear frame buffer. So vidmem[0] is the first byte of video memory, vidmem[1] is the second byte. Also, remember that Mode 0x13 uses a byte for each pixel as an index into the Color Palette. This means that, we can write a pixel easy like this: unsigned char* p = 0xa0000; p[0] = 1; // blue pixel Cool, huh? Thats all that is needed and you have a pixel! It is easier to think in terms of the cartesian coordinate system . In this system, we use coordinates, such as X and Y to represent its location on a 2d graph like this: The top-left corner of video memory is at v = [0,0] where v is a 2d vector. This is the first pixel in video display. The last byte is at v = [width, height] . Assuming each coordinate is a pixel, we can come up with a formula that allows us to be able to draw a pixel at any location on screen. Lets say we start at v = [0,0] in the graph above. If we add width to our position, we always end up right below where we were. For example, in the above graph, width = 16 . Assuming we started at the top-left corner, counting 16 to the right, you will find yourself right below (on the next line) from where you started. Because of this, we can calculate y by doing y * width . Afterwords we can just add x (The offset in that line) and we have our formula: To render a pixel at any [x,y] location, we use the formula x + y * width . With this, we can create a simple routine like this: ;-----------------------; ; renders pixel ; cl = color ax = y bx = x ; es:bp = buffer ;-----------------------; pixel: ; [x + y * width] = col pusha mov di, VGA_MODE13_WIDTH mul di ; ax = y * width add ax, bx ; add x mov di, ax mov byte [es:bp + di], cl ; plot pixel popa ret es:bp points to the video display, or another buffer that we want to render to. cl is the color index that you want to use, ax is the Y location and bx is the X location. Clearing the screen There are several ways of clearing the screen. This is important as alot of times when switching video modes, you may see alot of garbage on screen. One method that we can do is just call our pixel routine above width * height times. A better method would be to write multiple pixels at once. Knowing, for example, that the size of a pixel in Mode 13h is a byte, we can easily store 2 bytes (2 pixels) in a word size register and use that instead: ;---------------------------; ; clear screen ; cl = color ;---------------------------; clrscr: pusha mov dl, cl ; dx = 2 pixels mov dh, cl mov cx, 0 xor di, di .l: mov word [es:bp + di], dx ; plot 2 pixels inc di ; go forward 2 bytes inc di inc cx cmp cx, (VGA_MODE13_WIDTH * VGA_MODE13_HEIGHT) / 2 ;end of display? jl .l popa ret es:bp refers to either video memory or another buffer and cl is the color that you would like to use. Demo Demo Download This demo spices what we talked about a little by adding an additional routines: line , which renders a horizontal line, and is used to render the rectangles in the demo. Conclusion That's all for this chapter! The next chapter will cover VESA VBE and how we can use it to work with high resolution graphics modes. We will also cover the Super VGA, Bank Switching, and a few more graphics concepts including Double and Triple Buffering, and Page Flipping . Thats right, we are going high resolution with VBE ðŸ˜€ We will also be going back to C in the next chapter and cover some more graphics primitives. I still plan on covering VGA hardware however that will be after VBE. VGA hardware is quite overcomplicated; I want to hold off on the more complex topics in graphics and VGA until a little later."
  },
  "articles/61_unorganised_tutorial/Z3b.html": {
    "href": "articles/61_unorganised_tutorial/Z3b.html",
    "title": "Graphics 2: VGA and SuperVGA | BrokenThorn OS Dev Tutorials",
    "keywords": "Graphics 2: VGA and SuperVGA Welcome! In the previous article, we introduced some concepts pertaining to video devices with an emphasize on VGA on the Video BIOS firmware. In this article, we will look at different hardware and firmware interfaces for video devices for VGA, SuperVGA and Video BIOS support and implement a common video interface in C supporting the interfaces. Here are the topics to be covered. VGA hardware VGA BIOS Vesa BIOS Extensions style=\"margin-bottom: 0.2in\">Bochs VBE Interface Introduction We first introduce the Video Graphics Array (VGA) standard as it is the most supported on personal computers and one of the oldest. The VGA standard provides a way to interact with video hardware in a standard way, but it is limited to low resolution display modes and lack of graphics acceleration support present in modern display devices. We will look at both the hardware interface and the VGA BIOS firmware interface. The VGA BIOS interface is by far simpler then the VGA hardware interface but can only be used in real or v86 processor modes. The hardware interface can be used from any processor mode. Then we move on to Vesa BIOS Extensions (VBE) . VBE is a standard developed by the Video Electronic Standards Association (Vesa) that provides a standard set of BIOS extensions for supporting high resolution display modes and monitor features. Due to it being a BIOS extension, not all personal computers support it. It also can only be used from real or v86 modes. In summary, the goal of this chapter is to cover changing the video mode and accessing display memory. By the end of the chapter, you should have a demo built that does just that, either using VGA or SuperVGA. Later chapters will then focus on the graphics (and possibly some SuperVGA hardware graphics support.) Interfacing with the BIOS Before we start getting into the main topics of the chapter, we need to take a small detour and take a closer look at the BIOS. You may recall our use of some of these BIOS services for VGA in the previous article. If the software uses any of these services then it must run in real or v8086 mode. This poses a problem for protected mode or long mode software. Thus we need to find a way to resolve this before continuing. If you don't plan on using any BIOS services, however, please feel free to skip this section. There are two approaches of calling the BIOS from protected mode (not long mode.) Drop down to real mode and call the BIOS Virtual 8086 mode The first method is simpler but can be very ugly for more complete designed systems. The second approach is the most commonly used method but is also the hardest; requiring user mode, interrupt dispatching, task switching, and instruction emulation. Method 1 The first method requires that the software be able to switch to real mode from protected mode when needed. Without certain restrictions applied to the software design (such as not supporting virtual memory or higher half kernel support) this method can become increasingly complicated to support to the point where it is not worth it. It is, however, the simplest method to implement and requires the least amount of additional software support. For these reasons, we opted to go with this method for the associated demos but highly recommend using method 2 when the software system is large enough to warrant the need. In order to implement this method, we need a routine or a set of routines to act as an interface between 32 bit protected mode and 16 bit real mode. These routines must do the following while preserving routine input and output values. Save current system state that must be reserved. In the most basic case, this is the protected mode stack and IDTR. Disable hardware interrupts (CLI instruction). Reload original IVT. This is done by setting IDTR.size to 0xffff and IDTR.base to 0. Perform a jump to 16 bit protected mode. Disable protected mode by clearing CR0.PM bit Perform a jump to 16 bit real mode code. Set all real mode segments, enable interrupts and call BIOS. Perform a jump to 32 bit protected mode. Restore saved system state. In the most basic case as in (1) this is the selectors, protected mode stack, and IDTR. This routines can get very complicated as the system becomes more demanding in what it supports. The above list sounds like a lot, but its more tricky then hardâ€”provided the system does not use paging and the kernel image is less then 1MB. In other words, we assume the project base address is 64K and paging is disabled in order to keep the routine relatively simple. In the demos, the method io_services is used to call the BIOS. It drops into real mode using the steps above. io_services looks like this: extern void io_services (unsigned int num, INTR* in, INTR* out); Where num is the interrupt number, in is a pointer to a INTR structure, and out is a pointer to an output INTR structure. INTR is a set of structures that store register values. Both io_services and INTR are fairly large and so will be omitted in the text. Please reference bios.asm in the demos. Example: This example uses the function io_services and INTR structure to call the BIOS to set the video mode. Note the C code is runs in protected mode. void vga_set_mode(int mode) { /* call BIOS */ INTR in, out; in.eax.val = mode; io_services (0x10, &in, &out); } If the software is in long mode, the only options is to program the device directly or to write an emulator. Method 2 The second method is using v8086 mode. This is by far the best long-term way to support calling the BIOS firmware but is also the most demanding. At a minimum, v8086 mode requires that the operating system support the following. User mode processes Task switching Interrupt dispatching Instruction emulation Virtual 8086 mode can only execute as user mode processes. This poses a problem however as user mode processes can not execute kernel mode instructions (like int ) and so can not call the BIOS which sort of defeats the purpose. In other words, when the v8086 process executes an int (interrupt) instruction, it triggers a general protection fault (GPF) . What can we do to fix this? We are not entirely out of solutions here. While the v8086 process cannot call the BIOS, the kernel can . When the GPF occurs, the kernel effectively gets called. The kernel GPF handler then can detect what caused the GPF and do something about it like so: Check current process.v8086 flag If set; call v86_monitor If not set, continue with GPF and possibly terminate process Our v86_monitor is a special function that is called by the kernel GPF handler for all v8086 processes. Now we are getting somewhere; what we have here is that whenever the v8086 process attempts to call the BIOS (or use any kernel mode instruction) the kernel GPF handler gets called which calls v86_monitor to â€œmonitorâ€ the v8086 task. The v86_monitor implements a v8086 monitor that is responsible for emulating the problem instructions the v8086 task tried to use. For example, the v8086 monitor would detect the problem instruction (it will have the CS:EIP given by the CPU) as an interrupt call and emulate it by invoking IVT [n] where n = BIOS number to call (recall however that the IVT instruction pointers are in segment:offset format not linear.) Video Graphics Array (VGA) Readers may skip this section if you only want to look at SuperVGA. The Video Graphics Array (VGA) is the design of display hardware first introduced in 1987 for the IBM PS/2 computers [1] but has been widely adopted by organizations as a display standard. The highest video mode resolution supported is 640x480x16 color. Due to the widespread adoption by PC manufactures, VGA has become one of the oldest standards still supported by modern PC's. VGA was followed by IBM's Extended Graphics Array (XGA) standard but extensions implemented by different manufacturers produced SuperVGA adapters that are common in modern PC's. Most SuperVGA cards are backward compatible with the VGA standard. Please note that this is not going to be an exhaustive explanation of VGA due to its complexity. Please reference resources [2] and [3] for more information on VGA hardware and I encourage reading one of the many large books on VGA. Video modes There is a standard set of video modes and mode numbers supported by VGA. The video mode refers to the display configuration and its properties, such as resolution , bit depth (bits per pixel), number of colors, memory mode , etc. Standard video mode numbers are 0h, 1h, 2h, 3h, 4h, 5h, 7h, Dh, Eh, Fh, 10h, 11h, 12h, and 13h. There is nothing special about the mode number itself; it is just used by the video BIOS to refer to a particular video mode. There may be more modes, however they are nonstandard. Mode Resolution Color depth Mode Resolution Color depth 0h 40x25 Text 16 Color Dh 320x200 16 Color 1h 40x25 Text 16 Color Eh 640x200 16 Color 2h 80x25 Text 16 Color Fh 640x350 2 Color 3h 80x25 Text 16 Color 10h 640x350 16 Color 4h 320x200 4 Color 11h 640x480 2 Color 5h 320x200 4 Gray 12h 640x480 16 Color 7h 80x25 Text 2 Color 13h 320x200 256 Color The highest resolution supported by standard VGA is mode 12h which is 640x480x16 color. (Interesting note, Windows XP logo screen runs in mode 12h.) Higher resolutions can only be obtained using SuperVGA which is described later on. VGA Firmware We first look at the firmware interface of VGA, and the facilities provided by the Video BIOS . In the last article we introduced some of the facilities, most notably interrupt 0x10 function 0 to set the video mode. The Video BIOS provides services for setting, getting, and working with VGA hardware through a more abstract interface. Arguably it is far more safer, simpler, and more portable for software to use the video BIOS facilities then it is to directly control the hardware. Here we present some of the common facilities that software can use for video services. Of course, because these are BIOS interrupts, they can only be used in real or v8086 mode and on systems that have BIOS firmware. Also, they can only be used by kernel mode software. INT 0x10 Function 0 â€“ Set Video Mode Input: AH=0 AL = video mode Output: AL=video mode flag (Phoenix, AMI BIOS) AL = CRT Controller (CRTC) mode byte (Phoenix 386 BIOS v1.10) Example: This function sets the video mode. void vga_set_mode (int mode) { /* call BIOS */ INTR in, out; in.eax.val = mode; io_services (0x10, &in, &out); } We can now use the above function to set any VGA BIOS video mode, such as Mode 13h. The result might look something like this. As you can see from the above image, there is a lot of garbage on the display. This â€œgarbageâ€ is actually what what was in VGA memory before the mode switch. This includes everything from all 4 planes (we will look at these later on) such as any textural characters from plane 1 and the VGA font in plane 2. If we clear the display, all of this is cleared. This is a problem if the software must return back to text mode because by clearing the display the software cleared the VGA font. There are two ways to fix this: Upload a new copy of the VGA font from the BIOS Save the VGA font before clearing memory and restoring it later. By performing one of the above the software can switch to a graphics mode and return back to text mode without error. INT 0x10 Function B â€“ Set Palette (Text modes only) Input: AH=B BH=1 BL=Palette ID. 00h background, green, red, and brown/yellow 01h background, cyan, magenta, and white Example: The following code sets a VGA palette. void vga_set_palette (int id) { /* call BIOS */ INTR in, out; in.eax.val = 0xB; in.ebx.val = 0x0100 | id; io_services (0x10, &in, &out); } INT 0x10 Function C â€“ Write pixel Input: AH=C BH=Page number AL=Pixel color CX=Column DX=Row Output: AL=Pixel color Example: The following writes a pixel. This might be omitted in the demos as it shouldn't be used; we only provide it for completeness. void vga_plot_pixel (int col, int x, int y) { /* call BIOS */ INTR in, out; in.eax.val = 0x0C00 | col; in.ebx.val = 0; in.ecx.val = x; in.edx.val = y; io_services (0x10, &in, &out); } Note that some versions of the Bochs emulator do not support this interrupt. It is however implemented for VirtualPC. We can use the above interrupt to plot pixels. INT 0x10 Function F â€“ Get Video Mode Input: AH=F Output: AH=Number of character columns AL=Display page number BH=Active page Example: The following code returns the mode information. void vga_get_mode (unsigned int* col, unsigned int* dispPage, unsigned int* actPage) { INTR in, out; /* sanity check */ if (!col || !dispPage || !actPage) return; in.eax.val = 0xf; io_services (0x10, &in, &out); *dispPage = out.ax.r.al; *actPage = out.bx.r.bh; } VGA Hardware Interface The VGA hardware interface is very complex, consisting of five controllers and over a hundred hardware registers accessible from the Port I/O address space. A standard set of register configurations help define the standard VGA video modes we still see today. Due to the use of the Port I/O address space, software can interface with the VGA hardware in any processor mode. Of course, the software must be in supervisor level (ring 0) for the in and out family of instructions to actually interact with the hardware. Thus, only kernel mode software can access VGA hardware. User mode software that attempts it will generate a general protection fault when executing the in or out instruction. Before looking at the hardware, there is a warning. The warning applies to all display monitors and video cards that may lack protection from invalid data or data outside of the range supported by the device (for example, an excess frequency setting that the device is unable to work with in a safe manner.) Most modern monitors will display an error message or show no output on invalid settings. Make sure to test the driver software in an emulator and virtual environment first and verify the driver software works properly before testing on real hardware. Video memory The memory layout of VGA differs depending on the type of video mode is currently active. The VGA supports the following memory layouts. Linear Planar Palette 4 Color mode We will take a look at all of these modes next and when they are used. Knowing the different memory models is important in order to properly read and write to display memory. We will cover linear modes last as it is the most complex. Before that though, we first need to know how to access video memory. Recall the memory map that we have looked at in the system architecture chapter. Here it is again. 0x00000000 - 0x000003FF - Real Mode Interrupt Vector Table 0x00000400 - 0x000004FF - BIOS Data Area 0x00000500 - 0x00007BFF - Unused 0x00007C00 - 0x00007DFF - Our Bootloader 0x00007E00 - 0x0009FFFF - Unused 0x000A0000 - 0x000BFFFF - Video RAM (VRAM) Memory 0x000B0000 - 0x000B7777 - Monochrome Video Memory 0x000B8000 - 0x000BFFFF - Color Video Memory 0x000C0000 - 0x000C7FFF - Video ROM BIOS 0x000C8000 - 0x000EFFFF - BIOS Shadow Area 0x000F0000 - 0x000FFFFF - System BIOS According to the memory map, video memory is mapped into the physical address space at 0xA0000 â€“ 0xBFFFF . This is 0x1FFFF bytes of memory or 131072 bytes which is 128K. According to [2] VGA hardware has up to 256K or memory however only 128K of it is mapped. The unmapped memory is accessible by changing the address decoding mechanism of the VGA (we will not cover that here though.) Graphics mode memory starts at 0xA0000 and may extend to 0xAFFFF, or 64K. Some of the following examples will demonstrate this. Planar memory modes (16 bit color modes) VGA memory is referenced as 4 planes each 64k of memory. You can think of them as different memory banks that are connected to each other (although that might not be the case.) Its sort of like having 4 windows on top of each other. Those windows are the planes. In 16 color modes there are 4 bits per color. The 4 bits are stored at the same location on each plane. Example: A 4 bit pixel can be stored at plane0[0], plane1[0], plane2[0] and plane3[0]. This displays a single pixel to display memory. Notice that the 4 bit pixel is stored across all 4 planes, where each plane only stores one bit of the pixel. Also notice that the pixel is at the same location (index is 0) of all 4 planes. We will show an example of how to write a pixel in planar memory modes a little later after reviewing the registers and how to set a video mode. Unfortunately writing a pixel requires also writing to a hardware register to select the plane to write to and thus an example cannot be provided yet. Palette memory modes (256 color modes) In palette memory modes, each pixel is represented by a numberâ€”an _indexâ€”_into a color table. The color table is the palette . Probably most notable is the 256 color mode, where each pixel is 8 bits. Other palette modes include the 16 color (4 bit pixel) and monochrome (1 bit pixel) modes that have only 2 colors. The color table might look something like this. This is the palette used in a 16 color mode; in fact, its the VGA text mode palette that is the default on system start up. Index Color name Index Color name 0 Black 8 Dark Gray 1 Blue 9 Light Blue 2 Green 10 Light Green 3 Cyan 11 Light Cyan 4 Red 12 Light Red 5 Magenta 13 Light Magenta 6 Brown 14 Yellow 7 Light Gray 15 White Lets look at an example of the palette use in text modes. Note Recall that in text modes, each character includes a character code (ASCII character typically) and an attribute byte. The attribute byte is an index into the above palette. In other words, if you have worked with text modes in protected mode you have already been working with a palette memory mode! 256 color modes were widely used by DOS video games. This became infamously known as Mode 13h after its standard Video BIOS mode number. Mode 13h is an interesting mode because it is very fast, linear, and can display 256 colors on the screen at once. In other words, video memory in this mode is linear where each pixel is 1 byte and stored right after each other in memory. What makes Mode 13h interesting is that VGA is a planar display device not a linear one. Example: The following C code defines a function, pixel_256 that plots a pixel in 256 color mode at some x and y location in mode 13h. Recall that mode 13h is 320x200 and so the pitch (here pitch is width) is 320. Also unlike the VGA BIOS interrupt plot pixel service, this one will work in any PC emulator or virtual machine. #define VGA_VRAM 0xA0000 #define PITCH 320 void pixel_256 (unsigned char color, unsigned int x, unsigned int y) { unsigned char* fb = (unsigned char*) VGA_VRAM; unsigned int offset = y * PITCH + x; fb [offset] = color; } The above example also demonstrates the simplicity of working with Mode 13h. We can render multiple pixels by just writing to them consecutively. In 256 color modes each pixel is represented as a byte so we use unsigned char's. In palette memory modes, there is a maximum to the amount of colors that can be displayed at once. This is the same as the number of entries in the color table being used for the mode. For example, 256 color mode can only display at most 256 colors on the screen at once. 16 color modes can only display 16 colors. Software could modify the color table itself in order to display different colors. Linear memory modes Linear memory modes are the set of video modes that support a linear frame buffer (LFB) . Linear memory is an array of consecutive bytes; like an array in C. Mode 13h is an example mode that has a linear memory model. Another example is the infamous Mode X (360x480x256 color) and Mode Q (chain-4 256x256x256 color) which are modified versions of Mode 13h. Recall that VGA is not a linear device; it does not support linear memory modes. Modes like Mode 13h, Mode X, and Mode Q are all planar modes that configure the hardware in a way that creates the illusion of a linear memory model. To write a pixel in linear memory modes, all we need to do is calculate the offset of the pixel location and write the pixel to the frame buffer. Example. : The following code plots a 8 bit pixel in a linear memory mode. This example is the same as the above but is more generic; it can be applied to any mode that has a linear memory model. #define VGA_VRAM 0xA0000 #define PITCH 320 void pixel_256 (unsigned char color, unsigned int x, unsigned int y) { unsigned char* fb = (unsigned char*) VGA_VRAM; unsigned int offset = y * PITCH + x; fb [offset] = color; } Hardware The VGA hardware design consists of the following components. Some of these might look familiar. CRT Controller Sequencer Graphics Controller RAMDAC Video memory Attribute Controller All of the hardware registers are mapped into the I/O port space. That is, we can access them using the in and out family of CPU instructions. Most of the controllers map two registers: an address register and data register . The address register stores an index of a particular register that we want to read or write from, the data register contains the data of that register. This may become more clear as we see some examples. Before looking at each of these components, we would like to emphasize the complexity of VGA hardware. Entire books have been written that covers VGA in depth; covering all of the details in a single article is a very daunting task. In order to keep the discussion minimal, we will only look at what each component does and the set of registers used by the component. Due to the large number of registers, we will not be describing the registers here. Unfortunately we cannot describe how to set a video mode without having some background in the hardware registers. To rectify this, we present a list of all of the registers and a table of the video mode settings will be listed at the end. This will allow readers to set VGA video modes without having to worry about the details of each register nor its format . We do encourage reading more about each register by referencing [3] and [4] however for anyone that is interested in learning more about VGA. In short, don't worry to much on the details of the registers. The video mode list will tell you what value to put into what register. CRT Controller (CRTC) Warning Improperly configuring the CRT Controller (CRTC) can potentially damage the video card or attached monitor . Although rare, instances of CRT and LCD monitors have been known to burn out or explode due to improper or erroneous configuration. The CRT Controller (CRTC) is responsible for controlling the output of video data to the display monitor. It is accessed by an address and data register. Address register is at 3D4h the Data Register is at 3D5h (or 3B4h, 3B5h respectively if Miscellaneous Output Register I/O Address select field is set.) We can select what CRTC register we want to access by using the address register. We can then use the data register to read or write from that CRTC register. We will not be providing a complete technical review of each register due to the number of registers. Please reference the FreeVGA project page dedicated to describing the CRT registers in detail. If there is demand, we may extend our topic on VGA in the future. Register Description 0 Horizontal total register 1 End Horizontal display register 2 Start horizontal blanking register 3 End horizontal blanking register 4 Start horizontal retrace register 5 End horizontal retrace register 6 Vertical total register 7 Overflow register 8 Preset row scan line register 9 Maximum scan line register 10 Cursor start register 11 Cursor end register 12 Start address high register 13 Start address low register 14 Cursor location high register 15 Cursor location low register 16 Vertical retrace start register 17 Vertical retrace end register 18 Vertical display end register 19 Offset register 20 Underline location register 21 Start vertical blanking register 22 End vertical blanking register 23 CRTC mode control register 24 Line compare register The CRTC registers allow us to control the pixel clock timings of the horizontal and vertical retrace and blanking periods of the display. These timing periods help control the output of the display (the video resolution ), and the refresh rate . Other CRTC registers allow us to change the start address of video memory (the preset row scan line and start address registers, hardware cursor location ( cursor location registers) and underline ( underline location register.) The CRTC mode control register gives us some way of controlling the CRT itself and some addressing modes. Graphics Controller The graphics controller is responsible for managing the interface between CPU and video memory. The address register is mapped to 3CEh and the data register is mapped to 3CFh . In order to access the graphics controller registers, write the index of the register into the address register and read or write from the data register. The following is a list of the standard registers. Please reference the FreeVGA project for a detailed description of each register. Register Description 0 Set/Reset register 1 Enable Set/Reset register 2 Color compare register 3 Data rotate register 4 Read map select register 5 Graphics mode register 6 Miscellaneous graphics register 7 Color don't care register 8 Bit mask register Sequencer The sequencer manages the interface between the video data and RAMDAC. The address register is mapped to 3C4h and the data register is mapped to 3C5h . In order to access the sequencer registers, write the index of the register into the address register and read or write from the data register. The following is a list of the standard registers. Please reference the FreeVGA project for a detailed description of each register. Register Description 0 Reset register 1 Clocking mode register 2 Map mask register 3 Character map register 4 Sequencer memory mode register Attribute Controller The attribute controller consists of 21 registers for the VGA. The controller has two registers mapped into I/O port space, one at 3C0h and the other at 3C1h . Unlike the other controllers, the attribute controller uses the register at 3C0h as both a data write port and address port . The register at 3C1h is the data read register . In order to communicate with the attribute controller, the software should first write a register address to port 3C0h followed by the data to write to that register . Data can be read by writing to port 3C0h and reading from 3C1h after . The attribute address register also has a particular format. Attribute address register bit format: 0-4 : address 5 : PAS Address refers to a register index to access. Please refer to the following table of registers. PAS (Palette Address Source) Determines access to palette data by host or EGA display adapter. If it is 0, the host can access the palette RAM and the adapter will disallow display memory from gaining access to the palette. If 1, the display memory can access the palette RAM and the host is disallowed from accessing it. The attribute controller stores a set of 16 palette registers that map a color index to a color. This small palette is a drawback from EGA. VGA still uses these registers but instead of storing the palette information it stores an address into a second set of color index registers. We won't be covering the details of how it all works â€“ but I encourage reading [4] page 394 for anyone that is interested. The following is a list of the standard registers. Please reference the FreeVGA project or [4] for a detailed description of each register. Register Description 0-15 Palette entry register 16 Mode control register 17 Overscan color register 18 Color plane enable register 19 Horizontal pixel panning register 20 Color select register General Registers / External Registers These register lists just don't seem to end do they? We have looked at lists of registers for all of the major controllers of VGA however there are more sets of registers for general use and miscellaneous data that are used by the video modes and thus need to be looked at. These registers can be referred to as general registers or external registers . The following is a list of the standard registers. Please reference the FreeVGA project or [4] for a detailed description of each register. Please note that we assume a color adapter and VGA (not EGA). Monochrome and EGA adapters may use different ports. register Write port Read port Miscellaneous output register 3C2h 3CCh Feature control register 3BAh 3CAh Input Status #0 register 3C2h Input Status #1 register 3BAh Color Registers These registers allow us the software to manipulate and manage the 256 color palette. They are an important set of registers if working in 256 color modes and may be used after setting the video mode so getting familiar with them is a good idea. You might also be happy to learn that this is the final set of registers that we are going to look at. The following is a list of the standard registers. Please reference the FreeVGA project or [4] for a detailed description of each register. register Write port Read port PEL address write mode register 3C8h 3C8h PEL address read mode register 3C7h PEL data register 3C9h 3C9h DAC state register 3C7h PEL mask register 3C6h 3C6h Standard video modes By configuring the video hardware we can define different display modes with different properties. However many modes that the video hardware can support many monitors do not. Other configurations may have undesired effects. Some VGA mode configurations have become a standard; well supported by most monitors. The following is a list of standard video modes and their configurations. Standard video mode numbers are Mode 0h, 1h, 2h, 3h, 4h, 5h, 7h, Dh, Eh, Fh, 10h, 11h, 12h, and 13h . Other notable modes, such as Mode X and Mode Q while well supported are not standard modes. Please reference [3] or [4] for other lists. The following tables were adopted from pages 304-305 of [4]. The tables are split between the different sets of registers each mode modifies. The top row indicates the mode number, the left column is the index to use to access the particular register. According to [4] the values presented represent the initial mode state the standard video BIOS uses. In order to set a video mode, the software must disable the video output and write the associated values to all of the hardware registers that it modifies. This sets everything â€“ the read/write modes, address start, horizontal and vertical blanking periods and timing, refresh rate, resolution, graphics mode type, and more. While every attempt has been made to insure accuracy, there might be some errors that have been undetected in the following tables. The tables were written to match that of which what was presented in [4] but may have errors in the rewrite. We give all credit to the original authors. General registers Index/Mode 0 1 2 3 4 5 6 7 D E F 10 11 12 13 0 63 63 63 63 63 63 63 A6 63 63 A2 A3 E3 E3 63 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 3 4 4 5 5 4 4 5 FF 4 4 FF 4 4 4 4 Sequence registers Index/Mode 0 1 2 3 4 5 6 7 D E F 10 11 12 13 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 9 9 1 1 9 9 1 0 9 1 1 1 1 1 1 2 3 3 3 3 3 3 1 3 F F F F F F F 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 2 2 2 2 2 2 6 2 6 6 6 6 6 6 E CRTC Registers Index/Mode 0 1 2 3 4 5 6 7 D E F 10 11 12 13 0 2D 2D 5F 5F 2D 2D 5F FF 2D 5F FF 5F 5F 5F 5F 1 27 27 4F 4F 27 27 4F FF 27 4F FF 4F 4F 4F 4F 2 28 28 50 50 28 28 50 FF 28 50 FF 50 50 50 50 3 90 90 82 82 90 90 82 FF 90 82 FF 82 82 82 82 4 2B 2B 55 55 2B 2B 54 FF 2B 54 FF 54 54 54 24 5 A0 A0 81 81 80 80 80 FF 80 80 FF 80 80 80 80 6 BF BF BF BF BF BF BF FF BF BF FF BF B B BF 7 1F 1F 1F 1F 1F 1F 1F FF 1F 1F FF 1F 3E 3E 1F 8 0 0 0 0 0 0 0 FF 0 0 FF 0 0 0 0 9 C7 C7 C7 C7 C1 C1 C1 FF C0 C0 FF 40 40 40 41 A 6 6 6 6 0 0 0 FF 0 0 FF 0 0 0 0 B 7 7 7 7 0 0 0 FF 0 0 FF 0 0 0 0 C 0 0 0 0 0 0 0 FF 0 0 FF 0 0 0 0 D 0 0 0 0 0 0 0 FF 0 0 FF 0 0 0 0 E 0 0 0 0 0 0 0 FF 0 0 FF 0 0 0 0 F 31 31 59 59 31 31 59 FF 31 59 FF 59 59 59 31 10 9C 9C 9C 9C 9C 9C 9C FF 9C 9C FF 83 EA EA 9C 11 8E 8E 8E 8E 8E 8E 8E FF 8E 8E FF 85 8C 8C 8E 12 8F 8F 8F 8F 8F 8F 8F FF 8F 8F FF 5D DF DF 8F 13 14 14 28 28 14 14 28 FF 14 28 FF 28 28 28 28 14 1F 1F 1F 1F 0 0 0 FF 0 0 FF F 0 0 40 15 96 96 96 96 96 96 96 FF 96 96 FF 63 E7 E7 96 16 B9 B9 B9 B9 B9 B9 B9 FF B9 B9 FF BA 4 4 B9 17 A3 A3 A3 A3 A2 A2 C2 FF E3 E3 FF E3 C3 E3 A3 18 FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF Graphics Controller Registers Index/Mode 0 1 2 3 4 5 6 7 D E F 10 11 12 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 10 10 10 10 30 30 0 10 10 0 0 10 0 0 40 6 0E 0E 0E 0E 0F 0F 0D 0A 5 5 5 5 5 5 5 7 0 0 0 0 0 0 0 0 0 F 5 0 5 F F 8 FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF Attribute Controller Registers Index/Mode 0 1 2 3 4 5 6 7 D E F 10 11 12 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 13 13 17 8 1 1 8 1 3F 1 1 2 2 2 2 2 15 15 17 8 2 2 0 2 3F 2 2 3 3 3 3 3 17 17 17 8 3 3 0 3 3F 3 3 4 4 4 4 4 2 2 17 8 4 4 18 4 3F 4 4 5 5 5 5 5 4 4 17 8 5 5 18 5 3F 5 5 6 6 6 6 6 6 6 17 8 6 6 0 14 3F 14 6 7 7 7 7 7 7 7 17 8 7 7 0 7 3F 7 7 8 10 10 10 10 10 10 17 10 10 10 0 38 3F 38 8 9 11 11 11 11 11 11 17 18 11 11 8 39 3F 39 9 A 12 12 12 12 12 12 17 18 12 12 0 3A 3F 3A 0A B 13 13 13 13 13 13 17 18 13 13 0 3B 3F 3B 0B C 14 14 14 14 14 14 17 18 14 14 0 3C 3F 3C 0C D 15 15 15 15 15 15 17 18 15 15 18 3D 3F 3D 0D E 16 16 16 16 16 16 17 18 16 16 0 3E 3F 3E 0E F 17 17 17 17 17 17 17 18 17 17 0 3F 3F 3F 0F 10 8 8 8 8 1 1 1 0E 1 1 0B 1 1 1 41 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 12 0F 0F 0F 0F 3 3 1 0F 0F 0F 5 0F 0F 0F 0F 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 14 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 To set a video mode, we must set all of the registers the mode modifies in the above tables. The following example illustrates setting the mode. Example: In order to set a video mode, we need to upload all of the values into the registers associated with that mode. For example, if we have a function, uploadRegisters , that does this, we can set Mode 13h by doing the following. unsigned char _mode13h = { /* general registers */ 0x63,0,0x70,0x4, /* sequencer */ 0x3,0x1,0xF,0,0xE, /* CRTC */ 0x5F,0x4F,0x50,0x82,0x24,0x80,0xBF,0x1F,0,0x41, 0,0,0,0,0,0x31,0x9C,0x8E,0x8F,0x28,0x40,0x96,0x89,0xA3,0xFF, /* graphics */ 0,0,0,0,0,0x40,0x5,0xF,0xFF, /* attribute */ 0,1,2,3,4,5,6,7,8,9,0xA,0xB,0xC,0xD,0xE,0xF,0x41,0,0xF,0,0 } /* set mode 13h */ uploadRegisters (&_mode13); After writing the register values, we have successfully changed video modes. Recall that we have looked at the planar memory model earlier; we could not complete an example of plotting a pixel until looking at the hardware registers. We now present that example now. Example: The following code plots a 8 bit pixel in a planar mode. void pixel_p (unsigned char color, unsigned int x, unsigned int y) { unsigned int* fb = (unsigned int*) 0xa0000; unsigned int offset = y * pitch + (x/8); bankSwitch (offset >> 16); /* writes to bit mask register of graphics controller to select plane */ outportb(0x3CE,8); outportb(0x3CF,0x80 >> (x & 7)); fb [bankOffset] = color; } SuperVGA Interface SuperVGA refers to the class of display hardware that includes SuperVGA (SVGA), and typically also XGA, SXGA, SXGA+, UXGA, QXGA, QSXGA, and other standards that support resolutions to 2560x2048 and higher. SuperVGA began as a set of extensions by manufacturers to VGA and adopted into separate SuperVGA standards that we have today. This means that there is no all encompassing standard for SuperVGA devices. Every SuperVGA card is different and provide different hardware and firmware interfaces. Thus we have a problem. How could we support SuperVGA if there is no standard way of using it? The problem is compounded by the fact that most manufacturers do not release the technical specifications for the cards. Instead they write black box drivers for different operating systems such as Windows and Linux. Thus, in order for us to support SuperVGA devices we have only two options. Write a device driver for each type of display device we want to support. Use Vesa Bios Extensions (VBE) The first option is hard because we need to have the specification to work off of. For devices where we cannot get any specification we have to rely on reverse engineering. The SuperVGA â€œcardâ€ we will look at is the one used in the Bochs emulator. We chose this one because anyone that uses Bochs could use it. The code for the driver will be Bochs specific however. The second option is by using Vesa Bios Extensions (VBE) . VBE is a standard set of BIOS interrupt extensions for SuperVGA hardware. VBE is very simple to work with and creates a single standard interface for working with SuperVGA. It does however require real mode or v8086 mode and not all machines support VBE since it uses BIOS interrupts and is an extension. Vesa Bios Extensions (VBE) Firmware Interface Vesa Bios Extensions (VBE) defines a set of BIOS interrupt services for working with SuperVGA modes. VBE is defined in the Vesa Bios Extensions (VBE) Core Standard . (Please reference [5].) Kernel mode software could call the BIOS services in real mode or v8086 mode. VBE Mode numbers VBE defines a set of mode numbers in a similar way the video BIOS does. A mode number has the following format. Bits Description 0-8 Mode 9-13 Reserved, set to 0 14 LFB 15 DM Mode number is the actual mode number. If bit 8 is set, it is a standard VESA defined mode (more on this later.) LFB selects the mode as a Linear Frame Buffer (LFB) or Bank Switching mode. If 0, it uses bank switching and uses the standard VGA frame buffer. If 1, it uses a linear frame buffer. DM selects whether or not to clear display memory when setting the mode. If 0, display memory is cleared. If 1, display memory is not cleared. VESA defined modes are a standard set of video mode numbers that BIOS venders are recommended to support. The following table lists the graphical modes. Mode Resolution Color depth 100h 640x480 256 101h 640x480 256 102h 800x600 16 103h 800x600 256 10Dh 320x200 32K 10Eh 320x200 64K 10Fh 320x200 16.8M 110h 640x480 32K 111h 640x480 64K 112h 640x480 16.8M 113h 800x600 32K 114h 800x600 64K 115h 800x600 16.8M 116h 1024x768 32K 117h 1024x768 64K 118h 1024x768 16.8M 119h 1280x1024 32K 11Ah 1280x1024 64K 11Bh 1280x1024 16.8M Mode numbers beyond 11Bh can also be defined but are not standard. Thus there can be some support for even higher resolution modes. Note The VBE mode number 113h selects 800x600x32K color mode that uses bank switching while the VBE mode 8113h selects 800x600x32 color mode that uses a linear frame buffer (LFB). Remember the mode number format! VBE Services We now turn our attention to the VBE BIOS services. Please keep in mind all of these services can be referenced in [5]. We will also provide samples in C. We are only going to look at the three most important services required to set a video mode and display memory access. Please reference the specification (which is one of the easier specifications to read) for other interrupts. INT 0x10 Function 4F00h â€“ Get VBE Controller Information Input: AX=4F00h ES:DI=Pointer to VbeInfoBlock structure (See following example) Output: AX=Status vbeInfoBlock structure has the following format: typedef struct _vbeInfoBlock { uint8_t signature[4]; // â€œVESAâ€ uint16_t version; // Either 0x0200 (VBE 2.0) or 0x0300 (VBE 3.0) uint32_t oemString; // Far pointer to OEM name uint8_t capabilities[4]; // capabilities uint32_t videoModesPtr; // Far pointer to video mode list uint16_t totalMemory; // Memory size in 64K blocks uint16_t oemSoftwareRev; uint32_t oemVenderNamePtr; uint32_t oemProductNamePtr; uint32_t oemProductRevPtr; uint8_t reserved [222]; uint8_t oemData [256]; } vbeInfoBlock; The vbeInfoBlock.capabilities field has the following format: Bits Description 0 D0 1 D1 2 D2 3-31 Reserved D0: If 0, DAC is fixed at 6 bits per color. If 1, DAC width can be switched to 8 bits per color. D1: If 0, controller supports standard VGA modes. If 1, controller does not support standard VGA modes. D2: If 0, RAMDAC is in normal operation. If 1, the specification tells us to use the blank bit of function 9. The following example demonstrates calling this interrupt: There really isn't much to say here. To call the interrupt, we call our rm_bios routine with the structure. SEG and OFFSET are macros that calculate the real mode segment and offset respectively. This is used to convert the 32 bit linear address into a 16 bit segment:offset address when giving it to the BIOS. void vbe_get_descr (vbeInfoBlock* descr) { INTR in, out; /* sanity checks */ if (!descr) return; /* call BIOS */ in.eax.val =0x4F00; in.es = SEG((unsigned int) descr); in.edi.val = OFFSET((unsigned int) descr); io_services (0x10, &in, &out); } INT 0x10 Function 4F01h â€“ Get VBE Mode Info Input: AX=4F01h CX = Mode number (recall the format of a VBE mode number!) ES:DI=Pointer to ModeInfoBlock structure (See following example) Output: AX=Status ModeInfoBlock has the following structure: (Due to the size of the structure we will not be describing all of the members. Important members that may be described in later chapters are commented.) typedef struct _modeInfoBlock { uint16_t attributes; uint8_t windowA, windowB; uint16_t granularity; uint16_t windowSize; uint16_t segmentA, segmentB; uint32_t winFuncPtr; /* ptr to INT 0x10 Function 0x4F05 */ uint16_t pitch; /* bytes per scan line */ uint16_t resolutionX, resolutionY; /* resolution */ uint8_t wChar, yChar, planes, bpp, banks; /* number of banks */ uint8_t memoryModel, bankSize, imagePages; uint8_t reserved0; uint8_t readMask, redPosition; /* color masks */ uint8_t greenMask, greenPosition; uint8_t blueMask, bluePosition; uint8_t reservedMask, reservedPosition; uint8_t directColorAttributes; uint32_t physbase; /* pointer to LFB in LFB modes */ uint32_t offScreenMemOff; uint16_t offScreenMemSize; uint8_t reserved1 [206]; } modeInfoBlock; The following example demonstrates calling the interrupt: Example: The following function uses the above interrupt for basic bank switching. Note the use of SEG and OFFSET to convert the 32 bit linear address of out to a 16 bit segment:offset far pointer. void vbe_get_mode (int mode, modeInfoBlock* descr) { INTR in, out; /* sanity check */ if (!descr) return; /* call BIOS */ in.eax.val = 0x4F01; in.ecx.val = mode; in.es = SEG ((unsigned int)descr); in.edi.val = OFFSET((unsigned int)descr); io_services (0x10, &in, &out); } INT 0x10 Function 4F02h â€“ Set VBE Mode The final interrupt that we will look at allows us to set the display mode. This can be used to set any VGA and VBE defined SuperVGA mode as well as extended modes that are not standard. Input: AX=4F02h BX=Mode number (remember the VBE mode format!) Output: AX=Status The following function uses the above interrupt to set a VBE mode: void vbe_set_mode (int mode) { /* call BIOS */ INTR in, out; in.eax.val = 0x4F02; in.ebx.val = mode; io_services (0x10, &in, &out); } Calling vbe_set_mode allows us to set any VBE defined mode and yields us the following result. Demo running in SuperVGA Mode 118h (1024x768): VBE Display Memory VBE supports two standard approaches used in SuperVGA for display memory: Linear Frame Buffer (LFB) and bank switching . You may recall that we can try to set any video mode supported by VBE with both of these. These are just different ways of accessing display memory. We will look at how to work with both types of modes in this section. Linear Frame Buffer (LFB) Modes In LFB modes, all of video memory is mapped into the physical address space typically at a high address in the 3GB-4GB range (assuming IA32 architecture.) Display memory is linear like an array in C. We can read or write to it by just reading or writing from a pointer and can access all of video memory. In VBE, we can get this pointer by calling INT 0x10 Function 4F01h to get the modeInfoBlock structure of the current mode. The pointer to display then is just at modeInfoBlock.physbase . The following C code plots a 16 bit red-green-blue (RGB) pixel to display: void pixel_16RGB (unsigned short color, unsigned short x, unsigned short y) { unsigned short* fb = (unsigned short*) _modeInfo.physBasePtr; unsigned short offset = x + y * (_modeInfo.bytesPerScanLine / 2); fb [offset] = color; } Display memory in LFB modes can only be accessed from protected or long modes due to the amount of display memory mapped. In real mode the only way of accessing display memory of high resolution modes is using bank switching . Bank switching Modes that use bank switching always have 64K of display memory mapped at the VGA memory space at 0xa0000 physical address. This 64k block of display memory is called a bank . The software could only access a single bank at a time and so cannot access all of display memory. The software has to switch banks when needed to access all of display memory. In other words, Bank 0 refers to bytes 0-64K of display memory, Bank 1 refers to bytes at 64K-128K of display memory, and so on. So by switching between banks the software can access all of display memory (no matter how high of resolution) through this 64K â€œwindowâ€. The following code plots an 8 bit RGB pixel in a bank switching mode: void pixel_8RGB (unsigned char color, unsigned short x, unsigned short y) { unsigned char* fb = (unsigned char*) 0xa0000; unsigned int offset = x + (long)y * _modeInfo.bytesPerScanLine; vbe_bankSwitch (offset >> 16); fb [offset & 0xffff] = color; } Bank switching modes are typically more slower because they require more calculations. That is, the software not only needs to calculate the location of a pixel on screen but also its offset within a bank and the bank to switch to. This same calculations apply to reading from display memory. Bank switching modes however can be used in real mode or v86 mode since they only map 64K of display memory. Under VBE, software could switch banks by calling INT 0x10 Function 0x4F05 â€“ Display Window Control . It can also be called directly (as is recommended by the VBE specification) by calling INT 0x10 Function 0x4F01 â€“ Get VBE Mode Information and calling VbeModeInfo.WinFuncPtr . INT 0x10 Function 4F05h â€“ Display Window Control Sets or gets the display bank. Can also be called from VbeModeInfo.WinFuncPtr . Input: AX=4F05h BH=0 (Set memory window), 1 (Get memory window) BL=0 (Window A), 1 (Window B) DX=Window number in window granularity units. Only used when BH=0 (Set function) Output: AX=Status DX=Window number in granularity units. Only used when BH=1 (Get function) The following function uses the above interrupt for basic bank switching: (Notice that we call the interrupt twice for window A and window B. This is because, according to the standard, some VBE implementations might have separate read and write windows) void vbe_bankSwitch (int bank) { INTR in, out; bank <<= bankShift; in.eax.val=0x4F05; in.ebx.val = 0; /* BH=0 (Set memory window) BL=0 (Window A) */ in.edx.val = bank; io_services (0x10, &in, &out); /* call BIOS */ in.eax.val=0x4F05; in.ebx.val = 1; /* BH=0 (Set memory window) BL=1 (Window A) */ in.edx.val = bank; io_services (0x10, &in, &out); /* call BIOS */ } Bochs VBE Interface The Bochs emulator provides an alternative method of setting VBE modes directly without having to call the firmware. Although the support is limited, it does provide us a semi-portable method (only requires a compatible Bochs emulator) for working with high resolution graphics. Example: The following functions can be used to set any VBE mode supported by Bochs: #define VBE_DISPI_IOPORT_INDEX 0x01CE #define VBE_DISPI_IOPORT_DATA 0x01CF #define VBE_DISPI_INDEX_ID 0x0 #define VBE_DISPI_INDEX_XRES 0x1 #define VBE_DISPI_INDEX_YRES 0x2 #define VBE_DISPI_INDEX_BPP 0x3 #define VBE_DISPI_INDEX_ENABLE 0x4 #define VBE_DISPI_INDEX_BANK 0x5 #define VBE_DISPI_INDEX_VIRT_WIDTH 0x6 #define VBE_DISPI_INDEX_VIRT_HEIGHT 0x7 #define VBE_DISPI_INDEX_X_OFFSET 0x8 #define VBE_DISPI_INDEX_Y_OFFSET 0x9 #define VBE_DISPI_DISABLED 0x00 #define VBE_DISPI_ENABLED 0x01 #define VBE_DISPI_GETCAPS 0x02 #define VBE_DISPI_8BIT_DAC 0x20 #define VBE_DISPI_LFB_ENABLED 0x40 #define VBE_DISPI_NOCLEARMEM 0x80 void BlBochsVbeWrite (uint16_t index, uint16_t value) { WRITE_PORT_USHORT(VBE_DISPI_IOPORT_INDEX, index); WRITE_PORT_USHORT(VBE_DISPI_IOPORT_DATA, value); } void BlBochsSetMode (uint16_t xres, uint16_t yres, uint16_t bpp) { BlBochsVbeWrite (VBE_DISPI_INDEX_ENABLE, VBE_DISPI_DISABLED); BlBochsVbeWrite (VBE_DISPI_INDEX_XRES, xres); BlBochsVbeWrite (VBE_DISPI_INDEX_YRES, yres); BlBochsVbeWrite (VBE_DISPI_INDEX_BPP, bpp); BlBochsVbeWrite (VBE_DISPI_INDEX_ENABLE, VBE_DISPI_ENABLED | VBE_DISPI_LFB_ENABLED); } Recall that there is no standard Super VGA hardware interface. That is, this method is specific to Bochs and may not work in other environments or platforms. Because we assume most readers will be using Bochs as the primary emulator, this is the method we will use in order to maintain the highest form of compatibility. This method is also the simplest. For higher compatibility however, it is recommended to use virtual 8086 mode to utilize VBE services directly. Demos There are multiple demos that are planned for release for this article. These are a VGA BIOS demo, VBE SuperVGA demo, and VGA hardware demo. Conclusion We have covered a lot in this chapter including an introduction to the VGA BIOS, VGA hardware, SuperVGA, and VESA BIOS Extensions. We now have covered all of the material needed for switching into low and high resolution graphics modes that will be needed in later chapters. The next few chapters will be focused on the actual graphics rendering and pipeline with possibly some SuperVGA bits thrown in. We might begin with basic primitives and graphics rendering in the next article and transformations. The method we will be using in later demos is the last one presented here, the Bochs VBE Interface. This allows us to use high resolution LFB modes for later articles with the assumption that most readers will be using Bochs. Any new code however added in later articles will be hardware interface independent for the most part; that is, you can use any method that you want to set the display mode and can still follow the next few articles that will focus more on graphics. Resources The following links were referenced to provide more through and accurate information. Please reference them for additional information. http://en.wikipedia.org/wiki/Video_Graphics_Array http://www.osdever.net/FreeVGA/vga/vga.htm http://wiki.osdev.org/VGA_Hardware Programmer's Guide to the EGA, VGA, and Super VGA Cards (3rd Edition) VESA Bios Extensions (VBE) 2.0 Standard"
  },
  "articles/61_unorganised_tutorial/Z4.html": {
    "href": "articles/61_unorganised_tutorial/Z4.html",
    "title": "Standards | BrokenThorn OS Dev Tutorials",
    "keywords": "Standards"
  },
  "articles/61_unorganised_tutorial/Z4a.html": {
    "href": "articles/61_unorganised_tutorial/Z4a.html",
    "title": "Multiboot Standard | BrokenThorn OS Dev Tutorials",
    "keywords": "Multiboot Standard This tutorial covers the multiboot standard and how to develop a multiboot-complient operating system. While the series goes into the multiboot structure, there is more to creating a multiboot complient system. By your system being multiboot complient, it will be capable of being loaded by any multiboot complient boot loader. Cool, huh? This means any multi boot complient bootloader can boot your OS. Multiboot Specification Abstract The multiboot standard was originally created in 1995 and is overseen by the Free Software Foundation . They provide a written specification that defines a standard way to allow multi-booting . Multi-booting allows a computer system to install, and run, multiple operating systems and system environments. A dual-boot computer system is an example of multibooting, with two operating systems installed. Multibooting is made possible by another, unofficial software trick: Partitioning . Partitioning creates the effect of multiple logical disks on one physical disk. Partitioning separates the storage on a storage medium (typically a hard disk) for different uses. For example, the first partition can be from sector 0 to sector n and contain an NTFS formatted Windows operating system. The other partitions can be of any file system - containing data or another operating system software. Because partitioning is a software trick, it is up to the boot loader to be able to detect these partitions by reading the software Partition Table and, typically, display a list of the partitions that contain an operating system to boot. This is the boot menu . The Multiboot Specification defines the state of the computer when the bootloader transfers control to an operating system and how data is passed to the operating system. The multiboot standard can be used on disks that do not support multibooting as well. This means, if your multi-boot complient bootloader can boot from a floppy disk, you can make your floppy disk OS boot from it. Operating System Image Typical bootloaders can be configured to boot different types of operating system images. Typically this is the Kernel or another OS Loading program. The multiboot specification does not provide details on the format of the image. Because of this, you can use any format that you want - flat binary, ELF, or even PE files. However, this file requires an additional header - the Multiboot Header . This header must be located somewhere within the first 8k of your image and aligned on a dword (32 bit) boundery. Any multiboot complient bootloader will be able to find this header and obtain information from it. This is how the boot loader will know how to load and execute your image. Here is the structure format: typedef struct _MULTIBOOT_INFO { uint32_t magic; //all required... uint32_t flags; uint32_t checksum; uint32_t headerAddr; //all optional, set if bit 16 in flags is set... uint32_t loadAddr; uint32_t loadEndAddr; uint32_t bssEndAddr; uint32_t entryPoint; uint32_t modType; //all optional, set if bit 2 in flags is set... uint32_t width; uint32_t height; uint32_t depth; } MULTIBOOT_INFO, *PMULTIBOOT_INFO; You should make sure no padding is added. In MSVC, this can be done by adding a #pragma pack (push, 1) and #pragma pack(pop,1) around the structure declaration above. The above is the only structure that you need to get your OS booted by a multi boot complient bootloader, such as GRUB. Lets look at the members: magic: must always be 0x1BADB002 flags: Bit 0 0: All boot modules and OS image must be aligned in page (4k) bounderies. Bit 1 1: Boot loader must pass memory information to the operating system. Bit 2 1: Boot loader must pass the video mode table to the operating system. Bit 16 1: Offsets 12-28 of the multiboot header are valid. (That is, members header_addr through entry_addr in the multiboot header are valid.) If this bit is set, the boot loader will use these values instead of parsing the image format and obtaining the values from it. Multiboot complient bootloaders can provide support for native executable file formats, such as ELF or PE that it can load. checksum: This must be a value that which, when added to magic and flags must be a 32 bit unsigned sum of 0. headerAddr: Address of multiboot header loadAddr: Base address to load to loadEndAddr: End load address. If 0, bootloader assumes the end is the end of the OS image file bssEndAddr: End of BSS segment. Bootloader null's this segment. If 0, no BSS segment is assumed entryPoint: Address of entry point function. Yes, thats right, the entry point of your operating system modType: 0: Linear graphics mode 1: EGA Standard text mode Everything else is reserved width: width of display in text columns or pixels. If 0, the bootloader assumes no preference height: height of display in text columns or pixels. If 0, the bootloader assumes no preference depth: Number of Bits Per Pixels (BPP) in a graphics mode. If 0, the bootloader assumes no preference That is all there is to it. The boot loader can load and execute your operating system in two ways: By loading and reading its executable image format (ELF and PE are examples) or by using the information found in this structure. The boot loader looks for this structure in your image. Because of this, you need to fill out and create this structure. Implementing the Multi boot Header There are different solutions for implimenting the multiboot header into your operating system. Different solutions for different toolchains. Lets look at some of them. Visual C++ 2005, 2008 This is a recent trick I discovered and posted on another forum. It uses some extensions provided by Microsoft Visual C++ to define the header in your kernel. We first declare the structure, making sure there is no extra padding: #pragma pack (push, 1) /** * Multiboot structure */ typedef struct _MULTIBOOT_INFO { uint32_t magic; uint32_t flags; uint32_t checksum; uint32_t headerAddr; uint32_t loadAddr; uint32_t loadEndAddr; uint32_t bssEndAddr; uint32_t entryPoint; uint32_t modType; uint32_t width; uint32_t height; uint32_t depth; } MULTIBOOT_INFO, *PMULTIBOOT_INFO; #pragma pack(pop,1) Now all that we need to do is define this structure somewhere. Remember that this header must be defined on a dword (32 bit) boundery and within the first 8K of your kernel? This trick uses section alignment to insure the proper alignment of the structure. We set up the section alignment in the Linker Options of the IDE and it is guaranteed to be dword aligned. So, all we need to do is create a new program section and define the structure in it. Neat, huh? Lets do that now: //! Bad example: #pragma section(\".text\") __declspec(allocate(\".text\")) MULTIBOOT_INFO _MultibootInfo = { MULTIBOOT_HEADER_MAGIC, MULTIBOOT_HEADER_FLAGS, CHECKSUM, HEADER_ADDRESS, LOADBASE, 0, //load end address 0, //bss end address KeStartup }; This works but is problimatic. This allocates the structure in the .text section, but where? This is going to be a problem - Multiboot specification requires the structure be located in the first 8K of the image, but MSVC is still free to place it outside the 8K region. To fix this problem, we must use the section naming convention. The section naming conventions used in MSVC follow the format name$loc where name is the name of the section, and loc is an alpha-numeric value that represents where, in the section, it represents. Its in alphanumeric order: section$a is first, section$b is second and so on. So, by using .text$0 we are representing the beginning of the .text segment. But of course, just replacing the above .text to .text$a wont work - My, or my no, that would be too easy. ðŸ˜€ Instead, we define our own section - lets call it .a$0 . We can create this as a code segment and merge it into the .text section: //! Complete example #pragma code_seg(\".a$0\") __declspec(allocate(\".a$0\")) MULTIBOOT_INFO _MultibootInfo = { MULTIBOOT_HEADER_MAGIC, MULTIBOOT_HEADER_FLAGS, CHECKSUM, HEADER_ADDRESS, LOADBASE, 0, //load end address 0, //bss end address KeStartup }; #pragma comment(linker, \"/merge:.text=.a\") Thats all that there is to it. KeStartup is your entry point function, OADBASE is the base address of your kernel (like 1MB for example), HEADER_ADDRESS is the address of the multiboot header (which happens to be LOADBASE+0x400 do to .text always starting at offset 0x400), magic is 0x1BADB002 , flags of 0x00010003 and the checksum being -(MULTIBOOT_HEADER_MAGIC + MULTIBOOT_HEADER_FLAGS) . Here is the complete example: #pragma pack (push, 1) /** * Multiboot structure */ typedef struct _MULTIBOOT_INFO { uint32_t magic; uint32_t flags; uint32_t checksum; uint32_t headerAddr; uint32_t loadAddr; uint32_t loadEndAddr; uint32_t bssEndAddr; uint32_t entryPoint; uint32_t modType; uint32_t width; uint32_t height; uint32_t depth; } MULTIBOOT_INFO, *PMULTIBOOT_INFO; #pragma pack(pop,1) /** * Kernel entry */ void KeStartup ( PMULTIBOOT_INFO* loaderBlock ) { __halt (); } //! loading address #define LOADBASE 0x100000 //! header offset will always be this #define ALIGN 0x400 #define HEADER_ADDRESS LOADBASE+ALIGN #define MULTIBOOT_HEADER_MAGIC 0x1BADB002 #define MULTIBOOT_HEADER_FLAGS 0x00010003 #define STACK_SIZE 0x4000 #define CHECKSUM -(MULTIBOOT_HEADER_MAGIC + MULTIBOOT_HEADER_FLAGS) #pragma code_seg(\".a$0\") __declspec(allocate(\".a$0\")) MULTIBOOT_INFO _MultibootInfo = { MULTIBOOT_HEADER_MAGIC, MULTIBOOT_HEADER_FLAGS, CHECKSUM, HEADER_ADDRESS, LOADBASE, 0, //load end address 0, //bss end address KeStartup }; #pragma comment(linker, \"/merge:.text=.a\") Assuming this kernel has the base address of 1MB, and is compiled with Visual C++ to produce a valid PE executable, this should be bootable by any multiboot complient bootloader. Machine State When the bootloader executes our operating system, the registers must be the following values: EAX - Magic Number. Must be 0x2BADB002. This will indicate to the kernel that our boot loader is multiboot standard EBX - Containes the physical address of the Multiboot information structure CS - Must be a 32-bit read/execute code segment with an offset of 0 and a limit of 0xFFFFFFFF . The exact value is undefined. DS,ES,FS,GS,SS - Must be a 32-bit read/write data segment with an offset of 0 and a limit of 0xFFFFFFFF . The exact values are all undefined. A20 gate must be enabled CR0 - Bit 31 (PG) bit must be cleared (paging disabled) and Bit 0 (PE) bit must be set (Protected Mode enabled). Other bits undefined All other registers are undefined. Most of this is already done in our existing boot loader. The only additional two things we must add are for the EAX register and EBX. The most important one for us is stored in EBX. This will contain the physical address of the multiboot information structure. Lets take a look! Multi boot Information Structure Now that our operating system is being booted by the boot loader, whats next? Multiboot complient boot loaders also creates an information structure providing information to the operating system. These are passed by a pointer to the structure in the EBX register. This is possibly one of the most important structures contained in the multiboot specification. The information in this structure is passed to the kernel from the EBX register, This allows a standard way for the boot loader to pass information to the kernel. This is a fairly big structure but isnt to bad. Not all of these members are required. The specification states that the operating system must use the flags member to determin what members in the structure exist and what do not. Here is the entire structure format. Simular to the multi-boot header structure, it is recommended to insure there is no padding added. typedef struct _MULTIBOOT_INFO { uint32_t flags; //required uint32_t memLower; //if bit 0 in flags are set uint32_t memUpper; //if bit 0 in flags are set uint32_t bootDevice; //if bit 1 in flags are set uint32_t commandLine; //if bit 2 in flags are set uint32_t moduleCount; //if bit 3 in flags are set uint32_t moduleAddress; //if bit 3 in flags are set uint32_t syms[4]; //if bits 4 or 5 in flags are set uint32_t memMapLength; //if bit 6 in flags is set uint32_t memMapAddress; //if bit 6 in flags is set uint32_t drivesLength; //if bit 7 in flags is set uint32_t drivesAddress; //if bit 7 in flags is set uint32_t configTable; //if bit 8 in flags is set uint32_t apmTable; //if bit 9 in flags is set uint32_t vbeControlInfo; //if bit 10 in flags is set uint32_t vbeModeInfo; //if bit 11 in flags is set uint32_t vbeMode; // all vbe_* set if bit 12 in flags are set uint32_t vbeInterfaceSeg; uint32_t vbeInterfaceOff; uint32_t vbeInterfaceLength; } MULTIBOOT_INFO, *PMULTIBOOT_INFO; This structure isnt as complex as it looks. If the corrosponding bit in the flags member is set, it means that the members (shown above) are valid. Because of this, flags is, technically, the only required member, all other members are optional. Lets look at the members here: memLow, memUpper: Amount of low and upper memory in KB. Low memory starts at 0, upper memory starts at 1MB. bootDevice: Boot device (see below) commandLine: Pointer to C-string containing your kernel command line moduleCount: The number of additional boot modules that were loaded by the boot loader moduleAddress: address of first module structure (see below) syms: Location of symbol table. See below memMapLength: Number of entries in system memory map memMapAddress: Address of memory map drivesLength, drivesAddress: see below configTable: Address of BIOS ROM config table (returned from GET CONFIGUATION BIOS INT call) apmTable: Address of Advanced Power Management (APM) table vbeControlInfo, VbevbeModeInfo: Address of Video Bios Extensions (VBE) structures. vbeMode: VBE mode vbeInterfaceSeg, vbeInterfaceOff, vbeInterfaceLength: Used to access VBE 2.0 protected mode interface This chapter does not go over VBE nor APM so we wont cover them here. Memory map information has been described in [Chapter 17] (fix this link), including the format of the System Memory Map . The ROM configuation for configTable is the table obtained from BIOS INT 0x15 Function 0xC0 . Thats all there is to it. This structure isnt that bad :) There are a few members we havnt looked at though: bootDevice, moduleAddress, syms, drivesLength, and drivesAddress. Lets look at those in detail. bootDevice The bootDevice member follows the format: 1st word: BIOS drive number 2nd, 3rd, 4th words: Partition The BIOS drive number is the number used by the BIOS INT 0x13 services to represent the drive. The other words reoresent the partitions: Words 2,3, and 4 represent Partition 1,2,and 3. Partition 1 is the top level partition, partition 2 is the sub-partition in that partition and so on. Unused partitions are marked as 0xFF. moduleAddress This is a pointer to the first module structure. A module structure entry follows the format: typedef struct _MODULE_ENTRY { uint32_t moduleStart; uint32_t moduleEnd; char string[8]; } MODULE_ENTRY, *PMODULE_ENTRY; moduleStart and moduleEnd contain the start and end addresses of the loaded module. \"string\" represents that module, typically can be a command line or path name or 0 if there is none. drivesLength, drivesAddress The drivesLength member contains the size of all of the drive structures. drivesAddress contains a pointer to the first drive structure. A drive structure entry has the format: typedef struct _DRIVE_ENTRY { uint32_t size; //size of structure uint8_t driveNumber; uint8_t driveMode; uint16_t driveCylinders; uint8_t driveHeads; uint8_t driveSectors; uint8_t ports [0]; //can be any number of elements } DRIVE_ENTRY, *PDRIVE_ENTRY; Lets take a closer look at each member: driveNumber: Number used by BIOS driveMode: 0: CHS 1: LBA driveCylinders,driveHeads,driveSectors: Drive Geometry ports: contain a list of I/O port numbers used by the BIOS for drive access, terminated by 0 Thats all there is to this structure. Only one more member to cover, that strange syms member...lets take a look! syms The syms member is declared in the structure in this chapter as uint32_t syms[4] but that is not entirely true. It is actually several members that occupy those bytes that follow the members: syms[0] = uint32_t sym_num syms[1] = uint32_t sym_size syms[2] = uint32_t sym_addr syms[3] = uint32_t sym_shndx While the specifications state that any format for the operating system image can be used (Such as ELF, PE, flat binary, or anything), this one is specific to ELF formats only. Technically the system image (like the kernel) is able to parse itself to obtain symbolic information. However the miltiboot standard allows the boot loader to pass ELF-specific symbolic information to the operating system as well through these members. sym_num is the number of symbol entries in the ELF section header. size indicates the size of each entry, addr contains the address of the symbol table in the ELF binary. Conclusion Thats all that there is to the Multi boot standard! Technically all that you need is to define the Multiboot Header properly in order to get your system booted by any multiboot complient bootloader. However, you can use the multiboot information structure to obtain information that is normally obtained at boot time. If you would like to support multi boot in the series, you must insure your kernel is loaded at a physical address not a virtual one. This is because paging is disabled when a multiboot complient bootloader passes control to your kernel. A good typical address is 1MB, which can be loaded by alot of bootloaders, such as GRUB. You can, of course, enable paging and use it later on of course ðŸ˜€"
  },
  "articles/61_unorganised_tutorial/Z4b.html": {
    "href": "articles/61_unorganised_tutorial/Z4b.html",
    "title": "Scan Codes | BrokenThorn OS Dev Tutorials",
    "keywords": "Scan Codes This is a resource that lists all of the scan codes. There are three defined scan code sets for the keyboard controller. Original XT Scan Code Set Scan Code Set (Original XT Scan Code Set) KEY MAKE BREAK A 1E 9E B 30 B0 C 2E AE D 20 A0 E 12 92 F 21 A1 G 22 A2 H 23 A3 I 17 97 J 24 A4 K 25 A5 L 26 A6 M 32 B2 N 31 B1 O 18 98 P 19 99 Q 10 90 R 13 93 S 1F 9F T 14 94 U 16 96 V 2F AF W 11 91 X 2D AD Y 15 95 Z 2C AC 0 0B 8B 1 2 82 2 3 83 3 4 84 4 5 85 5 6 86 6 7 87 7 8 88 8 9 89 9 0A 8A ` 29 89 - 0C 8C = 0D 8D \\ 2B AB BKSP 0E 8E SPACE 39 B9 TAB 0F 8F CAPS 3A BA L SHFT 2A AA L CTRL 1D 9D L GUI E0,5B E0,DB L ALT 38 B8 R SHFT 36 B6 R CTRL E0,1D E0,9D R GUI E0,5C E0,DC R ALT E0,38 E0,B8 APPS E0,5D E0,DD ENTER 1C 9C ESC 1 81 F1 3B BB F2 3C BC F3 3D BD F4 3E BE F5 3F BF F6 40 C0 F7 41 C1 F8 42 C2 F9 43 C3 F10 44 C4 F11 57 D7 F12 58 D8 PRNT SCRN E0,2A,E0,37 E0,B7,E0,AA SCROLL 46 C6 PAUSE E1,1D,45,E1,9D,C5 -NONE- [ 1A 9A INSERT E0,52 E0,D2 HOME E0,47 E0,97 PG UP E0,49 E0,C9 DELETE E0,53 E0,D3 END E0,4F E0,CF PG DN E0,51 E0,D1 U ARROW E0,48 E0,C8 L ARROW E0,4B E0,CB D ARROW E0,50 E0,D0 R ARROW E0,4D E0,CD NUM 45 C5 KP / E0,35 E0,B5 KP * 37 B7 KP - 4A CA KP + 4E CE KP EN E0,1C E0,9C KP . 53 D3 KP 0 52 D2 KP 1 4F CF KP 2 50 D0 KP 3 51 D1 KP 4 4B CB KP 5 4C CC KP 6 4D CD KP 7 47 C7 KP 8 48 C8 KP 9 49 C9 ] 1B 9B ; 27 A7 ' 28 A8 , 33 B3 . 34 B4 / 35 B5 ACPI Scan Codes (Original XT Scan Code Set) Key Make Code Break Code Power E0, 5E E0, DE Sleep E0, 5F E0, DF Wake E0, 63 E0, E3 Windows Multimedia Scan Codes (Original XT Scan Code Set) Key Make Code Break Code Next Track E0, 19 E0, 99 Previous Track E0, 10 E0, 90 Stop E0, 24 E0, A4 Play/Pause E0, 22 E0, A2 Mute E0, 20 E0, A0 Volume Up E0, 30 E0, B0 Volume Down E0, 2E E0, AE Media Select E0, 6D E0, ED E-Mail E0, 6C E0, EC Calculator E0, 21 E0, A1 My Computer E0, 6B E0, EB WWW Search E0, 65 E0, E5 WWW Home E0, 32 E0, B2 WWW Back E0, 6A E0, EA WWW Forward E0, 69 E0, E9 WWW Stop E0, 68 E0, E8 WWW Refresh E0, 67 E0, E7 WWW Favorites E0, 66 E0, E6 Default Scan Code Set for Modern Keyboards Scan code set (Modern Default) KEY MAKE BREAK A 1C F0,1C B 32 F0,32 C 21 F0,21 D 23 F0,23 E 24 F0,24 F 2B F0,2B G 34 F0,34 H 33 F0,33 I 43 F0,43 J 3B F0,3B K 42 F0,42 L 4B F0,4B M 3A F0,3A N 31 F0,31 O 44 F0,44 P 4D F0,4D Q 15 F0,15 R 2D F0,2D S 1B F0,1B T 2C F0,2C U 3C F0,3C V 2A F0,2A W 1D F0,1D X 22 F0,22 Y 35 F0,35 Z 1A F0,1A 0 45 F0,45 1 16 F0,16 2 1E F0,1E 3 26 F0,26 4 25 F0,25 5 2E F0,2E 6 36 F0,36 7 3D F0,3D 8 3E F0,3E 9 46 F0,46 ` 0E F0,0E - 4E F0,4E = 55 FO,55 |5D F0,5D BKSP 66 F0,66 SPACE 29 F0,29 TAB 0D F0,0D CAPS 58 F0,58 L SHFT 12 FO,12 L CTRL 14 FO,14 L GUI E0,1F E0,F0,1F L ALT 11 F0,11 R SHFT 59 F0,59 R CTRL E0,14 E0,F0,14 R GUI E0,27 E0,F0,27 R ALT E0,11 E0,F0,11 APPS E0,2F E0,F0,2F ENTER 5A F0,5A ESC 76 F0,76 F1 5 F0,05 F2 6 F0,06 F3 4 F0,04 F4 0C F0,0C F5 3 F0,03 F6 0B F0,0B F7 83 F0,83 F8 0A F0,0A F9 1 F0,01 F10 9 F0,09 F11 78 F0,78 F12 7 F0,07 PRNT SCRN E0,12,E0,7C E0,F0,7C,E0,F0,12 SCROLL 7E F0,7E PAUSE E1,14,77,E1,F0,14,F0,77 -NONE- [ 54 FO,54 INSERT E0,70 E0,F0,70 HOME E0,6C E0,F0,6C PG UP E0,7D E0,F0,7D DELETE E0,71 E0,F0,71 END E0,69 E0,F0,69 PG DN E0,7A E0,F0,7A U ARROW E0,75 E0,F0,75 L ARROW E0,6B E0,F0,6B D ARROW E0,72 E0,F0,72 R ARROW E0,74 E0,F0,74 NUM 77 F0,77 KP / E0,4A E0,F0,4A KP * 7C F0,7C KP - 7B F0,7B KP + 79 F0,79 KP EN E0,5A E0,F0,5A KP . 71 F0,71 KP 0 70 F0,70 KP 1 69 F0,69 KP 2 72 F0,72 KP 3 7A F0,7A KP 4 6B F0,6B KP 5 73 F0,73 KP 6 74 F0,74 KP 7 6C F0,6C KP 8 75 F0,75 KP 9 7D F0,7D ] 5B F0,5B ; 4C F0,4C ' 52 F0,52 , 41 F0,41 . 49 F0,49 / 4A F0,4A ACPI Scan Codes (Modern Default) Key Make Code Break Code Power E0, 37 E0, F0, 37 Sleep E0, 3F E0, F0, 3F Wake E0, 5E E0, F0, 5E Windows Multimedia Scan Codes (Modern Default) Key Make Code Break Code Next Track E0, 4D E0, F0, 4D Previous Track E0, 15 E0, F0, 15 Stop E0, 3B E0, F0, 3B Play/Pause E0, 34 E0, F0, 34 Mute E0, 23 E0, F0, 23 Volume Up E0, 32 E0, F0, 32 Volume Down E0, 21 E0, F0, 21 Media Select E0, 50 E0, F0, 50 E-Mail E0, 48 E0, F0, 48 Calculator E0, 2B E0, F0, 2B My Computer E0, 40 E0, F0, 40 WWW Search E0, 10 E0, F0, 10 WWW Home E0, 3A E0, F0, 3A WWW Back E0, 38 E0, F0, 38 WWW Forward E0, 30 E0, F0, 30 WWW Stop E0, 28 E0, F0, 28 WWW Refresh E0, 20 E0, F0, 20 WWW Favorites E0, 18 E0, F0, 18 PS-2 Scan Code Set for AT Motherboards KEY MAKE BREAK A 1C F0,1C B 32 F0,32 C 21 F0,21 D 23 F0,23 E 24 F0,24 F 2B F0,2B G 34 F0,34 H 33 F0,33 I 43 F0,48 J 3B F0,3B K 42 F0,42 L 4B F0,4B M 3A F0,3A N 31 F0,31 O 44 F0,44 P 4D F0,4D Q 15 F0,15 R 2D F0,2D S 1B F0,1B T 2C F0,2C U 3C F0,3C V 2A F0,2A W 1D F0,1D X 22 F0,22 Y 35 F0,35 Z 1A F0,1A 0 45 F0,45 1 16 F0,16 2 1E F0,1E 3 26 F0,26 4 25 F0,25 5 2E F0,2E 6 36 F0,36 7 3D F0,3D 8 3E F0,3E 9 46 F0,46 ` 0E F0,0E - 4E F0,4E = 55 F0,55 |5C F0,5C BKSP 66 F0,66 SPACE 29 F0,29 TAB 0D F0,0D CAPS 14 F0,14 L SHFT 12 F0,12 L CTRL 11 F0,11 L WIN 8B F0,8B L ALT 19 F0,19 R SHFT 59 F0,59 R CTRL 58 F0,58 R WIN 8C F0,8C R ALT 39 F0,39 APPS 8D F0,8D ENTER 5A F0,5A ESC 8 F0,08 F1 7 F0,07 F2 0F F0,0F F3 17 F0,17 F4 1F F0,1F F5 27 F0,27 F6 2F F0,2F F7 37 F0,37 F8 3F F0,3F F9 47 F0,47 F10 4F F0,4F F11 56 F0,56 F12 5E F0,5E PRNT SCRN 57 F0,57 SCROLL 5F F0,5F PAUSE 62 F0,62 [ 54 F0,54 INSERT 67 F0,67 HOME 6E F0,6E PG UP 6F F0,6F DELETE 64 F0,64 END 65 F0,65 PG DN 6D F0,6D U ARROW 63 F0,63 L ARROW 61 F0,61 D ARROW 60 F0,60 R ARROW 6A F0,6A NUM 76 F0,76 KP / 4A F0,4A KP * 7E F0,7E KP - 4E F0,4E KP + 7C F0,7C KP EN 79 F0,79 KP . 71 F0,71 KP 0 70 F0,70 KP 1 69 F0,69 KP 2 72 F0,72 KP 3 7A F0,7A KP 4 6B F0,6B KP 5 73 F0,73 KP 6 74 F0,74 KP 7 6C F0,6C KP 8 75 F0,75 KP 9 7D F0,7D ] 5B F0,5B ; 4C F0,4C ' 52 F0,52 , 41 F0,41 . 49 F0,49 / 4A F0,4A"
  },
  "articles/61_unorganised_tutorial/Z4c.html": {
    "href": "articles/61_unorganised_tutorial/Z4c.html",
    "title": "IA32 Machine Language | BrokenThorn OS Dev Tutorials",
    "keywords": "IA32 Machine Language Introduction This chapter covers IA32 machine language programming. The information provided here is for information purposes only and is not needed for the development of a basic operating system or executive software. Understanding the instruction format for the IA32 (and IA64) instructions can help debugging improperly assembled instructions, v86 monitors that are required for supporting v8086 mode, emulating instructions (which is required for emulating certain FPU instructions or when developing assemblers, emulators, virtual machines, and some other types of software), and when developing certain system software like debuggers and compilers. This chapter is also for testing a new editor being used to write the new chapters that should help improve formatting and resolve spelling errors. If this test is successful, all of the new and earlier chapters will be updated to reflect the new format. Please send any feedback if you encounter any errors. Machine Language Overview Machine language , also known as machine code, native code, and byte code, is the set of raw instructions and data that can be executed by a central processing unit (CPU) . It allows a CPU to interpret a certain set of byte sequences as an \"instruction\" to perform a task. These tasks are very small, such as copying small amounts of data or arithmetic. The act of building a byte sequence that represents a CPU instruction is known as coding . The definition of coding has evolved as programming languages evolved. Originally the term referred to the actual coding of the byte sequence for an instruction; today it applies to many forms of programming in second, third, and fourth generation programming languages. Computer programs , also known as software, is the collection of machine code and data that performs a complicated task, such as word processing or playing HaloÂ®. Machine language is often interpreted by popular media as a â€œseries of 1's and 0'sâ€. This is an accurate descriptionâ€”to an extent. Digital Logic Digital logic is a field of electronics that utilizes logic gates that allows the electronics to make decisions. Some examples of logic gates include AND gates, OR gates, NOR gates, NAND gates, NOT gates and XOR gates. These gates reflect their binary operations: AND gates perform a binary AND, XOR performs a binary XOR, and so on. In order for these gates to be meaningful, a standard needed to be adopted in order to make sense of what is true and false . For example, AND gates only make sense if there are two inputs and one output. The two inputs are the two items to test for equality: if either one is false, the output is false else the output is true. The standard is to define a line with low electrical current as false and a line with higher electrical current as true . This is what connects the binary number system to digital logic electronics. In the binary number system, 0 is often denoted as false and 1 is often true . Machine language is often represented in binary because of its tight connection with the CPU instruction decoding mechanism and how its stored in RAM for instruction fetching. Program loading Programs are loaded into memory by the operating system, executive, or firmware. The IA32 and IA64 family of CPU's can execute programs from Read Only Memory (ROM) and Random Access Memory (RAM) . This is made possible through a common system bus and physical address space (PAS) shared by firmware and program images. Because firmware and program images can both be executed directly by the CPU cores, they utilize the same machine language byte code. Machine language is different then microcode (see chapter 7) that firmware might use, however, the actual firmware is still machine language. Assembly language Assembly language is a second generation programming language . It allows the programmer to write a program in a well defined language that uses mnemonics to aid the programmers in developing the software. For example, MOV is a common mnemonic common in a lot of assembly languages for different architectures. MOV represents an instruction that copies data from a source to a destination. It is also an example of a data movement instruction . The mnemonics gave a symbolic name to the instructions and instruction forms, allowing each assembly language instruction to be translated to a single (in some cases, several possible) machine language byte sequences. The program that translates assembly language instructions into machine language is known as an assembler . Assemblers are sometimes incorrectly called compilers . Machine Instruction overview A machine instruction is a single byte sequence that performs a specific task for the CPU. A set of machine instructions has been previously defined as a machine language . Machine instructions are defined by a CPU manufacturer in an instruction set that documents all of the CPU instructions the manufacturer implemented. Instruction sets also typically include suggestive assembly language mnemonics for assembler developers to use. Instruction sets are documented in CPU specifications. The CPU manufacture implements the machine instructions supported by a particular CPU and how the CPU interprets each instruction. This allows the CPU to â€œexecuteâ€ machine instructions that the manufacture intended. Bugs in the CPU hardware or firmware, however, can cause the CPU to â€œexecuteâ€ instructions that are not valid instructions. These are undocumented instructions . Some assemblers might define mnemonics to undocumented instructions that are well known. Some undocumented instructions that have had benefits have later become documented as real instructions. Some instructions might be left undocumented for manufacturer testing use only, such as the IA32 LOADALL instruction (this bug has since been fixed.) Some instructions might also have bad effects, such as halting the system or damaging the CPU (these are known as Halt and Catch Fire (HCF) instructions.) There is an instruction set for every CPU architecture. Due to the evolving nature of the software industry, certain trends in instruction sets have become common. Understanding these trends can help with understanding IA32 machine language. CISC and RISC Instruction sets typically fall in two categories: Complex Instruction Set Computing (CISC) and Reduced Instruction Set Computing (RISC) . Examples of RISC include PPC and ARM architectures. An example of CISC is the IA32 architecture. RISC architectures utilize a simplistic instruction set format over CISC. RISC architectures typically uses a standard encoding format for each instruction that allows each instruction to be of the same number of bytes. CISC architectures also follow a standard encoding format, but allows variable length instructions. Operation code An Operating Code (OPCode) is a single byte identifier that the CPU utilizes to determine the instruction type. For example, a MOV instruction has an opcode identifier that lets the CPU know information about the instruction, such as type (MOV). Many instruction sets use opcode to distinguish one instruction from another. Some instructions may have multi-byte opcodes and extended opcodes . This gives the instruction set more flexibility. Addressing mode An Addressing Mode defines a method for the CPU to be able to reference addresses. The addresses may be virtual or physical depending on the architecture. Instructions, such as data movement instructions , need to be able to tell the CPU how to reference addresses to obtain data. For example, many CPU's support a direct addressing mode that allows an instruction to tell the CPU to reference (read or write) data at a specific address. For example, in IA32 assembly language: mov eax, dword [0xa0000] This instruction tells the CPU to use the direct addressing mode to read from address 0xa0000 in the current address space. Another common addressing mode is indirect addressing , which allows an instruction to tell the CPU to reference data using a pointer. For example, in IA32 assembly language: mov eax, [ebp]</pre> This tells the CPU to read a dword from the address stored in the EBP register into the EAX register. There are many more addressing modes that architectures may utilize. IA32 and IA64 Instruction encoding We are now ready to begin looking at IA32 and IA64 machine instruction encoding. In order to save space, we will use IA64 to mean IA32 and IA64 instruction sets. IA32 is a subset of IA64 and thus shares a large part of the IA32 instruction set. The IA64 instruction set implements a CISC encoding. This means that each instruction follows a specific encoding structure and is variable in length. IA32 and IA64 instructions can range from 1 byte to 12 bytes in size. Register codes The CPU identifies internal registers by a numerical value. Many registers share the same code; the CPU decides what register to use based on the instruction being used and the current operating mode (real, protected, or long modes). The operand size override prefix is also used when determining what register to use. We will cover this prefix later on. Register codes are used in the instruction encoding to let the CPU know what registers the instruction operates on. The registers use the following codes: REX.r = 0 Code 0 1 2 3 4 5 6 7 No REX AL CL DL BL AH CH DH BH REX AL CL DL BL SPL BPL SIL DIL REG16 AX CX DX BX SP BP SI DI REG32 EAX ECX EDX EBX ESP EBP ESI EDI REG64 RAX RCX RDX RBX RSP RBP RSI RDI MM MM0 MM1 MM2 MM3 MM4 MM5 MM6 MM7 XMM XMM0 XMM1 XMM2 XMM3 XMM4 XMM5 XMM6 XMM7 YMM YMM0 YMM1 YMM2 YMM3 YMM4 YMM5 YMM6 YMM7 SSEG ES CS SS DS ES GS CR0 CR1 CR2 CR3 CR4 CR5 CR6 CR7 DR0 DR1 DR2 DR3 DR4 DR5 DR6 DR7 For example, in the instruction mov bx, 0x5 we would store 3 as the register code for BX. The instruction mov ss, ax would require storing 2 as the register code for SS and 0 for the register code of AX. Different instructions utilize different types of registers so there will never be a conflict between needing to choose between multiple registers of the same code. For example, the instruction mov REG16, IMM16 will always use a 16 bit general purpose register as an operand. For another example, the instruction movups xmm, xmm/m128 will always take an XMM register only. Long mode adds additional registers to this list. In order to support the above registers, long mode has a special flag set that allows instructions to select other registers using the same register codes. This is the REX.r field in the REX prefix byte that will be explained later on. When this bit is set, the register table will look like this: REX.r=1 Code 0 1 2 3 4 5 6 7 No REX R8B R9B R10B R11B R12B R13B R14B R15B REX R8W R9W R10W R11W R12W R13W R14W R15W REG16 R8D R9D R10D R11D R12D R13D R14D R15D REG32 R8 R9 R10 R11 R12 R13 R14 R15 MM MM0 MM1 MM2 MM3 MM4 MM5 MM6 MM7 XMM XMM8 XMM9 XMM10 XMM11 XMM12 XMM13 XMM14 XMM15 YMM YMM8 YMM9 YMM10 YMM11 YMM12 YMM13 YMM14 YMM15 SSEG ES CS SS DS FS GS CR8 CR9 CR10 CR11 CR12 CR13 CR14 CR15 DR8 DR9 DR10 DR11 DR12 DR13 DR14 DR15 Instruction Encoding An IA64 instruction follows a well defined structure that originated from the 8085 CPU. Each instruction follows the following format: Prefix bytes REX prefix Operation Mod R/M Displacement Immediate 0-4 1 0-3 1 1 0-4 0-4 For compactness, the number in parentheses is the number of bytes of the component. A number of 0 indicates that the byte is optional. For example, the prefix bytes can be from 0 to 4 bytes in an instruction. This means that an instruction can have 0, 1, 2, 3, or 4 prefix bytes. The REX prefix is only valid in IA64 and long modes. The only required field is an operation code . All other fields are optional and depend on if the instruction requires them. For example, the INT (interrupt) instruction requires an operation code and immediate byte while a MOV instruction might utilize all of the above fields. To provide another example, lets take a look at the INT instruction in more detail. The INT instruction has a form: INT imm8 where imm8 is an 8 bit immediate value and INT is the mnemonic for the operation code 0xCD. Knowing the format of the instruction encoding, we can encode a INT 5 instruction like this: 0xCD 0x05 The first byte, 0xCD, is the operation code and is bolded and italicized . Because prefix bytes are optional, and INT 5 does not require them, we do not need it. Mod R/M and SIB bytes are not needed either. Displacements are only used with memory a addressing modes so the only other field that we need is the immediate field. The immediate field is a 0-4 byte field. We know to use it as a 1 byte field because of the instruction form INT imm8. The purpose of this example is to demonstrate that certain fields are optional and not needed ; the fields that are needed by an instruction depends on the instruction. The order of these fields never changes . For example, note above how we chose to omit the fields that are not needed but kept the order of the fields: the operation code field comes before the immediate value field. In the next few sections, we will cover each of these fields in more detail. Prefix fields The prefix bytes allow an instruction to give more information to the CPU. For example, they allow the instruction to have the CPU lock the bus or to utilize a different segment register in a data movement instruction. Many of these prefixes have assembly language mnemonics. The prefix bytes are identified in 4 classes. An instruction can use at most 1 prefix byte from each of the 4 classes . Class 1 prefix 0xF0 LOCK prefix 0xF2 REPNE, REPNZ prefix 0xF3 REP, REPZ, REPE prefix Class 2 prefix 0x2E CS Segment override 0x36 SS Segment override 0x3E DS Segment override 0x26 ES Segment override 0x64 FS Segment override 0x65 GS Segment override Class 3 prefix 0x66 Operand size override Class 4 prefix 0x67 Address size override We assume the reader knows IA32 assembly language so will omit describing these prefixes in detail. A machine instruction can only have 1 prefix byte from any of the 4 classes. Due to their being 4 classes, an instruction can have 0 to 4 prefix bytes. If an instruction attempts to use 2 or more prefix bytes from a single class, the CPU will throw an invalid instruction exception. LOCK prefix If the LOCK prefix is used on an instruction that does not support LOCK the CPU will trigger an invalid instruction exception. Some assemblers allow using LOCK on invalid instructions without giving a warning to the programmer. Due to this, we will present the list of valid instructions here. The LOCK prefix can only be used on the following instructions: ADC, ADD, AND, BTC, BTR, BTS, CMPXCHG, CMPXCHG8B, CMPXCHG16B, DEC, INC, NEG, NOT, OR, SBB, SUB, XADD, XCHG, and XOR. Operand size override The operand size override allows the CPU to select between 16 bit and 32 bit operands. Assemblers typically allow the programmer to select a specific operand size indirectly using directives like bits16 or use32. The IA32 and IA64 instruction sets provide two operand sizes: legacy 16 bit and a native size that is 32 bit. The native size depends on the processors current operation mode. Operation mode CS.d REX.w Native Operand override Real mode 16 bit 16 bit V8086 mode 16 bit 16 bit Protected mode 0 16 bit 32 bit Protected mode 1 32 bit 16 bit Long mode 0 32 bit 16 bit For an example, lets look at the ADD AX/EAX, IMM16/IMM32 instruction. This instruction has operation code 0x05. In protected mode code, the CPU will interpret this as an ADD EAX, IMM32 instruction by default. However we can override the default behavior and copy a 16 bit immediate value by using an operand override prefix. We do this in assembly language like this: add eax, 5 ; MOV EAX, IMM32 add ax, 5 ; MOV AX, IMM16 The first instruction will assemble to: 0x05 0x05 0x00 0x00 0x00 The second instruction will assemble to: 0x66 0x05 0x05 0x00 Notice the only differences between these two instructions are the following: (1) The first instruction uses a 32 bit immediate value and the second instruction uses a 16 bit immediate value (these are bolded ), and (2) the second instruction uses the operand override prefix (this is neither bolded nor italicized). This tells the CPU to use the 16 bit operand form. For completeness, the values that are bolded nor italicized are the operation codes. Address size override The address size override prefix byte is very similar to the operand override prefix byte. Assemblers allow programmers to be able to select between address sizes by using keywords such as byte ptr and dword ptr . Due to the function being very similar to the operand override prefix, we will omit describing its purpose because it is the same but applies to address modes. |Operation mode|CS.d|REX.w|Native|Address override| |Real mode|||16 bit|16 bit| |V8086 mode|||16 bit|16 bit| |Protected mode|0||16 bit|32 bit| |Protected mode|1||32 bit|16 bit| |Long mode||0|64 bit|32 bit| |Long mode||1|64 bit|32 bit| For example, the instruction mov eax, [0xa000] when assembled in protected mode would not need an address size override. The assembler would treat 0xa000 as a 32 bit displacement. However, if we used mov ax, word [0xa000] the assembler would add an address size override prefix to the instruction to select the 16 bit address form. REX prefix The REX prefix enables certain 64 bit specific features. It has the following format: | 0 | 1 | 0 | 0 | w | r | x | b | +---+---+---+---+---+---+---+---+ 7 0 REX.w Operand size. 0: Default, 1: 64 bit REX.r ModRM.reg extension REX.x SIB.index extension REX.b ModRM.rm extension Prefix Order The order of the prefix bytes when used in conjunction with other prefix bytes does not matter. For example, you can use 0xF3 0x2E in the machine code to select REP and CS override. You can also use 0x2E 0xF3 to do the same thing. Operation code field The operation code field can be 1-3 bytes in length. All operation codes are unique; they identify the instruction to use and its operands. For example, the operation code 0 identifies the ADD REG/MEM8, REG8 instruction. The operation code 1 identifies an ADD REG/MEM16/MEM32, REG16/REG32 instruction. The IA32 and IA64 CPU manuals outline each instruction and their respective operation code. Primary Opcode The primary opcode is a single byte that is required in all instructions. It is the base of the operation code fields used to identify the instruction. The primary opcode can also take on one of the following formats depending on instruction. | | | | | | d | s | w | +---+---+---+---+---+----+---+---+ 7 0 | | | | | tttn | +---+---+---+---+---+----+---+---+ 7 0 | | | | | | register ID| +---+---+---+---+---+----+---+---+ 7 0 | | | | | | | mf | +---+---+---+---+---+----+---+---+ 7 0 PO.w Operand size PO.s Sign extend PO.d Direction PO.tttn Used on some FPU instructions PO.mf Memory format Secondary OPCode When the primary opcode byte is 0xf0, another byte follows called the secondary opcode byte. The secondary opcode then identifies different instructions and has the same functionality as above. These should be treated as two byte opcodes. OPCode extension Certain families of instructions has the same opcode but differ only by a special field called an opcode extension. This is a 3 bit extension that is stored in the Mod R/M.reg field. The Mod R/M byte will be explained in more detail in the next section. Multi-byte OPCodes The primary opcode field can be 1-3 bytes in length. Although most instructions only use 1 byte of the primary opcode field, there are some that can utilize all 3 bytes. All of these instructions also uses a secondary opcode byte (0xf0). Mod R/M field The Mod R/M (Register/Memory) field is used by instructions that require memory or register operands. The Mod R/M field has the following format. | mod | reg | rm | +---+---+---+---+---+---+---+---+ 7 0 The Mod R/M field is slightly different depending on if the CPU is running in real, protected or long modes. Real mode: ModRM.mod 00: [Memory] 01: [Memory+DISP8] 10: [Memory+DISP16] 11: Register ModRM.reg Register code ModRM.rm If ModRM.mod = 11: register code 000: [BX+SI] 001: [BX+DI] 010: [BP+SI] 011: [BP+DI] 100: [SI] 101: [DI] 110: [BP] or [DISP16] when ModRM.mod=0 111: [BX] Protected and Long modes: ModRM.mod 00: [Memory] 01: [Memory+DISP8] 10: [Memory+DISP32] 11: Register ModRM.reg Register code ModRM.rm If ModRM.mod = 11: register code REX.b=0 REX.b=1 000: [RAX] 000: [R8] 001: [RCX] 001: [R9] 010: [RDX] 010: [R10] 011: [RBX] 011: [R11] 100: [SIB] 100: [SIB] 101: [RBP][DISP32] 101: [DISP32] 110: [RSI] 110: [R14] 111: [RDI] 111: [R15] The ModRM.mod field is combined with Mod.rm field to determine the addressing mode. For example, the instruction mov ax, [0xa000] would use (in real mode) ModRM.mod = 0 (Memory) and ModRM.rm = 6 (DISP16). ModRM.reg would contain the register code for AX. If we are to use mov ax, [bx+0xa000] instead, ModRM would be 2 (Memory+DISP16) and ModRM.rm would be 7. Assemblers would treat 0xa000 here as a DISP16 rather then a DISP8 due to 0xa000 being a word size displacement. We can select the DISP8 form by using an address size override prefix. Looking at the above tables we can deduce that there is not many registers can be used for indirect addressing. For example, [BP] is not a valid addressing mode, but assemblers can assemble this fine in instructions like mov ax, [bp] . A common trick used by these assemblers is to set ModRM.mod = 1 (Memory+DISP8) and ModRM.rm = 6 (BP). In other words, the assemblers translate this into a [BP+DISP8] addressing mode, setting the displacement to 0. So mov ax, [bp] is assembled into mov ax, [bp+0] . Protected and long modes introduce another addressing mode, [SIB] which gives more capabilities. SIB addressing modes can be combined with ModRM.rm modes. For example, in protected mode, mov eax, [ebx+edi*2+0xa000] would be translated to ModRM.mod = 2 (Memory+DISP32) and ModRM.rm = 4 (SIB byte). The SIB byte tells us how to extract the edx+edi*2 in this instruction so will be explained in the next section. Certain instructions utilize an extended opcode field. Extended opcodes are identifiers that are used with the primary opcode when identifying instructions. This is a 3 bit field and is stored in Mod R/M.reg field for these instructions. Instructions that use an extended opcode field might still use ModRM.rm and ModRM.mod to store a register operand or memory addressing mode. SIB field The Scale Index Base (SIB) byte follows a Mod R/M byte only if Mod R/M.rm = 4 and the CPU is in protected or long modes . The byte provides additional addressing modes to the IA32 and IA64 architectures. SIB addressing is combined with Mod R/M addressing in order to create a wide array of additional addressing modes. SIB.Scale 00: Factor 1 01: Factor 2 10: Factor 4 11: Factor 8 SIB.Index Uses standard register codes If VSIB, uses VR register codes If REX.x = 1, uses 64 bit register codes If REX.x = 1 and VSIB, uses VR register codes SIB.Base Uses standard register codes If REX.b=1, uses 64 bit register codes Despite the names of the register fields in the SIB byte, you can technically use any register code. For example, you can put an index register in SIB.Base. Lets combine the SIB byte with Mod R/M again to demonstrate how they work together. Using our previous example, mov eax, [ebx+edi*2+0xa000] . We assume the CPU is running in protected mode for this example. EAX is the non-memory register, so that will be in Mod R/M.reg. We also have to set Mod R/M.mod = 2 to enable [Memory+DISP32] and Mod R/M.rm = 4 [SIB byte]. ebx is our base register, edi is our index register. The register code for EBX is 3 and the register code for EDI is 7. Using this, we can set SIB.index = 7 and SIB.base = 3. The scale factor, 2 goes into SIB.scale. Putting this together, we have a Mod R/M byte of 10 000 100 binary and an SIB byte of 10 111 011 binary. Knowing we have a 32 bit displacement of 0xa000 and the operation code being 0x89 , we can translate our example instruction into: 0x89 0x84 0xbb 0x00 0xa0 0x00 0x00 where 0x89 is opcode; 0x84 0xbb are the Mod R/M and SIB bytes and 0x00 0xa0 0x00 0x00 is the displacement field. This would be the correct translation of mov eax, [ebx+edi*2+0xa000] . Note that this follows the exact format of an instruction: first is the primary opcode, next is the Mod R/M byte, next is the SIB byte, and the displacement byte follows. If the displacement byte in the above instruction looks odd, please consider that the IA32 and IA64 architectures are little endian. Displacement field The displacement field is only valid if Mod R/M.mod is mode 1 (Memory+DISP8) or mode 2 (Memory+DISP16 or Memory+DISP32). The displacement can be a byte, word or dword value and is used in conjunction with the Mod R/M and SIB bytes to add displacements to addressing modes. The displacement field always follows the Mod R/M or SIB byte. Immediate field The immediate field is only valid if the instruction requires it as an operand. Instructions might require an 8, 16, or 32 bit immediate value. This field must then be present as the last field in the instruction. Instructions that allow both 16 and 32 bit values depend on if an operand override size prefix is present to determine the size of this field. Instruction tables An instruction look-up table is utilized by certain software to help facilitate the machine language translation of instructions. The tables reflect that of a generic instruction table that provides all of the operational codes and operand types for all of the instructions. We can use a resource, such as the IA32 manuals or an online reference, to construct the tables or to help with building machine instructions. The design of these tables varies considerably; it is important to read the documentation on how to read these look-up tables. The tables would present an instruction in a form similar to the following. | 0x10 | ADC | R/MEM8 | R8 | +------+-----+--------+----+ This represents an ADC instruction whose operation code is 0x10. The R/MEM8 is the first operand, and R8 is the second operand. Operands can be represented in different ways depending on the tables' design. The table may also present additional information such as effected flags the instruction sets, what form of the opcode byte the instruction might use (such as if it stores a register ID in the opcode field), supported processors, and so on. These tables can get really large in size but they all provide the same basic information typically presented in the above form. R/MEM8 in the above means that the first operand is a â€œregisterâ€ or â€œ8 bit memory locationâ€. The â€œR8â€ means the second operand is an 8 bit register. If an instruction has a memory operand, then a Mod R/M (and possibly an SIB byte) must follow . Also, if an instruction takes two register operands, a Mod R/M byte must follow . The Mod R/M byte will store the memory addressing mode information or both register codes in Mod R/M.rm and Mod R/M.reg. The CPU will know the register code is for an 8 bit register because of the opcode. The opcode tells the CPU not only what instruction to execute, but also what operands the instruction requires . An instruction may utilize different types of operands, because of this the same instruction can occupy multiple opcodes. For example, the above instruction form uses opcode 0x10. Other forms include but are not limited to the following. | 0x11 | ADC | R/MEM16/MEM32 | R16/REG32 | +------+-----+---------------+---------------+ | 0x12 | ADC | R8 | R/REG16/REG32 | +------+-----+---------------+---------------+ | 0x13 | ADC | R16/REG32 | R/MEM16/MEM32 | +------+-----+---------------+---------------+ If an instruction uses an operand like REG16/REG32 , you need to deduce the operand to use based on if an operand size override prefix is present and the current CPU operation mode (that is, if it is running in protected mode, real mode, long mode, and so on). For example, if the instruction is an ADC ax, word ptr [0] and we are running this in protected mode (or, in assembly language terminology, we used bits32 or use32 directives), we can use opcode 0x13 for the instruction. We know this instruction takes the form ADC REG16, MEM16/MEM32 . AX is the first operand, which is a 16 bit register (REG16). But what is [0]? In order to find out, we take into consideration that there is no address size override and that we are in protected mode. Due to there being no address size override we are to use the native size, which is 32 bit memory addressing. (Please see the section on the address size override prefix for more information.) Using this, we conclude that we select the ADC REG16, MEM32 form. (If an address size override did exist, we would select the ADC REG16, MEM16 form). If an instruction only has a single register operand, verify if the operand is stored in the OPCode.reg field. (Please see the Operational code section for more information.) Some instructions do this to save space, this is what allows single byte instructions . Some instructions might utilize two registers for operands storing them in OPCode.reg and Mod R/M.reg or Mod R/M.rm. To complete this example, we note the following: OPCode 0x13, AX register code (0), Addressing mode is [Memory] with a displacement of 0. Due to is being in protected mode, we use the 32 bit Mod R/M form. Mod R/M.reg = 0 (selecting AX), Mod R/M.rm = 5 (DISP32) and Mod R/M.mod = 0 ([MEMORY]). This creates a Mod R/M value of 00 000 101 binary . Due to us not using a [SIB] mode, we do not need to use an SIB byte. (For an example that does use the SIB, please see our previous example for disassembling mov eax, [ebx+edi*2+0xa000] ). Using this information, we can build the machine code. 0x66 0x13 0x05 0x00 0x00 0x00 0x00 where 0x13 is the opcode, 0x05 is the Mod R/M byte and 0x66 is an operand size override prefix The displacement byte is a DISP32 (due to Mod R/M.rm) so must be a dword. This is identified as 0x00 0x00 0x00 0x00 . We use an operand override size prefix in order to select the REG16 and MEM16 form rather then the REG32 and MEM32 form. If we omit the prefix, we will get the following instead. 0x13 0x05 0x00 0x00 0x00 0x00 In protected mode, this is an adc eax, dword ptr [0] instruction which was not what we wanted. Please see the operand size override prefix section for more information. If we wanted to turn ADC ax, word ptr [0] into REP ADC ax, word ptr ES:[0] we can use an ES override prefix and REP prefix: 0xf3 0x26 0x66 0x13 0x05 0x00 0x00 0x00 0x00 where 0xf3 0x26 0x66 0x13 is the opcode and 0x05 is the Mod R/M byte. The order of the prefix bytes do not matter. Resources The following resources are presented for supplemental reading. Please note that we do not provide support for these resources. IA32 and IA64 instruction table - ref.x86asm.net Instruction format tables - sandpile.org IA32 and IA64 Instruction encoding - wiki.osdev.org Conclusion This chapter provided an overview of machine language programming and the instruction encoding on IA32 and IA64 architectures. A goal of this chapter is to present the material in a new way to encourage the development of debuggers and tool-chains. This chapter can also be used as a reference with an instruction table when emulating certain instructions."
  },
  "articles/About/About_BrokenThorn.html": {
    "href": "articles/About/About_BrokenThorn.html",
    "title": "About BrokenThorn Entertainment | BrokenThorn OS Dev Tutorials",
    "keywords": "About BrokenThorn Entertainment Most of the contents of this tutorial have been written by \"BrokenThorn Entertainment Co.\" about a decade ago. Click here to visit their website. To learn more about the creators of the tutorials, go here . This is the original website where the project exists. Contacts You can contact the author at: webmaster@brokenthorn.com neon6000@aol.com (preferred) You might also be able to catch the editor on #osdev in either QuakeNet or FreeNode IRC networks however it is not guaranteed. Legal The BrokenThorn OS Dev tutorials websites legal statement as of 13-July-2020: The provided material in the OS Development Series is released to the public domain. Any users of this web site are free to use any of the material described within these chapters as they wish so long as the material is not duplicated in any form that violates copyright law. The OS Development Series, and the chapters, are a work in progress. Copyright 2009 BrokenThorn Entertainment, Co."
  },
  "articles/About/About_This_Project.html": {
    "href": "articles/About/About_This_Project.html",
    "title": "About This Project | BrokenThorn OS Dev Tutorials",
    "keywords": "About This Project These are a series of tutorials and articles about computers and operating systems, which intend to demonstrate and teach operating system development from the ground up. The series focuses on a new direction in developing an operating system from scratch , whilst describing architectures and concepts that are in system-level programming , providing the most comprehensive guide in operating systems and computer systems development. This project was created by Enygmator to provide a better user interface to navigate the OS dev series created by BrokenThorn entertainment and at the same time correct any grammatical, spelling or conceptual errors in the original tutorials. Note This project in no way intends to infringe on the copyright of the series and fully attributes the original documentation/tutorial series to \"BrokenThorn entertainment Co.\". I am not the author of this series (which has been created with lots of expertise and effort by the original author). I'd like to thank the original creators for creating such a great starting point for systems developers. This is certainly the best starting point resource out there (created with a lot of effort), which I myself referred to during a \"conceptual\" project called Lantern OS which you can have a look at [here] (insert link here/coming soon) which has its own documentation (unlike this series, its documentation is not a tutorial, but is actually the software (OS) documentation). Contributions I would love to receive contributions to the tutorials, not only in terms of new, helpful content, but also in correcting errors, making things clearer with better wording, more links and references to other resources that might be helpful to the community members, along with improvements in the UI (if you are experienced in using DocFX, which is what we use to generate this website from DFM i.e. DocFX Flavoured MArkdown) and ANY OTHER THING that might be USEFUL! Click here to get to know more about contributing to the project. This project is open source and is present on github . Click here to submit feedback or log issues with the site or its content, or even if you want to suggest features or maybe hold a discussion on a topic (the contents of a page) License I created this project, but I certainly didn't write any of the documentation/tutorial series, whose contents belong to \"BrokenThorn entertainment Co.\". Thus, the actual content license belongs to them. You can view their Privacy policy here and their Terms of use here . You can read their own legal statement here . The provided Privacy policy and Terms of use links don't seem to work. Until I can confirm the legal structure to use with \"BrokenThorn entertainment Co.\", in interest of the community, I have assigned it a AGPL-3.0 license whose details you may read in the LICENSE file, or a shorter version here , which requires that whatever changes you make to this project to distribute publicly, you must share the source code which can in turn help our community make better software and learn more effectively. For more information, visit the github page of this project here"
  },
  "articles/Forums.html": {
    "href": "articles/Forums.html",
    "title": "Forums | BrokenThorn OS Dev Tutorials",
    "keywords": "Forums Until there is a better place (like the way microsoft does stuff in github or some kind of StackOverflow integration), you can visit the official forums of BrokenThorn Entertainment here ."
  },
  "index.html": {
    "href": "index.html",
    "title": "Operating Systems Development | BrokenThorn OS Dev Tutorials",
    "keywords": "Operating Systems Development Welcome! These are a series of tutorials and articles about computers and operating systems, which intend to demonstrate and teach operating system development from the ground up. The series focuses on a new direction in developing an operating system from scratch , whilst describing architectures and concepts that are in system-level programming , providing the most comprehensive guide in operating systems and computer systems development. The goal of this series is to provide the most comprehensive guide in operating systems and computer systems, while attempting to cover every bit of it (pun intended). You can get to know more about this project here . Disclaimer This website aims to provide a better user interface to navigate the OS development series created by \"BrokenThorn entertainment\" and at the same time correct any grammatical, spelling or conceptual errors in the original tutorials. Note This project in no way intends to infringe on the copyright of the series and fully attributes the original documentation/tutorial series to \"BrokenThorn entertainment Co.\". I am not the author of this series (which has been created with lots of expertise and effort by the original author). I'd like to thank the original creators for creating such a great starting point for systems developers. This is certainly the best starting point resource out there (created with a lot of effort), which I myself referred to during a \"conceptual\" project called Lantern OS which you can have a look at [here] (insert link here/coming soon) which has its own documentation (unlike this series, its documentation is not a tutorial, but is actually the software (OS) documentation). More about this website This project was created by Enygmator to provide a better user interface to navigate the OS dev series created by BrokenThorn entertainment and at the same time correct any grammatical, spelling or conceptual errors in the original tutorials. This project is therefore, open source and is present on github . Click here to view the repo. Please do visit the github project page to get to know more about this project. To submit feedback (issues and suggestions) or to contribute to this project directly, visit the project page on github."
  }
}